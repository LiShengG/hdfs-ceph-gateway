#include "protocol/namenode/hdfs_namenode_service_impl.h"

#include "common/logging.h" 
#include <string>
#include "common/types.h"              // FileId, BlockIndex, BlockId, make_block_id
#include "common/status.h"
#include "gateway_internal.pb.h"      // internal::*
#include "ClientNamenodeProtocol.pb.h"
#include "hdfs.pb.h"

// HDFS åè®®è¯·æ±‚/å“åº”
using hadoop::hdfs::GetBlockLocationsRequestProto;
using hadoop::hdfs::GetBlockLocationsResponseProto;
using hadoop::hdfs::AddBlockRequestProto;
using hadoop::hdfs::AddBlockResponseProto;

// Block ç›¸å…³
using hadoop::hdfs::LocatedBlocksProto;
using hadoop::hdfs::LocatedBlockProto;
using hadoop::hdfs::ExtendedBlockProto;

// DataNode ç›¸å…³
using hadoop::hdfs::DatanodeInfoProto;
using hadoop::hdfs::DatanodeIDProto;

// å­˜å‚¨ä¸å®‰å…¨
using hadoop::hdfs::StorageTypeProto;
using hadoop::common::TokenProto;

namespace {

inline bool is_rpc_status_ok(const ::hcg::internal::RpcStatus& st) {
    return st.code() == 0;
}

inline void split_host_port(const std::string& ep,
                            std::string& host,
                            std::uint32_t& port) {
    auto pos = ep.find(':');
    if (pos == std::string::npos) {
        host = ep;
        port = 0;
        return;
    }
    host = ep.substr(0, pos);
    port = static_cast<std::uint32_t>(std::stoul(ep.substr(pos + 1)));
}

// æŠŠ "host:port" è½¬æˆ HDFS çš„ DatanodeInfoProto
inline void fill_datanode_info(const std::string& endpoint,
    DatanodeInfoProto* dn) {
    std::string host;
    std::uint32_t port = 0; 
    split_host_port(endpoint, host, port);

    auto* id_proto = dn->mutable_id();
    id_proto->set_ipaddr(host);
    id_proto->set_hostname("node-1");
    id_proto->set_datanodeuuid("abc-098");
    id_proto->set_xferport(port);
    id_proto->set_infoport(port);
    id_proto->set_ipcport(port);

    // DatanodeIDProto optional fields
    id_proto->set_infosecureport(0);
    // ğŸ’¥ å…³é”®ä¿®å¤ï¼šæ˜¾å¼è®¾ç½® suffix å­—æ®µï¼ˆå­—æ®µ 8ï¼‰  // å³ä½¿æ˜¯ç©ºå­—ç¬¦ä¸²ï¼Œä¹Ÿè¦ç¡®ä¿å®ƒè¢«åºåˆ—åŒ–ï¼Œé¿å… Java å®¢æˆ·ç«¯è§£æå¤±è´¥ã€‚ id_proto->set_suffix(""); 

    // --- DatanodeInfoProto (optional fields) ---
    // ä¿æŒä¸å˜ï¼Œç¡®ä¿äº†å…¶ä»–å­—æ®µä¹Ÿè¢«è®¾ç½®ï¼Œé¿å… Protobuf å…¼å®¹æ€§é—®é¢˜ã€‚
    dn->set_capacity(0);
    dn->set_dfsused(0);
    dn->set_remaining(0);
    dn->set_blockpoolused(0);
    dn->set_lastupdate(0);
    dn->set_xceivercount(0);
    dn->set_location("");
    dn->set_nondfsused(0);
    dn->set_adminstate(hadoop::hdfs::DatanodeInfoProto::NORMAL);
}

} // anonymous namespace

namespace hcg {

HdfsNamenodeServiceImpl::HdfsNamenodeServiceImpl(
    std::shared_ptr<IInternalGatewayService> internal)
    : internal_(std::move(internal)) {
    log(LogLevel::DEBUG, "HdfsNamenodeServiceImpl created.");
}

void HdfsNamenodeServiceImpl::mkdirs(const hadoop::hdfs::MkdirsRequestProto& req,
                                     hadoop::hdfs::MkdirsResponseProto& rsp) {
    uint32_t mode = 0644;
    if (req.has_masked() && req.masked().has_perm()) {
        mode = req.masked().perm() & 0777; // åªä¿ç•™ä½ 9 ä½ rwxrwxrwx
    }

    auto src = req.src();
    auto createParent = req.createparent();

    internal::MkdirRequest ireq;
    ireq.set_path(src);
    ireq.set_mode(mode);
    ireq.set_parents(createParent);

    internal::MkdirResponse ires;
    internal_->MakeDir(ireq, ires);

    log(LogLevel::INFO, "HdfsNamenodeServiceImpl::mkdirs called %s.", ires.status());
    rsp.set_result(ires.status()); 
}

void HdfsNamenodeServiceImpl::getFileInfo(
    const hadoop::hdfs::GetFileInfoRequestProto& req,
    hadoop::hdfs::GetFileInfoResponseProto& rsp) {

    log(LogLevel::DEBUG,
        "HdfsNamenodeServiceImpl::getFileInfo called for path: %s",
        req.src().c_str());

    // 1) ç»„è£…å†…éƒ¨è¯·æ±‚
    internal::GetFileInfoRequest ireq;
    ireq.set_path(req.src());

    // 2) è°ƒç”¨å†…éƒ¨æœåŠ¡
    internal::GetFileInfoResponse irsp;
    internal_->GetFileInfo(ireq, irsp);

    // 3) æŒ‰ HDFS è¯­ä¹‰å¤„ç†â€œä¸å­˜åœ¨â€çš„æƒ…å†µï¼š
    //    - å¯¹ getFileInfo æ¥è¯´ï¼Œâ€œä¸å­˜åœ¨â€= è¿”å› success ä¸” fs å­—æ®µä¸º null
    //    - proto å±‚å°±æ˜¯ï¼šGetFileInfoResponseProto ä¸­ä¸è®¾ç½® fs
    if (!irsp.has_status_info()) {
        // è¿™é‡Œä¸åŒºåˆ† ENOENT å’Œå…¶å®ƒé”™è¯¯ï¼ŒStage 0 å…ˆç»Ÿä¸€è§†ä¸ºâ€œnot foundâ€ï¼Œ
        // åç»­å¦‚éœ€åŒºåˆ†ï¼Œå¯ä»¥æ£€æŸ¥ irsp.status() å†³å®šæ˜¯å¦è½¬æˆ RPC ERRORã€‚
        log(LogLevel::DEBUG,
            "HdfsNamenodeServiceImpl::getFileInfo: path '%s' not found (no status_info)",
            req.src().c_str());
        return;  // ä¸è°ƒç”¨ rsp.mutable_fs()ï¼Œè®© fs å­—æ®µç¼ºçœ
    }

    // 4) æ­£å¸¸å­˜åœ¨ï¼šå¡«å…… HdfsFileStatusProto
    const auto& status = irsp.status_info();
    auto* fs = rsp.mutable_fs();

    // æ³¨æ„ï¼šHdfsFileStatusProto.path æ˜¯â€œæœ¬åœ°åâ€ï¼ˆä¸å¸¦çˆ¶ç›®å½•ï¼‰çš„ UTF8 bytesï¼Œ
    // Stage 0 æš‚æ—¶å¯ç›´æ¥ä½¿ç”¨å®Œæ•´è·¯å¾„ï¼Œåç»­å†æŒ‰éœ€è¦è£å‰ªä¸º basenameã€‚
    fs->set_path(status.path());

    fs->set_length(status.length());
    fs->set_owner(status.owner());
    fs->set_group(status.group());
    fs->set_modification_time(status.modification_time());
    fs->set_access_time(status.access_time());

    // æƒé™ç›´æ¥ä½¿ç”¨å†…éƒ¨çš„ modeï¼ˆå‡å®šå·²æ˜¯ 16bit POSIX æƒé™ä½ï¼‰
    fs->mutable_permission()->set_perm(status.mode());

    if (status.is_dir()) {
        fs->set_filetype(::hadoop::hdfs::HdfsFileStatusProto::IS_DIR);
        // ç›®å½•çš„ length é€šå¸¸ä¸º 0ï¼ˆæˆ–å®ç°è‡ªå®šä¹‰ï¼‰ï¼Œblock ä¿¡æ¯å¯¹ç›®å½•æ„ä¹‰ä¸å¤§
        fs->set_blocksize(0);
        fs->set_block_replication(0);
    } else {
        fs->set_filetype(::hadoop::hdfs::HdfsFileStatusProto::IS_FILE);
        // ä½¿ç”¨å†…éƒ¨ meta ä¸­å¸¦å‡ºçš„ block_size / replication
        fs->set_blocksize(status.block_size());
        fs->set_block_replication(status.replication());
    }

    // TODO: å¦‚æœå†…éƒ¨å°† symlink ä¿¡æ¯ä¹Ÿæ”¾å…¥ statusï¼Œå¯åœ¨è¿™é‡Œæ‰©å±•ï¼š
    // if (status.is_symlink()) {
    //     fs->set_filetype(::hadoop::hdfs::HdfsFileStatusProto::IS_SYMLINK);
    //     fs->set_symlink(status.symlink_target());
    // }
}

void HdfsNamenodeServiceImpl::listStatus(
    const hadoop::hdfs::GetListingRequestProto& req,
    hadoop::hdfs::GetListingResponseProto& rsp) {

    log(LogLevel::DEBUG, "HdfsNamenodeServiceImpl::listStatus called for path: {}", req.src());

    internal::ListStatusRequest ireq;
    ireq.set_path(req.src());
    // TODO: internal::ListStatus æ”¯æŒ startAfter å’Œ needLocationï¼Œä¹Ÿåº”ä¼ é€’ï¼š
    // ireq.set_start_after(req.startafter());  // æ³¨æ„ç±»å‹è½¬æ¢ï¼ˆbytes -> stringï¼‰
    // ireq.set_need_location(req.needlocation());

    internal::ListStatusResponse irsp;
    internal_->ListStatus(ireq, irsp);

    auto* dirlist = rsp.mutable_dirlist(); 

    // å¡«å……æ–‡ä»¶åˆ—è¡¨
    for (const auto& entry : irsp.entries()) {
        std::cout << entry.path() << " (dir: " << entry.is_dir() << ")\n";

        auto* status = dirlist->add_partiallisting();
        if (entry.is_dir()) {
            status->set_filetype(::hadoop::hdfs::HdfsFileStatusProto::IS_DIR);
        } else {
            status->set_filetype(::hadoop::hdfs::HdfsFileStatusProto::IS_FILE);
        }

        status->set_path(entry.path());
        status->set_length(entry.length());
        status->set_owner(entry.owner());
        status->set_group(entry.group());
        status->set_modification_time(entry.modification_time());
        status->set_access_time(entry.access_time());
        status->mutable_permission()->set_perm(entry.mode());
    }

    // 5. è®¾ç½® remainingEntriesï¼ˆç¤ºä¾‹ï¼šå‡è®¾ irsp æœ‰ has_more() æˆ– remaining å­—æ®µï¼‰
    // å¦‚æœ internal::ListStatusResponse æ²¡æœ‰å‰©ä½™ä¿¡æ¯ï¼Œå¯è®¾ä¸º 0
    dirlist->set_remainingentries(0);  
}

void HdfsNamenodeServiceImpl::deletePath(
    const hadoop::hdfs::DeleteRequestProto& req,
    hadoop::hdfs::DeleteResponseProto& rsp) {
    auto src = req.src();
    auto recursive = req.recursive();

    internal::DeleteRequest ireq;
    ireq.set_path(src);
    ireq.set_recursive(recursive);

    internal::DeleteResponse ires;
    internal_->DeletePath(ireq, ires);

    log(LogLevel::INFO, "HdfsNamenodeServiceImpl::deletePath called %d", ires.status().code());
    // rsp.set_result(ires.status().code()); 
    rsp.set_result(true);
}

void HdfsNamenodeServiceImpl::create(
    const hadoop::hdfs::CreateRequestProto &req,
    hadoop::hdfs::CreateResponseProto &rsp) {
    
    rsp.Clear();

    const std::string &src = req.src();
    const std::string &client = req.clientname(); // ç›®å‰æ²¡ç”¨åˆ°ï¼Œä½†å…ˆå–å‡ºæ¥

    // ---- 1. è§£æ permission / flags / block size / replication ----
    // FsPermissionProto.perm å°±æ˜¯ UNIX mode bitsï¼ˆ16 bitï¼‰
    uint32_t mode = 0644;
    if (req.has_masked() && req.masked().has_perm()) {
        mode = req.masked().perm() & 0777; // åªä¿ç•™ä½ 9 ä½ rwxrwxrwx
    }

    uint32_t replication = req.replication(); // HDFS é‡Œæ˜¯ uint32, å®é™…åªç”¨ 16 bit
    uint64_t block_size = req.blocksize();    // æ³¨æ„ï¼šauto-complete çœ‹ä¸‹æ˜¯
                                            // blocksize() è¿˜æ˜¯ block_size()

    // createFlag æ˜¯ä½æ©ç ï¼š0x01 CREATE, 0x02 OVERWRITE, 0x04 APPEND
    uint32_t create_flag = req.createflag();
    bool overwrite = (create_flag & 0x02u) != 0;
    bool append = (create_flag & 0x04u) != 0;

    // å½“å‰é˜¶æ®µä¸æ”¯æŒ appendï¼Œç›´æ¥æ‰“æ—¥å¿—ï¼ˆä¸¥æ ¼ä¸€ç‚¹å¯ä»¥æ˜ å°„æˆ RPC å¼‚å¸¸ï¼‰
    if (append) {
        log(LogLevel::ERROR,
            "HdfsNamenodeServiceImpl::create: APPEND not supported, src=%s "
            "client=%s",
            src.c_str(), client.c_str());
        // å½“å‰é˜¶æ®µæˆ‘ä»¬ä¸èµ°å¼‚å¸¸æ ˆï¼Œä¿æŒä¸å…¶å®ƒ RPC
        // ä¸€è‡´ï¼šè¿”å›ä¸€ä¸ªâ€œç©ºå“åº”â€ï¼Œä¸Šå±‚ä¸€èˆ¬ä¼šæŠ¥é”™
        rsp.clear_fs();
        return;
    }

    bool create_parent = req.createparent();

    log(LogLevel::INFO,
        "HdfsNamenodeServiceImpl::create src=%s mode=%o repl=%u block_size=%llu "
        "overwrite=%d create_parent=%d",
        src.c_str(), mode, replication,
        static_cast<unsigned long long>(block_size), overwrite, create_parent);

    // ---- 2. ç»„è£… internal::CreateFileRequest ----
    internal::CreateFileRequest ireq;
    ireq.set_path(src);
    ireq.set_mode(mode);
    ireq.set_replication(replication);
    ireq.set_block_size(block_size);
    ireq.set_overwrite(overwrite);
    ireq.set_create_parent(create_parent);

    internal::CreateFileResponse iresp;

    // ---- 3. è°ƒç”¨å†…éƒ¨ç½‘å…³ï¼ˆCephFS é€‚é…ï¼‰ ----
    internal_->CreateFile(ireq, iresp);
    if (iresp.status_code() != 0) {
        log(LogLevel::ERROR,
            "HdfsNamenodeServiceImpl::create: CreateFile error src=%s code=%d "
            "msg=%s",
            src.c_str(), iresp.status_code(), iresp.error_message().c_str());
        rsp.clear_fs();
        return;
    }

    // ---- 4. æŠŠ internal FileStatus æ˜ å°„æˆ HdfsFileStatusProto å¡«åˆ° rsp.fs ----
    // è¿™é‡Œå‡è®¾ CreateFileResponse ä¸€å®šå¸¦å›æœ€ç»ˆçš„æ–‡ä»¶çŠ¶æ€ï¼ˆlength=0 çš„æ™®é€šæ–‡ä»¶ï¼‰
    if (!iresp.has_status()) {
        // å†…éƒ¨æ²¡å› statusï¼Œå°±æŒ‰â€œæ— è¿”å›â€å¤„ç†ï¼ˆåˆæ³•ï¼Œå¯¹åº” Hadoop é‡Œçš„
        // VOID_CREATE_RESPONSEï¼‰
        rsp.clear_fs();
        return;
    }

    const internal::FileStatusProto& ist = iresp.filestatus();
    hadoop::hdfs::HdfsFileStatusProto *fs = rsp.mutable_fs();

    fs->set_length(ist.length()); // æ–‡ä»¶é•¿åº¦ï¼Œcreate å®Œä¸º 0
    fs->set_filetype(ist.is_dir() ? hadoop::hdfs::HdfsFileStatusProto::IS_DIR
                                : hadoop::hdfs::HdfsFileStatusProto::IS_FILE);
    fs->set_block_replication(ist.replication());
    fs->set_blocksize(ist.block_size());
    fs->set_modification_time(ist.modification_time());
    fs->set_access_time(ist.access_time());

    // owner / group
    fs->set_owner(ist.owner());
    fs->set_group(ist.group());

    // permissionï¼šFsPermissionProto.perm = UNIX mode bits
    hadoop::hdfs::FsPermissionProto *perm_proto = fs->mutable_permission();
    perm_proto->set_perm(ist.mode() & 0777);

    // è·¯å¾„ï¼šHdfsFileStatusProto é‡Œ path æ˜¯ bytesï¼Œå­˜ basenameï¼ˆä¸å«çˆ¶ç›®å½•ï¼‰
    // è¿™é‡ŒæŒ‰ HDFS è¯­ä¹‰åªå­˜æœ€åä¸€æ®µåå­—ï¼š
    std::string name = src;
    if (!name.empty() && name.back() == '/') {
        name.pop_back();
    }
    auto pos = name.find_last_of('/');
        if (pos != std::string::npos) {
        name = name.substr(pos + 1);
    }
    fs->set_path(name); // æ³¨æ„ï¼šproto é‡Œæ˜¯ bytes path = 10; C++ æ˜¯ set_path(const
                        // std::string&)

    // å¯¹äº Create é˜¶æ®µï¼Œæˆ‘ä»¬å…ˆä¸è¿”å› block ä½ç½®ä¿¡æ¯ï¼ˆlocationsï¼‰ï¼ŒHDFS
    // å®¢æˆ·ç«¯åç»­ä¼šèµ° addBlock å¦‚æœå·²ç»å®ç° LocatedBlocksï¼Œå¯ä»¥åœ¨è¿™é‡Œé¢å¤–å¡«
    // fs->mutable_locations()

    log(LogLevel::DEBUG,
        "HdfsNamenodeServiceImpl::create success src=%s length=%llu rsp.fs().blocksize()=%d", src.c_str(),
        static_cast<unsigned long long>(fs->length()),
        rsp.fs().blocksize());
}

void HdfsNamenodeServiceImpl::addBlock(
    const AddBlockRequestProto& req,
    AddBlockResponseProto& rsp) {

    rsp.Clear();

    const std::string path = req.src();
    log(LogLevel::DEBUG, "HdfsNamenodeServiceImpl::addBlock src=%s", path.c_str());

    // 1) internal åˆ†é…é€»è¾‘å—
    internal::AllocateBlockRequest ireq;
    internal::AllocateBlockResponse irsp;
    ireq.set_path(path);

    internal_->AllocateBlock(ireq, irsp);
    if (!is_rpc_status_ok(irsp.status())) {
        log(LogLevel::ERROR,
            "addBlock: internal AllocateBlock failed src=%s code=%d msg=%s",
            path.c_str(),
            irsp.status().code(),
            irsp.status().message().c_str());
        // å»ºè®®ï¼šå¦‚æœå†…éƒ¨æœåŠ¡å¤±è´¥ï¼Œåº”è¯¥è¿”å›ä¸€ä¸ª RPC é”™è¯¯ç»™å®¢æˆ·ç«¯
        // ä¾‹å¦‚ï¼šthrow RpcException(irsp.status().code(), irsp.status().message());
        return;
    }

    const internal::BlockHandle& bh = irsp.block();
    const std::uint64_t file_id     = bh.file_id();
    const std::uint64_t block_index = bh.index();
    
    // NameNodeé»˜è®¤å—å¤§å° (128MB)ï¼Œç”¨äºå‘ŠçŸ¥å®¢æˆ·ç«¯è¿™ä¸ªå—çš„æœ€å¤§å®¹é‡ã€‚
    const std::uint64_t DEFAULT_HDFS_BLOCK_SIZE = 134217728; 
    const std::uint64_t block_offset = block_index * DEFAULT_HDFS_BLOCK_SIZE;

    // 2) è®¡ç®— blockId
    hcg::BlockId bid = hcg::make_block_id(file_id, block_index);

    // 3) æ„é€  LocatedBlockProto
    LocatedBlockProto* lb = rsp.mutable_block();

    // 3.1 ExtendedBlockProtoï¼ˆå¿…å¡«ï¼‰
    ExtendedBlockProto* eb = lb->mutable_b();
    eb->set_poolid(block_pool_id_);
    eb->set_blockid(static_cast<std::uint64_t>(bid));
    eb->set_generationstamp(1);
    
    // ğŸ’¥ å…³é”®ä¿®å¤ç‚¹ï¼šç›´æ¥è®¾ç½®é»˜è®¤å—å¤§å°
    // ç¡®ä¿å®¢æˆ·ç«¯çŸ¥é“è¿™ä¸ªæ–°å—çš„æœ€å¤§å®¹é‡æ˜¯ 128MBã€‚
    eb->set_numbytes(DEFAULT_HDFS_BLOCK_SIZE); 

    // 3.2 offsetï¼ˆå¿…å¡«ï¼‰
    lb->set_offset(block_offset);

    // 3.3 locsï¼šä¸€ä¸ªè™šæ‹Ÿ DN
    DatanodeInfoProto* dn = lb->add_locs();
    fill_datanode_info(datanode_endpoint_, dn);

    // æ£€æŸ¥å¹¶è®¾ç½® Datanode UUID (å…³é”®ï¼Œç¡®ä¿ä¸ä¼šå› ä¸º null å¯¼è‡´å®¢æˆ·ç«¯å†…éƒ¨ NPE)
    if (dn->has_id() && dn->mutable_id()->datanodeuuid().empty()) {
        dn->mutable_id()->set_datanodeuuid("gw-dn-uuid-0");
    }

    // 3.4 corruptï¼ˆå¿…å¡«ï¼‰
    lb->set_corrupt(false);

    // 3.5 blockTokenï¼ˆå¿…å¡«ï¼Œå³ä½¿æ˜¯ç©º Tokenï¼‰
    TokenProto* tok = lb->mutable_blocktoken();
    tok->set_identifier("");
    tok->set_password("");
    tok->set_kind("");
    tok->set_service("");

    // 3.6 isCachedï¼šä¸ locs å¯¹é½
    lb->add_iscached(false);

    // 3.7 storageTypesï¼šä¸ locs å¯¹é½
    lb->add_storagetypes(StorageTypeProto::DISK);

    // 3.8 storageIDsï¼šä¸ locs å¯¹é½ï¼ˆå¿…é¡»ï¼ï¼‰
    const std::string storage_id = "gw-storage-0";
    lb->add_storageids(storage_id);

   log(LogLevel::DEBUG,
        "addBlock: locs=%d storageTypes=%d storageIDs=%d storageID[0]=%s "
        "dn(ip=%s xfer=%d info=%d ipc=%d uuid=%s)",
        lb->locs_size(),
        lb->storagetypes_size(),
        lb->storageids_size(),
        storage_id.c_str(),
        dn->mutable_id()->ipaddr().c_str(),
        dn->mutable_id()->xferport(),
        dn->mutable_id()->infoport(),
        dn->mutable_id()->ipcport(),
        dn->mutable_id()->datanodeuuid().c_str());
}

void HdfsNamenodeServiceImpl::getBlockLocation(
    const GetBlockLocationsRequestProto& req,
    GetBlockLocationsResponseProto& rsp) {
    const std::string path      = req.src();
    const std::uint64_t offset  = req.offset();
    const std::uint64_t length  = req.length();

    log(LogLevel::DEBUG,
        "HdfsNamenodeServiceImpl::getBlockLocation src=%s offset=%lu length=%lu",
        path.c_str(),
        static_cast<unsigned long>(offset),
        static_cast<unsigned long>(length));

    // 1. è½¬æˆ internal::GetBlockLocations è¯·æ±‚
    internal::GetBlockLocationsRequest ireq;
    internal::GetBlockLocationsResponse irsp;

    ireq.set_path(path);
    ireq.set_offset(offset);
    ireq.set_length(length);

    internal_->GetBlockLocations(ireq, irsp);

    // 2. æ£€æŸ¥ internal status
    if (!is_rpc_status_ok(irsp.status())) {
        log(LogLevel::ERROR,
            "getBlockLocation: internal GetBlockLocations failed src=%s code=%d msg=%s",
            path.c_str(),
            irsp.status().code(),
            irsp.status().message().c_str());

        // æœ€ç®€å•çš„å¤„ç†ï¼šä¸è®¾ç½® locationsï¼Œå®¢æˆ·ç«¯ä¼šå¾—åˆ° nullï¼Œç­‰ä»·äº "æ²¡æœ‰å—/æ–‡ä»¶ä¸å­˜åœ¨"
        return;
    }

    // 3. æ„é€  LocatedBlocksProtoï¼ˆGetBlockLocationsResponse.locationsï¼‰
    LocatedBlocksProto* lbs = rsp.mutable_locations();
    std::uint64_t file_len = 0;
    file_len = irsp.file_length();
    lbs->set_filelength(file_len);

    // underConstructionï¼ˆå¿…å¡«ï¼‰ï¼šStage 2 ç»Ÿä¸€å½“æˆå·²å®Œæˆæ–‡ä»¶
    lbs->set_underconstruction(false);

    // isLastBlockCompleteï¼ˆå¿…å¡«ï¼‰ï¼šå·²å®Œæˆæ–‡ä»¶ç»Ÿä¸€å¡« true
    lbs->set_islastblockcomplete(true);

    // lastBlock / fileEncryptionInfo / ecPolicy æš‚ä¸å¡«

    // 4. æŠŠ internal::BlockLocationProto -> LocatedBlockProto
    for (int i = 0; i < irsp.blocks_size(); ++i) {
        const internal::BlockLocationProto& bloc = irsp.blocks(i);
        const internal::BlockHandle& bh          = bloc.block();

        const std::uint64_t file_id     = bh.file_id();
        const std::uint64_t block_index = bh.index();
        const std::uint64_t blk_offset  = bloc.offset();
        const std::uint64_t blk_length  = bloc.length();

        // è®¡ç®—é€»è¾‘ BlockIdï¼ˆHDFS è§†è§’ï¼‰
        hcg::BlockId bid = hcg::make_block_id(file_id, block_index);

        LocatedBlockProto* lb = lbs->add_blocks();

        // 4.1 ExtendedBlockProtoï¼ˆå¿…å¡«ï¼‰
        ExtendedBlockProto* eb = lb->mutable_b();
        eb->set_poolid(block_pool_id_);                     // ä¾‹å¦‚ "BP-1"
        eb->set_blockid(static_cast<std::uint64_t>(bid));
        eb->set_generationstamp(1);                         // Stage 2 ç®€åŒ–ï¼šç»Ÿä¸€å†™ 1
        eb->set_numbytes(blk_length);                       // å½“å‰å—æœ‰æ•ˆé•¿åº¦

        // 4.2 offsetï¼ˆå¿…å¡«ï¼‰ï¼šå—åœ¨æ•´ä¸ªæ–‡ä»¶ä¸­çš„èµ·å§‹åç§»
        lb->set_offset(blk_offset);

        // 4.3 locs + isCached + storageTypes
        //
        // æœ€å°å¡«å……ç­–ç•¥ï¼š
        //   - locs è‡³å°‘æœ‰ä¸€ä¸ª DatanodeInfoProto
        //   - isCached ä¸ locs æ•°é‡å¯¹é½ï¼Œæ¯ä¸ª false
        //   - storageTypes ä¸ locs æ•°é‡å¯¹é½ï¼Œæ¯ä¸ª DISK
        for (int j = 0; j < bloc.datanodes_size(); ++j) {
            const std::string& ep = bloc.datanodes(j);

            DatanodeInfoProto* dn = lb->add_locs();
            fill_datanode_info(ep, dn);  // ä½¿ç”¨å’Œ addBlock ç›¸åŒçš„ helper

            // isCachedï¼šå¯¹åº”è¿™ä¸ª location ä¸æ˜¯ cache
            lb->add_iscached(false);

            // storageTypeï¼šå…ˆç®€å•è®¤ä¸ºéƒ½æ˜¯ç£ç›˜
            lb->add_storagetypes(StorageTypeProto::DISK);
        }

        // 4.4 corruptï¼ˆå¿…å¡«ï¼‰ï¼šStage 2 ä¸åšåå—æ£€æµ‹ï¼Œç»Ÿä¸€è®¤ä¸º false
        lb->set_corrupt(false);

        // 4.5 blockTokenï¼ˆå¿…å¡«ï¼‰ï¼šæœªå¯ç”¨å®‰å…¨ï¼Œç»™ä¸€ä¸ªâ€œç©º tokenâ€å³å¯
        TokenProto* tok = lb->mutable_blocktoken();
        tok->set_identifier("");   // ç©º bytes
        tok->set_password("");     // ç©º bytes
        tok->set_kind("");         // æˆ– "HDFS_BLOCK_TOKEN"ï¼Œç›®å‰æ²¡ç”¨
        tok->set_service("");      // å…ˆç•™ç©º

        if (lb->locs_size() > 0) {
            // å‡è®¾æ‚¨çš„ DataNode åªæœ‰ä¸€ä¸ªå­˜å‚¨ï¼ˆä¾‹å¦‚ /data/disk1ï¼‰
            // æ‚¨å¯ä»¥ä¸ºè¿™ä¸ªè™šæ‹Ÿ DataNode ç”Ÿæˆä¸€ä¸ªå›ºå®šçš„ã€å…¨å±€å”¯ä¸€çš„ Storage ID
            const std::string VIRTUAL_STORAGE_ID = "DS-3687e834-31e0-4965-8b89-a29d9196b01b";
            
            lb->add_storageids(VIRTUAL_STORAGE_ID); // æ·»åŠ  1 ä¸ªå…ƒç´ 
        }
        // 4.6 / blockIndices / blockTokens
        // è¿™äº›ä¸»è¦ç”¨äºå¤šä»‹è´¨/EC çš„åœºæ™¯ï¼Œæ­¤å¤„æŒ‰æœ€å°ç­–ç•¥ä¿æŒç©ºå³å¯ï¼š
        // - blockIndices ä¸å¡«
        // - blockTokens ä¸å¡«
    }
}

void HdfsNamenodeServiceImpl::complete(
    const hadoop::hdfs::CompleteRequestProto& req,
    hadoop::hdfs::CompleteResponseProto& rsp) {
    // TODO: å®ç° complete åŠŸèƒ½ï¼ˆå…³é—­æ–‡ä»¶å†™å…¥ï¼‰
    log(LogLevel::DEBUG, "HdfsNamenodeServiceImpl::complete called (stub).");
    rsp.set_result(true); 
}

void HdfsNamenodeServiceImpl::getServerDefaults(
    const hadoop::hdfs::GetServerDefaultsRequestProto& req,
    hadoop::hdfs::GetServerDefaultsResponseProto& rsp) {

    auto* d = rsp.mutable_serverdefaults();

    // Required fields (ä¸ä¹‹å‰ç›¸åŒ)
    d->set_blocksize(134217728); 
    d->set_replication(1);
    d->set_bytesperchecksum(512); 
    d->set_writepacketsize(65536); 
    d->set_filebuffersize(4096);

    // Optional fields: å¿…é¡»è®¾ç½®æˆ–æ˜ç¡®å…¶é»˜è®¤å€¼
    d->set_encryptdatatransfer(false);
    d->set_trashinterval(0);
    d->set_checksumtype(hadoop::hdfs::ChecksumTypeProto::CHECKSUM_CRC32C);
    
    // *** å…³é”®ä¿®å¤ 1ï¼šè®¾ç½® keyProviderUri (å­—ç¬¦ä¸²ç±»å‹) ***
    // å³ä½¿æ²¡æœ‰å¯ç”¨ KMS/åŠ å¯†ï¼Œä¹Ÿå¿…é¡»è®¾ç½®ä¸ºä¸€ä¸ªç©ºå­—ç¬¦ä¸² "" è€Œä¸æ˜¯ä¿æŒæœªè®¾ç½®çŠ¶æ€ã€‚
    // è¿™ç¡®ä¿ Java å®¢æˆ·ç«¯æ”¶åˆ°ä¸€ä¸ªé null çš„å­—ç¬¦ä¸²å¯¹è±¡ã€‚
    d->set_keyprovideruri(""); 
    
    // *** å…³é”®ä¿®å¤ 2ï¼šè®¾ç½® policyId (æ•´å‹) ***
    // è™½ç„¶å®šä¹‰ä¸­æœ‰ default = 0ï¼Œä½†æ˜¾å¼è®¾ç½®æ›´å®‰å…¨ã€‚
    d->set_policyid(0); 
}

void HdfsNamenodeServiceImpl::getFsStatus(
    const hadoop::hdfs::GetFsStatusRequestProto& req,
    hadoop::hdfs::GetFsStatsResponseProto& rsp) {
    // TODO: å®ç° getFsStatus åŠŸèƒ½ï¼ˆè·å–æ–‡ä»¶ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯ï¼‰
    // 1. è°ƒç”¨ internal_->getFsStats(...) è·å–å®¹é‡ã€å·²ç”¨ã€å‰©ä½™ç©ºé—´ç­‰
    // 2. å¡«å……åˆ° rsp
    log(LogLevel::DEBUG, "HdfsNamenodeServiceImpl::getFsStatus called (stub).");
    // rsp.set_capacity(0);
    // rsp.set_used(0);
    // rsp.set_remaining(0);
    // rsp.set_under_replicated(0);
    // rsp.set_corrupt_blocks(0);
    // rsp.set_missing_blocks(0);
}

void HdfsNamenodeServiceImpl::rename(
    const hadoop::hdfs::RenameRequestProto& req,
    hadoop::hdfs::RenameResponseProto& rsp) {
    log(LogLevel::INFO, "HdfsNamenodeServiceImpl::rename src=%s dst=%s",
        req.src().c_str(), req.dst().c_str());

    Status st = internal_->Rename(req.src(), req.dst());
    rsp.set_result(st == Status::OK());
}

void HdfsNamenodeServiceImpl::abandonBlock(const hadoop::hdfs::AbandonBlockRequestProto& req,
                                           hadoop::hdfs::AbandonBlockResponseProto& rsp) {
  const auto& b = req.b();
  const std::string& src = req.src();

    log(LogLevel::INFO, "abandonBlock src=%s blk=%lu gen=%lu",
      src.c_str(), b.blockid(), b.generationstamp());

//   internal_->abandonBlock(src, b.blockid(), b.generationstamp()); // ä½ è‡ªå·±å®ç°/å…ˆåšæˆ no-op ä¹Ÿè¡Œ
   (void)rsp; // response is empty but MUST be sent by RPC layer
}
} // namespace hcg