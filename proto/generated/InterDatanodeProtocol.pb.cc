// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: InterDatanodeProtocol.proto

#include "InterDatanodeProtocol.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/port.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// This is a temporary google only hack
#ifdef GOOGLE_PROTOBUF_ENFORCE_UNIQUENESS
#include "third_party/protobuf/version.h"
#endif
// @@protoc_insertion_point(includes)

namespace protobuf_HdfsServer_2eproto {
extern PROTOBUF_INTERNAL_EXPORT_protobuf_HdfsServer_2eproto ::google::protobuf::internal::SCCInfo<3> scc_info_RecoveringBlockProto;
}  // namespace protobuf_HdfsServer_2eproto
namespace protobuf_hdfs_2eproto {
extern PROTOBUF_INTERNAL_EXPORT_protobuf_hdfs_2eproto ::google::protobuf::internal::SCCInfo<0> scc_info_BlockProto;
extern PROTOBUF_INTERNAL_EXPORT_protobuf_hdfs_2eproto ::google::protobuf::internal::SCCInfo<0> scc_info_ExtendedBlockProto;
}  // namespace protobuf_hdfs_2eproto
namespace hadoop {
namespace hdfs {
class InitReplicaRecoveryRequestProtoDefaultTypeInternal {
 public:
  ::google::protobuf::internal::ExplicitlyConstructed<InitReplicaRecoveryRequestProto>
      _instance;
} _InitReplicaRecoveryRequestProto_default_instance_;
class InitReplicaRecoveryResponseProtoDefaultTypeInternal {
 public:
  ::google::protobuf::internal::ExplicitlyConstructed<InitReplicaRecoveryResponseProto>
      _instance;
} _InitReplicaRecoveryResponseProto_default_instance_;
class UpdateReplicaUnderRecoveryRequestProtoDefaultTypeInternal {
 public:
  ::google::protobuf::internal::ExplicitlyConstructed<UpdateReplicaUnderRecoveryRequestProto>
      _instance;
} _UpdateReplicaUnderRecoveryRequestProto_default_instance_;
class UpdateReplicaUnderRecoveryResponseProtoDefaultTypeInternal {
 public:
  ::google::protobuf::internal::ExplicitlyConstructed<UpdateReplicaUnderRecoveryResponseProto>
      _instance;
} _UpdateReplicaUnderRecoveryResponseProto_default_instance_;
}  // namespace hdfs
}  // namespace hadoop
namespace protobuf_InterDatanodeProtocol_2eproto {
static void InitDefaultsInitReplicaRecoveryRequestProto() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::hadoop::hdfs::_InitReplicaRecoveryRequestProto_default_instance_;
    new (ptr) ::hadoop::hdfs::InitReplicaRecoveryRequestProto();
    ::google::protobuf::internal::OnShutdownDestroyMessage(ptr);
  }
  ::hadoop::hdfs::InitReplicaRecoveryRequestProto::InitAsDefaultInstance();
}

::google::protobuf::internal::SCCInfo<1> scc_info_InitReplicaRecoveryRequestProto =
    {{ATOMIC_VAR_INIT(::google::protobuf::internal::SCCInfoBase::kUninitialized), 1, InitDefaultsInitReplicaRecoveryRequestProto}, {
      &protobuf_HdfsServer_2eproto::scc_info_RecoveringBlockProto.base,}};

static void InitDefaultsInitReplicaRecoveryResponseProto() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::hadoop::hdfs::_InitReplicaRecoveryResponseProto_default_instance_;
    new (ptr) ::hadoop::hdfs::InitReplicaRecoveryResponseProto();
    ::google::protobuf::internal::OnShutdownDestroyMessage(ptr);
  }
  ::hadoop::hdfs::InitReplicaRecoveryResponseProto::InitAsDefaultInstance();
}

::google::protobuf::internal::SCCInfo<1> scc_info_InitReplicaRecoveryResponseProto =
    {{ATOMIC_VAR_INIT(::google::protobuf::internal::SCCInfoBase::kUninitialized), 1, InitDefaultsInitReplicaRecoveryResponseProto}, {
      &protobuf_hdfs_2eproto::scc_info_BlockProto.base,}};

static void InitDefaultsUpdateReplicaUnderRecoveryRequestProto() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::hadoop::hdfs::_UpdateReplicaUnderRecoveryRequestProto_default_instance_;
    new (ptr) ::hadoop::hdfs::UpdateReplicaUnderRecoveryRequestProto();
    ::google::protobuf::internal::OnShutdownDestroyMessage(ptr);
  }
  ::hadoop::hdfs::UpdateReplicaUnderRecoveryRequestProto::InitAsDefaultInstance();
}

::google::protobuf::internal::SCCInfo<1> scc_info_UpdateReplicaUnderRecoveryRequestProto =
    {{ATOMIC_VAR_INIT(::google::protobuf::internal::SCCInfoBase::kUninitialized), 1, InitDefaultsUpdateReplicaUnderRecoveryRequestProto}, {
      &protobuf_hdfs_2eproto::scc_info_ExtendedBlockProto.base,}};

static void InitDefaultsUpdateReplicaUnderRecoveryResponseProto() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::hadoop::hdfs::_UpdateReplicaUnderRecoveryResponseProto_default_instance_;
    new (ptr) ::hadoop::hdfs::UpdateReplicaUnderRecoveryResponseProto();
    ::google::protobuf::internal::OnShutdownDestroyMessage(ptr);
  }
  ::hadoop::hdfs::UpdateReplicaUnderRecoveryResponseProto::InitAsDefaultInstance();
}

::google::protobuf::internal::SCCInfo<0> scc_info_UpdateReplicaUnderRecoveryResponseProto =
    {{ATOMIC_VAR_INIT(::google::protobuf::internal::SCCInfoBase::kUninitialized), 0, InitDefaultsUpdateReplicaUnderRecoveryResponseProto}, {}};

void InitDefaults() {
  ::google::protobuf::internal::InitSCC(&scc_info_InitReplicaRecoveryRequestProto.base);
  ::google::protobuf::internal::InitSCC(&scc_info_InitReplicaRecoveryResponseProto.base);
  ::google::protobuf::internal::InitSCC(&scc_info_UpdateReplicaUnderRecoveryRequestProto.base);
  ::google::protobuf::internal::InitSCC(&scc_info_UpdateReplicaUnderRecoveryResponseProto.base);
}

::google::protobuf::Metadata file_level_metadata[4];

const ::google::protobuf::uint32 TableStruct::offsets[] GOOGLE_PROTOBUF_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::InitReplicaRecoveryRequestProto, _has_bits_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::InitReplicaRecoveryRequestProto, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::InitReplicaRecoveryRequestProto, block_),
  0,
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::InitReplicaRecoveryResponseProto, _has_bits_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::InitReplicaRecoveryResponseProto, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::InitReplicaRecoveryResponseProto, replicafound_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::InitReplicaRecoveryResponseProto, state_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::InitReplicaRecoveryResponseProto, block_),
  1,
  2,
  0,
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::UpdateReplicaUnderRecoveryRequestProto, _has_bits_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::UpdateReplicaUnderRecoveryRequestProto, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::UpdateReplicaUnderRecoveryRequestProto, block_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::UpdateReplicaUnderRecoveryRequestProto, recoveryid_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::UpdateReplicaUnderRecoveryRequestProto, newlength_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::UpdateReplicaUnderRecoveryRequestProto, newblockid_),
  0,
  1,
  2,
  3,
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::UpdateReplicaUnderRecoveryResponseProto, _has_bits_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::UpdateReplicaUnderRecoveryResponseProto, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::UpdateReplicaUnderRecoveryResponseProto, storageuuid_),
  0,
};
static const ::google::protobuf::internal::MigrationSchema schemas[] GOOGLE_PROTOBUF_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
  { 0, 6, sizeof(::hadoop::hdfs::InitReplicaRecoveryRequestProto)},
  { 7, 15, sizeof(::hadoop::hdfs::InitReplicaRecoveryResponseProto)},
  { 18, 27, sizeof(::hadoop::hdfs::UpdateReplicaUnderRecoveryRequestProto)},
  { 31, 37, sizeof(::hadoop::hdfs::UpdateReplicaUnderRecoveryResponseProto)},
};

static ::google::protobuf::Message const * const file_default_instances[] = {
  reinterpret_cast<const ::google::protobuf::Message*>(&::hadoop::hdfs::_InitReplicaRecoveryRequestProto_default_instance_),
  reinterpret_cast<const ::google::protobuf::Message*>(&::hadoop::hdfs::_InitReplicaRecoveryResponseProto_default_instance_),
  reinterpret_cast<const ::google::protobuf::Message*>(&::hadoop::hdfs::_UpdateReplicaUnderRecoveryRequestProto_default_instance_),
  reinterpret_cast<const ::google::protobuf::Message*>(&::hadoop::hdfs::_UpdateReplicaUnderRecoveryResponseProto_default_instance_),
};

void protobuf_AssignDescriptors() {
  AddDescriptors();
  AssignDescriptors(
      "InterDatanodeProtocol.proto", schemas, file_default_instances, TableStruct::offsets,
      file_level_metadata, NULL, NULL);
}

void protobuf_AssignDescriptorsOnce() {
  static ::google::protobuf::internal::once_flag once;
  ::google::protobuf::internal::call_once(once, protobuf_AssignDescriptors);
}

void protobuf_RegisterTypes(const ::std::string&) GOOGLE_PROTOBUF_ATTRIBUTE_COLD;
void protobuf_RegisterTypes(const ::std::string&) {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::internal::RegisterAllTypes(file_level_metadata, 4);
}

void AddDescriptorsImpl() {
  InitDefaults();
  static const char descriptor[] GOOGLE_PROTOBUF_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
      "\n\033InterDatanodeProtocol.proto\022\013hadoop.hd"
      "fs\032\nhdfs.proto\032\020HdfsServer.proto\"S\n\037Init"
      "ReplicaRecoveryRequestProto\0220\n\005block\030\001 \002"
      "(\0132!.hadoop.hdfs.RecoveringBlockProto\"\217\001"
      "\n InitReplicaRecoveryResponseProto\022\024\n\014re"
      "plicaFound\030\001 \002(\010\022-\n\005state\030\002 \001(\0162\036.hadoop"
      ".hdfs.ReplicaStateProto\022&\n\005block\030\003 \001(\0132\027"
      ".hadoop.hdfs.BlockProto\"\226\001\n&UpdateReplic"
      "aUnderRecoveryRequestProto\022.\n\005block\030\001 \002("
      "\0132\037.hadoop.hdfs.ExtendedBlockProto\022\022\n\nre"
      "coveryId\030\002 \002(\004\022\021\n\tnewLength\030\003 \002(\004\022\025\n\nnew"
      "BlockId\030\004 \001(\004:\0010\">\n\'UpdateReplicaUnderRe"
      "coveryResponseProto\022\023\n\013storageUuid\030\001 \001(\t"
      "2\234\002\n\034InterDatanodeProtocolService\022r\n\023ini"
      "tReplicaRecovery\022,.hadoop.hdfs.InitRepli"
      "caRecoveryRequestProto\032-.hadoop.hdfs.Ini"
      "tReplicaRecoveryResponseProto\022\207\001\n\032update"
      "ReplicaUnderRecovery\0223.hadoop.hdfs.Updat"
      "eReplicaUnderRecoveryRequestProto\0324.hado"
      "op.hdfs.UpdateReplicaUnderRecoveryRespon"
      "seProtoBJ\n%org.apache.hadoop.hdfs.protoc"
      "ol.protoB\033InterDatanodeProtocolProtos\210\001\001"
      "\240\001\001"
  };
  ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
      descriptor, 883);
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
    "InterDatanodeProtocol.proto", &protobuf_RegisterTypes);
  ::protobuf_hdfs_2eproto::AddDescriptors();
  ::protobuf_HdfsServer_2eproto::AddDescriptors();
}

void AddDescriptors() {
  static ::google::protobuf::internal::once_flag once;
  ::google::protobuf::internal::call_once(once, AddDescriptorsImpl);
}
// Force AddDescriptors() to be called at dynamic initialization time.
struct StaticDescriptorInitializer {
  StaticDescriptorInitializer() {
    AddDescriptors();
  }
} static_descriptor_initializer;
}  // namespace protobuf_InterDatanodeProtocol_2eproto
namespace hadoop {
namespace hdfs {

// ===================================================================

void InitReplicaRecoveryRequestProto::InitAsDefaultInstance() {
  ::hadoop::hdfs::_InitReplicaRecoveryRequestProto_default_instance_._instance.get_mutable()->block_ = const_cast< ::hadoop::hdfs::RecoveringBlockProto*>(
      ::hadoop::hdfs::RecoveringBlockProto::internal_default_instance());
}
void InitReplicaRecoveryRequestProto::clear_block() {
  if (block_ != NULL) block_->Clear();
  clear_has_block();
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int InitReplicaRecoveryRequestProto::kBlockFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

InitReplicaRecoveryRequestProto::InitReplicaRecoveryRequestProto()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  ::google::protobuf::internal::InitSCC(
      &protobuf_InterDatanodeProtocol_2eproto::scc_info_InitReplicaRecoveryRequestProto.base);
  SharedCtor();
  // @@protoc_insertion_point(constructor:hadoop.hdfs.InitReplicaRecoveryRequestProto)
}
InitReplicaRecoveryRequestProto::InitReplicaRecoveryRequestProto(const InitReplicaRecoveryRequestProto& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      _has_bits_(from._has_bits_) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_block()) {
    block_ = new ::hadoop::hdfs::RecoveringBlockProto(*from.block_);
  } else {
    block_ = NULL;
  }
  // @@protoc_insertion_point(copy_constructor:hadoop.hdfs.InitReplicaRecoveryRequestProto)
}

void InitReplicaRecoveryRequestProto::SharedCtor() {
  block_ = NULL;
}

InitReplicaRecoveryRequestProto::~InitReplicaRecoveryRequestProto() {
  // @@protoc_insertion_point(destructor:hadoop.hdfs.InitReplicaRecoveryRequestProto)
  SharedDtor();
}

void InitReplicaRecoveryRequestProto::SharedDtor() {
  if (this != internal_default_instance()) delete block_;
}

void InitReplicaRecoveryRequestProto::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const ::google::protobuf::Descriptor* InitReplicaRecoveryRequestProto::descriptor() {
  ::protobuf_InterDatanodeProtocol_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_InterDatanodeProtocol_2eproto::file_level_metadata[kIndexInFileMessages].descriptor;
}

const InitReplicaRecoveryRequestProto& InitReplicaRecoveryRequestProto::default_instance() {
  ::google::protobuf::internal::InitSCC(&protobuf_InterDatanodeProtocol_2eproto::scc_info_InitReplicaRecoveryRequestProto.base);
  return *internal_default_instance();
}


void InitReplicaRecoveryRequestProto::Clear() {
// @@protoc_insertion_point(message_clear_start:hadoop.hdfs.InitReplicaRecoveryRequestProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    GOOGLE_DCHECK(block_ != NULL);
    block_->Clear();
  }
  _has_bits_.Clear();
  _internal_metadata_.Clear();
}

bool InitReplicaRecoveryRequestProto::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:hadoop.hdfs.InitReplicaRecoveryRequestProto)
  for (;;) {
    ::std::pair<::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // required .hadoop.hdfs.RecoveringBlockProto block = 1;
      case 1: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(10u /* 10 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_block()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:hadoop.hdfs.InitReplicaRecoveryRequestProto)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:hadoop.hdfs.InitReplicaRecoveryRequestProto)
  return false;
#undef DO_
}

void InitReplicaRecoveryRequestProto::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:hadoop.hdfs.InitReplicaRecoveryRequestProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  // required .hadoop.hdfs.RecoveringBlockProto block = 1;
  if (cached_has_bits & 0x00000001u) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->_internal_block(), output);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        _internal_metadata_.unknown_fields(), output);
  }
  // @@protoc_insertion_point(serialize_end:hadoop.hdfs.InitReplicaRecoveryRequestProto)
}

::google::protobuf::uint8* InitReplicaRecoveryRequestProto::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:hadoop.hdfs.InitReplicaRecoveryRequestProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  // required .hadoop.hdfs.RecoveringBlockProto block = 1;
  if (cached_has_bits & 0x00000001u) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        1, this->_internal_block(), deterministic, target);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields(), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:hadoop.hdfs.InitReplicaRecoveryRequestProto)
  return target;
}

size_t InitReplicaRecoveryRequestProto::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:hadoop.hdfs.InitReplicaRecoveryRequestProto)
  size_t total_size = 0;

  if (_internal_metadata_.have_unknown_fields()) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        _internal_metadata_.unknown_fields());
  }
  // required .hadoop.hdfs.RecoveringBlockProto block = 1;
  if (has_block()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *block_);
  }
  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void InitReplicaRecoveryRequestProto::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:hadoop.hdfs.InitReplicaRecoveryRequestProto)
  GOOGLE_DCHECK_NE(&from, this);
  const InitReplicaRecoveryRequestProto* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const InitReplicaRecoveryRequestProto>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:hadoop.hdfs.InitReplicaRecoveryRequestProto)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:hadoop.hdfs.InitReplicaRecoveryRequestProto)
    MergeFrom(*source);
  }
}

void InitReplicaRecoveryRequestProto::MergeFrom(const InitReplicaRecoveryRequestProto& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:hadoop.hdfs.InitReplicaRecoveryRequestProto)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  if (from.has_block()) {
    mutable_block()->::hadoop::hdfs::RecoveringBlockProto::MergeFrom(from.block());
  }
}

void InitReplicaRecoveryRequestProto::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:hadoop.hdfs.InitReplicaRecoveryRequestProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void InitReplicaRecoveryRequestProto::CopyFrom(const InitReplicaRecoveryRequestProto& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:hadoop.hdfs.InitReplicaRecoveryRequestProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool InitReplicaRecoveryRequestProto::IsInitialized() const {
  if ((_has_bits_[0] & 0x00000001) != 0x00000001) return false;
  if (has_block()) {
    if (!this->block_->IsInitialized()) return false;
  }
  return true;
}

void InitReplicaRecoveryRequestProto::Swap(InitReplicaRecoveryRequestProto* other) {
  if (other == this) return;
  InternalSwap(other);
}
void InitReplicaRecoveryRequestProto::InternalSwap(InitReplicaRecoveryRequestProto* other) {
  using std::swap;
  swap(block_, other->block_);
  swap(_has_bits_[0], other->_has_bits_[0]);
  _internal_metadata_.Swap(&other->_internal_metadata_);
}

::google::protobuf::Metadata InitReplicaRecoveryRequestProto::GetMetadata() const {
  protobuf_InterDatanodeProtocol_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_InterDatanodeProtocol_2eproto::file_level_metadata[kIndexInFileMessages];
}


// ===================================================================

void InitReplicaRecoveryResponseProto::InitAsDefaultInstance() {
  ::hadoop::hdfs::_InitReplicaRecoveryResponseProto_default_instance_._instance.get_mutable()->block_ = const_cast< ::hadoop::hdfs::BlockProto*>(
      ::hadoop::hdfs::BlockProto::internal_default_instance());
}
void InitReplicaRecoveryResponseProto::clear_block() {
  if (block_ != NULL) block_->Clear();
  clear_has_block();
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int InitReplicaRecoveryResponseProto::kReplicaFoundFieldNumber;
const int InitReplicaRecoveryResponseProto::kStateFieldNumber;
const int InitReplicaRecoveryResponseProto::kBlockFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

InitReplicaRecoveryResponseProto::InitReplicaRecoveryResponseProto()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  ::google::protobuf::internal::InitSCC(
      &protobuf_InterDatanodeProtocol_2eproto::scc_info_InitReplicaRecoveryResponseProto.base);
  SharedCtor();
  // @@protoc_insertion_point(constructor:hadoop.hdfs.InitReplicaRecoveryResponseProto)
}
InitReplicaRecoveryResponseProto::InitReplicaRecoveryResponseProto(const InitReplicaRecoveryResponseProto& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      _has_bits_(from._has_bits_) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_block()) {
    block_ = new ::hadoop::hdfs::BlockProto(*from.block_);
  } else {
    block_ = NULL;
  }
  ::memcpy(&replicafound_, &from.replicafound_,
    static_cast<size_t>(reinterpret_cast<char*>(&state_) -
    reinterpret_cast<char*>(&replicafound_)) + sizeof(state_));
  // @@protoc_insertion_point(copy_constructor:hadoop.hdfs.InitReplicaRecoveryResponseProto)
}

void InitReplicaRecoveryResponseProto::SharedCtor() {
  ::memset(&block_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&state_) -
      reinterpret_cast<char*>(&block_)) + sizeof(state_));
}

InitReplicaRecoveryResponseProto::~InitReplicaRecoveryResponseProto() {
  // @@protoc_insertion_point(destructor:hadoop.hdfs.InitReplicaRecoveryResponseProto)
  SharedDtor();
}

void InitReplicaRecoveryResponseProto::SharedDtor() {
  if (this != internal_default_instance()) delete block_;
}

void InitReplicaRecoveryResponseProto::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const ::google::protobuf::Descriptor* InitReplicaRecoveryResponseProto::descriptor() {
  ::protobuf_InterDatanodeProtocol_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_InterDatanodeProtocol_2eproto::file_level_metadata[kIndexInFileMessages].descriptor;
}

const InitReplicaRecoveryResponseProto& InitReplicaRecoveryResponseProto::default_instance() {
  ::google::protobuf::internal::InitSCC(&protobuf_InterDatanodeProtocol_2eproto::scc_info_InitReplicaRecoveryResponseProto.base);
  return *internal_default_instance();
}


void InitReplicaRecoveryResponseProto::Clear() {
// @@protoc_insertion_point(message_clear_start:hadoop.hdfs.InitReplicaRecoveryResponseProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    GOOGLE_DCHECK(block_ != NULL);
    block_->Clear();
  }
  if (cached_has_bits & 6u) {
    ::memset(&replicafound_, 0, static_cast<size_t>(
        reinterpret_cast<char*>(&state_) -
        reinterpret_cast<char*>(&replicafound_)) + sizeof(state_));
  }
  _has_bits_.Clear();
  _internal_metadata_.Clear();
}

bool InitReplicaRecoveryResponseProto::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:hadoop.hdfs.InitReplicaRecoveryResponseProto)
  for (;;) {
    ::std::pair<::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // required bool replicaFound = 1;
      case 1: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(8u /* 8 & 0xFF */)) {
          set_has_replicafound();
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &replicafound_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // optional .hadoop.hdfs.ReplicaStateProto state = 2;
      case 2: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(16u /* 16 & 0xFF */)) {
          int value;
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   int, ::google::protobuf::internal::WireFormatLite::TYPE_ENUM>(
                 input, &value)));
          if (::hadoop::hdfs::ReplicaStateProto_IsValid(value)) {
            set_state(static_cast< ::hadoop::hdfs::ReplicaStateProto >(value));
          } else {
            mutable_unknown_fields()->AddVarint(
                2, static_cast< ::google::protobuf::uint64>(value));
          }
        } else {
          goto handle_unusual;
        }
        break;
      }

      // optional .hadoop.hdfs.BlockProto block = 3;
      case 3: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(26u /* 26 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_block()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:hadoop.hdfs.InitReplicaRecoveryResponseProto)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:hadoop.hdfs.InitReplicaRecoveryResponseProto)
  return false;
#undef DO_
}

void InitReplicaRecoveryResponseProto::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:hadoop.hdfs.InitReplicaRecoveryResponseProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  // required bool replicaFound = 1;
  if (cached_has_bits & 0x00000002u) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(1, this->replicafound(), output);
  }

  // optional .hadoop.hdfs.ReplicaStateProto state = 2;
  if (cached_has_bits & 0x00000004u) {
    ::google::protobuf::internal::WireFormatLite::WriteEnum(
      2, this->state(), output);
  }

  // optional .hadoop.hdfs.BlockProto block = 3;
  if (cached_has_bits & 0x00000001u) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      3, this->_internal_block(), output);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        _internal_metadata_.unknown_fields(), output);
  }
  // @@protoc_insertion_point(serialize_end:hadoop.hdfs.InitReplicaRecoveryResponseProto)
}

::google::protobuf::uint8* InitReplicaRecoveryResponseProto::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:hadoop.hdfs.InitReplicaRecoveryResponseProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  // required bool replicaFound = 1;
  if (cached_has_bits & 0x00000002u) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(1, this->replicafound(), target);
  }

  // optional .hadoop.hdfs.ReplicaStateProto state = 2;
  if (cached_has_bits & 0x00000004u) {
    target = ::google::protobuf::internal::WireFormatLite::WriteEnumToArray(
      2, this->state(), target);
  }

  // optional .hadoop.hdfs.BlockProto block = 3;
  if (cached_has_bits & 0x00000001u) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        3, this->_internal_block(), deterministic, target);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields(), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:hadoop.hdfs.InitReplicaRecoveryResponseProto)
  return target;
}

size_t InitReplicaRecoveryResponseProto::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:hadoop.hdfs.InitReplicaRecoveryResponseProto)
  size_t total_size = 0;

  if (_internal_metadata_.have_unknown_fields()) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        _internal_metadata_.unknown_fields());
  }
  // required bool replicaFound = 1;
  if (has_replicafound()) {
    total_size += 1 + 1;
  }
  // optional .hadoop.hdfs.BlockProto block = 3;
  if (has_block()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *block_);
  }

  // optional .hadoop.hdfs.ReplicaStateProto state = 2;
  if (has_state()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::EnumSize(this->state());
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void InitReplicaRecoveryResponseProto::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:hadoop.hdfs.InitReplicaRecoveryResponseProto)
  GOOGLE_DCHECK_NE(&from, this);
  const InitReplicaRecoveryResponseProto* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const InitReplicaRecoveryResponseProto>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:hadoop.hdfs.InitReplicaRecoveryResponseProto)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:hadoop.hdfs.InitReplicaRecoveryResponseProto)
    MergeFrom(*source);
  }
}

void InitReplicaRecoveryResponseProto::MergeFrom(const InitReplicaRecoveryResponseProto& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:hadoop.hdfs.InitReplicaRecoveryResponseProto)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._has_bits_[0];
  if (cached_has_bits & 7u) {
    if (cached_has_bits & 0x00000001u) {
      mutable_block()->::hadoop::hdfs::BlockProto::MergeFrom(from.block());
    }
    if (cached_has_bits & 0x00000002u) {
      replicafound_ = from.replicafound_;
    }
    if (cached_has_bits & 0x00000004u) {
      state_ = from.state_;
    }
    _has_bits_[0] |= cached_has_bits;
  }
}

void InitReplicaRecoveryResponseProto::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:hadoop.hdfs.InitReplicaRecoveryResponseProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void InitReplicaRecoveryResponseProto::CopyFrom(const InitReplicaRecoveryResponseProto& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:hadoop.hdfs.InitReplicaRecoveryResponseProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool InitReplicaRecoveryResponseProto::IsInitialized() const {
  if ((_has_bits_[0] & 0x00000002) != 0x00000002) return false;
  if (has_block()) {
    if (!this->block_->IsInitialized()) return false;
  }
  return true;
}

void InitReplicaRecoveryResponseProto::Swap(InitReplicaRecoveryResponseProto* other) {
  if (other == this) return;
  InternalSwap(other);
}
void InitReplicaRecoveryResponseProto::InternalSwap(InitReplicaRecoveryResponseProto* other) {
  using std::swap;
  swap(block_, other->block_);
  swap(replicafound_, other->replicafound_);
  swap(state_, other->state_);
  swap(_has_bits_[0], other->_has_bits_[0]);
  _internal_metadata_.Swap(&other->_internal_metadata_);
}

::google::protobuf::Metadata InitReplicaRecoveryResponseProto::GetMetadata() const {
  protobuf_InterDatanodeProtocol_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_InterDatanodeProtocol_2eproto::file_level_metadata[kIndexInFileMessages];
}


// ===================================================================

void UpdateReplicaUnderRecoveryRequestProto::InitAsDefaultInstance() {
  ::hadoop::hdfs::_UpdateReplicaUnderRecoveryRequestProto_default_instance_._instance.get_mutable()->block_ = const_cast< ::hadoop::hdfs::ExtendedBlockProto*>(
      ::hadoop::hdfs::ExtendedBlockProto::internal_default_instance());
}
void UpdateReplicaUnderRecoveryRequestProto::clear_block() {
  if (block_ != NULL) block_->Clear();
  clear_has_block();
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int UpdateReplicaUnderRecoveryRequestProto::kBlockFieldNumber;
const int UpdateReplicaUnderRecoveryRequestProto::kRecoveryIdFieldNumber;
const int UpdateReplicaUnderRecoveryRequestProto::kNewLengthFieldNumber;
const int UpdateReplicaUnderRecoveryRequestProto::kNewBlockIdFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

UpdateReplicaUnderRecoveryRequestProto::UpdateReplicaUnderRecoveryRequestProto()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  ::google::protobuf::internal::InitSCC(
      &protobuf_InterDatanodeProtocol_2eproto::scc_info_UpdateReplicaUnderRecoveryRequestProto.base);
  SharedCtor();
  // @@protoc_insertion_point(constructor:hadoop.hdfs.UpdateReplicaUnderRecoveryRequestProto)
}
UpdateReplicaUnderRecoveryRequestProto::UpdateReplicaUnderRecoveryRequestProto(const UpdateReplicaUnderRecoveryRequestProto& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      _has_bits_(from._has_bits_) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_block()) {
    block_ = new ::hadoop::hdfs::ExtendedBlockProto(*from.block_);
  } else {
    block_ = NULL;
  }
  ::memcpy(&recoveryid_, &from.recoveryid_,
    static_cast<size_t>(reinterpret_cast<char*>(&newblockid_) -
    reinterpret_cast<char*>(&recoveryid_)) + sizeof(newblockid_));
  // @@protoc_insertion_point(copy_constructor:hadoop.hdfs.UpdateReplicaUnderRecoveryRequestProto)
}

void UpdateReplicaUnderRecoveryRequestProto::SharedCtor() {
  ::memset(&block_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&newblockid_) -
      reinterpret_cast<char*>(&block_)) + sizeof(newblockid_));
}

UpdateReplicaUnderRecoveryRequestProto::~UpdateReplicaUnderRecoveryRequestProto() {
  // @@protoc_insertion_point(destructor:hadoop.hdfs.UpdateReplicaUnderRecoveryRequestProto)
  SharedDtor();
}

void UpdateReplicaUnderRecoveryRequestProto::SharedDtor() {
  if (this != internal_default_instance()) delete block_;
}

void UpdateReplicaUnderRecoveryRequestProto::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const ::google::protobuf::Descriptor* UpdateReplicaUnderRecoveryRequestProto::descriptor() {
  ::protobuf_InterDatanodeProtocol_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_InterDatanodeProtocol_2eproto::file_level_metadata[kIndexInFileMessages].descriptor;
}

const UpdateReplicaUnderRecoveryRequestProto& UpdateReplicaUnderRecoveryRequestProto::default_instance() {
  ::google::protobuf::internal::InitSCC(&protobuf_InterDatanodeProtocol_2eproto::scc_info_UpdateReplicaUnderRecoveryRequestProto.base);
  return *internal_default_instance();
}


void UpdateReplicaUnderRecoveryRequestProto::Clear() {
// @@protoc_insertion_point(message_clear_start:hadoop.hdfs.UpdateReplicaUnderRecoveryRequestProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    GOOGLE_DCHECK(block_ != NULL);
    block_->Clear();
  }
  if (cached_has_bits & 14u) {
    ::memset(&recoveryid_, 0, static_cast<size_t>(
        reinterpret_cast<char*>(&newblockid_) -
        reinterpret_cast<char*>(&recoveryid_)) + sizeof(newblockid_));
  }
  _has_bits_.Clear();
  _internal_metadata_.Clear();
}

bool UpdateReplicaUnderRecoveryRequestProto::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:hadoop.hdfs.UpdateReplicaUnderRecoveryRequestProto)
  for (;;) {
    ::std::pair<::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // required .hadoop.hdfs.ExtendedBlockProto block = 1;
      case 1: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(10u /* 10 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_block()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // required uint64 recoveryId = 2;
      case 2: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(16u /* 16 & 0xFF */)) {
          set_has_recoveryid();
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::uint64, ::google::protobuf::internal::WireFormatLite::TYPE_UINT64>(
                 input, &recoveryid_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // required uint64 newLength = 3;
      case 3: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(24u /* 24 & 0xFF */)) {
          set_has_newlength();
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::uint64, ::google::protobuf::internal::WireFormatLite::TYPE_UINT64>(
                 input, &newlength_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // optional uint64 newBlockId = 4 [default = 0];
      case 4: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(32u /* 32 & 0xFF */)) {
          set_has_newblockid();
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::uint64, ::google::protobuf::internal::WireFormatLite::TYPE_UINT64>(
                 input, &newblockid_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:hadoop.hdfs.UpdateReplicaUnderRecoveryRequestProto)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:hadoop.hdfs.UpdateReplicaUnderRecoveryRequestProto)
  return false;
#undef DO_
}

void UpdateReplicaUnderRecoveryRequestProto::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:hadoop.hdfs.UpdateReplicaUnderRecoveryRequestProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  // required .hadoop.hdfs.ExtendedBlockProto block = 1;
  if (cached_has_bits & 0x00000001u) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->_internal_block(), output);
  }

  // required uint64 recoveryId = 2;
  if (cached_has_bits & 0x00000002u) {
    ::google::protobuf::internal::WireFormatLite::WriteUInt64(2, this->recoveryid(), output);
  }

  // required uint64 newLength = 3;
  if (cached_has_bits & 0x00000004u) {
    ::google::protobuf::internal::WireFormatLite::WriteUInt64(3, this->newlength(), output);
  }

  // optional uint64 newBlockId = 4 [default = 0];
  if (cached_has_bits & 0x00000008u) {
    ::google::protobuf::internal::WireFormatLite::WriteUInt64(4, this->newblockid(), output);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        _internal_metadata_.unknown_fields(), output);
  }
  // @@protoc_insertion_point(serialize_end:hadoop.hdfs.UpdateReplicaUnderRecoveryRequestProto)
}

::google::protobuf::uint8* UpdateReplicaUnderRecoveryRequestProto::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:hadoop.hdfs.UpdateReplicaUnderRecoveryRequestProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  // required .hadoop.hdfs.ExtendedBlockProto block = 1;
  if (cached_has_bits & 0x00000001u) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        1, this->_internal_block(), deterministic, target);
  }

  // required uint64 recoveryId = 2;
  if (cached_has_bits & 0x00000002u) {
    target = ::google::protobuf::internal::WireFormatLite::WriteUInt64ToArray(2, this->recoveryid(), target);
  }

  // required uint64 newLength = 3;
  if (cached_has_bits & 0x00000004u) {
    target = ::google::protobuf::internal::WireFormatLite::WriteUInt64ToArray(3, this->newlength(), target);
  }

  // optional uint64 newBlockId = 4 [default = 0];
  if (cached_has_bits & 0x00000008u) {
    target = ::google::protobuf::internal::WireFormatLite::WriteUInt64ToArray(4, this->newblockid(), target);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields(), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:hadoop.hdfs.UpdateReplicaUnderRecoveryRequestProto)
  return target;
}

size_t UpdateReplicaUnderRecoveryRequestProto::RequiredFieldsByteSizeFallback() const {
// @@protoc_insertion_point(required_fields_byte_size_fallback_start:hadoop.hdfs.UpdateReplicaUnderRecoveryRequestProto)
  size_t total_size = 0;

  if (has_block()) {
    // required .hadoop.hdfs.ExtendedBlockProto block = 1;
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *block_);
  }

  if (has_recoveryid()) {
    // required uint64 recoveryId = 2;
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::UInt64Size(
        this->recoveryid());
  }

  if (has_newlength()) {
    // required uint64 newLength = 3;
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::UInt64Size(
        this->newlength());
  }

  return total_size;
}
size_t UpdateReplicaUnderRecoveryRequestProto::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:hadoop.hdfs.UpdateReplicaUnderRecoveryRequestProto)
  size_t total_size = 0;

  if (_internal_metadata_.have_unknown_fields()) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        _internal_metadata_.unknown_fields());
  }
  if (((_has_bits_[0] & 0x00000007) ^ 0x00000007) == 0) {  // All required fields are present.
    // required .hadoop.hdfs.ExtendedBlockProto block = 1;
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *block_);

    // required uint64 recoveryId = 2;
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::UInt64Size(
        this->recoveryid());

    // required uint64 newLength = 3;
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::UInt64Size(
        this->newlength());

  } else {
    total_size += RequiredFieldsByteSizeFallback();
  }
  // optional uint64 newBlockId = 4 [default = 0];
  if (has_newblockid()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::UInt64Size(
        this->newblockid());
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void UpdateReplicaUnderRecoveryRequestProto::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:hadoop.hdfs.UpdateReplicaUnderRecoveryRequestProto)
  GOOGLE_DCHECK_NE(&from, this);
  const UpdateReplicaUnderRecoveryRequestProto* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const UpdateReplicaUnderRecoveryRequestProto>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:hadoop.hdfs.UpdateReplicaUnderRecoveryRequestProto)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:hadoop.hdfs.UpdateReplicaUnderRecoveryRequestProto)
    MergeFrom(*source);
  }
}

void UpdateReplicaUnderRecoveryRequestProto::MergeFrom(const UpdateReplicaUnderRecoveryRequestProto& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:hadoop.hdfs.UpdateReplicaUnderRecoveryRequestProto)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._has_bits_[0];
  if (cached_has_bits & 15u) {
    if (cached_has_bits & 0x00000001u) {
      mutable_block()->::hadoop::hdfs::ExtendedBlockProto::MergeFrom(from.block());
    }
    if (cached_has_bits & 0x00000002u) {
      recoveryid_ = from.recoveryid_;
    }
    if (cached_has_bits & 0x00000004u) {
      newlength_ = from.newlength_;
    }
    if (cached_has_bits & 0x00000008u) {
      newblockid_ = from.newblockid_;
    }
    _has_bits_[0] |= cached_has_bits;
  }
}

void UpdateReplicaUnderRecoveryRequestProto::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:hadoop.hdfs.UpdateReplicaUnderRecoveryRequestProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void UpdateReplicaUnderRecoveryRequestProto::CopyFrom(const UpdateReplicaUnderRecoveryRequestProto& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:hadoop.hdfs.UpdateReplicaUnderRecoveryRequestProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool UpdateReplicaUnderRecoveryRequestProto::IsInitialized() const {
  if ((_has_bits_[0] & 0x00000007) != 0x00000007) return false;
  if (has_block()) {
    if (!this->block_->IsInitialized()) return false;
  }
  return true;
}

void UpdateReplicaUnderRecoveryRequestProto::Swap(UpdateReplicaUnderRecoveryRequestProto* other) {
  if (other == this) return;
  InternalSwap(other);
}
void UpdateReplicaUnderRecoveryRequestProto::InternalSwap(UpdateReplicaUnderRecoveryRequestProto* other) {
  using std::swap;
  swap(block_, other->block_);
  swap(recoveryid_, other->recoveryid_);
  swap(newlength_, other->newlength_);
  swap(newblockid_, other->newblockid_);
  swap(_has_bits_[0], other->_has_bits_[0]);
  _internal_metadata_.Swap(&other->_internal_metadata_);
}

::google::protobuf::Metadata UpdateReplicaUnderRecoveryRequestProto::GetMetadata() const {
  protobuf_InterDatanodeProtocol_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_InterDatanodeProtocol_2eproto::file_level_metadata[kIndexInFileMessages];
}


// ===================================================================

void UpdateReplicaUnderRecoveryResponseProto::InitAsDefaultInstance() {
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int UpdateReplicaUnderRecoveryResponseProto::kStorageUuidFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

UpdateReplicaUnderRecoveryResponseProto::UpdateReplicaUnderRecoveryResponseProto()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  ::google::protobuf::internal::InitSCC(
      &protobuf_InterDatanodeProtocol_2eproto::scc_info_UpdateReplicaUnderRecoveryResponseProto.base);
  SharedCtor();
  // @@protoc_insertion_point(constructor:hadoop.hdfs.UpdateReplicaUnderRecoveryResponseProto)
}
UpdateReplicaUnderRecoveryResponseProto::UpdateReplicaUnderRecoveryResponseProto(const UpdateReplicaUnderRecoveryResponseProto& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      _has_bits_(from._has_bits_) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  storageuuid_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (from.has_storageuuid()) {
    storageuuid_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.storageuuid_);
  }
  // @@protoc_insertion_point(copy_constructor:hadoop.hdfs.UpdateReplicaUnderRecoveryResponseProto)
}

void UpdateReplicaUnderRecoveryResponseProto::SharedCtor() {
  storageuuid_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}

UpdateReplicaUnderRecoveryResponseProto::~UpdateReplicaUnderRecoveryResponseProto() {
  // @@protoc_insertion_point(destructor:hadoop.hdfs.UpdateReplicaUnderRecoveryResponseProto)
  SharedDtor();
}

void UpdateReplicaUnderRecoveryResponseProto::SharedDtor() {
  storageuuid_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}

void UpdateReplicaUnderRecoveryResponseProto::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const ::google::protobuf::Descriptor* UpdateReplicaUnderRecoveryResponseProto::descriptor() {
  ::protobuf_InterDatanodeProtocol_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_InterDatanodeProtocol_2eproto::file_level_metadata[kIndexInFileMessages].descriptor;
}

const UpdateReplicaUnderRecoveryResponseProto& UpdateReplicaUnderRecoveryResponseProto::default_instance() {
  ::google::protobuf::internal::InitSCC(&protobuf_InterDatanodeProtocol_2eproto::scc_info_UpdateReplicaUnderRecoveryResponseProto.base);
  return *internal_default_instance();
}


void UpdateReplicaUnderRecoveryResponseProto::Clear() {
// @@protoc_insertion_point(message_clear_start:hadoop.hdfs.UpdateReplicaUnderRecoveryResponseProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    storageuuid_.ClearNonDefaultToEmptyNoArena();
  }
  _has_bits_.Clear();
  _internal_metadata_.Clear();
}

bool UpdateReplicaUnderRecoveryResponseProto::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:hadoop.hdfs.UpdateReplicaUnderRecoveryResponseProto)
  for (;;) {
    ::std::pair<::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional string storageUuid = 1;
      case 1: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(10u /* 10 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_storageuuid()));
          ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
            this->storageuuid().data(), static_cast<int>(this->storageuuid().length()),
            ::google::protobuf::internal::WireFormat::PARSE,
            "hadoop.hdfs.UpdateReplicaUnderRecoveryResponseProto.storageUuid");
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:hadoop.hdfs.UpdateReplicaUnderRecoveryResponseProto)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:hadoop.hdfs.UpdateReplicaUnderRecoveryResponseProto)
  return false;
#undef DO_
}

void UpdateReplicaUnderRecoveryResponseProto::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:hadoop.hdfs.UpdateReplicaUnderRecoveryResponseProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  // optional string storageUuid = 1;
  if (cached_has_bits & 0x00000001u) {
    ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
      this->storageuuid().data(), static_cast<int>(this->storageuuid().length()),
      ::google::protobuf::internal::WireFormat::SERIALIZE,
      "hadoop.hdfs.UpdateReplicaUnderRecoveryResponseProto.storageUuid");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      1, this->storageuuid(), output);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        _internal_metadata_.unknown_fields(), output);
  }
  // @@protoc_insertion_point(serialize_end:hadoop.hdfs.UpdateReplicaUnderRecoveryResponseProto)
}

::google::protobuf::uint8* UpdateReplicaUnderRecoveryResponseProto::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:hadoop.hdfs.UpdateReplicaUnderRecoveryResponseProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  // optional string storageUuid = 1;
  if (cached_has_bits & 0x00000001u) {
    ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
      this->storageuuid().data(), static_cast<int>(this->storageuuid().length()),
      ::google::protobuf::internal::WireFormat::SERIALIZE,
      "hadoop.hdfs.UpdateReplicaUnderRecoveryResponseProto.storageUuid");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        1, this->storageuuid(), target);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields(), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:hadoop.hdfs.UpdateReplicaUnderRecoveryResponseProto)
  return target;
}

size_t UpdateReplicaUnderRecoveryResponseProto::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:hadoop.hdfs.UpdateReplicaUnderRecoveryResponseProto)
  size_t total_size = 0;

  if (_internal_metadata_.have_unknown_fields()) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        _internal_metadata_.unknown_fields());
  }
  // optional string storageUuid = 1;
  if (has_storageuuid()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->storageuuid());
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void UpdateReplicaUnderRecoveryResponseProto::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:hadoop.hdfs.UpdateReplicaUnderRecoveryResponseProto)
  GOOGLE_DCHECK_NE(&from, this);
  const UpdateReplicaUnderRecoveryResponseProto* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const UpdateReplicaUnderRecoveryResponseProto>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:hadoop.hdfs.UpdateReplicaUnderRecoveryResponseProto)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:hadoop.hdfs.UpdateReplicaUnderRecoveryResponseProto)
    MergeFrom(*source);
  }
}

void UpdateReplicaUnderRecoveryResponseProto::MergeFrom(const UpdateReplicaUnderRecoveryResponseProto& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:hadoop.hdfs.UpdateReplicaUnderRecoveryResponseProto)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  if (from.has_storageuuid()) {
    set_has_storageuuid();
    storageuuid_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.storageuuid_);
  }
}

void UpdateReplicaUnderRecoveryResponseProto::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:hadoop.hdfs.UpdateReplicaUnderRecoveryResponseProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void UpdateReplicaUnderRecoveryResponseProto::CopyFrom(const UpdateReplicaUnderRecoveryResponseProto& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:hadoop.hdfs.UpdateReplicaUnderRecoveryResponseProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool UpdateReplicaUnderRecoveryResponseProto::IsInitialized() const {
  return true;
}

void UpdateReplicaUnderRecoveryResponseProto::Swap(UpdateReplicaUnderRecoveryResponseProto* other) {
  if (other == this) return;
  InternalSwap(other);
}
void UpdateReplicaUnderRecoveryResponseProto::InternalSwap(UpdateReplicaUnderRecoveryResponseProto* other) {
  using std::swap;
  storageuuid_.Swap(&other->storageuuid_, &::google::protobuf::internal::GetEmptyStringAlreadyInited(),
    GetArenaNoVirtual());
  swap(_has_bits_[0], other->_has_bits_[0]);
  _internal_metadata_.Swap(&other->_internal_metadata_);
}

::google::protobuf::Metadata UpdateReplicaUnderRecoveryResponseProto::GetMetadata() const {
  protobuf_InterDatanodeProtocol_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_InterDatanodeProtocol_2eproto::file_level_metadata[kIndexInFileMessages];
}


// @@protoc_insertion_point(namespace_scope)
}  // namespace hdfs
}  // namespace hadoop
namespace google {
namespace protobuf {
template<> GOOGLE_PROTOBUF_ATTRIBUTE_NOINLINE ::hadoop::hdfs::InitReplicaRecoveryRequestProto* Arena::CreateMaybeMessage< ::hadoop::hdfs::InitReplicaRecoveryRequestProto >(Arena* arena) {
  return Arena::CreateInternal< ::hadoop::hdfs::InitReplicaRecoveryRequestProto >(arena);
}
template<> GOOGLE_PROTOBUF_ATTRIBUTE_NOINLINE ::hadoop::hdfs::InitReplicaRecoveryResponseProto* Arena::CreateMaybeMessage< ::hadoop::hdfs::InitReplicaRecoveryResponseProto >(Arena* arena) {
  return Arena::CreateInternal< ::hadoop::hdfs::InitReplicaRecoveryResponseProto >(arena);
}
template<> GOOGLE_PROTOBUF_ATTRIBUTE_NOINLINE ::hadoop::hdfs::UpdateReplicaUnderRecoveryRequestProto* Arena::CreateMaybeMessage< ::hadoop::hdfs::UpdateReplicaUnderRecoveryRequestProto >(Arena* arena) {
  return Arena::CreateInternal< ::hadoop::hdfs::UpdateReplicaUnderRecoveryRequestProto >(arena);
}
template<> GOOGLE_PROTOBUF_ATTRIBUTE_NOINLINE ::hadoop::hdfs::UpdateReplicaUnderRecoveryResponseProto* Arena::CreateMaybeMessage< ::hadoop::hdfs::UpdateReplicaUnderRecoveryResponseProto >(Arena* arena) {
  return Arena::CreateInternal< ::hadoop::hdfs::UpdateReplicaUnderRecoveryResponseProto >(arena);
}
}  // namespace protobuf
}  // namespace google

// @@protoc_insertion_point(global_scope)
