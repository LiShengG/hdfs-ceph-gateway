// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: JournalProtocol.proto

#ifndef PROTOBUF_INCLUDED_JournalProtocol_2eproto
#define PROTOBUF_INCLUDED_JournalProtocol_2eproto

#include <string>

#include <google/protobuf/stubs/common.h>

#if GOOGLE_PROTOBUF_VERSION < 3006001
#error This file was generated by a newer version of protoc which is
#error incompatible with your Protocol Buffer headers.  Please update
#error your headers.
#endif
#if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
#error This file was generated by an older version of protoc which is
#error incompatible with your Protocol Buffer headers.  Please
#error regenerate this file with a newer version of protoc.
#endif

#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/arena.h>
#include <google/protobuf/arenastring.h>
#include <google/protobuf/generated_message_table_driven.h>
#include <google/protobuf/generated_message_util.h>
#include <google/protobuf/inlined_string_field.h>
#include <google/protobuf/metadata.h>
#include <google/protobuf/message.h>
#include <google/protobuf/repeated_field.h>  // IWYU pragma: export
#include <google/protobuf/extension_set.h>  // IWYU pragma: export
#include <google/protobuf/unknown_field_set.h>
#include "hdfs.pb.h"
#include "HdfsServer.pb.h"
// @@protoc_insertion_point(includes)
#define PROTOBUF_INTERNAL_EXPORT_protobuf_JournalProtocol_2eproto 

namespace protobuf_JournalProtocol_2eproto {
// Internal implementation detail -- do not use these members.
struct TableStruct {
  static const ::google::protobuf::internal::ParseTableField entries[];
  static const ::google::protobuf::internal::AuxillaryParseTableField aux[];
  static const ::google::protobuf::internal::ParseTable schema[7];
  static const ::google::protobuf::internal::FieldMetadata field_metadata[];
  static const ::google::protobuf::internal::SerializationTable serialization_table[];
  static const ::google::protobuf::uint32 offsets[];
};
void AddDescriptors();
}  // namespace protobuf_JournalProtocol_2eproto
namespace hadoop {
namespace hdfs {
class FenceRequestProto;
class FenceRequestProtoDefaultTypeInternal;
extern FenceRequestProtoDefaultTypeInternal _FenceRequestProto_default_instance_;
class FenceResponseProto;
class FenceResponseProtoDefaultTypeInternal;
extern FenceResponseProtoDefaultTypeInternal _FenceResponseProto_default_instance_;
class JournalInfoProto;
class JournalInfoProtoDefaultTypeInternal;
extern JournalInfoProtoDefaultTypeInternal _JournalInfoProto_default_instance_;
class JournalRequestProto;
class JournalRequestProtoDefaultTypeInternal;
extern JournalRequestProtoDefaultTypeInternal _JournalRequestProto_default_instance_;
class JournalResponseProto;
class JournalResponseProtoDefaultTypeInternal;
extern JournalResponseProtoDefaultTypeInternal _JournalResponseProto_default_instance_;
class StartLogSegmentRequestProto;
class StartLogSegmentRequestProtoDefaultTypeInternal;
extern StartLogSegmentRequestProtoDefaultTypeInternal _StartLogSegmentRequestProto_default_instance_;
class StartLogSegmentResponseProto;
class StartLogSegmentResponseProtoDefaultTypeInternal;
extern StartLogSegmentResponseProtoDefaultTypeInternal _StartLogSegmentResponseProto_default_instance_;
}  // namespace hdfs
}  // namespace hadoop
namespace google {
namespace protobuf {
template<> ::hadoop::hdfs::FenceRequestProto* Arena::CreateMaybeMessage<::hadoop::hdfs::FenceRequestProto>(Arena*);
template<> ::hadoop::hdfs::FenceResponseProto* Arena::CreateMaybeMessage<::hadoop::hdfs::FenceResponseProto>(Arena*);
template<> ::hadoop::hdfs::JournalInfoProto* Arena::CreateMaybeMessage<::hadoop::hdfs::JournalInfoProto>(Arena*);
template<> ::hadoop::hdfs::JournalRequestProto* Arena::CreateMaybeMessage<::hadoop::hdfs::JournalRequestProto>(Arena*);
template<> ::hadoop::hdfs::JournalResponseProto* Arena::CreateMaybeMessage<::hadoop::hdfs::JournalResponseProto>(Arena*);
template<> ::hadoop::hdfs::StartLogSegmentRequestProto* Arena::CreateMaybeMessage<::hadoop::hdfs::StartLogSegmentRequestProto>(Arena*);
template<> ::hadoop::hdfs::StartLogSegmentResponseProto* Arena::CreateMaybeMessage<::hadoop::hdfs::StartLogSegmentResponseProto>(Arena*);
}  // namespace protobuf
}  // namespace google
namespace hadoop {
namespace hdfs {

// ===================================================================

class JournalInfoProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.JournalInfoProto) */ {
 public:
  JournalInfoProto();
  virtual ~JournalInfoProto();

  JournalInfoProto(const JournalInfoProto& from);

  inline JournalInfoProto& operator=(const JournalInfoProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  JournalInfoProto(JournalInfoProto&& from) noexcept
    : JournalInfoProto() {
    *this = ::std::move(from);
  }

  inline JournalInfoProto& operator=(JournalInfoProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const JournalInfoProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const JournalInfoProto* internal_default_instance() {
    return reinterpret_cast<const JournalInfoProto*>(
               &_JournalInfoProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    0;

  void Swap(JournalInfoProto* other);
  friend void swap(JournalInfoProto& a, JournalInfoProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline JournalInfoProto* New() const final {
    return CreateMaybeMessage<JournalInfoProto>(NULL);
  }

  JournalInfoProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<JournalInfoProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const JournalInfoProto& from);
  void MergeFrom(const JournalInfoProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(JournalInfoProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required string clusterID = 1;
  bool has_clusterid() const;
  void clear_clusterid();
  static const int kClusterIDFieldNumber = 1;
  const ::std::string& clusterid() const;
  void set_clusterid(const ::std::string& value);
  #if LANG_CXX11
  void set_clusterid(::std::string&& value);
  #endif
  void set_clusterid(const char* value);
  void set_clusterid(const char* value, size_t size);
  ::std::string* mutable_clusterid();
  ::std::string* release_clusterid();
  void set_allocated_clusterid(::std::string* clusterid);

  // optional uint32 layoutVersion = 2;
  bool has_layoutversion() const;
  void clear_layoutversion();
  static const int kLayoutVersionFieldNumber = 2;
  ::google::protobuf::uint32 layoutversion() const;
  void set_layoutversion(::google::protobuf::uint32 value);

  // optional uint32 namespaceID = 3;
  bool has_namespaceid() const;
  void clear_namespaceid();
  static const int kNamespaceIDFieldNumber = 3;
  ::google::protobuf::uint32 namespaceid() const;
  void set_namespaceid(::google::protobuf::uint32 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.JournalInfoProto)
 private:
  void set_has_clusterid();
  void clear_has_clusterid();
  void set_has_layoutversion();
  void clear_has_layoutversion();
  void set_has_namespaceid();
  void clear_has_namespaceid();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr clusterid_;
  ::google::protobuf::uint32 layoutversion_;
  ::google::protobuf::uint32 namespaceid_;
  friend struct ::protobuf_JournalProtocol_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class JournalRequestProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.JournalRequestProto) */ {
 public:
  JournalRequestProto();
  virtual ~JournalRequestProto();

  JournalRequestProto(const JournalRequestProto& from);

  inline JournalRequestProto& operator=(const JournalRequestProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  JournalRequestProto(JournalRequestProto&& from) noexcept
    : JournalRequestProto() {
    *this = ::std::move(from);
  }

  inline JournalRequestProto& operator=(JournalRequestProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const JournalRequestProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const JournalRequestProto* internal_default_instance() {
    return reinterpret_cast<const JournalRequestProto*>(
               &_JournalRequestProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    1;

  void Swap(JournalRequestProto* other);
  friend void swap(JournalRequestProto& a, JournalRequestProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline JournalRequestProto* New() const final {
    return CreateMaybeMessage<JournalRequestProto>(NULL);
  }

  JournalRequestProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<JournalRequestProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const JournalRequestProto& from);
  void MergeFrom(const JournalRequestProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(JournalRequestProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required bytes records = 4;
  bool has_records() const;
  void clear_records();
  static const int kRecordsFieldNumber = 4;
  const ::std::string& records() const;
  void set_records(const ::std::string& value);
  #if LANG_CXX11
  void set_records(::std::string&& value);
  #endif
  void set_records(const char* value);
  void set_records(const void* value, size_t size);
  ::std::string* mutable_records();
  ::std::string* release_records();
  void set_allocated_records(::std::string* records);

  // required .hadoop.hdfs.JournalInfoProto journalInfo = 1;
  bool has_journalinfo() const;
  void clear_journalinfo();
  static const int kJournalInfoFieldNumber = 1;
  private:
  const ::hadoop::hdfs::JournalInfoProto& _internal_journalinfo() const;
  public:
  const ::hadoop::hdfs::JournalInfoProto& journalinfo() const;
  ::hadoop::hdfs::JournalInfoProto* release_journalinfo();
  ::hadoop::hdfs::JournalInfoProto* mutable_journalinfo();
  void set_allocated_journalinfo(::hadoop::hdfs::JournalInfoProto* journalinfo);

  // required uint64 firstTxnId = 2;
  bool has_firsttxnid() const;
  void clear_firsttxnid();
  static const int kFirstTxnIdFieldNumber = 2;
  ::google::protobuf::uint64 firsttxnid() const;
  void set_firsttxnid(::google::protobuf::uint64 value);

  // required uint64 epoch = 5;
  bool has_epoch() const;
  void clear_epoch();
  static const int kEpochFieldNumber = 5;
  ::google::protobuf::uint64 epoch() const;
  void set_epoch(::google::protobuf::uint64 value);

  // required uint32 numTxns = 3;
  bool has_numtxns() const;
  void clear_numtxns();
  static const int kNumTxnsFieldNumber = 3;
  ::google::protobuf::uint32 numtxns() const;
  void set_numtxns(::google::protobuf::uint32 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.JournalRequestProto)
 private:
  void set_has_journalinfo();
  void clear_has_journalinfo();
  void set_has_firsttxnid();
  void clear_has_firsttxnid();
  void set_has_numtxns();
  void clear_has_numtxns();
  void set_has_records();
  void clear_has_records();
  void set_has_epoch();
  void clear_has_epoch();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr records_;
  ::hadoop::hdfs::JournalInfoProto* journalinfo_;
  ::google::protobuf::uint64 firsttxnid_;
  ::google::protobuf::uint64 epoch_;
  ::google::protobuf::uint32 numtxns_;
  friend struct ::protobuf_JournalProtocol_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class JournalResponseProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.JournalResponseProto) */ {
 public:
  JournalResponseProto();
  virtual ~JournalResponseProto();

  JournalResponseProto(const JournalResponseProto& from);

  inline JournalResponseProto& operator=(const JournalResponseProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  JournalResponseProto(JournalResponseProto&& from) noexcept
    : JournalResponseProto() {
    *this = ::std::move(from);
  }

  inline JournalResponseProto& operator=(JournalResponseProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const JournalResponseProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const JournalResponseProto* internal_default_instance() {
    return reinterpret_cast<const JournalResponseProto*>(
               &_JournalResponseProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    2;

  void Swap(JournalResponseProto* other);
  friend void swap(JournalResponseProto& a, JournalResponseProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline JournalResponseProto* New() const final {
    return CreateMaybeMessage<JournalResponseProto>(NULL);
  }

  JournalResponseProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<JournalResponseProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const JournalResponseProto& from);
  void MergeFrom(const JournalResponseProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(JournalResponseProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.JournalResponseProto)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  friend struct ::protobuf_JournalProtocol_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class StartLogSegmentRequestProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.StartLogSegmentRequestProto) */ {
 public:
  StartLogSegmentRequestProto();
  virtual ~StartLogSegmentRequestProto();

  StartLogSegmentRequestProto(const StartLogSegmentRequestProto& from);

  inline StartLogSegmentRequestProto& operator=(const StartLogSegmentRequestProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  StartLogSegmentRequestProto(StartLogSegmentRequestProto&& from) noexcept
    : StartLogSegmentRequestProto() {
    *this = ::std::move(from);
  }

  inline StartLogSegmentRequestProto& operator=(StartLogSegmentRequestProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const StartLogSegmentRequestProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const StartLogSegmentRequestProto* internal_default_instance() {
    return reinterpret_cast<const StartLogSegmentRequestProto*>(
               &_StartLogSegmentRequestProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    3;

  void Swap(StartLogSegmentRequestProto* other);
  friend void swap(StartLogSegmentRequestProto& a, StartLogSegmentRequestProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline StartLogSegmentRequestProto* New() const final {
    return CreateMaybeMessage<StartLogSegmentRequestProto>(NULL);
  }

  StartLogSegmentRequestProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<StartLogSegmentRequestProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const StartLogSegmentRequestProto& from);
  void MergeFrom(const StartLogSegmentRequestProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(StartLogSegmentRequestProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required .hadoop.hdfs.JournalInfoProto journalInfo = 1;
  bool has_journalinfo() const;
  void clear_journalinfo();
  static const int kJournalInfoFieldNumber = 1;
  private:
  const ::hadoop::hdfs::JournalInfoProto& _internal_journalinfo() const;
  public:
  const ::hadoop::hdfs::JournalInfoProto& journalinfo() const;
  ::hadoop::hdfs::JournalInfoProto* release_journalinfo();
  ::hadoop::hdfs::JournalInfoProto* mutable_journalinfo();
  void set_allocated_journalinfo(::hadoop::hdfs::JournalInfoProto* journalinfo);

  // required uint64 txid = 2;
  bool has_txid() const;
  void clear_txid();
  static const int kTxidFieldNumber = 2;
  ::google::protobuf::uint64 txid() const;
  void set_txid(::google::protobuf::uint64 value);

  // required uint64 epoch = 3;
  bool has_epoch() const;
  void clear_epoch();
  static const int kEpochFieldNumber = 3;
  ::google::protobuf::uint64 epoch() const;
  void set_epoch(::google::protobuf::uint64 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.StartLogSegmentRequestProto)
 private:
  void set_has_journalinfo();
  void clear_has_journalinfo();
  void set_has_txid();
  void clear_has_txid();
  void set_has_epoch();
  void clear_has_epoch();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::hadoop::hdfs::JournalInfoProto* journalinfo_;
  ::google::protobuf::uint64 txid_;
  ::google::protobuf::uint64 epoch_;
  friend struct ::protobuf_JournalProtocol_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class StartLogSegmentResponseProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.StartLogSegmentResponseProto) */ {
 public:
  StartLogSegmentResponseProto();
  virtual ~StartLogSegmentResponseProto();

  StartLogSegmentResponseProto(const StartLogSegmentResponseProto& from);

  inline StartLogSegmentResponseProto& operator=(const StartLogSegmentResponseProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  StartLogSegmentResponseProto(StartLogSegmentResponseProto&& from) noexcept
    : StartLogSegmentResponseProto() {
    *this = ::std::move(from);
  }

  inline StartLogSegmentResponseProto& operator=(StartLogSegmentResponseProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const StartLogSegmentResponseProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const StartLogSegmentResponseProto* internal_default_instance() {
    return reinterpret_cast<const StartLogSegmentResponseProto*>(
               &_StartLogSegmentResponseProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    4;

  void Swap(StartLogSegmentResponseProto* other);
  friend void swap(StartLogSegmentResponseProto& a, StartLogSegmentResponseProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline StartLogSegmentResponseProto* New() const final {
    return CreateMaybeMessage<StartLogSegmentResponseProto>(NULL);
  }

  StartLogSegmentResponseProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<StartLogSegmentResponseProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const StartLogSegmentResponseProto& from);
  void MergeFrom(const StartLogSegmentResponseProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(StartLogSegmentResponseProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.StartLogSegmentResponseProto)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  friend struct ::protobuf_JournalProtocol_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class FenceRequestProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.FenceRequestProto) */ {
 public:
  FenceRequestProto();
  virtual ~FenceRequestProto();

  FenceRequestProto(const FenceRequestProto& from);

  inline FenceRequestProto& operator=(const FenceRequestProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  FenceRequestProto(FenceRequestProto&& from) noexcept
    : FenceRequestProto() {
    *this = ::std::move(from);
  }

  inline FenceRequestProto& operator=(FenceRequestProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const FenceRequestProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const FenceRequestProto* internal_default_instance() {
    return reinterpret_cast<const FenceRequestProto*>(
               &_FenceRequestProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    5;

  void Swap(FenceRequestProto* other);
  friend void swap(FenceRequestProto& a, FenceRequestProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline FenceRequestProto* New() const final {
    return CreateMaybeMessage<FenceRequestProto>(NULL);
  }

  FenceRequestProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<FenceRequestProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const FenceRequestProto& from);
  void MergeFrom(const FenceRequestProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(FenceRequestProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string fencerInfo = 3;
  bool has_fencerinfo() const;
  void clear_fencerinfo();
  static const int kFencerInfoFieldNumber = 3;
  const ::std::string& fencerinfo() const;
  void set_fencerinfo(const ::std::string& value);
  #if LANG_CXX11
  void set_fencerinfo(::std::string&& value);
  #endif
  void set_fencerinfo(const char* value);
  void set_fencerinfo(const char* value, size_t size);
  ::std::string* mutable_fencerinfo();
  ::std::string* release_fencerinfo();
  void set_allocated_fencerinfo(::std::string* fencerinfo);

  // required .hadoop.hdfs.JournalInfoProto journalInfo = 1;
  bool has_journalinfo() const;
  void clear_journalinfo();
  static const int kJournalInfoFieldNumber = 1;
  private:
  const ::hadoop::hdfs::JournalInfoProto& _internal_journalinfo() const;
  public:
  const ::hadoop::hdfs::JournalInfoProto& journalinfo() const;
  ::hadoop::hdfs::JournalInfoProto* release_journalinfo();
  ::hadoop::hdfs::JournalInfoProto* mutable_journalinfo();
  void set_allocated_journalinfo(::hadoop::hdfs::JournalInfoProto* journalinfo);

  // required uint64 epoch = 2;
  bool has_epoch() const;
  void clear_epoch();
  static const int kEpochFieldNumber = 2;
  ::google::protobuf::uint64 epoch() const;
  void set_epoch(::google::protobuf::uint64 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.FenceRequestProto)
 private:
  void set_has_journalinfo();
  void clear_has_journalinfo();
  void set_has_epoch();
  void clear_has_epoch();
  void set_has_fencerinfo();
  void clear_has_fencerinfo();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr fencerinfo_;
  ::hadoop::hdfs::JournalInfoProto* journalinfo_;
  ::google::protobuf::uint64 epoch_;
  friend struct ::protobuf_JournalProtocol_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class FenceResponseProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.FenceResponseProto) */ {
 public:
  FenceResponseProto();
  virtual ~FenceResponseProto();

  FenceResponseProto(const FenceResponseProto& from);

  inline FenceResponseProto& operator=(const FenceResponseProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  FenceResponseProto(FenceResponseProto&& from) noexcept
    : FenceResponseProto() {
    *this = ::std::move(from);
  }

  inline FenceResponseProto& operator=(FenceResponseProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const FenceResponseProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const FenceResponseProto* internal_default_instance() {
    return reinterpret_cast<const FenceResponseProto*>(
               &_FenceResponseProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    6;

  void Swap(FenceResponseProto* other);
  friend void swap(FenceResponseProto& a, FenceResponseProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline FenceResponseProto* New() const final {
    return CreateMaybeMessage<FenceResponseProto>(NULL);
  }

  FenceResponseProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<FenceResponseProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const FenceResponseProto& from);
  void MergeFrom(const FenceResponseProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(FenceResponseProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional uint64 previousEpoch = 1;
  bool has_previousepoch() const;
  void clear_previousepoch();
  static const int kPreviousEpochFieldNumber = 1;
  ::google::protobuf::uint64 previousepoch() const;
  void set_previousepoch(::google::protobuf::uint64 value);

  // optional uint64 lastTransactionId = 2;
  bool has_lasttransactionid() const;
  void clear_lasttransactionid();
  static const int kLastTransactionIdFieldNumber = 2;
  ::google::protobuf::uint64 lasttransactionid() const;
  void set_lasttransactionid(::google::protobuf::uint64 value);

  // optional bool inSync = 3;
  bool has_insync() const;
  void clear_insync();
  static const int kInSyncFieldNumber = 3;
  bool insync() const;
  void set_insync(bool value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.FenceResponseProto)
 private:
  void set_has_previousepoch();
  void clear_has_previousepoch();
  void set_has_lasttransactionid();
  void clear_has_lasttransactionid();
  void set_has_insync();
  void clear_has_insync();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::uint64 previousepoch_;
  ::google::protobuf::uint64 lasttransactionid_;
  bool insync_;
  friend struct ::protobuf_JournalProtocol_2eproto::TableStruct;
};
// ===================================================================


// ===================================================================

#ifdef __GNUC__
  #pragma GCC diagnostic push
  #pragma GCC diagnostic ignored "-Wstrict-aliasing"
#endif  // __GNUC__
// JournalInfoProto

// required string clusterID = 1;
inline bool JournalInfoProto::has_clusterid() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void JournalInfoProto::set_has_clusterid() {
  _has_bits_[0] |= 0x00000001u;
}
inline void JournalInfoProto::clear_has_clusterid() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void JournalInfoProto::clear_clusterid() {
  clusterid_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_clusterid();
}
inline const ::std::string& JournalInfoProto::clusterid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.JournalInfoProto.clusterID)
  return clusterid_.GetNoArena();
}
inline void JournalInfoProto::set_clusterid(const ::std::string& value) {
  set_has_clusterid();
  clusterid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.JournalInfoProto.clusterID)
}
#if LANG_CXX11
inline void JournalInfoProto::set_clusterid(::std::string&& value) {
  set_has_clusterid();
  clusterid_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.JournalInfoProto.clusterID)
}
#endif
inline void JournalInfoProto::set_clusterid(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_clusterid();
  clusterid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.JournalInfoProto.clusterID)
}
inline void JournalInfoProto::set_clusterid(const char* value, size_t size) {
  set_has_clusterid();
  clusterid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.JournalInfoProto.clusterID)
}
inline ::std::string* JournalInfoProto::mutable_clusterid() {
  set_has_clusterid();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.JournalInfoProto.clusterID)
  return clusterid_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* JournalInfoProto::release_clusterid() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.JournalInfoProto.clusterID)
  if (!has_clusterid()) {
    return NULL;
  }
  clear_has_clusterid();
  return clusterid_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void JournalInfoProto::set_allocated_clusterid(::std::string* clusterid) {
  if (clusterid != NULL) {
    set_has_clusterid();
  } else {
    clear_has_clusterid();
  }
  clusterid_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), clusterid);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.JournalInfoProto.clusterID)
}

// optional uint32 layoutVersion = 2;
inline bool JournalInfoProto::has_layoutversion() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void JournalInfoProto::set_has_layoutversion() {
  _has_bits_[0] |= 0x00000002u;
}
inline void JournalInfoProto::clear_has_layoutversion() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void JournalInfoProto::clear_layoutversion() {
  layoutversion_ = 0u;
  clear_has_layoutversion();
}
inline ::google::protobuf::uint32 JournalInfoProto::layoutversion() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.JournalInfoProto.layoutVersion)
  return layoutversion_;
}
inline void JournalInfoProto::set_layoutversion(::google::protobuf::uint32 value) {
  set_has_layoutversion();
  layoutversion_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.JournalInfoProto.layoutVersion)
}

// optional uint32 namespaceID = 3;
inline bool JournalInfoProto::has_namespaceid() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void JournalInfoProto::set_has_namespaceid() {
  _has_bits_[0] |= 0x00000004u;
}
inline void JournalInfoProto::clear_has_namespaceid() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void JournalInfoProto::clear_namespaceid() {
  namespaceid_ = 0u;
  clear_has_namespaceid();
}
inline ::google::protobuf::uint32 JournalInfoProto::namespaceid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.JournalInfoProto.namespaceID)
  return namespaceid_;
}
inline void JournalInfoProto::set_namespaceid(::google::protobuf::uint32 value) {
  set_has_namespaceid();
  namespaceid_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.JournalInfoProto.namespaceID)
}

// -------------------------------------------------------------------

// JournalRequestProto

// required .hadoop.hdfs.JournalInfoProto journalInfo = 1;
inline bool JournalRequestProto::has_journalinfo() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void JournalRequestProto::set_has_journalinfo() {
  _has_bits_[0] |= 0x00000002u;
}
inline void JournalRequestProto::clear_has_journalinfo() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void JournalRequestProto::clear_journalinfo() {
  if (journalinfo_ != NULL) journalinfo_->Clear();
  clear_has_journalinfo();
}
inline const ::hadoop::hdfs::JournalInfoProto& JournalRequestProto::_internal_journalinfo() const {
  return *journalinfo_;
}
inline const ::hadoop::hdfs::JournalInfoProto& JournalRequestProto::journalinfo() const {
  const ::hadoop::hdfs::JournalInfoProto* p = journalinfo_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.JournalRequestProto.journalInfo)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::JournalInfoProto*>(
      &::hadoop::hdfs::_JournalInfoProto_default_instance_);
}
inline ::hadoop::hdfs::JournalInfoProto* JournalRequestProto::release_journalinfo() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.JournalRequestProto.journalInfo)
  clear_has_journalinfo();
  ::hadoop::hdfs::JournalInfoProto* temp = journalinfo_;
  journalinfo_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::JournalInfoProto* JournalRequestProto::mutable_journalinfo() {
  set_has_journalinfo();
  if (journalinfo_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::JournalInfoProto>(GetArenaNoVirtual());
    journalinfo_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.JournalRequestProto.journalInfo)
  return journalinfo_;
}
inline void JournalRequestProto::set_allocated_journalinfo(::hadoop::hdfs::JournalInfoProto* journalinfo) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete journalinfo_;
  }
  if (journalinfo) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      journalinfo = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, journalinfo, submessage_arena);
    }
    set_has_journalinfo();
  } else {
    clear_has_journalinfo();
  }
  journalinfo_ = journalinfo;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.JournalRequestProto.journalInfo)
}

// required uint64 firstTxnId = 2;
inline bool JournalRequestProto::has_firsttxnid() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void JournalRequestProto::set_has_firsttxnid() {
  _has_bits_[0] |= 0x00000004u;
}
inline void JournalRequestProto::clear_has_firsttxnid() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void JournalRequestProto::clear_firsttxnid() {
  firsttxnid_ = GOOGLE_ULONGLONG(0);
  clear_has_firsttxnid();
}
inline ::google::protobuf::uint64 JournalRequestProto::firsttxnid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.JournalRequestProto.firstTxnId)
  return firsttxnid_;
}
inline void JournalRequestProto::set_firsttxnid(::google::protobuf::uint64 value) {
  set_has_firsttxnid();
  firsttxnid_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.JournalRequestProto.firstTxnId)
}

// required uint32 numTxns = 3;
inline bool JournalRequestProto::has_numtxns() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void JournalRequestProto::set_has_numtxns() {
  _has_bits_[0] |= 0x00000010u;
}
inline void JournalRequestProto::clear_has_numtxns() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void JournalRequestProto::clear_numtxns() {
  numtxns_ = 0u;
  clear_has_numtxns();
}
inline ::google::protobuf::uint32 JournalRequestProto::numtxns() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.JournalRequestProto.numTxns)
  return numtxns_;
}
inline void JournalRequestProto::set_numtxns(::google::protobuf::uint32 value) {
  set_has_numtxns();
  numtxns_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.JournalRequestProto.numTxns)
}

// required bytes records = 4;
inline bool JournalRequestProto::has_records() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void JournalRequestProto::set_has_records() {
  _has_bits_[0] |= 0x00000001u;
}
inline void JournalRequestProto::clear_has_records() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void JournalRequestProto::clear_records() {
  records_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_records();
}
inline const ::std::string& JournalRequestProto::records() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.JournalRequestProto.records)
  return records_.GetNoArena();
}
inline void JournalRequestProto::set_records(const ::std::string& value) {
  set_has_records();
  records_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.JournalRequestProto.records)
}
#if LANG_CXX11
inline void JournalRequestProto::set_records(::std::string&& value) {
  set_has_records();
  records_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.JournalRequestProto.records)
}
#endif
inline void JournalRequestProto::set_records(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_records();
  records_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.JournalRequestProto.records)
}
inline void JournalRequestProto::set_records(const void* value, size_t size) {
  set_has_records();
  records_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.JournalRequestProto.records)
}
inline ::std::string* JournalRequestProto::mutable_records() {
  set_has_records();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.JournalRequestProto.records)
  return records_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* JournalRequestProto::release_records() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.JournalRequestProto.records)
  if (!has_records()) {
    return NULL;
  }
  clear_has_records();
  return records_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void JournalRequestProto::set_allocated_records(::std::string* records) {
  if (records != NULL) {
    set_has_records();
  } else {
    clear_has_records();
  }
  records_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), records);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.JournalRequestProto.records)
}

// required uint64 epoch = 5;
inline bool JournalRequestProto::has_epoch() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void JournalRequestProto::set_has_epoch() {
  _has_bits_[0] |= 0x00000008u;
}
inline void JournalRequestProto::clear_has_epoch() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void JournalRequestProto::clear_epoch() {
  epoch_ = GOOGLE_ULONGLONG(0);
  clear_has_epoch();
}
inline ::google::protobuf::uint64 JournalRequestProto::epoch() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.JournalRequestProto.epoch)
  return epoch_;
}
inline void JournalRequestProto::set_epoch(::google::protobuf::uint64 value) {
  set_has_epoch();
  epoch_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.JournalRequestProto.epoch)
}

// -------------------------------------------------------------------

// JournalResponseProto

// -------------------------------------------------------------------

// StartLogSegmentRequestProto

// required .hadoop.hdfs.JournalInfoProto journalInfo = 1;
inline bool StartLogSegmentRequestProto::has_journalinfo() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void StartLogSegmentRequestProto::set_has_journalinfo() {
  _has_bits_[0] |= 0x00000001u;
}
inline void StartLogSegmentRequestProto::clear_has_journalinfo() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void StartLogSegmentRequestProto::clear_journalinfo() {
  if (journalinfo_ != NULL) journalinfo_->Clear();
  clear_has_journalinfo();
}
inline const ::hadoop::hdfs::JournalInfoProto& StartLogSegmentRequestProto::_internal_journalinfo() const {
  return *journalinfo_;
}
inline const ::hadoop::hdfs::JournalInfoProto& StartLogSegmentRequestProto::journalinfo() const {
  const ::hadoop::hdfs::JournalInfoProto* p = journalinfo_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.StartLogSegmentRequestProto.journalInfo)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::JournalInfoProto*>(
      &::hadoop::hdfs::_JournalInfoProto_default_instance_);
}
inline ::hadoop::hdfs::JournalInfoProto* StartLogSegmentRequestProto::release_journalinfo() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.StartLogSegmentRequestProto.journalInfo)
  clear_has_journalinfo();
  ::hadoop::hdfs::JournalInfoProto* temp = journalinfo_;
  journalinfo_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::JournalInfoProto* StartLogSegmentRequestProto::mutable_journalinfo() {
  set_has_journalinfo();
  if (journalinfo_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::JournalInfoProto>(GetArenaNoVirtual());
    journalinfo_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.StartLogSegmentRequestProto.journalInfo)
  return journalinfo_;
}
inline void StartLogSegmentRequestProto::set_allocated_journalinfo(::hadoop::hdfs::JournalInfoProto* journalinfo) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete journalinfo_;
  }
  if (journalinfo) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      journalinfo = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, journalinfo, submessage_arena);
    }
    set_has_journalinfo();
  } else {
    clear_has_journalinfo();
  }
  journalinfo_ = journalinfo;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.StartLogSegmentRequestProto.journalInfo)
}

// required uint64 txid = 2;
inline bool StartLogSegmentRequestProto::has_txid() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void StartLogSegmentRequestProto::set_has_txid() {
  _has_bits_[0] |= 0x00000002u;
}
inline void StartLogSegmentRequestProto::clear_has_txid() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void StartLogSegmentRequestProto::clear_txid() {
  txid_ = GOOGLE_ULONGLONG(0);
  clear_has_txid();
}
inline ::google::protobuf::uint64 StartLogSegmentRequestProto::txid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.StartLogSegmentRequestProto.txid)
  return txid_;
}
inline void StartLogSegmentRequestProto::set_txid(::google::protobuf::uint64 value) {
  set_has_txid();
  txid_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.StartLogSegmentRequestProto.txid)
}

// required uint64 epoch = 3;
inline bool StartLogSegmentRequestProto::has_epoch() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void StartLogSegmentRequestProto::set_has_epoch() {
  _has_bits_[0] |= 0x00000004u;
}
inline void StartLogSegmentRequestProto::clear_has_epoch() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void StartLogSegmentRequestProto::clear_epoch() {
  epoch_ = GOOGLE_ULONGLONG(0);
  clear_has_epoch();
}
inline ::google::protobuf::uint64 StartLogSegmentRequestProto::epoch() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.StartLogSegmentRequestProto.epoch)
  return epoch_;
}
inline void StartLogSegmentRequestProto::set_epoch(::google::protobuf::uint64 value) {
  set_has_epoch();
  epoch_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.StartLogSegmentRequestProto.epoch)
}

// -------------------------------------------------------------------

// StartLogSegmentResponseProto

// -------------------------------------------------------------------

// FenceRequestProto

// required .hadoop.hdfs.JournalInfoProto journalInfo = 1;
inline bool FenceRequestProto::has_journalinfo() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void FenceRequestProto::set_has_journalinfo() {
  _has_bits_[0] |= 0x00000002u;
}
inline void FenceRequestProto::clear_has_journalinfo() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void FenceRequestProto::clear_journalinfo() {
  if (journalinfo_ != NULL) journalinfo_->Clear();
  clear_has_journalinfo();
}
inline const ::hadoop::hdfs::JournalInfoProto& FenceRequestProto::_internal_journalinfo() const {
  return *journalinfo_;
}
inline const ::hadoop::hdfs::JournalInfoProto& FenceRequestProto::journalinfo() const {
  const ::hadoop::hdfs::JournalInfoProto* p = journalinfo_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.FenceRequestProto.journalInfo)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::JournalInfoProto*>(
      &::hadoop::hdfs::_JournalInfoProto_default_instance_);
}
inline ::hadoop::hdfs::JournalInfoProto* FenceRequestProto::release_journalinfo() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.FenceRequestProto.journalInfo)
  clear_has_journalinfo();
  ::hadoop::hdfs::JournalInfoProto* temp = journalinfo_;
  journalinfo_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::JournalInfoProto* FenceRequestProto::mutable_journalinfo() {
  set_has_journalinfo();
  if (journalinfo_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::JournalInfoProto>(GetArenaNoVirtual());
    journalinfo_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.FenceRequestProto.journalInfo)
  return journalinfo_;
}
inline void FenceRequestProto::set_allocated_journalinfo(::hadoop::hdfs::JournalInfoProto* journalinfo) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete journalinfo_;
  }
  if (journalinfo) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      journalinfo = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, journalinfo, submessage_arena);
    }
    set_has_journalinfo();
  } else {
    clear_has_journalinfo();
  }
  journalinfo_ = journalinfo;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.FenceRequestProto.journalInfo)
}

// required uint64 epoch = 2;
inline bool FenceRequestProto::has_epoch() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void FenceRequestProto::set_has_epoch() {
  _has_bits_[0] |= 0x00000004u;
}
inline void FenceRequestProto::clear_has_epoch() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void FenceRequestProto::clear_epoch() {
  epoch_ = GOOGLE_ULONGLONG(0);
  clear_has_epoch();
}
inline ::google::protobuf::uint64 FenceRequestProto::epoch() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.FenceRequestProto.epoch)
  return epoch_;
}
inline void FenceRequestProto::set_epoch(::google::protobuf::uint64 value) {
  set_has_epoch();
  epoch_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.FenceRequestProto.epoch)
}

// optional string fencerInfo = 3;
inline bool FenceRequestProto::has_fencerinfo() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void FenceRequestProto::set_has_fencerinfo() {
  _has_bits_[0] |= 0x00000001u;
}
inline void FenceRequestProto::clear_has_fencerinfo() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void FenceRequestProto::clear_fencerinfo() {
  fencerinfo_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_fencerinfo();
}
inline const ::std::string& FenceRequestProto::fencerinfo() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.FenceRequestProto.fencerInfo)
  return fencerinfo_.GetNoArena();
}
inline void FenceRequestProto::set_fencerinfo(const ::std::string& value) {
  set_has_fencerinfo();
  fencerinfo_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.FenceRequestProto.fencerInfo)
}
#if LANG_CXX11
inline void FenceRequestProto::set_fencerinfo(::std::string&& value) {
  set_has_fencerinfo();
  fencerinfo_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.FenceRequestProto.fencerInfo)
}
#endif
inline void FenceRequestProto::set_fencerinfo(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_fencerinfo();
  fencerinfo_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.FenceRequestProto.fencerInfo)
}
inline void FenceRequestProto::set_fencerinfo(const char* value, size_t size) {
  set_has_fencerinfo();
  fencerinfo_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.FenceRequestProto.fencerInfo)
}
inline ::std::string* FenceRequestProto::mutable_fencerinfo() {
  set_has_fencerinfo();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.FenceRequestProto.fencerInfo)
  return fencerinfo_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* FenceRequestProto::release_fencerinfo() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.FenceRequestProto.fencerInfo)
  if (!has_fencerinfo()) {
    return NULL;
  }
  clear_has_fencerinfo();
  return fencerinfo_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void FenceRequestProto::set_allocated_fencerinfo(::std::string* fencerinfo) {
  if (fencerinfo != NULL) {
    set_has_fencerinfo();
  } else {
    clear_has_fencerinfo();
  }
  fencerinfo_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), fencerinfo);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.FenceRequestProto.fencerInfo)
}

// -------------------------------------------------------------------

// FenceResponseProto

// optional uint64 previousEpoch = 1;
inline bool FenceResponseProto::has_previousepoch() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void FenceResponseProto::set_has_previousepoch() {
  _has_bits_[0] |= 0x00000001u;
}
inline void FenceResponseProto::clear_has_previousepoch() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void FenceResponseProto::clear_previousepoch() {
  previousepoch_ = GOOGLE_ULONGLONG(0);
  clear_has_previousepoch();
}
inline ::google::protobuf::uint64 FenceResponseProto::previousepoch() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.FenceResponseProto.previousEpoch)
  return previousepoch_;
}
inline void FenceResponseProto::set_previousepoch(::google::protobuf::uint64 value) {
  set_has_previousepoch();
  previousepoch_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.FenceResponseProto.previousEpoch)
}

// optional uint64 lastTransactionId = 2;
inline bool FenceResponseProto::has_lasttransactionid() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void FenceResponseProto::set_has_lasttransactionid() {
  _has_bits_[0] |= 0x00000002u;
}
inline void FenceResponseProto::clear_has_lasttransactionid() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void FenceResponseProto::clear_lasttransactionid() {
  lasttransactionid_ = GOOGLE_ULONGLONG(0);
  clear_has_lasttransactionid();
}
inline ::google::protobuf::uint64 FenceResponseProto::lasttransactionid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.FenceResponseProto.lastTransactionId)
  return lasttransactionid_;
}
inline void FenceResponseProto::set_lasttransactionid(::google::protobuf::uint64 value) {
  set_has_lasttransactionid();
  lasttransactionid_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.FenceResponseProto.lastTransactionId)
}

// optional bool inSync = 3;
inline bool FenceResponseProto::has_insync() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void FenceResponseProto::set_has_insync() {
  _has_bits_[0] |= 0x00000004u;
}
inline void FenceResponseProto::clear_has_insync() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void FenceResponseProto::clear_insync() {
  insync_ = false;
  clear_has_insync();
}
inline bool FenceResponseProto::insync() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.FenceResponseProto.inSync)
  return insync_;
}
inline void FenceResponseProto::set_insync(bool value) {
  set_has_insync();
  insync_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.FenceResponseProto.inSync)
}

#ifdef __GNUC__
  #pragma GCC diagnostic pop
#endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

}  // namespace hdfs
}  // namespace hadoop

// @@protoc_insertion_point(global_scope)

#endif  // PROTOBUF_INCLUDED_JournalProtocol_2eproto
