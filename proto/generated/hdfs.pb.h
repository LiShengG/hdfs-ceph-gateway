// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: hdfs.proto

#ifndef PROTOBUF_INCLUDED_hdfs_2eproto
#define PROTOBUF_INCLUDED_hdfs_2eproto

#include <string>

#include <google/protobuf/stubs/common.h>

#if GOOGLE_PROTOBUF_VERSION < 3006001
#error This file was generated by a newer version of protoc which is
#error incompatible with your Protocol Buffer headers.  Please update
#error your headers.
#endif
#if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
#error This file was generated by an older version of protoc which is
#error incompatible with your Protocol Buffer headers.  Please
#error regenerate this file with a newer version of protoc.
#endif

#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/arena.h>
#include <google/protobuf/arenastring.h>
#include <google/protobuf/generated_message_table_driven.h>
#include <google/protobuf/generated_message_util.h>
#include <google/protobuf/inlined_string_field.h>
#include <google/protobuf/metadata.h>
#include <google/protobuf/message.h>
#include <google/protobuf/repeated_field.h>  // IWYU pragma: export
#include <google/protobuf/extension_set.h>  // IWYU pragma: export
#include <google/protobuf/generated_enum_reflection.h>
#include <google/protobuf/unknown_field_set.h>
#include "Security.pb.h"
#include "acl.pb.h"
// @@protoc_insertion_point(includes)
#define PROTOBUF_INTERNAL_EXPORT_protobuf_hdfs_2eproto 

namespace protobuf_hdfs_2eproto {
// Internal implementation detail -- do not use these members.
struct TableStruct {
  static const ::google::protobuf::internal::ParseTableField entries[];
  static const ::google::protobuf::internal::AuxillaryParseTableField aux[];
  static const ::google::protobuf::internal::ParseTable schema[49];
  static const ::google::protobuf::internal::FieldMetadata field_metadata[];
  static const ::google::protobuf::internal::SerializationTable serialization_table[];
  static const ::google::protobuf::uint32 offsets[];
};
void AddDescriptors();
}  // namespace protobuf_hdfs_2eproto
namespace hadoop {
namespace hdfs {
class AddErasureCodingPolicyResponseProto;
class AddErasureCodingPolicyResponseProtoDefaultTypeInternal;
extern AddErasureCodingPolicyResponseProtoDefaultTypeInternal _AddErasureCodingPolicyResponseProto_default_instance_;
class BatchedDirectoryListingProto;
class BatchedDirectoryListingProtoDefaultTypeInternal;
extern BatchedDirectoryListingProtoDefaultTypeInternal _BatchedDirectoryListingProto_default_instance_;
class BatchedListingKeyProto;
class BatchedListingKeyProtoDefaultTypeInternal;
extern BatchedListingKeyProtoDefaultTypeInternal _BatchedListingKeyProto_default_instance_;
class BlockChecksumOptionsProto;
class BlockChecksumOptionsProtoDefaultTypeInternal;
extern BlockChecksumOptionsProtoDefaultTypeInternal _BlockChecksumOptionsProto_default_instance_;
class BlockProto;
class BlockProtoDefaultTypeInternal;
extern BlockProtoDefaultTypeInternal _BlockProto_default_instance_;
class BlockStoragePolicyProto;
class BlockStoragePolicyProtoDefaultTypeInternal;
extern BlockStoragePolicyProtoDefaultTypeInternal _BlockStoragePolicyProto_default_instance_;
class BlockTokenSecretProto;
class BlockTokenSecretProtoDefaultTypeInternal;
extern BlockTokenSecretProtoDefaultTypeInternal _BlockTokenSecretProto_default_instance_;
class CipherOptionProto;
class CipherOptionProtoDefaultTypeInternal;
extern CipherOptionProtoDefaultTypeInternal _CipherOptionProto_default_instance_;
class ContentSummaryProto;
class ContentSummaryProtoDefaultTypeInternal;
extern ContentSummaryProtoDefaultTypeInternal _ContentSummaryProto_default_instance_;
class CorruptFileBlocksProto;
class CorruptFileBlocksProtoDefaultTypeInternal;
extern CorruptFileBlocksProtoDefaultTypeInternal _CorruptFileBlocksProto_default_instance_;
class DataEncryptionKeyProto;
class DataEncryptionKeyProtoDefaultTypeInternal;
extern DataEncryptionKeyProtoDefaultTypeInternal _DataEncryptionKeyProto_default_instance_;
class DatanodeIDProto;
class DatanodeIDProtoDefaultTypeInternal;
extern DatanodeIDProtoDefaultTypeInternal _DatanodeIDProto_default_instance_;
class DatanodeInfoProto;
class DatanodeInfoProtoDefaultTypeInternal;
extern DatanodeInfoProtoDefaultTypeInternal _DatanodeInfoProto_default_instance_;
class DatanodeInfosProto;
class DatanodeInfosProtoDefaultTypeInternal;
extern DatanodeInfosProtoDefaultTypeInternal _DatanodeInfosProto_default_instance_;
class DatanodeLocalInfoProto;
class DatanodeLocalInfoProtoDefaultTypeInternal;
extern DatanodeLocalInfoProtoDefaultTypeInternal _DatanodeLocalInfoProto_default_instance_;
class DatanodeStorageProto;
class DatanodeStorageProtoDefaultTypeInternal;
extern DatanodeStorageProtoDefaultTypeInternal _DatanodeStorageProto_default_instance_;
class DatanodeVolumeInfoProto;
class DatanodeVolumeInfoProtoDefaultTypeInternal;
extern DatanodeVolumeInfoProtoDefaultTypeInternal _DatanodeVolumeInfoProto_default_instance_;
class DirectoryListingProto;
class DirectoryListingProtoDefaultTypeInternal;
extern DirectoryListingProtoDefaultTypeInternal _DirectoryListingProto_default_instance_;
class ECSchemaOptionEntryProto;
class ECSchemaOptionEntryProtoDefaultTypeInternal;
extern ECSchemaOptionEntryProtoDefaultTypeInternal _ECSchemaOptionEntryProto_default_instance_;
class ECSchemaProto;
class ECSchemaProtoDefaultTypeInternal;
extern ECSchemaProtoDefaultTypeInternal _ECSchemaProto_default_instance_;
class ECTopologyVerifierResultProto;
class ECTopologyVerifierResultProtoDefaultTypeInternal;
extern ECTopologyVerifierResultProtoDefaultTypeInternal _ECTopologyVerifierResultProto_default_instance_;
class ErasureCodingPolicyProto;
class ErasureCodingPolicyProtoDefaultTypeInternal;
extern ErasureCodingPolicyProtoDefaultTypeInternal _ErasureCodingPolicyProto_default_instance_;
class ExtendedBlockProto;
class ExtendedBlockProtoDefaultTypeInternal;
extern ExtendedBlockProtoDefaultTypeInternal _ExtendedBlockProto_default_instance_;
class FileEncryptionInfoProto;
class FileEncryptionInfoProtoDefaultTypeInternal;
extern FileEncryptionInfoProtoDefaultTypeInternal _FileEncryptionInfoProto_default_instance_;
class FsServerDefaultsProto;
class FsServerDefaultsProtoDefaultTypeInternal;
extern FsServerDefaultsProtoDefaultTypeInternal _FsServerDefaultsProto_default_instance_;
class HdfsFileStatusProto;
class HdfsFileStatusProtoDefaultTypeInternal;
extern HdfsFileStatusProtoDefaultTypeInternal _HdfsFileStatusProto_default_instance_;
class HdfsPathHandleProto;
class HdfsPathHandleProtoDefaultTypeInternal;
extern HdfsPathHandleProtoDefaultTypeInternal _HdfsPathHandleProto_default_instance_;
class LocatedBlockProto;
class LocatedBlockProtoDefaultTypeInternal;
extern LocatedBlockProtoDefaultTypeInternal _LocatedBlockProto_default_instance_;
class LocatedBlocksProto;
class LocatedBlocksProtoDefaultTypeInternal;
extern LocatedBlocksProtoDefaultTypeInternal _LocatedBlocksProto_default_instance_;
class PerFileEncryptionInfoProto;
class PerFileEncryptionInfoProtoDefaultTypeInternal;
extern PerFileEncryptionInfoProtoDefaultTypeInternal _PerFileEncryptionInfoProto_default_instance_;
class ProvidedStorageLocationProto;
class ProvidedStorageLocationProtoDefaultTypeInternal;
extern ProvidedStorageLocationProtoDefaultTypeInternal _ProvidedStorageLocationProto_default_instance_;
class QuotaUsageProto;
class QuotaUsageProtoDefaultTypeInternal;
extern QuotaUsageProtoDefaultTypeInternal _QuotaUsageProto_default_instance_;
class ReencryptionInfoProto;
class ReencryptionInfoProtoDefaultTypeInternal;
extern ReencryptionInfoProtoDefaultTypeInternal _ReencryptionInfoProto_default_instance_;
class RemoteExceptionProto;
class RemoteExceptionProtoDefaultTypeInternal;
extern RemoteExceptionProtoDefaultTypeInternal _RemoteExceptionProto_default_instance_;
class RollingUpgradeStatusProto;
class RollingUpgradeStatusProtoDefaultTypeInternal;
extern RollingUpgradeStatusProtoDefaultTypeInternal _RollingUpgradeStatusProto_default_instance_;
class SnapshotDiffReportCursorProto;
class SnapshotDiffReportCursorProtoDefaultTypeInternal;
extern SnapshotDiffReportCursorProtoDefaultTypeInternal _SnapshotDiffReportCursorProto_default_instance_;
class SnapshotDiffReportEntryProto;
class SnapshotDiffReportEntryProtoDefaultTypeInternal;
extern SnapshotDiffReportEntryProtoDefaultTypeInternal _SnapshotDiffReportEntryProto_default_instance_;
class SnapshotDiffReportListingEntryProto;
class SnapshotDiffReportListingEntryProtoDefaultTypeInternal;
extern SnapshotDiffReportListingEntryProtoDefaultTypeInternal _SnapshotDiffReportListingEntryProto_default_instance_;
class SnapshotDiffReportListingProto;
class SnapshotDiffReportListingProtoDefaultTypeInternal;
extern SnapshotDiffReportListingProtoDefaultTypeInternal _SnapshotDiffReportListingProto_default_instance_;
class SnapshotDiffReportProto;
class SnapshotDiffReportProtoDefaultTypeInternal;
extern SnapshotDiffReportProtoDefaultTypeInternal _SnapshotDiffReportProto_default_instance_;
class SnapshotInfoProto;
class SnapshotInfoProtoDefaultTypeInternal;
extern SnapshotInfoProtoDefaultTypeInternal _SnapshotInfoProto_default_instance_;
class SnapshottableDirectoryListingProto;
class SnapshottableDirectoryListingProtoDefaultTypeInternal;
extern SnapshottableDirectoryListingProtoDefaultTypeInternal _SnapshottableDirectoryListingProto_default_instance_;
class SnapshottableDirectoryStatusProto;
class SnapshottableDirectoryStatusProtoDefaultTypeInternal;
extern SnapshottableDirectoryStatusProtoDefaultTypeInternal _SnapshottableDirectoryStatusProto_default_instance_;
class StorageReportProto;
class StorageReportProtoDefaultTypeInternal;
extern StorageReportProtoDefaultTypeInternal _StorageReportProto_default_instance_;
class StorageTypeQuotaInfoProto;
class StorageTypeQuotaInfoProtoDefaultTypeInternal;
extern StorageTypeQuotaInfoProtoDefaultTypeInternal _StorageTypeQuotaInfoProto_default_instance_;
class StorageTypeQuotaInfosProto;
class StorageTypeQuotaInfosProtoDefaultTypeInternal;
extern StorageTypeQuotaInfosProtoDefaultTypeInternal _StorageTypeQuotaInfosProto_default_instance_;
class StorageTypesProto;
class StorageTypesProtoDefaultTypeInternal;
extern StorageTypesProtoDefaultTypeInternal _StorageTypesProto_default_instance_;
class StorageUuidsProto;
class StorageUuidsProtoDefaultTypeInternal;
extern StorageUuidsProtoDefaultTypeInternal _StorageUuidsProto_default_instance_;
class ZoneEncryptionInfoProto;
class ZoneEncryptionInfoProtoDefaultTypeInternal;
extern ZoneEncryptionInfoProtoDefaultTypeInternal _ZoneEncryptionInfoProto_default_instance_;
}  // namespace hdfs
}  // namespace hadoop
namespace google {
namespace protobuf {
template<> ::hadoop::hdfs::AddErasureCodingPolicyResponseProto* Arena::CreateMaybeMessage<::hadoop::hdfs::AddErasureCodingPolicyResponseProto>(Arena*);
template<> ::hadoop::hdfs::BatchedDirectoryListingProto* Arena::CreateMaybeMessage<::hadoop::hdfs::BatchedDirectoryListingProto>(Arena*);
template<> ::hadoop::hdfs::BatchedListingKeyProto* Arena::CreateMaybeMessage<::hadoop::hdfs::BatchedListingKeyProto>(Arena*);
template<> ::hadoop::hdfs::BlockChecksumOptionsProto* Arena::CreateMaybeMessage<::hadoop::hdfs::BlockChecksumOptionsProto>(Arena*);
template<> ::hadoop::hdfs::BlockProto* Arena::CreateMaybeMessage<::hadoop::hdfs::BlockProto>(Arena*);
template<> ::hadoop::hdfs::BlockStoragePolicyProto* Arena::CreateMaybeMessage<::hadoop::hdfs::BlockStoragePolicyProto>(Arena*);
template<> ::hadoop::hdfs::BlockTokenSecretProto* Arena::CreateMaybeMessage<::hadoop::hdfs::BlockTokenSecretProto>(Arena*);
template<> ::hadoop::hdfs::CipherOptionProto* Arena::CreateMaybeMessage<::hadoop::hdfs::CipherOptionProto>(Arena*);
template<> ::hadoop::hdfs::ContentSummaryProto* Arena::CreateMaybeMessage<::hadoop::hdfs::ContentSummaryProto>(Arena*);
template<> ::hadoop::hdfs::CorruptFileBlocksProto* Arena::CreateMaybeMessage<::hadoop::hdfs::CorruptFileBlocksProto>(Arena*);
template<> ::hadoop::hdfs::DataEncryptionKeyProto* Arena::CreateMaybeMessage<::hadoop::hdfs::DataEncryptionKeyProto>(Arena*);
template<> ::hadoop::hdfs::DatanodeIDProto* Arena::CreateMaybeMessage<::hadoop::hdfs::DatanodeIDProto>(Arena*);
template<> ::hadoop::hdfs::DatanodeInfoProto* Arena::CreateMaybeMessage<::hadoop::hdfs::DatanodeInfoProto>(Arena*);
template<> ::hadoop::hdfs::DatanodeInfosProto* Arena::CreateMaybeMessage<::hadoop::hdfs::DatanodeInfosProto>(Arena*);
template<> ::hadoop::hdfs::DatanodeLocalInfoProto* Arena::CreateMaybeMessage<::hadoop::hdfs::DatanodeLocalInfoProto>(Arena*);
template<> ::hadoop::hdfs::DatanodeStorageProto* Arena::CreateMaybeMessage<::hadoop::hdfs::DatanodeStorageProto>(Arena*);
template<> ::hadoop::hdfs::DatanodeVolumeInfoProto* Arena::CreateMaybeMessage<::hadoop::hdfs::DatanodeVolumeInfoProto>(Arena*);
template<> ::hadoop::hdfs::DirectoryListingProto* Arena::CreateMaybeMessage<::hadoop::hdfs::DirectoryListingProto>(Arena*);
template<> ::hadoop::hdfs::ECSchemaOptionEntryProto* Arena::CreateMaybeMessage<::hadoop::hdfs::ECSchemaOptionEntryProto>(Arena*);
template<> ::hadoop::hdfs::ECSchemaProto* Arena::CreateMaybeMessage<::hadoop::hdfs::ECSchemaProto>(Arena*);
template<> ::hadoop::hdfs::ECTopologyVerifierResultProto* Arena::CreateMaybeMessage<::hadoop::hdfs::ECTopologyVerifierResultProto>(Arena*);
template<> ::hadoop::hdfs::ErasureCodingPolicyProto* Arena::CreateMaybeMessage<::hadoop::hdfs::ErasureCodingPolicyProto>(Arena*);
template<> ::hadoop::hdfs::ExtendedBlockProto* Arena::CreateMaybeMessage<::hadoop::hdfs::ExtendedBlockProto>(Arena*);
template<> ::hadoop::hdfs::FileEncryptionInfoProto* Arena::CreateMaybeMessage<::hadoop::hdfs::FileEncryptionInfoProto>(Arena*);
template<> ::hadoop::hdfs::FsServerDefaultsProto* Arena::CreateMaybeMessage<::hadoop::hdfs::FsServerDefaultsProto>(Arena*);
template<> ::hadoop::hdfs::HdfsFileStatusProto* Arena::CreateMaybeMessage<::hadoop::hdfs::HdfsFileStatusProto>(Arena*);
template<> ::hadoop::hdfs::HdfsPathHandleProto* Arena::CreateMaybeMessage<::hadoop::hdfs::HdfsPathHandleProto>(Arena*);
template<> ::hadoop::hdfs::LocatedBlockProto* Arena::CreateMaybeMessage<::hadoop::hdfs::LocatedBlockProto>(Arena*);
template<> ::hadoop::hdfs::LocatedBlocksProto* Arena::CreateMaybeMessage<::hadoop::hdfs::LocatedBlocksProto>(Arena*);
template<> ::hadoop::hdfs::PerFileEncryptionInfoProto* Arena::CreateMaybeMessage<::hadoop::hdfs::PerFileEncryptionInfoProto>(Arena*);
template<> ::hadoop::hdfs::ProvidedStorageLocationProto* Arena::CreateMaybeMessage<::hadoop::hdfs::ProvidedStorageLocationProto>(Arena*);
template<> ::hadoop::hdfs::QuotaUsageProto* Arena::CreateMaybeMessage<::hadoop::hdfs::QuotaUsageProto>(Arena*);
template<> ::hadoop::hdfs::ReencryptionInfoProto* Arena::CreateMaybeMessage<::hadoop::hdfs::ReencryptionInfoProto>(Arena*);
template<> ::hadoop::hdfs::RemoteExceptionProto* Arena::CreateMaybeMessage<::hadoop::hdfs::RemoteExceptionProto>(Arena*);
template<> ::hadoop::hdfs::RollingUpgradeStatusProto* Arena::CreateMaybeMessage<::hadoop::hdfs::RollingUpgradeStatusProto>(Arena*);
template<> ::hadoop::hdfs::SnapshotDiffReportCursorProto* Arena::CreateMaybeMessage<::hadoop::hdfs::SnapshotDiffReportCursorProto>(Arena*);
template<> ::hadoop::hdfs::SnapshotDiffReportEntryProto* Arena::CreateMaybeMessage<::hadoop::hdfs::SnapshotDiffReportEntryProto>(Arena*);
template<> ::hadoop::hdfs::SnapshotDiffReportListingEntryProto* Arena::CreateMaybeMessage<::hadoop::hdfs::SnapshotDiffReportListingEntryProto>(Arena*);
template<> ::hadoop::hdfs::SnapshotDiffReportListingProto* Arena::CreateMaybeMessage<::hadoop::hdfs::SnapshotDiffReportListingProto>(Arena*);
template<> ::hadoop::hdfs::SnapshotDiffReportProto* Arena::CreateMaybeMessage<::hadoop::hdfs::SnapshotDiffReportProto>(Arena*);
template<> ::hadoop::hdfs::SnapshotInfoProto* Arena::CreateMaybeMessage<::hadoop::hdfs::SnapshotInfoProto>(Arena*);
template<> ::hadoop::hdfs::SnapshottableDirectoryListingProto* Arena::CreateMaybeMessage<::hadoop::hdfs::SnapshottableDirectoryListingProto>(Arena*);
template<> ::hadoop::hdfs::SnapshottableDirectoryStatusProto* Arena::CreateMaybeMessage<::hadoop::hdfs::SnapshottableDirectoryStatusProto>(Arena*);
template<> ::hadoop::hdfs::StorageReportProto* Arena::CreateMaybeMessage<::hadoop::hdfs::StorageReportProto>(Arena*);
template<> ::hadoop::hdfs::StorageTypeQuotaInfoProto* Arena::CreateMaybeMessage<::hadoop::hdfs::StorageTypeQuotaInfoProto>(Arena*);
template<> ::hadoop::hdfs::StorageTypeQuotaInfosProto* Arena::CreateMaybeMessage<::hadoop::hdfs::StorageTypeQuotaInfosProto>(Arena*);
template<> ::hadoop::hdfs::StorageTypesProto* Arena::CreateMaybeMessage<::hadoop::hdfs::StorageTypesProto>(Arena*);
template<> ::hadoop::hdfs::StorageUuidsProto* Arena::CreateMaybeMessage<::hadoop::hdfs::StorageUuidsProto>(Arena*);
template<> ::hadoop::hdfs::ZoneEncryptionInfoProto* Arena::CreateMaybeMessage<::hadoop::hdfs::ZoneEncryptionInfoProto>(Arena*);
}  // namespace protobuf
}  // namespace google
namespace hadoop {
namespace hdfs {

enum DatanodeInfoProto_AdminState {
  DatanodeInfoProto_AdminState_NORMAL = 0,
  DatanodeInfoProto_AdminState_DECOMMISSION_INPROGRESS = 1,
  DatanodeInfoProto_AdminState_DECOMMISSIONED = 2,
  DatanodeInfoProto_AdminState_ENTERING_MAINTENANCE = 3,
  DatanodeInfoProto_AdminState_IN_MAINTENANCE = 4
};
bool DatanodeInfoProto_AdminState_IsValid(int value);
const DatanodeInfoProto_AdminState DatanodeInfoProto_AdminState_AdminState_MIN = DatanodeInfoProto_AdminState_NORMAL;
const DatanodeInfoProto_AdminState DatanodeInfoProto_AdminState_AdminState_MAX = DatanodeInfoProto_AdminState_IN_MAINTENANCE;
const int DatanodeInfoProto_AdminState_AdminState_ARRAYSIZE = DatanodeInfoProto_AdminState_AdminState_MAX + 1;

const ::google::protobuf::EnumDescriptor* DatanodeInfoProto_AdminState_descriptor();
inline const ::std::string& DatanodeInfoProto_AdminState_Name(DatanodeInfoProto_AdminState value) {
  return ::google::protobuf::internal::NameOfEnum(
    DatanodeInfoProto_AdminState_descriptor(), value);
}
inline bool DatanodeInfoProto_AdminState_Parse(
    const ::std::string& name, DatanodeInfoProto_AdminState* value) {
  return ::google::protobuf::internal::ParseNamedEnum<DatanodeInfoProto_AdminState>(
    DatanodeInfoProto_AdminState_descriptor(), name, value);
}
enum DatanodeStorageProto_StorageState {
  DatanodeStorageProto_StorageState_NORMAL = 0,
  DatanodeStorageProto_StorageState_READ_ONLY_SHARED = 1
};
bool DatanodeStorageProto_StorageState_IsValid(int value);
const DatanodeStorageProto_StorageState DatanodeStorageProto_StorageState_StorageState_MIN = DatanodeStorageProto_StorageState_NORMAL;
const DatanodeStorageProto_StorageState DatanodeStorageProto_StorageState_StorageState_MAX = DatanodeStorageProto_StorageState_READ_ONLY_SHARED;
const int DatanodeStorageProto_StorageState_StorageState_ARRAYSIZE = DatanodeStorageProto_StorageState_StorageState_MAX + 1;

const ::google::protobuf::EnumDescriptor* DatanodeStorageProto_StorageState_descriptor();
inline const ::std::string& DatanodeStorageProto_StorageState_Name(DatanodeStorageProto_StorageState value) {
  return ::google::protobuf::internal::NameOfEnum(
    DatanodeStorageProto_StorageState_descriptor(), value);
}
inline bool DatanodeStorageProto_StorageState_Parse(
    const ::std::string& name, DatanodeStorageProto_StorageState* value) {
  return ::google::protobuf::internal::ParseNamedEnum<DatanodeStorageProto_StorageState>(
    DatanodeStorageProto_StorageState_descriptor(), name, value);
}
enum HdfsFileStatusProto_FileType {
  HdfsFileStatusProto_FileType_IS_DIR = 1,
  HdfsFileStatusProto_FileType_IS_FILE = 2,
  HdfsFileStatusProto_FileType_IS_SYMLINK = 3
};
bool HdfsFileStatusProto_FileType_IsValid(int value);
const HdfsFileStatusProto_FileType HdfsFileStatusProto_FileType_FileType_MIN = HdfsFileStatusProto_FileType_IS_DIR;
const HdfsFileStatusProto_FileType HdfsFileStatusProto_FileType_FileType_MAX = HdfsFileStatusProto_FileType_IS_SYMLINK;
const int HdfsFileStatusProto_FileType_FileType_ARRAYSIZE = HdfsFileStatusProto_FileType_FileType_MAX + 1;

const ::google::protobuf::EnumDescriptor* HdfsFileStatusProto_FileType_descriptor();
inline const ::std::string& HdfsFileStatusProto_FileType_Name(HdfsFileStatusProto_FileType value) {
  return ::google::protobuf::internal::NameOfEnum(
    HdfsFileStatusProto_FileType_descriptor(), value);
}
inline bool HdfsFileStatusProto_FileType_Parse(
    const ::std::string& name, HdfsFileStatusProto_FileType* value) {
  return ::google::protobuf::internal::ParseNamedEnum<HdfsFileStatusProto_FileType>(
    HdfsFileStatusProto_FileType_descriptor(), name, value);
}
enum HdfsFileStatusProto_Flags {
  HdfsFileStatusProto_Flags_HAS_ACL = 1,
  HdfsFileStatusProto_Flags_HAS_CRYPT = 2,
  HdfsFileStatusProto_Flags_HAS_EC = 4,
  HdfsFileStatusProto_Flags_SNAPSHOT_ENABLED = 8
};
bool HdfsFileStatusProto_Flags_IsValid(int value);
const HdfsFileStatusProto_Flags HdfsFileStatusProto_Flags_Flags_MIN = HdfsFileStatusProto_Flags_HAS_ACL;
const HdfsFileStatusProto_Flags HdfsFileStatusProto_Flags_Flags_MAX = HdfsFileStatusProto_Flags_SNAPSHOT_ENABLED;
const int HdfsFileStatusProto_Flags_Flags_ARRAYSIZE = HdfsFileStatusProto_Flags_Flags_MAX + 1;

const ::google::protobuf::EnumDescriptor* HdfsFileStatusProto_Flags_descriptor();
inline const ::std::string& HdfsFileStatusProto_Flags_Name(HdfsFileStatusProto_Flags value) {
  return ::google::protobuf::internal::NameOfEnum(
    HdfsFileStatusProto_Flags_descriptor(), value);
}
inline bool HdfsFileStatusProto_Flags_Parse(
    const ::std::string& name, HdfsFileStatusProto_Flags* value) {
  return ::google::protobuf::internal::ParseNamedEnum<HdfsFileStatusProto_Flags>(
    HdfsFileStatusProto_Flags_descriptor(), name, value);
}
enum StorageTypeProto {
  DISK = 1,
  SSD = 2,
  ARCHIVE = 3,
  RAM_DISK = 4,
  PROVIDED = 5
};
bool StorageTypeProto_IsValid(int value);
const StorageTypeProto StorageTypeProto_MIN = DISK;
const StorageTypeProto StorageTypeProto_MAX = PROVIDED;
const int StorageTypeProto_ARRAYSIZE = StorageTypeProto_MAX + 1;

const ::google::protobuf::EnumDescriptor* StorageTypeProto_descriptor();
inline const ::std::string& StorageTypeProto_Name(StorageTypeProto value) {
  return ::google::protobuf::internal::NameOfEnum(
    StorageTypeProto_descriptor(), value);
}
inline bool StorageTypeProto_Parse(
    const ::std::string& name, StorageTypeProto* value) {
  return ::google::protobuf::internal::ParseNamedEnum<StorageTypeProto>(
    StorageTypeProto_descriptor(), name, value);
}
enum BlockTypeProto {
  CONTIGUOUS = 0,
  STRIPED = 1
};
bool BlockTypeProto_IsValid(int value);
const BlockTypeProto BlockTypeProto_MIN = CONTIGUOUS;
const BlockTypeProto BlockTypeProto_MAX = STRIPED;
const int BlockTypeProto_ARRAYSIZE = BlockTypeProto_MAX + 1;

const ::google::protobuf::EnumDescriptor* BlockTypeProto_descriptor();
inline const ::std::string& BlockTypeProto_Name(BlockTypeProto value) {
  return ::google::protobuf::internal::NameOfEnum(
    BlockTypeProto_descriptor(), value);
}
inline bool BlockTypeProto_Parse(
    const ::std::string& name, BlockTypeProto* value) {
  return ::google::protobuf::internal::ParseNamedEnum<BlockTypeProto>(
    BlockTypeProto_descriptor(), name, value);
}
enum CipherSuiteProto {
  UNKNOWN = 1,
  AES_CTR_NOPADDING = 2
};
bool CipherSuiteProto_IsValid(int value);
const CipherSuiteProto CipherSuiteProto_MIN = UNKNOWN;
const CipherSuiteProto CipherSuiteProto_MAX = AES_CTR_NOPADDING;
const int CipherSuiteProto_ARRAYSIZE = CipherSuiteProto_MAX + 1;

const ::google::protobuf::EnumDescriptor* CipherSuiteProto_descriptor();
inline const ::std::string& CipherSuiteProto_Name(CipherSuiteProto value) {
  return ::google::protobuf::internal::NameOfEnum(
    CipherSuiteProto_descriptor(), value);
}
inline bool CipherSuiteProto_Parse(
    const ::std::string& name, CipherSuiteProto* value) {
  return ::google::protobuf::internal::ParseNamedEnum<CipherSuiteProto>(
    CipherSuiteProto_descriptor(), name, value);
}
enum CryptoProtocolVersionProto {
  UNKNOWN_PROTOCOL_VERSION = 1,
  ENCRYPTION_ZONES = 2
};
bool CryptoProtocolVersionProto_IsValid(int value);
const CryptoProtocolVersionProto CryptoProtocolVersionProto_MIN = UNKNOWN_PROTOCOL_VERSION;
const CryptoProtocolVersionProto CryptoProtocolVersionProto_MAX = ENCRYPTION_ZONES;
const int CryptoProtocolVersionProto_ARRAYSIZE = CryptoProtocolVersionProto_MAX + 1;

const ::google::protobuf::EnumDescriptor* CryptoProtocolVersionProto_descriptor();
inline const ::std::string& CryptoProtocolVersionProto_Name(CryptoProtocolVersionProto value) {
  return ::google::protobuf::internal::NameOfEnum(
    CryptoProtocolVersionProto_descriptor(), value);
}
inline bool CryptoProtocolVersionProto_Parse(
    const ::std::string& name, CryptoProtocolVersionProto* value) {
  return ::google::protobuf::internal::ParseNamedEnum<CryptoProtocolVersionProto>(
    CryptoProtocolVersionProto_descriptor(), name, value);
}
enum ErasureCodingPolicyState {
  DISABLED = 1,
  ENABLED = 2,
  REMOVED = 3
};
bool ErasureCodingPolicyState_IsValid(int value);
const ErasureCodingPolicyState ErasureCodingPolicyState_MIN = DISABLED;
const ErasureCodingPolicyState ErasureCodingPolicyState_MAX = REMOVED;
const int ErasureCodingPolicyState_ARRAYSIZE = ErasureCodingPolicyState_MAX + 1;

const ::google::protobuf::EnumDescriptor* ErasureCodingPolicyState_descriptor();
inline const ::std::string& ErasureCodingPolicyState_Name(ErasureCodingPolicyState value) {
  return ::google::protobuf::internal::NameOfEnum(
    ErasureCodingPolicyState_descriptor(), value);
}
inline bool ErasureCodingPolicyState_Parse(
    const ::std::string& name, ErasureCodingPolicyState* value) {
  return ::google::protobuf::internal::ParseNamedEnum<ErasureCodingPolicyState>(
    ErasureCodingPolicyState_descriptor(), name, value);
}
enum ChecksumTypeProto {
  CHECKSUM_NULL = 0,
  CHECKSUM_CRC32 = 1,
  CHECKSUM_CRC32C = 2
};
bool ChecksumTypeProto_IsValid(int value);
const ChecksumTypeProto ChecksumTypeProto_MIN = CHECKSUM_NULL;
const ChecksumTypeProto ChecksumTypeProto_MAX = CHECKSUM_CRC32C;
const int ChecksumTypeProto_ARRAYSIZE = ChecksumTypeProto_MAX + 1;

const ::google::protobuf::EnumDescriptor* ChecksumTypeProto_descriptor();
inline const ::std::string& ChecksumTypeProto_Name(ChecksumTypeProto value) {
  return ::google::protobuf::internal::NameOfEnum(
    ChecksumTypeProto_descriptor(), value);
}
inline bool ChecksumTypeProto_Parse(
    const ::std::string& name, ChecksumTypeProto* value) {
  return ::google::protobuf::internal::ParseNamedEnum<ChecksumTypeProto>(
    ChecksumTypeProto_descriptor(), name, value);
}
enum BlockChecksumTypeProto {
  MD5CRC = 1,
  COMPOSITE_CRC = 2
};
bool BlockChecksumTypeProto_IsValid(int value);
const BlockChecksumTypeProto BlockChecksumTypeProto_MIN = MD5CRC;
const BlockChecksumTypeProto BlockChecksumTypeProto_MAX = COMPOSITE_CRC;
const int BlockChecksumTypeProto_ARRAYSIZE = BlockChecksumTypeProto_MAX + 1;

const ::google::protobuf::EnumDescriptor* BlockChecksumTypeProto_descriptor();
inline const ::std::string& BlockChecksumTypeProto_Name(BlockChecksumTypeProto value) {
  return ::google::protobuf::internal::NameOfEnum(
    BlockChecksumTypeProto_descriptor(), value);
}
inline bool BlockChecksumTypeProto_Parse(
    const ::std::string& name, BlockChecksumTypeProto* value) {
  return ::google::protobuf::internal::ParseNamedEnum<BlockChecksumTypeProto>(
    BlockChecksumTypeProto_descriptor(), name, value);
}
enum AccessModeProto {
  READ = 1,
  WRITE = 2,
  COPY = 3,
  REPLACE = 4
};
bool AccessModeProto_IsValid(int value);
const AccessModeProto AccessModeProto_MIN = READ;
const AccessModeProto AccessModeProto_MAX = REPLACE;
const int AccessModeProto_ARRAYSIZE = AccessModeProto_MAX + 1;

const ::google::protobuf::EnumDescriptor* AccessModeProto_descriptor();
inline const ::std::string& AccessModeProto_Name(AccessModeProto value) {
  return ::google::protobuf::internal::NameOfEnum(
    AccessModeProto_descriptor(), value);
}
inline bool AccessModeProto_Parse(
    const ::std::string& name, AccessModeProto* value) {
  return ::google::protobuf::internal::ParseNamedEnum<AccessModeProto>(
    AccessModeProto_descriptor(), name, value);
}
// ===================================================================

class ExtendedBlockProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.ExtendedBlockProto) */ {
 public:
  ExtendedBlockProto();
  virtual ~ExtendedBlockProto();

  ExtendedBlockProto(const ExtendedBlockProto& from);

  inline ExtendedBlockProto& operator=(const ExtendedBlockProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  ExtendedBlockProto(ExtendedBlockProto&& from) noexcept
    : ExtendedBlockProto() {
    *this = ::std::move(from);
  }

  inline ExtendedBlockProto& operator=(ExtendedBlockProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ExtendedBlockProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const ExtendedBlockProto* internal_default_instance() {
    return reinterpret_cast<const ExtendedBlockProto*>(
               &_ExtendedBlockProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    0;

  void Swap(ExtendedBlockProto* other);
  friend void swap(ExtendedBlockProto& a, ExtendedBlockProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline ExtendedBlockProto* New() const final {
    return CreateMaybeMessage<ExtendedBlockProto>(NULL);
  }

  ExtendedBlockProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<ExtendedBlockProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const ExtendedBlockProto& from);
  void MergeFrom(const ExtendedBlockProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(ExtendedBlockProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required string poolId = 1;
  bool has_poolid() const;
  void clear_poolid();
  static const int kPoolIdFieldNumber = 1;
  const ::std::string& poolid() const;
  void set_poolid(const ::std::string& value);
  #if LANG_CXX11
  void set_poolid(::std::string&& value);
  #endif
  void set_poolid(const char* value);
  void set_poolid(const char* value, size_t size);
  ::std::string* mutable_poolid();
  ::std::string* release_poolid();
  void set_allocated_poolid(::std::string* poolid);

  // required uint64 blockId = 2;
  bool has_blockid() const;
  void clear_blockid();
  static const int kBlockIdFieldNumber = 2;
  ::google::protobuf::uint64 blockid() const;
  void set_blockid(::google::protobuf::uint64 value);

  // required uint64 generationStamp = 3;
  bool has_generationstamp() const;
  void clear_generationstamp();
  static const int kGenerationStampFieldNumber = 3;
  ::google::protobuf::uint64 generationstamp() const;
  void set_generationstamp(::google::protobuf::uint64 value);

  // optional uint64 numBytes = 4 [default = 0];
  bool has_numbytes() const;
  void clear_numbytes();
  static const int kNumBytesFieldNumber = 4;
  ::google::protobuf::uint64 numbytes() const;
  void set_numbytes(::google::protobuf::uint64 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.ExtendedBlockProto)
 private:
  void set_has_poolid();
  void clear_has_poolid();
  void set_has_blockid();
  void clear_has_blockid();
  void set_has_generationstamp();
  void clear_has_generationstamp();
  void set_has_numbytes();
  void clear_has_numbytes();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr poolid_;
  ::google::protobuf::uint64 blockid_;
  ::google::protobuf::uint64 generationstamp_;
  ::google::protobuf::uint64 numbytes_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class ProvidedStorageLocationProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.ProvidedStorageLocationProto) */ {
 public:
  ProvidedStorageLocationProto();
  virtual ~ProvidedStorageLocationProto();

  ProvidedStorageLocationProto(const ProvidedStorageLocationProto& from);

  inline ProvidedStorageLocationProto& operator=(const ProvidedStorageLocationProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  ProvidedStorageLocationProto(ProvidedStorageLocationProto&& from) noexcept
    : ProvidedStorageLocationProto() {
    *this = ::std::move(from);
  }

  inline ProvidedStorageLocationProto& operator=(ProvidedStorageLocationProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ProvidedStorageLocationProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const ProvidedStorageLocationProto* internal_default_instance() {
    return reinterpret_cast<const ProvidedStorageLocationProto*>(
               &_ProvidedStorageLocationProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    1;

  void Swap(ProvidedStorageLocationProto* other);
  friend void swap(ProvidedStorageLocationProto& a, ProvidedStorageLocationProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline ProvidedStorageLocationProto* New() const final {
    return CreateMaybeMessage<ProvidedStorageLocationProto>(NULL);
  }

  ProvidedStorageLocationProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<ProvidedStorageLocationProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const ProvidedStorageLocationProto& from);
  void MergeFrom(const ProvidedStorageLocationProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(ProvidedStorageLocationProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required string path = 1;
  bool has_path() const;
  void clear_path();
  static const int kPathFieldNumber = 1;
  const ::std::string& path() const;
  void set_path(const ::std::string& value);
  #if LANG_CXX11
  void set_path(::std::string&& value);
  #endif
  void set_path(const char* value);
  void set_path(const char* value, size_t size);
  ::std::string* mutable_path();
  ::std::string* release_path();
  void set_allocated_path(::std::string* path);

  // required bytes nonce = 4;
  bool has_nonce() const;
  void clear_nonce();
  static const int kNonceFieldNumber = 4;
  const ::std::string& nonce() const;
  void set_nonce(const ::std::string& value);
  #if LANG_CXX11
  void set_nonce(::std::string&& value);
  #endif
  void set_nonce(const char* value);
  void set_nonce(const void* value, size_t size);
  ::std::string* mutable_nonce();
  ::std::string* release_nonce();
  void set_allocated_nonce(::std::string* nonce);

  // required int64 offset = 2;
  bool has_offset() const;
  void clear_offset();
  static const int kOffsetFieldNumber = 2;
  ::google::protobuf::int64 offset() const;
  void set_offset(::google::protobuf::int64 value);

  // required int64 length = 3;
  bool has_length() const;
  void clear_length();
  static const int kLengthFieldNumber = 3;
  ::google::protobuf::int64 length() const;
  void set_length(::google::protobuf::int64 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.ProvidedStorageLocationProto)
 private:
  void set_has_path();
  void clear_has_path();
  void set_has_offset();
  void clear_has_offset();
  void set_has_length();
  void clear_has_length();
  void set_has_nonce();
  void clear_has_nonce();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr path_;
  ::google::protobuf::internal::ArenaStringPtr nonce_;
  ::google::protobuf::int64 offset_;
  ::google::protobuf::int64 length_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class DatanodeIDProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.DatanodeIDProto) */ {
 public:
  DatanodeIDProto();
  virtual ~DatanodeIDProto();

  DatanodeIDProto(const DatanodeIDProto& from);

  inline DatanodeIDProto& operator=(const DatanodeIDProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  DatanodeIDProto(DatanodeIDProto&& from) noexcept
    : DatanodeIDProto() {
    *this = ::std::move(from);
  }

  inline DatanodeIDProto& operator=(DatanodeIDProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const DatanodeIDProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const DatanodeIDProto* internal_default_instance() {
    return reinterpret_cast<const DatanodeIDProto*>(
               &_DatanodeIDProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    2;

  void Swap(DatanodeIDProto* other);
  friend void swap(DatanodeIDProto& a, DatanodeIDProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline DatanodeIDProto* New() const final {
    return CreateMaybeMessage<DatanodeIDProto>(NULL);
  }

  DatanodeIDProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<DatanodeIDProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const DatanodeIDProto& from);
  void MergeFrom(const DatanodeIDProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(DatanodeIDProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required string ipAddr = 1;
  bool has_ipaddr() const;
  void clear_ipaddr();
  static const int kIpAddrFieldNumber = 1;
  const ::std::string& ipaddr() const;
  void set_ipaddr(const ::std::string& value);
  #if LANG_CXX11
  void set_ipaddr(::std::string&& value);
  #endif
  void set_ipaddr(const char* value);
  void set_ipaddr(const char* value, size_t size);
  ::std::string* mutable_ipaddr();
  ::std::string* release_ipaddr();
  void set_allocated_ipaddr(::std::string* ipaddr);

  // required string hostName = 2;
  bool has_hostname() const;
  void clear_hostname();
  static const int kHostNameFieldNumber = 2;
  const ::std::string& hostname() const;
  void set_hostname(const ::std::string& value);
  #if LANG_CXX11
  void set_hostname(::std::string&& value);
  #endif
  void set_hostname(const char* value);
  void set_hostname(const char* value, size_t size);
  ::std::string* mutable_hostname();
  ::std::string* release_hostname();
  void set_allocated_hostname(::std::string* hostname);

  // required string datanodeUuid = 3;
  bool has_datanodeuuid() const;
  void clear_datanodeuuid();
  static const int kDatanodeUuidFieldNumber = 3;
  const ::std::string& datanodeuuid() const;
  void set_datanodeuuid(const ::std::string& value);
  #if LANG_CXX11
  void set_datanodeuuid(::std::string&& value);
  #endif
  void set_datanodeuuid(const char* value);
  void set_datanodeuuid(const char* value, size_t size);
  ::std::string* mutable_datanodeuuid();
  ::std::string* release_datanodeuuid();
  void set_allocated_datanodeuuid(::std::string* datanodeuuid);

  // required uint32 xferPort = 4;
  bool has_xferport() const;
  void clear_xferport();
  static const int kXferPortFieldNumber = 4;
  ::google::protobuf::uint32 xferport() const;
  void set_xferport(::google::protobuf::uint32 value);

  // required uint32 infoPort = 5;
  bool has_infoport() const;
  void clear_infoport();
  static const int kInfoPortFieldNumber = 5;
  ::google::protobuf::uint32 infoport() const;
  void set_infoport(::google::protobuf::uint32 value);

  // required uint32 ipcPort = 6;
  bool has_ipcport() const;
  void clear_ipcport();
  static const int kIpcPortFieldNumber = 6;
  ::google::protobuf::uint32 ipcport() const;
  void set_ipcport(::google::protobuf::uint32 value);

  // optional uint32 infoSecurePort = 7 [default = 0];
  bool has_infosecureport() const;
  void clear_infosecureport();
  static const int kInfoSecurePortFieldNumber = 7;
  ::google::protobuf::uint32 infosecureport() const;
  void set_infosecureport(::google::protobuf::uint32 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.DatanodeIDProto)
 private:
  void set_has_ipaddr();
  void clear_has_ipaddr();
  void set_has_hostname();
  void clear_has_hostname();
  void set_has_datanodeuuid();
  void clear_has_datanodeuuid();
  void set_has_xferport();
  void clear_has_xferport();
  void set_has_infoport();
  void clear_has_infoport();
  void set_has_ipcport();
  void clear_has_ipcport();
  void set_has_infosecureport();
  void clear_has_infosecureport();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr ipaddr_;
  ::google::protobuf::internal::ArenaStringPtr hostname_;
  ::google::protobuf::internal::ArenaStringPtr datanodeuuid_;
  ::google::protobuf::uint32 xferport_;
  ::google::protobuf::uint32 infoport_;
  ::google::protobuf::uint32 ipcport_;
  ::google::protobuf::uint32 infosecureport_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class DatanodeLocalInfoProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.DatanodeLocalInfoProto) */ {
 public:
  DatanodeLocalInfoProto();
  virtual ~DatanodeLocalInfoProto();

  DatanodeLocalInfoProto(const DatanodeLocalInfoProto& from);

  inline DatanodeLocalInfoProto& operator=(const DatanodeLocalInfoProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  DatanodeLocalInfoProto(DatanodeLocalInfoProto&& from) noexcept
    : DatanodeLocalInfoProto() {
    *this = ::std::move(from);
  }

  inline DatanodeLocalInfoProto& operator=(DatanodeLocalInfoProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const DatanodeLocalInfoProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const DatanodeLocalInfoProto* internal_default_instance() {
    return reinterpret_cast<const DatanodeLocalInfoProto*>(
               &_DatanodeLocalInfoProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    3;

  void Swap(DatanodeLocalInfoProto* other);
  friend void swap(DatanodeLocalInfoProto& a, DatanodeLocalInfoProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline DatanodeLocalInfoProto* New() const final {
    return CreateMaybeMessage<DatanodeLocalInfoProto>(NULL);
  }

  DatanodeLocalInfoProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<DatanodeLocalInfoProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const DatanodeLocalInfoProto& from);
  void MergeFrom(const DatanodeLocalInfoProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(DatanodeLocalInfoProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required string softwareVersion = 1;
  bool has_softwareversion() const;
  void clear_softwareversion();
  static const int kSoftwareVersionFieldNumber = 1;
  const ::std::string& softwareversion() const;
  void set_softwareversion(const ::std::string& value);
  #if LANG_CXX11
  void set_softwareversion(::std::string&& value);
  #endif
  void set_softwareversion(const char* value);
  void set_softwareversion(const char* value, size_t size);
  ::std::string* mutable_softwareversion();
  ::std::string* release_softwareversion();
  void set_allocated_softwareversion(::std::string* softwareversion);

  // required string configVersion = 2;
  bool has_configversion() const;
  void clear_configversion();
  static const int kConfigVersionFieldNumber = 2;
  const ::std::string& configversion() const;
  void set_configversion(const ::std::string& value);
  #if LANG_CXX11
  void set_configversion(::std::string&& value);
  #endif
  void set_configversion(const char* value);
  void set_configversion(const char* value, size_t size);
  ::std::string* mutable_configversion();
  ::std::string* release_configversion();
  void set_allocated_configversion(::std::string* configversion);

  // required uint64 uptime = 3;
  bool has_uptime() const;
  void clear_uptime();
  static const int kUptimeFieldNumber = 3;
  ::google::protobuf::uint64 uptime() const;
  void set_uptime(::google::protobuf::uint64 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.DatanodeLocalInfoProto)
 private:
  void set_has_softwareversion();
  void clear_has_softwareversion();
  void set_has_configversion();
  void clear_has_configversion();
  void set_has_uptime();
  void clear_has_uptime();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr softwareversion_;
  ::google::protobuf::internal::ArenaStringPtr configversion_;
  ::google::protobuf::uint64 uptime_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class DatanodeVolumeInfoProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.DatanodeVolumeInfoProto) */ {
 public:
  DatanodeVolumeInfoProto();
  virtual ~DatanodeVolumeInfoProto();

  DatanodeVolumeInfoProto(const DatanodeVolumeInfoProto& from);

  inline DatanodeVolumeInfoProto& operator=(const DatanodeVolumeInfoProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  DatanodeVolumeInfoProto(DatanodeVolumeInfoProto&& from) noexcept
    : DatanodeVolumeInfoProto() {
    *this = ::std::move(from);
  }

  inline DatanodeVolumeInfoProto& operator=(DatanodeVolumeInfoProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const DatanodeVolumeInfoProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const DatanodeVolumeInfoProto* internal_default_instance() {
    return reinterpret_cast<const DatanodeVolumeInfoProto*>(
               &_DatanodeVolumeInfoProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    4;

  void Swap(DatanodeVolumeInfoProto* other);
  friend void swap(DatanodeVolumeInfoProto& a, DatanodeVolumeInfoProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline DatanodeVolumeInfoProto* New() const final {
    return CreateMaybeMessage<DatanodeVolumeInfoProto>(NULL);
  }

  DatanodeVolumeInfoProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<DatanodeVolumeInfoProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const DatanodeVolumeInfoProto& from);
  void MergeFrom(const DatanodeVolumeInfoProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(DatanodeVolumeInfoProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required string path = 1;
  bool has_path() const;
  void clear_path();
  static const int kPathFieldNumber = 1;
  const ::std::string& path() const;
  void set_path(const ::std::string& value);
  #if LANG_CXX11
  void set_path(::std::string&& value);
  #endif
  void set_path(const char* value);
  void set_path(const char* value, size_t size);
  ::std::string* mutable_path();
  ::std::string* release_path();
  void set_allocated_path(::std::string* path);

  // required uint64 usedSpace = 3;
  bool has_usedspace() const;
  void clear_usedspace();
  static const int kUsedSpaceFieldNumber = 3;
  ::google::protobuf::uint64 usedspace() const;
  void set_usedspace(::google::protobuf::uint64 value);

  // required uint64 freeSpace = 4;
  bool has_freespace() const;
  void clear_freespace();
  static const int kFreeSpaceFieldNumber = 4;
  ::google::protobuf::uint64 freespace() const;
  void set_freespace(::google::protobuf::uint64 value);

  // required uint64 reservedSpace = 5;
  bool has_reservedspace() const;
  void clear_reservedspace();
  static const int kReservedSpaceFieldNumber = 5;
  ::google::protobuf::uint64 reservedspace() const;
  void set_reservedspace(::google::protobuf::uint64 value);

  // required uint64 reservedSpaceForReplicas = 6;
  bool has_reservedspaceforreplicas() const;
  void clear_reservedspaceforreplicas();
  static const int kReservedSpaceForReplicasFieldNumber = 6;
  ::google::protobuf::uint64 reservedspaceforreplicas() const;
  void set_reservedspaceforreplicas(::google::protobuf::uint64 value);

  // required uint64 numBlocks = 7;
  bool has_numblocks() const;
  void clear_numblocks();
  static const int kNumBlocksFieldNumber = 7;
  ::google::protobuf::uint64 numblocks() const;
  void set_numblocks(::google::protobuf::uint64 value);

  // required .hadoop.hdfs.StorageTypeProto storageType = 2;
  bool has_storagetype() const;
  void clear_storagetype();
  static const int kStorageTypeFieldNumber = 2;
  ::hadoop::hdfs::StorageTypeProto storagetype() const;
  void set_storagetype(::hadoop::hdfs::StorageTypeProto value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.DatanodeVolumeInfoProto)
 private:
  void set_has_path();
  void clear_has_path();
  void set_has_storagetype();
  void clear_has_storagetype();
  void set_has_usedspace();
  void clear_has_usedspace();
  void set_has_freespace();
  void clear_has_freespace();
  void set_has_reservedspace();
  void clear_has_reservedspace();
  void set_has_reservedspaceforreplicas();
  void clear_has_reservedspaceforreplicas();
  void set_has_numblocks();
  void clear_has_numblocks();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr path_;
  ::google::protobuf::uint64 usedspace_;
  ::google::protobuf::uint64 freespace_;
  ::google::protobuf::uint64 reservedspace_;
  ::google::protobuf::uint64 reservedspaceforreplicas_;
  ::google::protobuf::uint64 numblocks_;
  int storagetype_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class DatanodeInfosProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.DatanodeInfosProto) */ {
 public:
  DatanodeInfosProto();
  virtual ~DatanodeInfosProto();

  DatanodeInfosProto(const DatanodeInfosProto& from);

  inline DatanodeInfosProto& operator=(const DatanodeInfosProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  DatanodeInfosProto(DatanodeInfosProto&& from) noexcept
    : DatanodeInfosProto() {
    *this = ::std::move(from);
  }

  inline DatanodeInfosProto& operator=(DatanodeInfosProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const DatanodeInfosProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const DatanodeInfosProto* internal_default_instance() {
    return reinterpret_cast<const DatanodeInfosProto*>(
               &_DatanodeInfosProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    5;

  void Swap(DatanodeInfosProto* other);
  friend void swap(DatanodeInfosProto& a, DatanodeInfosProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline DatanodeInfosProto* New() const final {
    return CreateMaybeMessage<DatanodeInfosProto>(NULL);
  }

  DatanodeInfosProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<DatanodeInfosProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const DatanodeInfosProto& from);
  void MergeFrom(const DatanodeInfosProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(DatanodeInfosProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.hdfs.DatanodeInfoProto datanodes = 1;
  int datanodes_size() const;
  void clear_datanodes();
  static const int kDatanodesFieldNumber = 1;
  ::hadoop::hdfs::DatanodeInfoProto* mutable_datanodes(int index);
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::DatanodeInfoProto >*
      mutable_datanodes();
  const ::hadoop::hdfs::DatanodeInfoProto& datanodes(int index) const;
  ::hadoop::hdfs::DatanodeInfoProto* add_datanodes();
  const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::DatanodeInfoProto >&
      datanodes() const;

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.DatanodeInfosProto)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::DatanodeInfoProto > datanodes_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class DatanodeInfoProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.DatanodeInfoProto) */ {
 public:
  DatanodeInfoProto();
  virtual ~DatanodeInfoProto();

  DatanodeInfoProto(const DatanodeInfoProto& from);

  inline DatanodeInfoProto& operator=(const DatanodeInfoProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  DatanodeInfoProto(DatanodeInfoProto&& from) noexcept
    : DatanodeInfoProto() {
    *this = ::std::move(from);
  }

  inline DatanodeInfoProto& operator=(DatanodeInfoProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const DatanodeInfoProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const DatanodeInfoProto* internal_default_instance() {
    return reinterpret_cast<const DatanodeInfoProto*>(
               &_DatanodeInfoProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    6;

  void Swap(DatanodeInfoProto* other);
  friend void swap(DatanodeInfoProto& a, DatanodeInfoProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline DatanodeInfoProto* New() const final {
    return CreateMaybeMessage<DatanodeInfoProto>(NULL);
  }

  DatanodeInfoProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<DatanodeInfoProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const DatanodeInfoProto& from);
  void MergeFrom(const DatanodeInfoProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(DatanodeInfoProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  typedef DatanodeInfoProto_AdminState AdminState;
  static const AdminState NORMAL =
    DatanodeInfoProto_AdminState_NORMAL;
  static const AdminState DECOMMISSION_INPROGRESS =
    DatanodeInfoProto_AdminState_DECOMMISSION_INPROGRESS;
  static const AdminState DECOMMISSIONED =
    DatanodeInfoProto_AdminState_DECOMMISSIONED;
  static const AdminState ENTERING_MAINTENANCE =
    DatanodeInfoProto_AdminState_ENTERING_MAINTENANCE;
  static const AdminState IN_MAINTENANCE =
    DatanodeInfoProto_AdminState_IN_MAINTENANCE;
  static inline bool AdminState_IsValid(int value) {
    return DatanodeInfoProto_AdminState_IsValid(value);
  }
  static const AdminState AdminState_MIN =
    DatanodeInfoProto_AdminState_AdminState_MIN;
  static const AdminState AdminState_MAX =
    DatanodeInfoProto_AdminState_AdminState_MAX;
  static const int AdminState_ARRAYSIZE =
    DatanodeInfoProto_AdminState_AdminState_ARRAYSIZE;
  static inline const ::google::protobuf::EnumDescriptor*
  AdminState_descriptor() {
    return DatanodeInfoProto_AdminState_descriptor();
  }
  static inline const ::std::string& AdminState_Name(AdminState value) {
    return DatanodeInfoProto_AdminState_Name(value);
  }
  static inline bool AdminState_Parse(const ::std::string& name,
      AdminState* value) {
    return DatanodeInfoProto_AdminState_Parse(name, value);
  }

  // accessors -------------------------------------------------------

  // optional string location = 8;
  bool has_location() const;
  void clear_location();
  static const int kLocationFieldNumber = 8;
  const ::std::string& location() const;
  void set_location(const ::std::string& value);
  #if LANG_CXX11
  void set_location(::std::string&& value);
  #endif
  void set_location(const char* value);
  void set_location(const char* value, size_t size);
  ::std::string* mutable_location();
  ::std::string* release_location();
  void set_allocated_location(::std::string* location);

  // optional string upgradeDomain = 14;
  bool has_upgradedomain() const;
  void clear_upgradedomain();
  static const int kUpgradeDomainFieldNumber = 14;
  const ::std::string& upgradedomain() const;
  void set_upgradedomain(const ::std::string& value);
  #if LANG_CXX11
  void set_upgradedomain(::std::string&& value);
  #endif
  void set_upgradedomain(const char* value);
  void set_upgradedomain(const char* value, size_t size);
  ::std::string* mutable_upgradedomain();
  ::std::string* release_upgradedomain();
  void set_allocated_upgradedomain(::std::string* upgradedomain);

  // required .hadoop.hdfs.DatanodeIDProto id = 1;
  bool has_id() const;
  void clear_id();
  static const int kIdFieldNumber = 1;
  private:
  const ::hadoop::hdfs::DatanodeIDProto& _internal_id() const;
  public:
  const ::hadoop::hdfs::DatanodeIDProto& id() const;
  ::hadoop::hdfs::DatanodeIDProto* release_id();
  ::hadoop::hdfs::DatanodeIDProto* mutable_id();
  void set_allocated_id(::hadoop::hdfs::DatanodeIDProto* id);

  // optional uint64 capacity = 2 [default = 0];
  bool has_capacity() const;
  void clear_capacity();
  static const int kCapacityFieldNumber = 2;
  ::google::protobuf::uint64 capacity() const;
  void set_capacity(::google::protobuf::uint64 value);

  // optional uint64 dfsUsed = 3 [default = 0];
  bool has_dfsused() const;
  void clear_dfsused();
  static const int kDfsUsedFieldNumber = 3;
  ::google::protobuf::uint64 dfsused() const;
  void set_dfsused(::google::protobuf::uint64 value);

  // optional uint64 remaining = 4 [default = 0];
  bool has_remaining() const;
  void clear_remaining();
  static const int kRemainingFieldNumber = 4;
  ::google::protobuf::uint64 remaining() const;
  void set_remaining(::google::protobuf::uint64 value);

  // optional uint64 blockPoolUsed = 5 [default = 0];
  bool has_blockpoolused() const;
  void clear_blockpoolused();
  static const int kBlockPoolUsedFieldNumber = 5;
  ::google::protobuf::uint64 blockpoolused() const;
  void set_blockpoolused(::google::protobuf::uint64 value);

  // optional uint64 lastUpdate = 6 [default = 0];
  bool has_lastupdate() const;
  void clear_lastupdate();
  static const int kLastUpdateFieldNumber = 6;
  ::google::protobuf::uint64 lastupdate() const;
  void set_lastupdate(::google::protobuf::uint64 value);

  // optional uint32 xceiverCount = 7 [default = 0];
  bool has_xceivercount() const;
  void clear_xceivercount();
  static const int kXceiverCountFieldNumber = 7;
  ::google::protobuf::uint32 xceivercount() const;
  void set_xceivercount(::google::protobuf::uint32 value);

  // optional .hadoop.hdfs.DatanodeInfoProto.AdminState adminState = 10 [default = NORMAL];
  bool has_adminstate() const;
  void clear_adminstate();
  static const int kAdminStateFieldNumber = 10;
  ::hadoop::hdfs::DatanodeInfoProto_AdminState adminstate() const;
  void set_adminstate(::hadoop::hdfs::DatanodeInfoProto_AdminState value);

  // optional uint64 nonDfsUsed = 9;
  bool has_nondfsused() const;
  void clear_nondfsused();
  static const int kNonDfsUsedFieldNumber = 9;
  ::google::protobuf::uint64 nondfsused() const;
  void set_nondfsused(::google::protobuf::uint64 value);

  // optional uint64 cacheCapacity = 11 [default = 0];
  bool has_cachecapacity() const;
  void clear_cachecapacity();
  static const int kCacheCapacityFieldNumber = 11;
  ::google::protobuf::uint64 cachecapacity() const;
  void set_cachecapacity(::google::protobuf::uint64 value);

  // optional uint64 cacheUsed = 12 [default = 0];
  bool has_cacheused() const;
  void clear_cacheused();
  static const int kCacheUsedFieldNumber = 12;
  ::google::protobuf::uint64 cacheused() const;
  void set_cacheused(::google::protobuf::uint64 value);

  // optional uint64 lastUpdateMonotonic = 13 [default = 0];
  bool has_lastupdatemonotonic() const;
  void clear_lastupdatemonotonic();
  static const int kLastUpdateMonotonicFieldNumber = 13;
  ::google::protobuf::uint64 lastupdatemonotonic() const;
  void set_lastupdatemonotonic(::google::protobuf::uint64 value);

  // optional uint64 lastBlockReportTime = 15 [default = 0];
  bool has_lastblockreporttime() const;
  void clear_lastblockreporttime();
  static const int kLastBlockReportTimeFieldNumber = 15;
  ::google::protobuf::uint64 lastblockreporttime() const;
  void set_lastblockreporttime(::google::protobuf::uint64 value);

  // optional uint64 lastBlockReportMonotonic = 16 [default = 0];
  bool has_lastblockreportmonotonic() const;
  void clear_lastblockreportmonotonic();
  static const int kLastBlockReportMonotonicFieldNumber = 16;
  ::google::protobuf::uint64 lastblockreportmonotonic() const;
  void set_lastblockreportmonotonic(::google::protobuf::uint64 value);

  // optional uint32 numBlocks = 17 [default = 0];
  bool has_numblocks() const;
  void clear_numblocks();
  static const int kNumBlocksFieldNumber = 17;
  ::google::protobuf::uint32 numblocks() const;
  void set_numblocks(::google::protobuf::uint32 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.DatanodeInfoProto)
 private:
  void set_has_id();
  void clear_has_id();
  void set_has_capacity();
  void clear_has_capacity();
  void set_has_dfsused();
  void clear_has_dfsused();
  void set_has_remaining();
  void clear_has_remaining();
  void set_has_blockpoolused();
  void clear_has_blockpoolused();
  void set_has_lastupdate();
  void clear_has_lastupdate();
  void set_has_xceivercount();
  void clear_has_xceivercount();
  void set_has_location();
  void clear_has_location();
  void set_has_nondfsused();
  void clear_has_nondfsused();
  void set_has_adminstate();
  void clear_has_adminstate();
  void set_has_cachecapacity();
  void clear_has_cachecapacity();
  void set_has_cacheused();
  void clear_has_cacheused();
  void set_has_lastupdatemonotonic();
  void clear_has_lastupdatemonotonic();
  void set_has_upgradedomain();
  void clear_has_upgradedomain();
  void set_has_lastblockreporttime();
  void clear_has_lastblockreporttime();
  void set_has_lastblockreportmonotonic();
  void clear_has_lastblockreportmonotonic();
  void set_has_numblocks();
  void clear_has_numblocks();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr location_;
  ::google::protobuf::internal::ArenaStringPtr upgradedomain_;
  ::hadoop::hdfs::DatanodeIDProto* id_;
  ::google::protobuf::uint64 capacity_;
  ::google::protobuf::uint64 dfsused_;
  ::google::protobuf::uint64 remaining_;
  ::google::protobuf::uint64 blockpoolused_;
  ::google::protobuf::uint64 lastupdate_;
  ::google::protobuf::uint32 xceivercount_;
  int adminstate_;
  ::google::protobuf::uint64 nondfsused_;
  ::google::protobuf::uint64 cachecapacity_;
  ::google::protobuf::uint64 cacheused_;
  ::google::protobuf::uint64 lastupdatemonotonic_;
  ::google::protobuf::uint64 lastblockreporttime_;
  ::google::protobuf::uint64 lastblockreportmonotonic_;
  ::google::protobuf::uint32 numblocks_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class DatanodeStorageProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.DatanodeStorageProto) */ {
 public:
  DatanodeStorageProto();
  virtual ~DatanodeStorageProto();

  DatanodeStorageProto(const DatanodeStorageProto& from);

  inline DatanodeStorageProto& operator=(const DatanodeStorageProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  DatanodeStorageProto(DatanodeStorageProto&& from) noexcept
    : DatanodeStorageProto() {
    *this = ::std::move(from);
  }

  inline DatanodeStorageProto& operator=(DatanodeStorageProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const DatanodeStorageProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const DatanodeStorageProto* internal_default_instance() {
    return reinterpret_cast<const DatanodeStorageProto*>(
               &_DatanodeStorageProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    7;

  void Swap(DatanodeStorageProto* other);
  friend void swap(DatanodeStorageProto& a, DatanodeStorageProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline DatanodeStorageProto* New() const final {
    return CreateMaybeMessage<DatanodeStorageProto>(NULL);
  }

  DatanodeStorageProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<DatanodeStorageProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const DatanodeStorageProto& from);
  void MergeFrom(const DatanodeStorageProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(DatanodeStorageProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  typedef DatanodeStorageProto_StorageState StorageState;
  static const StorageState NORMAL =
    DatanodeStorageProto_StorageState_NORMAL;
  static const StorageState READ_ONLY_SHARED =
    DatanodeStorageProto_StorageState_READ_ONLY_SHARED;
  static inline bool StorageState_IsValid(int value) {
    return DatanodeStorageProto_StorageState_IsValid(value);
  }
  static const StorageState StorageState_MIN =
    DatanodeStorageProto_StorageState_StorageState_MIN;
  static const StorageState StorageState_MAX =
    DatanodeStorageProto_StorageState_StorageState_MAX;
  static const int StorageState_ARRAYSIZE =
    DatanodeStorageProto_StorageState_StorageState_ARRAYSIZE;
  static inline const ::google::protobuf::EnumDescriptor*
  StorageState_descriptor() {
    return DatanodeStorageProto_StorageState_descriptor();
  }
  static inline const ::std::string& StorageState_Name(StorageState value) {
    return DatanodeStorageProto_StorageState_Name(value);
  }
  static inline bool StorageState_Parse(const ::std::string& name,
      StorageState* value) {
    return DatanodeStorageProto_StorageState_Parse(name, value);
  }

  // accessors -------------------------------------------------------

  // required string storageUuid = 1;
  bool has_storageuuid() const;
  void clear_storageuuid();
  static const int kStorageUuidFieldNumber = 1;
  const ::std::string& storageuuid() const;
  void set_storageuuid(const ::std::string& value);
  #if LANG_CXX11
  void set_storageuuid(::std::string&& value);
  #endif
  void set_storageuuid(const char* value);
  void set_storageuuid(const char* value, size_t size);
  ::std::string* mutable_storageuuid();
  ::std::string* release_storageuuid();
  void set_allocated_storageuuid(::std::string* storageuuid);

  // optional .hadoop.hdfs.DatanodeStorageProto.StorageState state = 2 [default = NORMAL];
  bool has_state() const;
  void clear_state();
  static const int kStateFieldNumber = 2;
  ::hadoop::hdfs::DatanodeStorageProto_StorageState state() const;
  void set_state(::hadoop::hdfs::DatanodeStorageProto_StorageState value);

  // optional .hadoop.hdfs.StorageTypeProto storageType = 3 [default = DISK];
  bool has_storagetype() const;
  void clear_storagetype();
  static const int kStorageTypeFieldNumber = 3;
  ::hadoop::hdfs::StorageTypeProto storagetype() const;
  void set_storagetype(::hadoop::hdfs::StorageTypeProto value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.DatanodeStorageProto)
 private:
  void set_has_storageuuid();
  void clear_has_storageuuid();
  void set_has_state();
  void clear_has_state();
  void set_has_storagetype();
  void clear_has_storagetype();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr storageuuid_;
  int state_;
  int storagetype_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class StorageReportProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.StorageReportProto) */ {
 public:
  StorageReportProto();
  virtual ~StorageReportProto();

  StorageReportProto(const StorageReportProto& from);

  inline StorageReportProto& operator=(const StorageReportProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  StorageReportProto(StorageReportProto&& from) noexcept
    : StorageReportProto() {
    *this = ::std::move(from);
  }

  inline StorageReportProto& operator=(StorageReportProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const StorageReportProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const StorageReportProto* internal_default_instance() {
    return reinterpret_cast<const StorageReportProto*>(
               &_StorageReportProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    8;

  void Swap(StorageReportProto* other);
  friend void swap(StorageReportProto& a, StorageReportProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline StorageReportProto* New() const final {
    return CreateMaybeMessage<StorageReportProto>(NULL);
  }

  StorageReportProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<StorageReportProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const StorageReportProto& from);
  void MergeFrom(const StorageReportProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(StorageReportProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required string storageUuid = 1 [deprecated = true];
  GOOGLE_PROTOBUF_DEPRECATED_ATTR bool has_storageuuid() const;
  GOOGLE_PROTOBUF_DEPRECATED_ATTR void clear_storageuuid();
  GOOGLE_PROTOBUF_DEPRECATED_ATTR static const int kStorageUuidFieldNumber = 1;
  GOOGLE_PROTOBUF_DEPRECATED_ATTR const ::std::string& storageuuid() const;
  GOOGLE_PROTOBUF_DEPRECATED_ATTR void set_storageuuid(const ::std::string& value);
  #if LANG_CXX11
  GOOGLE_PROTOBUF_DEPRECATED_ATTR void set_storageuuid(::std::string&& value);
  #endif
  GOOGLE_PROTOBUF_DEPRECATED_ATTR void set_storageuuid(const char* value);
  GOOGLE_PROTOBUF_DEPRECATED_ATTR void set_storageuuid(const char* value, size_t size);
  GOOGLE_PROTOBUF_DEPRECATED_ATTR ::std::string* mutable_storageuuid();
  GOOGLE_PROTOBUF_DEPRECATED_ATTR ::std::string* release_storageuuid();
  GOOGLE_PROTOBUF_DEPRECATED_ATTR void set_allocated_storageuuid(::std::string* storageuuid);

  // optional .hadoop.hdfs.DatanodeStorageProto storage = 7;
  bool has_storage() const;
  void clear_storage();
  static const int kStorageFieldNumber = 7;
  private:
  const ::hadoop::hdfs::DatanodeStorageProto& _internal_storage() const;
  public:
  const ::hadoop::hdfs::DatanodeStorageProto& storage() const;
  ::hadoop::hdfs::DatanodeStorageProto* release_storage();
  ::hadoop::hdfs::DatanodeStorageProto* mutable_storage();
  void set_allocated_storage(::hadoop::hdfs::DatanodeStorageProto* storage);

  // optional uint64 capacity = 3 [default = 0];
  bool has_capacity() const;
  void clear_capacity();
  static const int kCapacityFieldNumber = 3;
  ::google::protobuf::uint64 capacity() const;
  void set_capacity(::google::protobuf::uint64 value);

  // optional uint64 dfsUsed = 4 [default = 0];
  bool has_dfsused() const;
  void clear_dfsused();
  static const int kDfsUsedFieldNumber = 4;
  ::google::protobuf::uint64 dfsused() const;
  void set_dfsused(::google::protobuf::uint64 value);

  // optional uint64 remaining = 5 [default = 0];
  bool has_remaining() const;
  void clear_remaining();
  static const int kRemainingFieldNumber = 5;
  ::google::protobuf::uint64 remaining() const;
  void set_remaining(::google::protobuf::uint64 value);

  // optional uint64 blockPoolUsed = 6 [default = 0];
  bool has_blockpoolused() const;
  void clear_blockpoolused();
  static const int kBlockPoolUsedFieldNumber = 6;
  ::google::protobuf::uint64 blockpoolused() const;
  void set_blockpoolused(::google::protobuf::uint64 value);

  // optional uint64 nonDfsUsed = 8;
  bool has_nondfsused() const;
  void clear_nondfsused();
  static const int kNonDfsUsedFieldNumber = 8;
  ::google::protobuf::uint64 nondfsused() const;
  void set_nondfsused(::google::protobuf::uint64 value);

  // optional bool failed = 2 [default = false];
  bool has_failed() const;
  void clear_failed();
  static const int kFailedFieldNumber = 2;
  bool failed() const;
  void set_failed(bool value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.StorageReportProto)
 private:
  void set_has_storageuuid();
  void clear_has_storageuuid();
  void set_has_failed();
  void clear_has_failed();
  void set_has_capacity();
  void clear_has_capacity();
  void set_has_dfsused();
  void clear_has_dfsused();
  void set_has_remaining();
  void clear_has_remaining();
  void set_has_blockpoolused();
  void clear_has_blockpoolused();
  void set_has_storage();
  void clear_has_storage();
  void set_has_nondfsused();
  void clear_has_nondfsused();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr storageuuid_;
  ::hadoop::hdfs::DatanodeStorageProto* storage_;
  ::google::protobuf::uint64 capacity_;
  ::google::protobuf::uint64 dfsused_;
  ::google::protobuf::uint64 remaining_;
  ::google::protobuf::uint64 blockpoolused_;
  ::google::protobuf::uint64 nondfsused_;
  bool failed_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class ContentSummaryProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.ContentSummaryProto) */ {
 public:
  ContentSummaryProto();
  virtual ~ContentSummaryProto();

  ContentSummaryProto(const ContentSummaryProto& from);

  inline ContentSummaryProto& operator=(const ContentSummaryProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  ContentSummaryProto(ContentSummaryProto&& from) noexcept
    : ContentSummaryProto() {
    *this = ::std::move(from);
  }

  inline ContentSummaryProto& operator=(ContentSummaryProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ContentSummaryProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const ContentSummaryProto* internal_default_instance() {
    return reinterpret_cast<const ContentSummaryProto*>(
               &_ContentSummaryProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    9;

  void Swap(ContentSummaryProto* other);
  friend void swap(ContentSummaryProto& a, ContentSummaryProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline ContentSummaryProto* New() const final {
    return CreateMaybeMessage<ContentSummaryProto>(NULL);
  }

  ContentSummaryProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<ContentSummaryProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const ContentSummaryProto& from);
  void MergeFrom(const ContentSummaryProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(ContentSummaryProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string erasureCodingPolicy = 12;
  bool has_erasurecodingpolicy() const;
  void clear_erasurecodingpolicy();
  static const int kErasureCodingPolicyFieldNumber = 12;
  const ::std::string& erasurecodingpolicy() const;
  void set_erasurecodingpolicy(const ::std::string& value);
  #if LANG_CXX11
  void set_erasurecodingpolicy(::std::string&& value);
  #endif
  void set_erasurecodingpolicy(const char* value);
  void set_erasurecodingpolicy(const char* value, size_t size);
  ::std::string* mutable_erasurecodingpolicy();
  ::std::string* release_erasurecodingpolicy();
  void set_allocated_erasurecodingpolicy(::std::string* erasurecodingpolicy);

  // optional .hadoop.hdfs.StorageTypeQuotaInfosProto typeQuotaInfos = 7;
  bool has_typequotainfos() const;
  void clear_typequotainfos();
  static const int kTypeQuotaInfosFieldNumber = 7;
  private:
  const ::hadoop::hdfs::StorageTypeQuotaInfosProto& _internal_typequotainfos() const;
  public:
  const ::hadoop::hdfs::StorageTypeQuotaInfosProto& typequotainfos() const;
  ::hadoop::hdfs::StorageTypeQuotaInfosProto* release_typequotainfos();
  ::hadoop::hdfs::StorageTypeQuotaInfosProto* mutable_typequotainfos();
  void set_allocated_typequotainfos(::hadoop::hdfs::StorageTypeQuotaInfosProto* typequotainfos);

  // required uint64 length = 1;
  bool has_length() const;
  void clear_length();
  static const int kLengthFieldNumber = 1;
  ::google::protobuf::uint64 length() const;
  void set_length(::google::protobuf::uint64 value);

  // required uint64 fileCount = 2;
  bool has_filecount() const;
  void clear_filecount();
  static const int kFileCountFieldNumber = 2;
  ::google::protobuf::uint64 filecount() const;
  void set_filecount(::google::protobuf::uint64 value);

  // required uint64 directoryCount = 3;
  bool has_directorycount() const;
  void clear_directorycount();
  static const int kDirectoryCountFieldNumber = 3;
  ::google::protobuf::uint64 directorycount() const;
  void set_directorycount(::google::protobuf::uint64 value);

  // required uint64 quota = 4;
  bool has_quota() const;
  void clear_quota();
  static const int kQuotaFieldNumber = 4;
  ::google::protobuf::uint64 quota() const;
  void set_quota(::google::protobuf::uint64 value);

  // required uint64 spaceConsumed = 5;
  bool has_spaceconsumed() const;
  void clear_spaceconsumed();
  static const int kSpaceConsumedFieldNumber = 5;
  ::google::protobuf::uint64 spaceconsumed() const;
  void set_spaceconsumed(::google::protobuf::uint64 value);

  // required uint64 spaceQuota = 6;
  bool has_spacequota() const;
  void clear_spacequota();
  static const int kSpaceQuotaFieldNumber = 6;
  ::google::protobuf::uint64 spacequota() const;
  void set_spacequota(::google::protobuf::uint64 value);

  // optional uint64 snapshotLength = 8;
  bool has_snapshotlength() const;
  void clear_snapshotlength();
  static const int kSnapshotLengthFieldNumber = 8;
  ::google::protobuf::uint64 snapshotlength() const;
  void set_snapshotlength(::google::protobuf::uint64 value);

  // optional uint64 snapshotFileCount = 9;
  bool has_snapshotfilecount() const;
  void clear_snapshotfilecount();
  static const int kSnapshotFileCountFieldNumber = 9;
  ::google::protobuf::uint64 snapshotfilecount() const;
  void set_snapshotfilecount(::google::protobuf::uint64 value);

  // optional uint64 snapshotDirectoryCount = 10;
  bool has_snapshotdirectorycount() const;
  void clear_snapshotdirectorycount();
  static const int kSnapshotDirectoryCountFieldNumber = 10;
  ::google::protobuf::uint64 snapshotdirectorycount() const;
  void set_snapshotdirectorycount(::google::protobuf::uint64 value);

  // optional uint64 snapshotSpaceConsumed = 11;
  bool has_snapshotspaceconsumed() const;
  void clear_snapshotspaceconsumed();
  static const int kSnapshotSpaceConsumedFieldNumber = 11;
  ::google::protobuf::uint64 snapshotspaceconsumed() const;
  void set_snapshotspaceconsumed(::google::protobuf::uint64 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.ContentSummaryProto)
 private:
  void set_has_length();
  void clear_has_length();
  void set_has_filecount();
  void clear_has_filecount();
  void set_has_directorycount();
  void clear_has_directorycount();
  void set_has_quota();
  void clear_has_quota();
  void set_has_spaceconsumed();
  void clear_has_spaceconsumed();
  void set_has_spacequota();
  void clear_has_spacequota();
  void set_has_typequotainfos();
  void clear_has_typequotainfos();
  void set_has_snapshotlength();
  void clear_has_snapshotlength();
  void set_has_snapshotfilecount();
  void clear_has_snapshotfilecount();
  void set_has_snapshotdirectorycount();
  void clear_has_snapshotdirectorycount();
  void set_has_snapshotspaceconsumed();
  void clear_has_snapshotspaceconsumed();
  void set_has_erasurecodingpolicy();
  void clear_has_erasurecodingpolicy();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr erasurecodingpolicy_;
  ::hadoop::hdfs::StorageTypeQuotaInfosProto* typequotainfos_;
  ::google::protobuf::uint64 length_;
  ::google::protobuf::uint64 filecount_;
  ::google::protobuf::uint64 directorycount_;
  ::google::protobuf::uint64 quota_;
  ::google::protobuf::uint64 spaceconsumed_;
  ::google::protobuf::uint64 spacequota_;
  ::google::protobuf::uint64 snapshotlength_;
  ::google::protobuf::uint64 snapshotfilecount_;
  ::google::protobuf::uint64 snapshotdirectorycount_;
  ::google::protobuf::uint64 snapshotspaceconsumed_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class QuotaUsageProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.QuotaUsageProto) */ {
 public:
  QuotaUsageProto();
  virtual ~QuotaUsageProto();

  QuotaUsageProto(const QuotaUsageProto& from);

  inline QuotaUsageProto& operator=(const QuotaUsageProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  QuotaUsageProto(QuotaUsageProto&& from) noexcept
    : QuotaUsageProto() {
    *this = ::std::move(from);
  }

  inline QuotaUsageProto& operator=(QuotaUsageProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const QuotaUsageProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const QuotaUsageProto* internal_default_instance() {
    return reinterpret_cast<const QuotaUsageProto*>(
               &_QuotaUsageProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    10;

  void Swap(QuotaUsageProto* other);
  friend void swap(QuotaUsageProto& a, QuotaUsageProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline QuotaUsageProto* New() const final {
    return CreateMaybeMessage<QuotaUsageProto>(NULL);
  }

  QuotaUsageProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<QuotaUsageProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const QuotaUsageProto& from);
  void MergeFrom(const QuotaUsageProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(QuotaUsageProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional .hadoop.hdfs.StorageTypeQuotaInfosProto typeQuotaInfos = 5;
  bool has_typequotainfos() const;
  void clear_typequotainfos();
  static const int kTypeQuotaInfosFieldNumber = 5;
  private:
  const ::hadoop::hdfs::StorageTypeQuotaInfosProto& _internal_typequotainfos() const;
  public:
  const ::hadoop::hdfs::StorageTypeQuotaInfosProto& typequotainfos() const;
  ::hadoop::hdfs::StorageTypeQuotaInfosProto* release_typequotainfos();
  ::hadoop::hdfs::StorageTypeQuotaInfosProto* mutable_typequotainfos();
  void set_allocated_typequotainfos(::hadoop::hdfs::StorageTypeQuotaInfosProto* typequotainfos);

  // required uint64 fileAndDirectoryCount = 1;
  bool has_fileanddirectorycount() const;
  void clear_fileanddirectorycount();
  static const int kFileAndDirectoryCountFieldNumber = 1;
  ::google::protobuf::uint64 fileanddirectorycount() const;
  void set_fileanddirectorycount(::google::protobuf::uint64 value);

  // required uint64 quota = 2;
  bool has_quota() const;
  void clear_quota();
  static const int kQuotaFieldNumber = 2;
  ::google::protobuf::uint64 quota() const;
  void set_quota(::google::protobuf::uint64 value);

  // required uint64 spaceConsumed = 3;
  bool has_spaceconsumed() const;
  void clear_spaceconsumed();
  static const int kSpaceConsumedFieldNumber = 3;
  ::google::protobuf::uint64 spaceconsumed() const;
  void set_spaceconsumed(::google::protobuf::uint64 value);

  // required uint64 spaceQuota = 4;
  bool has_spacequota() const;
  void clear_spacequota();
  static const int kSpaceQuotaFieldNumber = 4;
  ::google::protobuf::uint64 spacequota() const;
  void set_spacequota(::google::protobuf::uint64 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.QuotaUsageProto)
 private:
  void set_has_fileanddirectorycount();
  void clear_has_fileanddirectorycount();
  void set_has_quota();
  void clear_has_quota();
  void set_has_spaceconsumed();
  void clear_has_spaceconsumed();
  void set_has_spacequota();
  void clear_has_spacequota();
  void set_has_typequotainfos();
  void clear_has_typequotainfos();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::hadoop::hdfs::StorageTypeQuotaInfosProto* typequotainfos_;
  ::google::protobuf::uint64 fileanddirectorycount_;
  ::google::protobuf::uint64 quota_;
  ::google::protobuf::uint64 spaceconsumed_;
  ::google::protobuf::uint64 spacequota_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class StorageTypeQuotaInfosProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.StorageTypeQuotaInfosProto) */ {
 public:
  StorageTypeQuotaInfosProto();
  virtual ~StorageTypeQuotaInfosProto();

  StorageTypeQuotaInfosProto(const StorageTypeQuotaInfosProto& from);

  inline StorageTypeQuotaInfosProto& operator=(const StorageTypeQuotaInfosProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  StorageTypeQuotaInfosProto(StorageTypeQuotaInfosProto&& from) noexcept
    : StorageTypeQuotaInfosProto() {
    *this = ::std::move(from);
  }

  inline StorageTypeQuotaInfosProto& operator=(StorageTypeQuotaInfosProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const StorageTypeQuotaInfosProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const StorageTypeQuotaInfosProto* internal_default_instance() {
    return reinterpret_cast<const StorageTypeQuotaInfosProto*>(
               &_StorageTypeQuotaInfosProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    11;

  void Swap(StorageTypeQuotaInfosProto* other);
  friend void swap(StorageTypeQuotaInfosProto& a, StorageTypeQuotaInfosProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline StorageTypeQuotaInfosProto* New() const final {
    return CreateMaybeMessage<StorageTypeQuotaInfosProto>(NULL);
  }

  StorageTypeQuotaInfosProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<StorageTypeQuotaInfosProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const StorageTypeQuotaInfosProto& from);
  void MergeFrom(const StorageTypeQuotaInfosProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(StorageTypeQuotaInfosProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.hdfs.StorageTypeQuotaInfoProto typeQuotaInfo = 1;
  int typequotainfo_size() const;
  void clear_typequotainfo();
  static const int kTypeQuotaInfoFieldNumber = 1;
  ::hadoop::hdfs::StorageTypeQuotaInfoProto* mutable_typequotainfo(int index);
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::StorageTypeQuotaInfoProto >*
      mutable_typequotainfo();
  const ::hadoop::hdfs::StorageTypeQuotaInfoProto& typequotainfo(int index) const;
  ::hadoop::hdfs::StorageTypeQuotaInfoProto* add_typequotainfo();
  const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::StorageTypeQuotaInfoProto >&
      typequotainfo() const;

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.StorageTypeQuotaInfosProto)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::StorageTypeQuotaInfoProto > typequotainfo_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class StorageTypeQuotaInfoProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.StorageTypeQuotaInfoProto) */ {
 public:
  StorageTypeQuotaInfoProto();
  virtual ~StorageTypeQuotaInfoProto();

  StorageTypeQuotaInfoProto(const StorageTypeQuotaInfoProto& from);

  inline StorageTypeQuotaInfoProto& operator=(const StorageTypeQuotaInfoProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  StorageTypeQuotaInfoProto(StorageTypeQuotaInfoProto&& from) noexcept
    : StorageTypeQuotaInfoProto() {
    *this = ::std::move(from);
  }

  inline StorageTypeQuotaInfoProto& operator=(StorageTypeQuotaInfoProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const StorageTypeQuotaInfoProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const StorageTypeQuotaInfoProto* internal_default_instance() {
    return reinterpret_cast<const StorageTypeQuotaInfoProto*>(
               &_StorageTypeQuotaInfoProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    12;

  void Swap(StorageTypeQuotaInfoProto* other);
  friend void swap(StorageTypeQuotaInfoProto& a, StorageTypeQuotaInfoProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline StorageTypeQuotaInfoProto* New() const final {
    return CreateMaybeMessage<StorageTypeQuotaInfoProto>(NULL);
  }

  StorageTypeQuotaInfoProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<StorageTypeQuotaInfoProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const StorageTypeQuotaInfoProto& from);
  void MergeFrom(const StorageTypeQuotaInfoProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(StorageTypeQuotaInfoProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required uint64 quota = 2;
  bool has_quota() const;
  void clear_quota();
  static const int kQuotaFieldNumber = 2;
  ::google::protobuf::uint64 quota() const;
  void set_quota(::google::protobuf::uint64 value);

  // required uint64 consumed = 3;
  bool has_consumed() const;
  void clear_consumed();
  static const int kConsumedFieldNumber = 3;
  ::google::protobuf::uint64 consumed() const;
  void set_consumed(::google::protobuf::uint64 value);

  // optional .hadoop.hdfs.StorageTypeProto type = 1 [default = DISK];
  bool has_type() const;
  void clear_type();
  static const int kTypeFieldNumber = 1;
  ::hadoop::hdfs::StorageTypeProto type() const;
  void set_type(::hadoop::hdfs::StorageTypeProto value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.StorageTypeQuotaInfoProto)
 private:
  void set_has_type();
  void clear_has_type();
  void set_has_quota();
  void clear_has_quota();
  void set_has_consumed();
  void clear_has_consumed();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::uint64 quota_;
  ::google::protobuf::uint64 consumed_;
  int type_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class CorruptFileBlocksProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.CorruptFileBlocksProto) */ {
 public:
  CorruptFileBlocksProto();
  virtual ~CorruptFileBlocksProto();

  CorruptFileBlocksProto(const CorruptFileBlocksProto& from);

  inline CorruptFileBlocksProto& operator=(const CorruptFileBlocksProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  CorruptFileBlocksProto(CorruptFileBlocksProto&& from) noexcept
    : CorruptFileBlocksProto() {
    *this = ::std::move(from);
  }

  inline CorruptFileBlocksProto& operator=(CorruptFileBlocksProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const CorruptFileBlocksProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const CorruptFileBlocksProto* internal_default_instance() {
    return reinterpret_cast<const CorruptFileBlocksProto*>(
               &_CorruptFileBlocksProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    13;

  void Swap(CorruptFileBlocksProto* other);
  friend void swap(CorruptFileBlocksProto& a, CorruptFileBlocksProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline CorruptFileBlocksProto* New() const final {
    return CreateMaybeMessage<CorruptFileBlocksProto>(NULL);
  }

  CorruptFileBlocksProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<CorruptFileBlocksProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const CorruptFileBlocksProto& from);
  void MergeFrom(const CorruptFileBlocksProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(CorruptFileBlocksProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated string files = 1;
  int files_size() const;
  void clear_files();
  static const int kFilesFieldNumber = 1;
  const ::std::string& files(int index) const;
  ::std::string* mutable_files(int index);
  void set_files(int index, const ::std::string& value);
  #if LANG_CXX11
  void set_files(int index, ::std::string&& value);
  #endif
  void set_files(int index, const char* value);
  void set_files(int index, const char* value, size_t size);
  ::std::string* add_files();
  void add_files(const ::std::string& value);
  #if LANG_CXX11
  void add_files(::std::string&& value);
  #endif
  void add_files(const char* value);
  void add_files(const char* value, size_t size);
  const ::google::protobuf::RepeatedPtrField< ::std::string>& files() const;
  ::google::protobuf::RepeatedPtrField< ::std::string>* mutable_files();

  // required string cookie = 2;
  bool has_cookie() const;
  void clear_cookie();
  static const int kCookieFieldNumber = 2;
  const ::std::string& cookie() const;
  void set_cookie(const ::std::string& value);
  #if LANG_CXX11
  void set_cookie(::std::string&& value);
  #endif
  void set_cookie(const char* value);
  void set_cookie(const char* value, size_t size);
  ::std::string* mutable_cookie();
  ::std::string* release_cookie();
  void set_allocated_cookie(::std::string* cookie);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.CorruptFileBlocksProto)
 private:
  void set_has_cookie();
  void clear_has_cookie();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::RepeatedPtrField< ::std::string> files_;
  ::google::protobuf::internal::ArenaStringPtr cookie_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class StorageTypesProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.StorageTypesProto) */ {
 public:
  StorageTypesProto();
  virtual ~StorageTypesProto();

  StorageTypesProto(const StorageTypesProto& from);

  inline StorageTypesProto& operator=(const StorageTypesProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  StorageTypesProto(StorageTypesProto&& from) noexcept
    : StorageTypesProto() {
    *this = ::std::move(from);
  }

  inline StorageTypesProto& operator=(StorageTypesProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const StorageTypesProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const StorageTypesProto* internal_default_instance() {
    return reinterpret_cast<const StorageTypesProto*>(
               &_StorageTypesProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    14;

  void Swap(StorageTypesProto* other);
  friend void swap(StorageTypesProto& a, StorageTypesProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline StorageTypesProto* New() const final {
    return CreateMaybeMessage<StorageTypesProto>(NULL);
  }

  StorageTypesProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<StorageTypesProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const StorageTypesProto& from);
  void MergeFrom(const StorageTypesProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(StorageTypesProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.hdfs.StorageTypeProto storageTypes = 1;
  int storagetypes_size() const;
  void clear_storagetypes();
  static const int kStorageTypesFieldNumber = 1;
  ::hadoop::hdfs::StorageTypeProto storagetypes(int index) const;
  void set_storagetypes(int index, ::hadoop::hdfs::StorageTypeProto value);
  void add_storagetypes(::hadoop::hdfs::StorageTypeProto value);
  const ::google::protobuf::RepeatedField<int>& storagetypes() const;
  ::google::protobuf::RepeatedField<int>* mutable_storagetypes();

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.StorageTypesProto)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::RepeatedField<int> storagetypes_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class BlockStoragePolicyProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.BlockStoragePolicyProto) */ {
 public:
  BlockStoragePolicyProto();
  virtual ~BlockStoragePolicyProto();

  BlockStoragePolicyProto(const BlockStoragePolicyProto& from);

  inline BlockStoragePolicyProto& operator=(const BlockStoragePolicyProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  BlockStoragePolicyProto(BlockStoragePolicyProto&& from) noexcept
    : BlockStoragePolicyProto() {
    *this = ::std::move(from);
  }

  inline BlockStoragePolicyProto& operator=(BlockStoragePolicyProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const BlockStoragePolicyProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const BlockStoragePolicyProto* internal_default_instance() {
    return reinterpret_cast<const BlockStoragePolicyProto*>(
               &_BlockStoragePolicyProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    15;

  void Swap(BlockStoragePolicyProto* other);
  friend void swap(BlockStoragePolicyProto& a, BlockStoragePolicyProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline BlockStoragePolicyProto* New() const final {
    return CreateMaybeMessage<BlockStoragePolicyProto>(NULL);
  }

  BlockStoragePolicyProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<BlockStoragePolicyProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const BlockStoragePolicyProto& from);
  void MergeFrom(const BlockStoragePolicyProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(BlockStoragePolicyProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required string name = 2;
  bool has_name() const;
  void clear_name();
  static const int kNameFieldNumber = 2;
  const ::std::string& name() const;
  void set_name(const ::std::string& value);
  #if LANG_CXX11
  void set_name(::std::string&& value);
  #endif
  void set_name(const char* value);
  void set_name(const char* value, size_t size);
  ::std::string* mutable_name();
  ::std::string* release_name();
  void set_allocated_name(::std::string* name);

  // required .hadoop.hdfs.StorageTypesProto creationPolicy = 3;
  bool has_creationpolicy() const;
  void clear_creationpolicy();
  static const int kCreationPolicyFieldNumber = 3;
  private:
  const ::hadoop::hdfs::StorageTypesProto& _internal_creationpolicy() const;
  public:
  const ::hadoop::hdfs::StorageTypesProto& creationpolicy() const;
  ::hadoop::hdfs::StorageTypesProto* release_creationpolicy();
  ::hadoop::hdfs::StorageTypesProto* mutable_creationpolicy();
  void set_allocated_creationpolicy(::hadoop::hdfs::StorageTypesProto* creationpolicy);

  // optional .hadoop.hdfs.StorageTypesProto creationFallbackPolicy = 4;
  bool has_creationfallbackpolicy() const;
  void clear_creationfallbackpolicy();
  static const int kCreationFallbackPolicyFieldNumber = 4;
  private:
  const ::hadoop::hdfs::StorageTypesProto& _internal_creationfallbackpolicy() const;
  public:
  const ::hadoop::hdfs::StorageTypesProto& creationfallbackpolicy() const;
  ::hadoop::hdfs::StorageTypesProto* release_creationfallbackpolicy();
  ::hadoop::hdfs::StorageTypesProto* mutable_creationfallbackpolicy();
  void set_allocated_creationfallbackpolicy(::hadoop::hdfs::StorageTypesProto* creationfallbackpolicy);

  // optional .hadoop.hdfs.StorageTypesProto replicationFallbackPolicy = 5;
  bool has_replicationfallbackpolicy() const;
  void clear_replicationfallbackpolicy();
  static const int kReplicationFallbackPolicyFieldNumber = 5;
  private:
  const ::hadoop::hdfs::StorageTypesProto& _internal_replicationfallbackpolicy() const;
  public:
  const ::hadoop::hdfs::StorageTypesProto& replicationfallbackpolicy() const;
  ::hadoop::hdfs::StorageTypesProto* release_replicationfallbackpolicy();
  ::hadoop::hdfs::StorageTypesProto* mutable_replicationfallbackpolicy();
  void set_allocated_replicationfallbackpolicy(::hadoop::hdfs::StorageTypesProto* replicationfallbackpolicy);

  // required uint32 policyId = 1;
  bool has_policyid() const;
  void clear_policyid();
  static const int kPolicyIdFieldNumber = 1;
  ::google::protobuf::uint32 policyid() const;
  void set_policyid(::google::protobuf::uint32 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.BlockStoragePolicyProto)
 private:
  void set_has_policyid();
  void clear_has_policyid();
  void set_has_name();
  void clear_has_name();
  void set_has_creationpolicy();
  void clear_has_creationpolicy();
  void set_has_creationfallbackpolicy();
  void clear_has_creationfallbackpolicy();
  void set_has_replicationfallbackpolicy();
  void clear_has_replicationfallbackpolicy();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr name_;
  ::hadoop::hdfs::StorageTypesProto* creationpolicy_;
  ::hadoop::hdfs::StorageTypesProto* creationfallbackpolicy_;
  ::hadoop::hdfs::StorageTypesProto* replicationfallbackpolicy_;
  ::google::protobuf::uint32 policyid_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class LocatedBlockProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.LocatedBlockProto) */ {
 public:
  LocatedBlockProto();
  virtual ~LocatedBlockProto();

  LocatedBlockProto(const LocatedBlockProto& from);

  inline LocatedBlockProto& operator=(const LocatedBlockProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  LocatedBlockProto(LocatedBlockProto&& from) noexcept
    : LocatedBlockProto() {
    *this = ::std::move(from);
  }

  inline LocatedBlockProto& operator=(LocatedBlockProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const LocatedBlockProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const LocatedBlockProto* internal_default_instance() {
    return reinterpret_cast<const LocatedBlockProto*>(
               &_LocatedBlockProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    16;

  void Swap(LocatedBlockProto* other);
  friend void swap(LocatedBlockProto& a, LocatedBlockProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline LocatedBlockProto* New() const final {
    return CreateMaybeMessage<LocatedBlockProto>(NULL);
  }

  LocatedBlockProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<LocatedBlockProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const LocatedBlockProto& from);
  void MergeFrom(const LocatedBlockProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(LocatedBlockProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.hdfs.DatanodeInfoProto locs = 3;
  int locs_size() const;
  void clear_locs();
  static const int kLocsFieldNumber = 3;
  ::hadoop::hdfs::DatanodeInfoProto* mutable_locs(int index);
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::DatanodeInfoProto >*
      mutable_locs();
  const ::hadoop::hdfs::DatanodeInfoProto& locs(int index) const;
  ::hadoop::hdfs::DatanodeInfoProto* add_locs();
  const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::DatanodeInfoProto >&
      locs() const;

  // repeated bool isCached = 6 [packed = true];
  int iscached_size() const;
  void clear_iscached();
  static const int kIsCachedFieldNumber = 6;
  bool iscached(int index) const;
  void set_iscached(int index, bool value);
  void add_iscached(bool value);
  const ::google::protobuf::RepeatedField< bool >&
      iscached() const;
  ::google::protobuf::RepeatedField< bool >*
      mutable_iscached();

  // repeated .hadoop.hdfs.StorageTypeProto storageTypes = 7;
  int storagetypes_size() const;
  void clear_storagetypes();
  static const int kStorageTypesFieldNumber = 7;
  ::hadoop::hdfs::StorageTypeProto storagetypes(int index) const;
  void set_storagetypes(int index, ::hadoop::hdfs::StorageTypeProto value);
  void add_storagetypes(::hadoop::hdfs::StorageTypeProto value);
  const ::google::protobuf::RepeatedField<int>& storagetypes() const;
  ::google::protobuf::RepeatedField<int>* mutable_storagetypes();

  // repeated string storageIDs = 8;
  int storageids_size() const;
  void clear_storageids();
  static const int kStorageIDsFieldNumber = 8;
  const ::std::string& storageids(int index) const;
  ::std::string* mutable_storageids(int index);
  void set_storageids(int index, const ::std::string& value);
  #if LANG_CXX11
  void set_storageids(int index, ::std::string&& value);
  #endif
  void set_storageids(int index, const char* value);
  void set_storageids(int index, const char* value, size_t size);
  ::std::string* add_storageids();
  void add_storageids(const ::std::string& value);
  #if LANG_CXX11
  void add_storageids(::std::string&& value);
  #endif
  void add_storageids(const char* value);
  void add_storageids(const char* value, size_t size);
  const ::google::protobuf::RepeatedPtrField< ::std::string>& storageids() const;
  ::google::protobuf::RepeatedPtrField< ::std::string>* mutable_storageids();

  // repeated .hadoop.common.TokenProto blockTokens = 10;
  int blocktokens_size() const;
  void clear_blocktokens();
  static const int kBlockTokensFieldNumber = 10;
  ::hadoop::common::TokenProto* mutable_blocktokens(int index);
  ::google::protobuf::RepeatedPtrField< ::hadoop::common::TokenProto >*
      mutable_blocktokens();
  const ::hadoop::common::TokenProto& blocktokens(int index) const;
  ::hadoop::common::TokenProto* add_blocktokens();
  const ::google::protobuf::RepeatedPtrField< ::hadoop::common::TokenProto >&
      blocktokens() const;

  // optional bytes blockIndices = 9;
  bool has_blockindices() const;
  void clear_blockindices();
  static const int kBlockIndicesFieldNumber = 9;
  const ::std::string& blockindices() const;
  void set_blockindices(const ::std::string& value);
  #if LANG_CXX11
  void set_blockindices(::std::string&& value);
  #endif
  void set_blockindices(const char* value);
  void set_blockindices(const void* value, size_t size);
  ::std::string* mutable_blockindices();
  ::std::string* release_blockindices();
  void set_allocated_blockindices(::std::string* blockindices);

  // required .hadoop.hdfs.ExtendedBlockProto b = 1;
  bool has_b() const;
  void clear_b();
  static const int kBFieldNumber = 1;
  private:
  const ::hadoop::hdfs::ExtendedBlockProto& _internal_b() const;
  public:
  const ::hadoop::hdfs::ExtendedBlockProto& b() const;
  ::hadoop::hdfs::ExtendedBlockProto* release_b();
  ::hadoop::hdfs::ExtendedBlockProto* mutable_b();
  void set_allocated_b(::hadoop::hdfs::ExtendedBlockProto* b);

  // required .hadoop.common.TokenProto blockToken = 5;
  bool has_blocktoken() const;
  void clear_blocktoken();
  static const int kBlockTokenFieldNumber = 5;
  private:
  const ::hadoop::common::TokenProto& _internal_blocktoken() const;
  public:
  const ::hadoop::common::TokenProto& blocktoken() const;
  ::hadoop::common::TokenProto* release_blocktoken();
  ::hadoop::common::TokenProto* mutable_blocktoken();
  void set_allocated_blocktoken(::hadoop::common::TokenProto* blocktoken);

  // required uint64 offset = 2;
  bool has_offset() const;
  void clear_offset();
  static const int kOffsetFieldNumber = 2;
  ::google::protobuf::uint64 offset() const;
  void set_offset(::google::protobuf::uint64 value);

  // required bool corrupt = 4;
  bool has_corrupt() const;
  void clear_corrupt();
  static const int kCorruptFieldNumber = 4;
  bool corrupt() const;
  void set_corrupt(bool value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.LocatedBlockProto)
 private:
  void set_has_b();
  void clear_has_b();
  void set_has_offset();
  void clear_has_offset();
  void set_has_corrupt();
  void clear_has_corrupt();
  void set_has_blocktoken();
  void clear_has_blocktoken();
  void set_has_blockindices();
  void clear_has_blockindices();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::DatanodeInfoProto > locs_;
  ::google::protobuf::RepeatedField< bool > iscached_;
  mutable int _iscached_cached_byte_size_;
  ::google::protobuf::RepeatedField<int> storagetypes_;
  ::google::protobuf::RepeatedPtrField< ::std::string> storageids_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::common::TokenProto > blocktokens_;
  ::google::protobuf::internal::ArenaStringPtr blockindices_;
  ::hadoop::hdfs::ExtendedBlockProto* b_;
  ::hadoop::common::TokenProto* blocktoken_;
  ::google::protobuf::uint64 offset_;
  bool corrupt_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class BatchedListingKeyProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.BatchedListingKeyProto) */ {
 public:
  BatchedListingKeyProto();
  virtual ~BatchedListingKeyProto();

  BatchedListingKeyProto(const BatchedListingKeyProto& from);

  inline BatchedListingKeyProto& operator=(const BatchedListingKeyProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  BatchedListingKeyProto(BatchedListingKeyProto&& from) noexcept
    : BatchedListingKeyProto() {
    *this = ::std::move(from);
  }

  inline BatchedListingKeyProto& operator=(BatchedListingKeyProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const BatchedListingKeyProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const BatchedListingKeyProto* internal_default_instance() {
    return reinterpret_cast<const BatchedListingKeyProto*>(
               &_BatchedListingKeyProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    17;

  void Swap(BatchedListingKeyProto* other);
  friend void swap(BatchedListingKeyProto& a, BatchedListingKeyProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline BatchedListingKeyProto* New() const final {
    return CreateMaybeMessage<BatchedListingKeyProto>(NULL);
  }

  BatchedListingKeyProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<BatchedListingKeyProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const BatchedListingKeyProto& from);
  void MergeFrom(const BatchedListingKeyProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(BatchedListingKeyProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required bytes checksum = 1;
  bool has_checksum() const;
  void clear_checksum();
  static const int kChecksumFieldNumber = 1;
  const ::std::string& checksum() const;
  void set_checksum(const ::std::string& value);
  #if LANG_CXX11
  void set_checksum(::std::string&& value);
  #endif
  void set_checksum(const char* value);
  void set_checksum(const void* value, size_t size);
  ::std::string* mutable_checksum();
  ::std::string* release_checksum();
  void set_allocated_checksum(::std::string* checksum);

  // required bytes startAfter = 3;
  bool has_startafter() const;
  void clear_startafter();
  static const int kStartAfterFieldNumber = 3;
  const ::std::string& startafter() const;
  void set_startafter(const ::std::string& value);
  #if LANG_CXX11
  void set_startafter(::std::string&& value);
  #endif
  void set_startafter(const char* value);
  void set_startafter(const void* value, size_t size);
  ::std::string* mutable_startafter();
  ::std::string* release_startafter();
  void set_allocated_startafter(::std::string* startafter);

  // required uint32 pathIndex = 2;
  bool has_pathindex() const;
  void clear_pathindex();
  static const int kPathIndexFieldNumber = 2;
  ::google::protobuf::uint32 pathindex() const;
  void set_pathindex(::google::protobuf::uint32 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.BatchedListingKeyProto)
 private:
  void set_has_checksum();
  void clear_has_checksum();
  void set_has_pathindex();
  void clear_has_pathindex();
  void set_has_startafter();
  void clear_has_startafter();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr checksum_;
  ::google::protobuf::internal::ArenaStringPtr startafter_;
  ::google::protobuf::uint32 pathindex_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class DataEncryptionKeyProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.DataEncryptionKeyProto) */ {
 public:
  DataEncryptionKeyProto();
  virtual ~DataEncryptionKeyProto();

  DataEncryptionKeyProto(const DataEncryptionKeyProto& from);

  inline DataEncryptionKeyProto& operator=(const DataEncryptionKeyProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  DataEncryptionKeyProto(DataEncryptionKeyProto&& from) noexcept
    : DataEncryptionKeyProto() {
    *this = ::std::move(from);
  }

  inline DataEncryptionKeyProto& operator=(DataEncryptionKeyProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const DataEncryptionKeyProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const DataEncryptionKeyProto* internal_default_instance() {
    return reinterpret_cast<const DataEncryptionKeyProto*>(
               &_DataEncryptionKeyProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    18;

  void Swap(DataEncryptionKeyProto* other);
  friend void swap(DataEncryptionKeyProto& a, DataEncryptionKeyProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline DataEncryptionKeyProto* New() const final {
    return CreateMaybeMessage<DataEncryptionKeyProto>(NULL);
  }

  DataEncryptionKeyProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<DataEncryptionKeyProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const DataEncryptionKeyProto& from);
  void MergeFrom(const DataEncryptionKeyProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(DataEncryptionKeyProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required string blockPoolId = 2;
  bool has_blockpoolid() const;
  void clear_blockpoolid();
  static const int kBlockPoolIdFieldNumber = 2;
  const ::std::string& blockpoolid() const;
  void set_blockpoolid(const ::std::string& value);
  #if LANG_CXX11
  void set_blockpoolid(::std::string&& value);
  #endif
  void set_blockpoolid(const char* value);
  void set_blockpoolid(const char* value, size_t size);
  ::std::string* mutable_blockpoolid();
  ::std::string* release_blockpoolid();
  void set_allocated_blockpoolid(::std::string* blockpoolid);

  // required bytes nonce = 3;
  bool has_nonce() const;
  void clear_nonce();
  static const int kNonceFieldNumber = 3;
  const ::std::string& nonce() const;
  void set_nonce(const ::std::string& value);
  #if LANG_CXX11
  void set_nonce(::std::string&& value);
  #endif
  void set_nonce(const char* value);
  void set_nonce(const void* value, size_t size);
  ::std::string* mutable_nonce();
  ::std::string* release_nonce();
  void set_allocated_nonce(::std::string* nonce);

  // required bytes encryptionKey = 4;
  bool has_encryptionkey() const;
  void clear_encryptionkey();
  static const int kEncryptionKeyFieldNumber = 4;
  const ::std::string& encryptionkey() const;
  void set_encryptionkey(const ::std::string& value);
  #if LANG_CXX11
  void set_encryptionkey(::std::string&& value);
  #endif
  void set_encryptionkey(const char* value);
  void set_encryptionkey(const void* value, size_t size);
  ::std::string* mutable_encryptionkey();
  ::std::string* release_encryptionkey();
  void set_allocated_encryptionkey(::std::string* encryptionkey);

  // optional string encryptionAlgorithm = 6;
  bool has_encryptionalgorithm() const;
  void clear_encryptionalgorithm();
  static const int kEncryptionAlgorithmFieldNumber = 6;
  const ::std::string& encryptionalgorithm() const;
  void set_encryptionalgorithm(const ::std::string& value);
  #if LANG_CXX11
  void set_encryptionalgorithm(::std::string&& value);
  #endif
  void set_encryptionalgorithm(const char* value);
  void set_encryptionalgorithm(const char* value, size_t size);
  ::std::string* mutable_encryptionalgorithm();
  ::std::string* release_encryptionalgorithm();
  void set_allocated_encryptionalgorithm(::std::string* encryptionalgorithm);

  // required uint64 expiryDate = 5;
  bool has_expirydate() const;
  void clear_expirydate();
  static const int kExpiryDateFieldNumber = 5;
  ::google::protobuf::uint64 expirydate() const;
  void set_expirydate(::google::protobuf::uint64 value);

  // required uint32 keyId = 1;
  bool has_keyid() const;
  void clear_keyid();
  static const int kKeyIdFieldNumber = 1;
  ::google::protobuf::uint32 keyid() const;
  void set_keyid(::google::protobuf::uint32 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.DataEncryptionKeyProto)
 private:
  void set_has_keyid();
  void clear_has_keyid();
  void set_has_blockpoolid();
  void clear_has_blockpoolid();
  void set_has_nonce();
  void clear_has_nonce();
  void set_has_encryptionkey();
  void clear_has_encryptionkey();
  void set_has_expirydate();
  void clear_has_expirydate();
  void set_has_encryptionalgorithm();
  void clear_has_encryptionalgorithm();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr blockpoolid_;
  ::google::protobuf::internal::ArenaStringPtr nonce_;
  ::google::protobuf::internal::ArenaStringPtr encryptionkey_;
  ::google::protobuf::internal::ArenaStringPtr encryptionalgorithm_;
  ::google::protobuf::uint64 expirydate_;
  ::google::protobuf::uint32 keyid_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class FileEncryptionInfoProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.FileEncryptionInfoProto) */ {
 public:
  FileEncryptionInfoProto();
  virtual ~FileEncryptionInfoProto();

  FileEncryptionInfoProto(const FileEncryptionInfoProto& from);

  inline FileEncryptionInfoProto& operator=(const FileEncryptionInfoProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  FileEncryptionInfoProto(FileEncryptionInfoProto&& from) noexcept
    : FileEncryptionInfoProto() {
    *this = ::std::move(from);
  }

  inline FileEncryptionInfoProto& operator=(FileEncryptionInfoProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const FileEncryptionInfoProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const FileEncryptionInfoProto* internal_default_instance() {
    return reinterpret_cast<const FileEncryptionInfoProto*>(
               &_FileEncryptionInfoProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    19;

  void Swap(FileEncryptionInfoProto* other);
  friend void swap(FileEncryptionInfoProto& a, FileEncryptionInfoProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline FileEncryptionInfoProto* New() const final {
    return CreateMaybeMessage<FileEncryptionInfoProto>(NULL);
  }

  FileEncryptionInfoProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<FileEncryptionInfoProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const FileEncryptionInfoProto& from);
  void MergeFrom(const FileEncryptionInfoProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(FileEncryptionInfoProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required bytes key = 3;
  bool has_key() const;
  void clear_key();
  static const int kKeyFieldNumber = 3;
  const ::std::string& key() const;
  void set_key(const ::std::string& value);
  #if LANG_CXX11
  void set_key(::std::string&& value);
  #endif
  void set_key(const char* value);
  void set_key(const void* value, size_t size);
  ::std::string* mutable_key();
  ::std::string* release_key();
  void set_allocated_key(::std::string* key);

  // required bytes iv = 4;
  bool has_iv() const;
  void clear_iv();
  static const int kIvFieldNumber = 4;
  const ::std::string& iv() const;
  void set_iv(const ::std::string& value);
  #if LANG_CXX11
  void set_iv(::std::string&& value);
  #endif
  void set_iv(const char* value);
  void set_iv(const void* value, size_t size);
  ::std::string* mutable_iv();
  ::std::string* release_iv();
  void set_allocated_iv(::std::string* iv);

  // required string keyName = 5;
  bool has_keyname() const;
  void clear_keyname();
  static const int kKeyNameFieldNumber = 5;
  const ::std::string& keyname() const;
  void set_keyname(const ::std::string& value);
  #if LANG_CXX11
  void set_keyname(::std::string&& value);
  #endif
  void set_keyname(const char* value);
  void set_keyname(const char* value, size_t size);
  ::std::string* mutable_keyname();
  ::std::string* release_keyname();
  void set_allocated_keyname(::std::string* keyname);

  // required string ezKeyVersionName = 6;
  bool has_ezkeyversionname() const;
  void clear_ezkeyversionname();
  static const int kEzKeyVersionNameFieldNumber = 6;
  const ::std::string& ezkeyversionname() const;
  void set_ezkeyversionname(const ::std::string& value);
  #if LANG_CXX11
  void set_ezkeyversionname(::std::string&& value);
  #endif
  void set_ezkeyversionname(const char* value);
  void set_ezkeyversionname(const char* value, size_t size);
  ::std::string* mutable_ezkeyversionname();
  ::std::string* release_ezkeyversionname();
  void set_allocated_ezkeyversionname(::std::string* ezkeyversionname);

  // required .hadoop.hdfs.CipherSuiteProto suite = 1;
  bool has_suite() const;
  void clear_suite();
  static const int kSuiteFieldNumber = 1;
  ::hadoop::hdfs::CipherSuiteProto suite() const;
  void set_suite(::hadoop::hdfs::CipherSuiteProto value);

  // required .hadoop.hdfs.CryptoProtocolVersionProto cryptoProtocolVersion = 2;
  bool has_cryptoprotocolversion() const;
  void clear_cryptoprotocolversion();
  static const int kCryptoProtocolVersionFieldNumber = 2;
  ::hadoop::hdfs::CryptoProtocolVersionProto cryptoprotocolversion() const;
  void set_cryptoprotocolversion(::hadoop::hdfs::CryptoProtocolVersionProto value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.FileEncryptionInfoProto)
 private:
  void set_has_suite();
  void clear_has_suite();
  void set_has_cryptoprotocolversion();
  void clear_has_cryptoprotocolversion();
  void set_has_key();
  void clear_has_key();
  void set_has_iv();
  void clear_has_iv();
  void set_has_keyname();
  void clear_has_keyname();
  void set_has_ezkeyversionname();
  void clear_has_ezkeyversionname();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr key_;
  ::google::protobuf::internal::ArenaStringPtr iv_;
  ::google::protobuf::internal::ArenaStringPtr keyname_;
  ::google::protobuf::internal::ArenaStringPtr ezkeyversionname_;
  int suite_;
  int cryptoprotocolversion_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class PerFileEncryptionInfoProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.PerFileEncryptionInfoProto) */ {
 public:
  PerFileEncryptionInfoProto();
  virtual ~PerFileEncryptionInfoProto();

  PerFileEncryptionInfoProto(const PerFileEncryptionInfoProto& from);

  inline PerFileEncryptionInfoProto& operator=(const PerFileEncryptionInfoProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  PerFileEncryptionInfoProto(PerFileEncryptionInfoProto&& from) noexcept
    : PerFileEncryptionInfoProto() {
    *this = ::std::move(from);
  }

  inline PerFileEncryptionInfoProto& operator=(PerFileEncryptionInfoProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const PerFileEncryptionInfoProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const PerFileEncryptionInfoProto* internal_default_instance() {
    return reinterpret_cast<const PerFileEncryptionInfoProto*>(
               &_PerFileEncryptionInfoProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    20;

  void Swap(PerFileEncryptionInfoProto* other);
  friend void swap(PerFileEncryptionInfoProto& a, PerFileEncryptionInfoProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline PerFileEncryptionInfoProto* New() const final {
    return CreateMaybeMessage<PerFileEncryptionInfoProto>(NULL);
  }

  PerFileEncryptionInfoProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<PerFileEncryptionInfoProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const PerFileEncryptionInfoProto& from);
  void MergeFrom(const PerFileEncryptionInfoProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(PerFileEncryptionInfoProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required bytes key = 1;
  bool has_key() const;
  void clear_key();
  static const int kKeyFieldNumber = 1;
  const ::std::string& key() const;
  void set_key(const ::std::string& value);
  #if LANG_CXX11
  void set_key(::std::string&& value);
  #endif
  void set_key(const char* value);
  void set_key(const void* value, size_t size);
  ::std::string* mutable_key();
  ::std::string* release_key();
  void set_allocated_key(::std::string* key);

  // required bytes iv = 2;
  bool has_iv() const;
  void clear_iv();
  static const int kIvFieldNumber = 2;
  const ::std::string& iv() const;
  void set_iv(const ::std::string& value);
  #if LANG_CXX11
  void set_iv(::std::string&& value);
  #endif
  void set_iv(const char* value);
  void set_iv(const void* value, size_t size);
  ::std::string* mutable_iv();
  ::std::string* release_iv();
  void set_allocated_iv(::std::string* iv);

  // required string ezKeyVersionName = 3;
  bool has_ezkeyversionname() const;
  void clear_ezkeyversionname();
  static const int kEzKeyVersionNameFieldNumber = 3;
  const ::std::string& ezkeyversionname() const;
  void set_ezkeyversionname(const ::std::string& value);
  #if LANG_CXX11
  void set_ezkeyversionname(::std::string&& value);
  #endif
  void set_ezkeyversionname(const char* value);
  void set_ezkeyversionname(const char* value, size_t size);
  ::std::string* mutable_ezkeyversionname();
  ::std::string* release_ezkeyversionname();
  void set_allocated_ezkeyversionname(::std::string* ezkeyversionname);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.PerFileEncryptionInfoProto)
 private:
  void set_has_key();
  void clear_has_key();
  void set_has_iv();
  void clear_has_iv();
  void set_has_ezkeyversionname();
  void clear_has_ezkeyversionname();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr key_;
  ::google::protobuf::internal::ArenaStringPtr iv_;
  ::google::protobuf::internal::ArenaStringPtr ezkeyversionname_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class ZoneEncryptionInfoProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.ZoneEncryptionInfoProto) */ {
 public:
  ZoneEncryptionInfoProto();
  virtual ~ZoneEncryptionInfoProto();

  ZoneEncryptionInfoProto(const ZoneEncryptionInfoProto& from);

  inline ZoneEncryptionInfoProto& operator=(const ZoneEncryptionInfoProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  ZoneEncryptionInfoProto(ZoneEncryptionInfoProto&& from) noexcept
    : ZoneEncryptionInfoProto() {
    *this = ::std::move(from);
  }

  inline ZoneEncryptionInfoProto& operator=(ZoneEncryptionInfoProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ZoneEncryptionInfoProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const ZoneEncryptionInfoProto* internal_default_instance() {
    return reinterpret_cast<const ZoneEncryptionInfoProto*>(
               &_ZoneEncryptionInfoProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    21;

  void Swap(ZoneEncryptionInfoProto* other);
  friend void swap(ZoneEncryptionInfoProto& a, ZoneEncryptionInfoProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline ZoneEncryptionInfoProto* New() const final {
    return CreateMaybeMessage<ZoneEncryptionInfoProto>(NULL);
  }

  ZoneEncryptionInfoProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<ZoneEncryptionInfoProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const ZoneEncryptionInfoProto& from);
  void MergeFrom(const ZoneEncryptionInfoProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(ZoneEncryptionInfoProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required string keyName = 3;
  bool has_keyname() const;
  void clear_keyname();
  static const int kKeyNameFieldNumber = 3;
  const ::std::string& keyname() const;
  void set_keyname(const ::std::string& value);
  #if LANG_CXX11
  void set_keyname(::std::string&& value);
  #endif
  void set_keyname(const char* value);
  void set_keyname(const char* value, size_t size);
  ::std::string* mutable_keyname();
  ::std::string* release_keyname();
  void set_allocated_keyname(::std::string* keyname);

  // optional .hadoop.hdfs.ReencryptionInfoProto reencryptionProto = 4;
  bool has_reencryptionproto() const;
  void clear_reencryptionproto();
  static const int kReencryptionProtoFieldNumber = 4;
  private:
  const ::hadoop::hdfs::ReencryptionInfoProto& _internal_reencryptionproto() const;
  public:
  const ::hadoop::hdfs::ReencryptionInfoProto& reencryptionproto() const;
  ::hadoop::hdfs::ReencryptionInfoProto* release_reencryptionproto();
  ::hadoop::hdfs::ReencryptionInfoProto* mutable_reencryptionproto();
  void set_allocated_reencryptionproto(::hadoop::hdfs::ReencryptionInfoProto* reencryptionproto);

  // required .hadoop.hdfs.CipherSuiteProto suite = 1;
  bool has_suite() const;
  void clear_suite();
  static const int kSuiteFieldNumber = 1;
  ::hadoop::hdfs::CipherSuiteProto suite() const;
  void set_suite(::hadoop::hdfs::CipherSuiteProto value);

  // required .hadoop.hdfs.CryptoProtocolVersionProto cryptoProtocolVersion = 2;
  bool has_cryptoprotocolversion() const;
  void clear_cryptoprotocolversion();
  static const int kCryptoProtocolVersionFieldNumber = 2;
  ::hadoop::hdfs::CryptoProtocolVersionProto cryptoprotocolversion() const;
  void set_cryptoprotocolversion(::hadoop::hdfs::CryptoProtocolVersionProto value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.ZoneEncryptionInfoProto)
 private:
  void set_has_suite();
  void clear_has_suite();
  void set_has_cryptoprotocolversion();
  void clear_has_cryptoprotocolversion();
  void set_has_keyname();
  void clear_has_keyname();
  void set_has_reencryptionproto();
  void clear_has_reencryptionproto();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr keyname_;
  ::hadoop::hdfs::ReencryptionInfoProto* reencryptionproto_;
  int suite_;
  int cryptoprotocolversion_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class ReencryptionInfoProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.ReencryptionInfoProto) */ {
 public:
  ReencryptionInfoProto();
  virtual ~ReencryptionInfoProto();

  ReencryptionInfoProto(const ReencryptionInfoProto& from);

  inline ReencryptionInfoProto& operator=(const ReencryptionInfoProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  ReencryptionInfoProto(ReencryptionInfoProto&& from) noexcept
    : ReencryptionInfoProto() {
    *this = ::std::move(from);
  }

  inline ReencryptionInfoProto& operator=(ReencryptionInfoProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ReencryptionInfoProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const ReencryptionInfoProto* internal_default_instance() {
    return reinterpret_cast<const ReencryptionInfoProto*>(
               &_ReencryptionInfoProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    22;

  void Swap(ReencryptionInfoProto* other);
  friend void swap(ReencryptionInfoProto& a, ReencryptionInfoProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline ReencryptionInfoProto* New() const final {
    return CreateMaybeMessage<ReencryptionInfoProto>(NULL);
  }

  ReencryptionInfoProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<ReencryptionInfoProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const ReencryptionInfoProto& from);
  void MergeFrom(const ReencryptionInfoProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(ReencryptionInfoProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required string ezKeyVersionName = 1;
  bool has_ezkeyversionname() const;
  void clear_ezkeyversionname();
  static const int kEzKeyVersionNameFieldNumber = 1;
  const ::std::string& ezkeyversionname() const;
  void set_ezkeyversionname(const ::std::string& value);
  #if LANG_CXX11
  void set_ezkeyversionname(::std::string&& value);
  #endif
  void set_ezkeyversionname(const char* value);
  void set_ezkeyversionname(const char* value, size_t size);
  ::std::string* mutable_ezkeyversionname();
  ::std::string* release_ezkeyversionname();
  void set_allocated_ezkeyversionname(::std::string* ezkeyversionname);

  // optional string lastFile = 7;
  bool has_lastfile() const;
  void clear_lastfile();
  static const int kLastFileFieldNumber = 7;
  const ::std::string& lastfile() const;
  void set_lastfile(const ::std::string& value);
  #if LANG_CXX11
  void set_lastfile(::std::string&& value);
  #endif
  void set_lastfile(const char* value);
  void set_lastfile(const char* value, size_t size);
  ::std::string* mutable_lastfile();
  ::std::string* release_lastfile();
  void set_allocated_lastfile(::std::string* lastfile);

  // required uint64 submissionTime = 2;
  bool has_submissiontime() const;
  void clear_submissiontime();
  static const int kSubmissionTimeFieldNumber = 2;
  ::google::protobuf::uint64 submissiontime() const;
  void set_submissiontime(::google::protobuf::uint64 value);

  // required int64 numReencrypted = 4;
  bool has_numreencrypted() const;
  void clear_numreencrypted();
  static const int kNumReencryptedFieldNumber = 4;
  ::google::protobuf::int64 numreencrypted() const;
  void set_numreencrypted(::google::protobuf::int64 value);

  // required int64 numFailures = 5;
  bool has_numfailures() const;
  void clear_numfailures();
  static const int kNumFailuresFieldNumber = 5;
  ::google::protobuf::int64 numfailures() const;
  void set_numfailures(::google::protobuf::int64 value);

  // optional uint64 completionTime = 6;
  bool has_completiontime() const;
  void clear_completiontime();
  static const int kCompletionTimeFieldNumber = 6;
  ::google::protobuf::uint64 completiontime() const;
  void set_completiontime(::google::protobuf::uint64 value);

  // required bool canceled = 3;
  bool has_canceled() const;
  void clear_canceled();
  static const int kCanceledFieldNumber = 3;
  bool canceled() const;
  void set_canceled(bool value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.ReencryptionInfoProto)
 private:
  void set_has_ezkeyversionname();
  void clear_has_ezkeyversionname();
  void set_has_submissiontime();
  void clear_has_submissiontime();
  void set_has_canceled();
  void clear_has_canceled();
  void set_has_numreencrypted();
  void clear_has_numreencrypted();
  void set_has_numfailures();
  void clear_has_numfailures();
  void set_has_completiontime();
  void clear_has_completiontime();
  void set_has_lastfile();
  void clear_has_lastfile();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr ezkeyversionname_;
  ::google::protobuf::internal::ArenaStringPtr lastfile_;
  ::google::protobuf::uint64 submissiontime_;
  ::google::protobuf::int64 numreencrypted_;
  ::google::protobuf::int64 numfailures_;
  ::google::protobuf::uint64 completiontime_;
  bool canceled_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class CipherOptionProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.CipherOptionProto) */ {
 public:
  CipherOptionProto();
  virtual ~CipherOptionProto();

  CipherOptionProto(const CipherOptionProto& from);

  inline CipherOptionProto& operator=(const CipherOptionProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  CipherOptionProto(CipherOptionProto&& from) noexcept
    : CipherOptionProto() {
    *this = ::std::move(from);
  }

  inline CipherOptionProto& operator=(CipherOptionProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const CipherOptionProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const CipherOptionProto* internal_default_instance() {
    return reinterpret_cast<const CipherOptionProto*>(
               &_CipherOptionProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    23;

  void Swap(CipherOptionProto* other);
  friend void swap(CipherOptionProto& a, CipherOptionProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline CipherOptionProto* New() const final {
    return CreateMaybeMessage<CipherOptionProto>(NULL);
  }

  CipherOptionProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<CipherOptionProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const CipherOptionProto& from);
  void MergeFrom(const CipherOptionProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(CipherOptionProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional bytes inKey = 2;
  bool has_inkey() const;
  void clear_inkey();
  static const int kInKeyFieldNumber = 2;
  const ::std::string& inkey() const;
  void set_inkey(const ::std::string& value);
  #if LANG_CXX11
  void set_inkey(::std::string&& value);
  #endif
  void set_inkey(const char* value);
  void set_inkey(const void* value, size_t size);
  ::std::string* mutable_inkey();
  ::std::string* release_inkey();
  void set_allocated_inkey(::std::string* inkey);

  // optional bytes inIv = 3;
  bool has_iniv() const;
  void clear_iniv();
  static const int kInIvFieldNumber = 3;
  const ::std::string& iniv() const;
  void set_iniv(const ::std::string& value);
  #if LANG_CXX11
  void set_iniv(::std::string&& value);
  #endif
  void set_iniv(const char* value);
  void set_iniv(const void* value, size_t size);
  ::std::string* mutable_iniv();
  ::std::string* release_iniv();
  void set_allocated_iniv(::std::string* iniv);

  // optional bytes outKey = 4;
  bool has_outkey() const;
  void clear_outkey();
  static const int kOutKeyFieldNumber = 4;
  const ::std::string& outkey() const;
  void set_outkey(const ::std::string& value);
  #if LANG_CXX11
  void set_outkey(::std::string&& value);
  #endif
  void set_outkey(const char* value);
  void set_outkey(const void* value, size_t size);
  ::std::string* mutable_outkey();
  ::std::string* release_outkey();
  void set_allocated_outkey(::std::string* outkey);

  // optional bytes outIv = 5;
  bool has_outiv() const;
  void clear_outiv();
  static const int kOutIvFieldNumber = 5;
  const ::std::string& outiv() const;
  void set_outiv(const ::std::string& value);
  #if LANG_CXX11
  void set_outiv(::std::string&& value);
  #endif
  void set_outiv(const char* value);
  void set_outiv(const void* value, size_t size);
  ::std::string* mutable_outiv();
  ::std::string* release_outiv();
  void set_allocated_outiv(::std::string* outiv);

  // required .hadoop.hdfs.CipherSuiteProto suite = 1;
  bool has_suite() const;
  void clear_suite();
  static const int kSuiteFieldNumber = 1;
  ::hadoop::hdfs::CipherSuiteProto suite() const;
  void set_suite(::hadoop::hdfs::CipherSuiteProto value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.CipherOptionProto)
 private:
  void set_has_suite();
  void clear_has_suite();
  void set_has_inkey();
  void clear_has_inkey();
  void set_has_iniv();
  void clear_has_iniv();
  void set_has_outkey();
  void clear_has_outkey();
  void set_has_outiv();
  void clear_has_outiv();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr inkey_;
  ::google::protobuf::internal::ArenaStringPtr iniv_;
  ::google::protobuf::internal::ArenaStringPtr outkey_;
  ::google::protobuf::internal::ArenaStringPtr outiv_;
  int suite_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class LocatedBlocksProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.LocatedBlocksProto) */ {
 public:
  LocatedBlocksProto();
  virtual ~LocatedBlocksProto();

  LocatedBlocksProto(const LocatedBlocksProto& from);

  inline LocatedBlocksProto& operator=(const LocatedBlocksProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  LocatedBlocksProto(LocatedBlocksProto&& from) noexcept
    : LocatedBlocksProto() {
    *this = ::std::move(from);
  }

  inline LocatedBlocksProto& operator=(LocatedBlocksProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const LocatedBlocksProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const LocatedBlocksProto* internal_default_instance() {
    return reinterpret_cast<const LocatedBlocksProto*>(
               &_LocatedBlocksProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    24;

  void Swap(LocatedBlocksProto* other);
  friend void swap(LocatedBlocksProto& a, LocatedBlocksProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline LocatedBlocksProto* New() const final {
    return CreateMaybeMessage<LocatedBlocksProto>(NULL);
  }

  LocatedBlocksProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<LocatedBlocksProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const LocatedBlocksProto& from);
  void MergeFrom(const LocatedBlocksProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(LocatedBlocksProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.hdfs.LocatedBlockProto blocks = 2;
  int blocks_size() const;
  void clear_blocks();
  static const int kBlocksFieldNumber = 2;
  ::hadoop::hdfs::LocatedBlockProto* mutable_blocks(int index);
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::LocatedBlockProto >*
      mutable_blocks();
  const ::hadoop::hdfs::LocatedBlockProto& blocks(int index) const;
  ::hadoop::hdfs::LocatedBlockProto* add_blocks();
  const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::LocatedBlockProto >&
      blocks() const;

  // optional .hadoop.hdfs.LocatedBlockProto lastBlock = 4;
  bool has_lastblock() const;
  void clear_lastblock();
  static const int kLastBlockFieldNumber = 4;
  private:
  const ::hadoop::hdfs::LocatedBlockProto& _internal_lastblock() const;
  public:
  const ::hadoop::hdfs::LocatedBlockProto& lastblock() const;
  ::hadoop::hdfs::LocatedBlockProto* release_lastblock();
  ::hadoop::hdfs::LocatedBlockProto* mutable_lastblock();
  void set_allocated_lastblock(::hadoop::hdfs::LocatedBlockProto* lastblock);

  // optional .hadoop.hdfs.FileEncryptionInfoProto fileEncryptionInfo = 6;
  bool has_fileencryptioninfo() const;
  void clear_fileencryptioninfo();
  static const int kFileEncryptionInfoFieldNumber = 6;
  private:
  const ::hadoop::hdfs::FileEncryptionInfoProto& _internal_fileencryptioninfo() const;
  public:
  const ::hadoop::hdfs::FileEncryptionInfoProto& fileencryptioninfo() const;
  ::hadoop::hdfs::FileEncryptionInfoProto* release_fileencryptioninfo();
  ::hadoop::hdfs::FileEncryptionInfoProto* mutable_fileencryptioninfo();
  void set_allocated_fileencryptioninfo(::hadoop::hdfs::FileEncryptionInfoProto* fileencryptioninfo);

  // optional .hadoop.hdfs.ErasureCodingPolicyProto ecPolicy = 7;
  bool has_ecpolicy() const;
  void clear_ecpolicy();
  static const int kEcPolicyFieldNumber = 7;
  private:
  const ::hadoop::hdfs::ErasureCodingPolicyProto& _internal_ecpolicy() const;
  public:
  const ::hadoop::hdfs::ErasureCodingPolicyProto& ecpolicy() const;
  ::hadoop::hdfs::ErasureCodingPolicyProto* release_ecpolicy();
  ::hadoop::hdfs::ErasureCodingPolicyProto* mutable_ecpolicy();
  void set_allocated_ecpolicy(::hadoop::hdfs::ErasureCodingPolicyProto* ecpolicy);

  // required uint64 fileLength = 1;
  bool has_filelength() const;
  void clear_filelength();
  static const int kFileLengthFieldNumber = 1;
  ::google::protobuf::uint64 filelength() const;
  void set_filelength(::google::protobuf::uint64 value);

  // required bool underConstruction = 3;
  bool has_underconstruction() const;
  void clear_underconstruction();
  static const int kUnderConstructionFieldNumber = 3;
  bool underconstruction() const;
  void set_underconstruction(bool value);

  // required bool isLastBlockComplete = 5;
  bool has_islastblockcomplete() const;
  void clear_islastblockcomplete();
  static const int kIsLastBlockCompleteFieldNumber = 5;
  bool islastblockcomplete() const;
  void set_islastblockcomplete(bool value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.LocatedBlocksProto)
 private:
  void set_has_filelength();
  void clear_has_filelength();
  void set_has_underconstruction();
  void clear_has_underconstruction();
  void set_has_lastblock();
  void clear_has_lastblock();
  void set_has_islastblockcomplete();
  void clear_has_islastblockcomplete();
  void set_has_fileencryptioninfo();
  void clear_has_fileencryptioninfo();
  void set_has_ecpolicy();
  void clear_has_ecpolicy();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::LocatedBlockProto > blocks_;
  ::hadoop::hdfs::LocatedBlockProto* lastblock_;
  ::hadoop::hdfs::FileEncryptionInfoProto* fileencryptioninfo_;
  ::hadoop::hdfs::ErasureCodingPolicyProto* ecpolicy_;
  ::google::protobuf::uint64 filelength_;
  bool underconstruction_;
  bool islastblockcomplete_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class ECSchemaOptionEntryProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.ECSchemaOptionEntryProto) */ {
 public:
  ECSchemaOptionEntryProto();
  virtual ~ECSchemaOptionEntryProto();

  ECSchemaOptionEntryProto(const ECSchemaOptionEntryProto& from);

  inline ECSchemaOptionEntryProto& operator=(const ECSchemaOptionEntryProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  ECSchemaOptionEntryProto(ECSchemaOptionEntryProto&& from) noexcept
    : ECSchemaOptionEntryProto() {
    *this = ::std::move(from);
  }

  inline ECSchemaOptionEntryProto& operator=(ECSchemaOptionEntryProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ECSchemaOptionEntryProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const ECSchemaOptionEntryProto* internal_default_instance() {
    return reinterpret_cast<const ECSchemaOptionEntryProto*>(
               &_ECSchemaOptionEntryProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    25;

  void Swap(ECSchemaOptionEntryProto* other);
  friend void swap(ECSchemaOptionEntryProto& a, ECSchemaOptionEntryProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline ECSchemaOptionEntryProto* New() const final {
    return CreateMaybeMessage<ECSchemaOptionEntryProto>(NULL);
  }

  ECSchemaOptionEntryProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<ECSchemaOptionEntryProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const ECSchemaOptionEntryProto& from);
  void MergeFrom(const ECSchemaOptionEntryProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(ECSchemaOptionEntryProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required string key = 1;
  bool has_key() const;
  void clear_key();
  static const int kKeyFieldNumber = 1;
  const ::std::string& key() const;
  void set_key(const ::std::string& value);
  #if LANG_CXX11
  void set_key(::std::string&& value);
  #endif
  void set_key(const char* value);
  void set_key(const char* value, size_t size);
  ::std::string* mutable_key();
  ::std::string* release_key();
  void set_allocated_key(::std::string* key);

  // required string value = 2;
  bool has_value() const;
  void clear_value();
  static const int kValueFieldNumber = 2;
  const ::std::string& value() const;
  void set_value(const ::std::string& value);
  #if LANG_CXX11
  void set_value(::std::string&& value);
  #endif
  void set_value(const char* value);
  void set_value(const char* value, size_t size);
  ::std::string* mutable_value();
  ::std::string* release_value();
  void set_allocated_value(::std::string* value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.ECSchemaOptionEntryProto)
 private:
  void set_has_key();
  void clear_has_key();
  void set_has_value();
  void clear_has_value();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr key_;
  ::google::protobuf::internal::ArenaStringPtr value_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class ECSchemaProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.ECSchemaProto) */ {
 public:
  ECSchemaProto();
  virtual ~ECSchemaProto();

  ECSchemaProto(const ECSchemaProto& from);

  inline ECSchemaProto& operator=(const ECSchemaProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  ECSchemaProto(ECSchemaProto&& from) noexcept
    : ECSchemaProto() {
    *this = ::std::move(from);
  }

  inline ECSchemaProto& operator=(ECSchemaProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ECSchemaProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const ECSchemaProto* internal_default_instance() {
    return reinterpret_cast<const ECSchemaProto*>(
               &_ECSchemaProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    26;

  void Swap(ECSchemaProto* other);
  friend void swap(ECSchemaProto& a, ECSchemaProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline ECSchemaProto* New() const final {
    return CreateMaybeMessage<ECSchemaProto>(NULL);
  }

  ECSchemaProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<ECSchemaProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const ECSchemaProto& from);
  void MergeFrom(const ECSchemaProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(ECSchemaProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.hdfs.ECSchemaOptionEntryProto options = 4;
  int options_size() const;
  void clear_options();
  static const int kOptionsFieldNumber = 4;
  ::hadoop::hdfs::ECSchemaOptionEntryProto* mutable_options(int index);
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::ECSchemaOptionEntryProto >*
      mutable_options();
  const ::hadoop::hdfs::ECSchemaOptionEntryProto& options(int index) const;
  ::hadoop::hdfs::ECSchemaOptionEntryProto* add_options();
  const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::ECSchemaOptionEntryProto >&
      options() const;

  // required string codecName = 1;
  bool has_codecname() const;
  void clear_codecname();
  static const int kCodecNameFieldNumber = 1;
  const ::std::string& codecname() const;
  void set_codecname(const ::std::string& value);
  #if LANG_CXX11
  void set_codecname(::std::string&& value);
  #endif
  void set_codecname(const char* value);
  void set_codecname(const char* value, size_t size);
  ::std::string* mutable_codecname();
  ::std::string* release_codecname();
  void set_allocated_codecname(::std::string* codecname);

  // required uint32 dataUnits = 2;
  bool has_dataunits() const;
  void clear_dataunits();
  static const int kDataUnitsFieldNumber = 2;
  ::google::protobuf::uint32 dataunits() const;
  void set_dataunits(::google::protobuf::uint32 value);

  // required uint32 parityUnits = 3;
  bool has_parityunits() const;
  void clear_parityunits();
  static const int kParityUnitsFieldNumber = 3;
  ::google::protobuf::uint32 parityunits() const;
  void set_parityunits(::google::protobuf::uint32 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.ECSchemaProto)
 private:
  void set_has_codecname();
  void clear_has_codecname();
  void set_has_dataunits();
  void clear_has_dataunits();
  void set_has_parityunits();
  void clear_has_parityunits();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::ECSchemaOptionEntryProto > options_;
  ::google::protobuf::internal::ArenaStringPtr codecname_;
  ::google::protobuf::uint32 dataunits_;
  ::google::protobuf::uint32 parityunits_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class ErasureCodingPolicyProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.ErasureCodingPolicyProto) */ {
 public:
  ErasureCodingPolicyProto();
  virtual ~ErasureCodingPolicyProto();

  ErasureCodingPolicyProto(const ErasureCodingPolicyProto& from);

  inline ErasureCodingPolicyProto& operator=(const ErasureCodingPolicyProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  ErasureCodingPolicyProto(ErasureCodingPolicyProto&& from) noexcept
    : ErasureCodingPolicyProto() {
    *this = ::std::move(from);
  }

  inline ErasureCodingPolicyProto& operator=(ErasureCodingPolicyProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ErasureCodingPolicyProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const ErasureCodingPolicyProto* internal_default_instance() {
    return reinterpret_cast<const ErasureCodingPolicyProto*>(
               &_ErasureCodingPolicyProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    27;

  void Swap(ErasureCodingPolicyProto* other);
  friend void swap(ErasureCodingPolicyProto& a, ErasureCodingPolicyProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline ErasureCodingPolicyProto* New() const final {
    return CreateMaybeMessage<ErasureCodingPolicyProto>(NULL);
  }

  ErasureCodingPolicyProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<ErasureCodingPolicyProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const ErasureCodingPolicyProto& from);
  void MergeFrom(const ErasureCodingPolicyProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(ErasureCodingPolicyProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string name = 1;
  bool has_name() const;
  void clear_name();
  static const int kNameFieldNumber = 1;
  const ::std::string& name() const;
  void set_name(const ::std::string& value);
  #if LANG_CXX11
  void set_name(::std::string&& value);
  #endif
  void set_name(const char* value);
  void set_name(const char* value, size_t size);
  ::std::string* mutable_name();
  ::std::string* release_name();
  void set_allocated_name(::std::string* name);

  // optional .hadoop.hdfs.ECSchemaProto schema = 2;
  bool has_schema() const;
  void clear_schema();
  static const int kSchemaFieldNumber = 2;
  private:
  const ::hadoop::hdfs::ECSchemaProto& _internal_schema() const;
  public:
  const ::hadoop::hdfs::ECSchemaProto& schema() const;
  ::hadoop::hdfs::ECSchemaProto* release_schema();
  ::hadoop::hdfs::ECSchemaProto* mutable_schema();
  void set_allocated_schema(::hadoop::hdfs::ECSchemaProto* schema);

  // optional uint32 cellSize = 3;
  bool has_cellsize() const;
  void clear_cellsize();
  static const int kCellSizeFieldNumber = 3;
  ::google::protobuf::uint32 cellsize() const;
  void set_cellsize(::google::protobuf::uint32 value);

  // required uint32 id = 4;
  bool has_id() const;
  void clear_id();
  static const int kIdFieldNumber = 4;
  ::google::protobuf::uint32 id() const;
  void set_id(::google::protobuf::uint32 value);

  // optional .hadoop.hdfs.ErasureCodingPolicyState state = 5 [default = ENABLED];
  bool has_state() const;
  void clear_state();
  static const int kStateFieldNumber = 5;
  ::hadoop::hdfs::ErasureCodingPolicyState state() const;
  void set_state(::hadoop::hdfs::ErasureCodingPolicyState value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.ErasureCodingPolicyProto)
 private:
  void set_has_name();
  void clear_has_name();
  void set_has_schema();
  void clear_has_schema();
  void set_has_cellsize();
  void clear_has_cellsize();
  void set_has_id();
  void clear_has_id();
  void set_has_state();
  void clear_has_state();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr name_;
  ::hadoop::hdfs::ECSchemaProto* schema_;
  ::google::protobuf::uint32 cellsize_;
  ::google::protobuf::uint32 id_;
  int state_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class AddErasureCodingPolicyResponseProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.AddErasureCodingPolicyResponseProto) */ {
 public:
  AddErasureCodingPolicyResponseProto();
  virtual ~AddErasureCodingPolicyResponseProto();

  AddErasureCodingPolicyResponseProto(const AddErasureCodingPolicyResponseProto& from);

  inline AddErasureCodingPolicyResponseProto& operator=(const AddErasureCodingPolicyResponseProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  AddErasureCodingPolicyResponseProto(AddErasureCodingPolicyResponseProto&& from) noexcept
    : AddErasureCodingPolicyResponseProto() {
    *this = ::std::move(from);
  }

  inline AddErasureCodingPolicyResponseProto& operator=(AddErasureCodingPolicyResponseProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const AddErasureCodingPolicyResponseProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const AddErasureCodingPolicyResponseProto* internal_default_instance() {
    return reinterpret_cast<const AddErasureCodingPolicyResponseProto*>(
               &_AddErasureCodingPolicyResponseProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    28;

  void Swap(AddErasureCodingPolicyResponseProto* other);
  friend void swap(AddErasureCodingPolicyResponseProto& a, AddErasureCodingPolicyResponseProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline AddErasureCodingPolicyResponseProto* New() const final {
    return CreateMaybeMessage<AddErasureCodingPolicyResponseProto>(NULL);
  }

  AddErasureCodingPolicyResponseProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<AddErasureCodingPolicyResponseProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const AddErasureCodingPolicyResponseProto& from);
  void MergeFrom(const AddErasureCodingPolicyResponseProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(AddErasureCodingPolicyResponseProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string errorMsg = 3;
  bool has_errormsg() const;
  void clear_errormsg();
  static const int kErrorMsgFieldNumber = 3;
  const ::std::string& errormsg() const;
  void set_errormsg(const ::std::string& value);
  #if LANG_CXX11
  void set_errormsg(::std::string&& value);
  #endif
  void set_errormsg(const char* value);
  void set_errormsg(const char* value, size_t size);
  ::std::string* mutable_errormsg();
  ::std::string* release_errormsg();
  void set_allocated_errormsg(::std::string* errormsg);

  // required .hadoop.hdfs.ErasureCodingPolicyProto policy = 1;
  bool has_policy() const;
  void clear_policy();
  static const int kPolicyFieldNumber = 1;
  private:
  const ::hadoop::hdfs::ErasureCodingPolicyProto& _internal_policy() const;
  public:
  const ::hadoop::hdfs::ErasureCodingPolicyProto& policy() const;
  ::hadoop::hdfs::ErasureCodingPolicyProto* release_policy();
  ::hadoop::hdfs::ErasureCodingPolicyProto* mutable_policy();
  void set_allocated_policy(::hadoop::hdfs::ErasureCodingPolicyProto* policy);

  // required bool succeed = 2;
  bool has_succeed() const;
  void clear_succeed();
  static const int kSucceedFieldNumber = 2;
  bool succeed() const;
  void set_succeed(bool value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.AddErasureCodingPolicyResponseProto)
 private:
  void set_has_policy();
  void clear_has_policy();
  void set_has_succeed();
  void clear_has_succeed();
  void set_has_errormsg();
  void clear_has_errormsg();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr errormsg_;
  ::hadoop::hdfs::ErasureCodingPolicyProto* policy_;
  bool succeed_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class ECTopologyVerifierResultProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.ECTopologyVerifierResultProto) */ {
 public:
  ECTopologyVerifierResultProto();
  virtual ~ECTopologyVerifierResultProto();

  ECTopologyVerifierResultProto(const ECTopologyVerifierResultProto& from);

  inline ECTopologyVerifierResultProto& operator=(const ECTopologyVerifierResultProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  ECTopologyVerifierResultProto(ECTopologyVerifierResultProto&& from) noexcept
    : ECTopologyVerifierResultProto() {
    *this = ::std::move(from);
  }

  inline ECTopologyVerifierResultProto& operator=(ECTopologyVerifierResultProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ECTopologyVerifierResultProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const ECTopologyVerifierResultProto* internal_default_instance() {
    return reinterpret_cast<const ECTopologyVerifierResultProto*>(
               &_ECTopologyVerifierResultProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    29;

  void Swap(ECTopologyVerifierResultProto* other);
  friend void swap(ECTopologyVerifierResultProto& a, ECTopologyVerifierResultProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline ECTopologyVerifierResultProto* New() const final {
    return CreateMaybeMessage<ECTopologyVerifierResultProto>(NULL);
  }

  ECTopologyVerifierResultProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<ECTopologyVerifierResultProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const ECTopologyVerifierResultProto& from);
  void MergeFrom(const ECTopologyVerifierResultProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(ECTopologyVerifierResultProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required string resultMessage = 1;
  bool has_resultmessage() const;
  void clear_resultmessage();
  static const int kResultMessageFieldNumber = 1;
  const ::std::string& resultmessage() const;
  void set_resultmessage(const ::std::string& value);
  #if LANG_CXX11
  void set_resultmessage(::std::string&& value);
  #endif
  void set_resultmessage(const char* value);
  void set_resultmessage(const char* value, size_t size);
  ::std::string* mutable_resultmessage();
  ::std::string* release_resultmessage();
  void set_allocated_resultmessage(::std::string* resultmessage);

  // required bool isSupported = 2;
  bool has_issupported() const;
  void clear_issupported();
  static const int kIsSupportedFieldNumber = 2;
  bool issupported() const;
  void set_issupported(bool value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.ECTopologyVerifierResultProto)
 private:
  void set_has_resultmessage();
  void clear_has_resultmessage();
  void set_has_issupported();
  void clear_has_issupported();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr resultmessage_;
  bool issupported_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class HdfsPathHandleProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.HdfsPathHandleProto) */ {
 public:
  HdfsPathHandleProto();
  virtual ~HdfsPathHandleProto();

  HdfsPathHandleProto(const HdfsPathHandleProto& from);

  inline HdfsPathHandleProto& operator=(const HdfsPathHandleProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  HdfsPathHandleProto(HdfsPathHandleProto&& from) noexcept
    : HdfsPathHandleProto() {
    *this = ::std::move(from);
  }

  inline HdfsPathHandleProto& operator=(HdfsPathHandleProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const HdfsPathHandleProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const HdfsPathHandleProto* internal_default_instance() {
    return reinterpret_cast<const HdfsPathHandleProto*>(
               &_HdfsPathHandleProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    30;

  void Swap(HdfsPathHandleProto* other);
  friend void swap(HdfsPathHandleProto& a, HdfsPathHandleProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline HdfsPathHandleProto* New() const final {
    return CreateMaybeMessage<HdfsPathHandleProto>(NULL);
  }

  HdfsPathHandleProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<HdfsPathHandleProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const HdfsPathHandleProto& from);
  void MergeFrom(const HdfsPathHandleProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(HdfsPathHandleProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string path = 3;
  bool has_path() const;
  void clear_path();
  static const int kPathFieldNumber = 3;
  const ::std::string& path() const;
  void set_path(const ::std::string& value);
  #if LANG_CXX11
  void set_path(::std::string&& value);
  #endif
  void set_path(const char* value);
  void set_path(const char* value, size_t size);
  ::std::string* mutable_path();
  ::std::string* release_path();
  void set_allocated_path(::std::string* path);

  // optional uint64 inodeId = 1;
  bool has_inodeid() const;
  void clear_inodeid();
  static const int kInodeIdFieldNumber = 1;
  ::google::protobuf::uint64 inodeid() const;
  void set_inodeid(::google::protobuf::uint64 value);

  // optional uint64 mtime = 2;
  bool has_mtime() const;
  void clear_mtime();
  static const int kMtimeFieldNumber = 2;
  ::google::protobuf::uint64 mtime() const;
  void set_mtime(::google::protobuf::uint64 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.HdfsPathHandleProto)
 private:
  void set_has_inodeid();
  void clear_has_inodeid();
  void set_has_mtime();
  void clear_has_mtime();
  void set_has_path();
  void clear_has_path();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr path_;
  ::google::protobuf::uint64 inodeid_;
  ::google::protobuf::uint64 mtime_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class HdfsFileStatusProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.HdfsFileStatusProto) */ {
 public:
  HdfsFileStatusProto();
  virtual ~HdfsFileStatusProto();

  HdfsFileStatusProto(const HdfsFileStatusProto& from);

  inline HdfsFileStatusProto& operator=(const HdfsFileStatusProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  HdfsFileStatusProto(HdfsFileStatusProto&& from) noexcept
    : HdfsFileStatusProto() {
    *this = ::std::move(from);
  }

  inline HdfsFileStatusProto& operator=(HdfsFileStatusProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const HdfsFileStatusProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const HdfsFileStatusProto* internal_default_instance() {
    return reinterpret_cast<const HdfsFileStatusProto*>(
               &_HdfsFileStatusProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    31;

  void Swap(HdfsFileStatusProto* other);
  friend void swap(HdfsFileStatusProto& a, HdfsFileStatusProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline HdfsFileStatusProto* New() const final {
    return CreateMaybeMessage<HdfsFileStatusProto>(NULL);
  }

  HdfsFileStatusProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<HdfsFileStatusProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const HdfsFileStatusProto& from);
  void MergeFrom(const HdfsFileStatusProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(HdfsFileStatusProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  typedef HdfsFileStatusProto_FileType FileType;
  static const FileType IS_DIR =
    HdfsFileStatusProto_FileType_IS_DIR;
  static const FileType IS_FILE =
    HdfsFileStatusProto_FileType_IS_FILE;
  static const FileType IS_SYMLINK =
    HdfsFileStatusProto_FileType_IS_SYMLINK;
  static inline bool FileType_IsValid(int value) {
    return HdfsFileStatusProto_FileType_IsValid(value);
  }
  static const FileType FileType_MIN =
    HdfsFileStatusProto_FileType_FileType_MIN;
  static const FileType FileType_MAX =
    HdfsFileStatusProto_FileType_FileType_MAX;
  static const int FileType_ARRAYSIZE =
    HdfsFileStatusProto_FileType_FileType_ARRAYSIZE;
  static inline const ::google::protobuf::EnumDescriptor*
  FileType_descriptor() {
    return HdfsFileStatusProto_FileType_descriptor();
  }
  static inline const ::std::string& FileType_Name(FileType value) {
    return HdfsFileStatusProto_FileType_Name(value);
  }
  static inline bool FileType_Parse(const ::std::string& name,
      FileType* value) {
    return HdfsFileStatusProto_FileType_Parse(name, value);
  }

  typedef HdfsFileStatusProto_Flags Flags;
  static const Flags HAS_ACL =
    HdfsFileStatusProto_Flags_HAS_ACL;
  static const Flags HAS_CRYPT =
    HdfsFileStatusProto_Flags_HAS_CRYPT;
  static const Flags HAS_EC =
    HdfsFileStatusProto_Flags_HAS_EC;
  static const Flags SNAPSHOT_ENABLED =
    HdfsFileStatusProto_Flags_SNAPSHOT_ENABLED;
  static inline bool Flags_IsValid(int value) {
    return HdfsFileStatusProto_Flags_IsValid(value);
  }
  static const Flags Flags_MIN =
    HdfsFileStatusProto_Flags_Flags_MIN;
  static const Flags Flags_MAX =
    HdfsFileStatusProto_Flags_Flags_MAX;
  static const int Flags_ARRAYSIZE =
    HdfsFileStatusProto_Flags_Flags_ARRAYSIZE;
  static inline const ::google::protobuf::EnumDescriptor*
  Flags_descriptor() {
    return HdfsFileStatusProto_Flags_descriptor();
  }
  static inline const ::std::string& Flags_Name(Flags value) {
    return HdfsFileStatusProto_Flags_Name(value);
  }
  static inline bool Flags_Parse(const ::std::string& name,
      Flags* value) {
    return HdfsFileStatusProto_Flags_Parse(name, value);
  }

  // accessors -------------------------------------------------------

  // required bytes path = 2;
  bool has_path() const;
  void clear_path();
  static const int kPathFieldNumber = 2;
  const ::std::string& path() const;
  void set_path(const ::std::string& value);
  #if LANG_CXX11
  void set_path(::std::string&& value);
  #endif
  void set_path(const char* value);
  void set_path(const void* value, size_t size);
  ::std::string* mutable_path();
  ::std::string* release_path();
  void set_allocated_path(::std::string* path);

  // required string owner = 5;
  bool has_owner() const;
  void clear_owner();
  static const int kOwnerFieldNumber = 5;
  const ::std::string& owner() const;
  void set_owner(const ::std::string& value);
  #if LANG_CXX11
  void set_owner(::std::string&& value);
  #endif
  void set_owner(const char* value);
  void set_owner(const char* value, size_t size);
  ::std::string* mutable_owner();
  ::std::string* release_owner();
  void set_allocated_owner(::std::string* owner);

  // required string group = 6;
  bool has_group() const;
  void clear_group();
  static const int kGroupFieldNumber = 6;
  const ::std::string& group() const;
  void set_group(const ::std::string& value);
  #if LANG_CXX11
  void set_group(::std::string&& value);
  #endif
  void set_group(const char* value);
  void set_group(const char* value, size_t size);
  ::std::string* mutable_group();
  ::std::string* release_group();
  void set_allocated_group(::std::string* group);

  // optional bytes symlink = 9;
  bool has_symlink() const;
  void clear_symlink();
  static const int kSymlinkFieldNumber = 9;
  const ::std::string& symlink() const;
  void set_symlink(const ::std::string& value);
  #if LANG_CXX11
  void set_symlink(::std::string&& value);
  #endif
  void set_symlink(const char* value);
  void set_symlink(const void* value, size_t size);
  ::std::string* mutable_symlink();
  ::std::string* release_symlink();
  void set_allocated_symlink(::std::string* symlink);

  // required .hadoop.hdfs.FsPermissionProto permission = 4;
  bool has_permission() const;
  void clear_permission();
  static const int kPermissionFieldNumber = 4;
  private:
  const ::hadoop::hdfs::FsPermissionProto& _internal_permission() const;
  public:
  const ::hadoop::hdfs::FsPermissionProto& permission() const;
  ::hadoop::hdfs::FsPermissionProto* release_permission();
  ::hadoop::hdfs::FsPermissionProto* mutable_permission();
  void set_allocated_permission(::hadoop::hdfs::FsPermissionProto* permission);

  // optional .hadoop.hdfs.LocatedBlocksProto locations = 12;
  bool has_locations() const;
  void clear_locations();
  static const int kLocationsFieldNumber = 12;
  private:
  const ::hadoop::hdfs::LocatedBlocksProto& _internal_locations() const;
  public:
  const ::hadoop::hdfs::LocatedBlocksProto& locations() const;
  ::hadoop::hdfs::LocatedBlocksProto* release_locations();
  ::hadoop::hdfs::LocatedBlocksProto* mutable_locations();
  void set_allocated_locations(::hadoop::hdfs::LocatedBlocksProto* locations);

  // optional .hadoop.hdfs.FileEncryptionInfoProto fileEncryptionInfo = 15;
  bool has_fileencryptioninfo() const;
  void clear_fileencryptioninfo();
  static const int kFileEncryptionInfoFieldNumber = 15;
  private:
  const ::hadoop::hdfs::FileEncryptionInfoProto& _internal_fileencryptioninfo() const;
  public:
  const ::hadoop::hdfs::FileEncryptionInfoProto& fileencryptioninfo() const;
  ::hadoop::hdfs::FileEncryptionInfoProto* release_fileencryptioninfo();
  ::hadoop::hdfs::FileEncryptionInfoProto* mutable_fileencryptioninfo();
  void set_allocated_fileencryptioninfo(::hadoop::hdfs::FileEncryptionInfoProto* fileencryptioninfo);

  // optional .hadoop.hdfs.ErasureCodingPolicyProto ecPolicy = 17;
  bool has_ecpolicy() const;
  void clear_ecpolicy();
  static const int kEcPolicyFieldNumber = 17;
  private:
  const ::hadoop::hdfs::ErasureCodingPolicyProto& _internal_ecpolicy() const;
  public:
  const ::hadoop::hdfs::ErasureCodingPolicyProto& ecpolicy() const;
  ::hadoop::hdfs::ErasureCodingPolicyProto* release_ecpolicy();
  ::hadoop::hdfs::ErasureCodingPolicyProto* mutable_ecpolicy();
  void set_allocated_ecpolicy(::hadoop::hdfs::ErasureCodingPolicyProto* ecpolicy);

  // required uint64 length = 3;
  bool has_length() const;
  void clear_length();
  static const int kLengthFieldNumber = 3;
  ::google::protobuf::uint64 length() const;
  void set_length(::google::protobuf::uint64 value);

  // required uint64 modification_time = 7;
  bool has_modification_time() const;
  void clear_modification_time();
  static const int kModificationTimeFieldNumber = 7;
  ::google::protobuf::uint64 modification_time() const;
  void set_modification_time(::google::protobuf::uint64 value);

  // required uint64 access_time = 8;
  bool has_access_time() const;
  void clear_access_time();
  static const int kAccessTimeFieldNumber = 8;
  ::google::protobuf::uint64 access_time() const;
  void set_access_time(::google::protobuf::uint64 value);

  // optional uint64 blocksize = 11 [default = 0];
  bool has_blocksize() const;
  void clear_blocksize();
  static const int kBlocksizeFieldNumber = 11;
  ::google::protobuf::uint64 blocksize() const;
  void set_blocksize(::google::protobuf::uint64 value);

  // optional uint64 fileId = 13 [default = 0];
  bool has_fileid() const;
  void clear_fileid();
  static const int kFileIdFieldNumber = 13;
  ::google::protobuf::uint64 fileid() const;
  void set_fileid(::google::protobuf::uint64 value);

  // optional uint32 block_replication = 10 [default = 0];
  bool has_block_replication() const;
  void clear_block_replication();
  static const int kBlockReplicationFieldNumber = 10;
  ::google::protobuf::uint32 block_replication() const;
  void set_block_replication(::google::protobuf::uint32 value);

  // optional uint32 storagePolicy = 16 [default = 0];
  bool has_storagepolicy() const;
  void clear_storagepolicy();
  static const int kStoragePolicyFieldNumber = 16;
  ::google::protobuf::uint32 storagepolicy() const;
  void set_storagepolicy(::google::protobuf::uint32 value);

  // optional uint32 flags = 18 [default = 0];
  bool has_flags() const;
  void clear_flags();
  static const int kFlagsFieldNumber = 18;
  ::google::protobuf::uint32 flags() const;
  void set_flags(::google::protobuf::uint32 value);

  // required .hadoop.hdfs.HdfsFileStatusProto.FileType fileType = 1;
  bool has_filetype() const;
  void clear_filetype();
  static const int kFileTypeFieldNumber = 1;
  ::hadoop::hdfs::HdfsFileStatusProto_FileType filetype() const;
  void set_filetype(::hadoop::hdfs::HdfsFileStatusProto_FileType value);

  // optional int32 childrenNum = 14 [default = -1];
  bool has_childrennum() const;
  void clear_childrennum();
  static const int kChildrenNumFieldNumber = 14;
  ::google::protobuf::int32 childrennum() const;
  void set_childrennum(::google::protobuf::int32 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.HdfsFileStatusProto)
 private:
  void set_has_filetype();
  void clear_has_filetype();
  void set_has_path();
  void clear_has_path();
  void set_has_length();
  void clear_has_length();
  void set_has_permission();
  void clear_has_permission();
  void set_has_owner();
  void clear_has_owner();
  void set_has_group();
  void clear_has_group();
  void set_has_modification_time();
  void clear_has_modification_time();
  void set_has_access_time();
  void clear_has_access_time();
  void set_has_symlink();
  void clear_has_symlink();
  void set_has_block_replication();
  void clear_has_block_replication();
  void set_has_blocksize();
  void clear_has_blocksize();
  void set_has_locations();
  void clear_has_locations();
  void set_has_fileid();
  void clear_has_fileid();
  void set_has_childrennum();
  void clear_has_childrennum();
  void set_has_fileencryptioninfo();
  void clear_has_fileencryptioninfo();
  void set_has_storagepolicy();
  void clear_has_storagepolicy();
  void set_has_ecpolicy();
  void clear_has_ecpolicy();
  void set_has_flags();
  void clear_has_flags();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr path_;
  ::google::protobuf::internal::ArenaStringPtr owner_;
  ::google::protobuf::internal::ArenaStringPtr group_;
  ::google::protobuf::internal::ArenaStringPtr symlink_;
  ::hadoop::hdfs::FsPermissionProto* permission_;
  ::hadoop::hdfs::LocatedBlocksProto* locations_;
  ::hadoop::hdfs::FileEncryptionInfoProto* fileencryptioninfo_;
  ::hadoop::hdfs::ErasureCodingPolicyProto* ecpolicy_;
  ::google::protobuf::uint64 length_;
  ::google::protobuf::uint64 modification_time_;
  ::google::protobuf::uint64 access_time_;
  ::google::protobuf::uint64 blocksize_;
  ::google::protobuf::uint64 fileid_;
  ::google::protobuf::uint32 block_replication_;
  ::google::protobuf::uint32 storagepolicy_;
  ::google::protobuf::uint32 flags_;
  int filetype_;
  ::google::protobuf::int32 childrennum_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class BlockChecksumOptionsProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.BlockChecksumOptionsProto) */ {
 public:
  BlockChecksumOptionsProto();
  virtual ~BlockChecksumOptionsProto();

  BlockChecksumOptionsProto(const BlockChecksumOptionsProto& from);

  inline BlockChecksumOptionsProto& operator=(const BlockChecksumOptionsProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  BlockChecksumOptionsProto(BlockChecksumOptionsProto&& from) noexcept
    : BlockChecksumOptionsProto() {
    *this = ::std::move(from);
  }

  inline BlockChecksumOptionsProto& operator=(BlockChecksumOptionsProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const BlockChecksumOptionsProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const BlockChecksumOptionsProto* internal_default_instance() {
    return reinterpret_cast<const BlockChecksumOptionsProto*>(
               &_BlockChecksumOptionsProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    32;

  void Swap(BlockChecksumOptionsProto* other);
  friend void swap(BlockChecksumOptionsProto& a, BlockChecksumOptionsProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline BlockChecksumOptionsProto* New() const final {
    return CreateMaybeMessage<BlockChecksumOptionsProto>(NULL);
  }

  BlockChecksumOptionsProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<BlockChecksumOptionsProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const BlockChecksumOptionsProto& from);
  void MergeFrom(const BlockChecksumOptionsProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(BlockChecksumOptionsProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional uint64 stripeLength = 2;
  bool has_stripelength() const;
  void clear_stripelength();
  static const int kStripeLengthFieldNumber = 2;
  ::google::protobuf::uint64 stripelength() const;
  void set_stripelength(::google::protobuf::uint64 value);

  // optional .hadoop.hdfs.BlockChecksumTypeProto blockChecksumType = 1 [default = MD5CRC];
  bool has_blockchecksumtype() const;
  void clear_blockchecksumtype();
  static const int kBlockChecksumTypeFieldNumber = 1;
  ::hadoop::hdfs::BlockChecksumTypeProto blockchecksumtype() const;
  void set_blockchecksumtype(::hadoop::hdfs::BlockChecksumTypeProto value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.BlockChecksumOptionsProto)
 private:
  void set_has_blockchecksumtype();
  void clear_has_blockchecksumtype();
  void set_has_stripelength();
  void clear_has_stripelength();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::uint64 stripelength_;
  int blockchecksumtype_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class FsServerDefaultsProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.FsServerDefaultsProto) */ {
 public:
  FsServerDefaultsProto();
  virtual ~FsServerDefaultsProto();

  FsServerDefaultsProto(const FsServerDefaultsProto& from);

  inline FsServerDefaultsProto& operator=(const FsServerDefaultsProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  FsServerDefaultsProto(FsServerDefaultsProto&& from) noexcept
    : FsServerDefaultsProto() {
    *this = ::std::move(from);
  }

  inline FsServerDefaultsProto& operator=(FsServerDefaultsProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const FsServerDefaultsProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const FsServerDefaultsProto* internal_default_instance() {
    return reinterpret_cast<const FsServerDefaultsProto*>(
               &_FsServerDefaultsProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    33;

  void Swap(FsServerDefaultsProto* other);
  friend void swap(FsServerDefaultsProto& a, FsServerDefaultsProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline FsServerDefaultsProto* New() const final {
    return CreateMaybeMessage<FsServerDefaultsProto>(NULL);
  }

  FsServerDefaultsProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<FsServerDefaultsProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const FsServerDefaultsProto& from);
  void MergeFrom(const FsServerDefaultsProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(FsServerDefaultsProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string keyProviderUri = 9;
  bool has_keyprovideruri() const;
  void clear_keyprovideruri();
  static const int kKeyProviderUriFieldNumber = 9;
  const ::std::string& keyprovideruri() const;
  void set_keyprovideruri(const ::std::string& value);
  #if LANG_CXX11
  void set_keyprovideruri(::std::string&& value);
  #endif
  void set_keyprovideruri(const char* value);
  void set_keyprovideruri(const char* value, size_t size);
  ::std::string* mutable_keyprovideruri();
  ::std::string* release_keyprovideruri();
  void set_allocated_keyprovideruri(::std::string* keyprovideruri);

  // required uint64 blockSize = 1;
  bool has_blocksize() const;
  void clear_blocksize();
  static const int kBlockSizeFieldNumber = 1;
  ::google::protobuf::uint64 blocksize() const;
  void set_blocksize(::google::protobuf::uint64 value);

  // required uint32 bytesPerChecksum = 2;
  bool has_bytesperchecksum() const;
  void clear_bytesperchecksum();
  static const int kBytesPerChecksumFieldNumber = 2;
  ::google::protobuf::uint32 bytesperchecksum() const;
  void set_bytesperchecksum(::google::protobuf::uint32 value);

  // required uint32 writePacketSize = 3;
  bool has_writepacketsize() const;
  void clear_writepacketsize();
  static const int kWritePacketSizeFieldNumber = 3;
  ::google::protobuf::uint32 writepacketsize() const;
  void set_writepacketsize(::google::protobuf::uint32 value);

  // required uint32 replication = 4;
  bool has_replication() const;
  void clear_replication();
  static const int kReplicationFieldNumber = 4;
  ::google::protobuf::uint32 replication() const;
  void set_replication(::google::protobuf::uint32 value);

  // required uint32 fileBufferSize = 5;
  bool has_filebuffersize() const;
  void clear_filebuffersize();
  static const int kFileBufferSizeFieldNumber = 5;
  ::google::protobuf::uint32 filebuffersize() const;
  void set_filebuffersize(::google::protobuf::uint32 value);

  // optional uint64 trashInterval = 7 [default = 0];
  bool has_trashinterval() const;
  void clear_trashinterval();
  static const int kTrashIntervalFieldNumber = 7;
  ::google::protobuf::uint64 trashinterval() const;
  void set_trashinterval(::google::protobuf::uint64 value);

  // optional bool encryptDataTransfer = 6 [default = false];
  bool has_encryptdatatransfer() const;
  void clear_encryptdatatransfer();
  static const int kEncryptDataTransferFieldNumber = 6;
  bool encryptdatatransfer() const;
  void set_encryptdatatransfer(bool value);

  // optional uint32 policyId = 10 [default = 0];
  bool has_policyid() const;
  void clear_policyid();
  static const int kPolicyIdFieldNumber = 10;
  ::google::protobuf::uint32 policyid() const;
  void set_policyid(::google::protobuf::uint32 value);

  // optional .hadoop.hdfs.ChecksumTypeProto checksumType = 8 [default = CHECKSUM_CRC32];
  bool has_checksumtype() const;
  void clear_checksumtype();
  static const int kChecksumTypeFieldNumber = 8;
  ::hadoop::hdfs::ChecksumTypeProto checksumtype() const;
  void set_checksumtype(::hadoop::hdfs::ChecksumTypeProto value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.FsServerDefaultsProto)
 private:
  void set_has_blocksize();
  void clear_has_blocksize();
  void set_has_bytesperchecksum();
  void clear_has_bytesperchecksum();
  void set_has_writepacketsize();
  void clear_has_writepacketsize();
  void set_has_replication();
  void clear_has_replication();
  void set_has_filebuffersize();
  void clear_has_filebuffersize();
  void set_has_encryptdatatransfer();
  void clear_has_encryptdatatransfer();
  void set_has_trashinterval();
  void clear_has_trashinterval();
  void set_has_checksumtype();
  void clear_has_checksumtype();
  void set_has_keyprovideruri();
  void clear_has_keyprovideruri();
  void set_has_policyid();
  void clear_has_policyid();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr keyprovideruri_;
  ::google::protobuf::uint64 blocksize_;
  ::google::protobuf::uint32 bytesperchecksum_;
  ::google::protobuf::uint32 writepacketsize_;
  ::google::protobuf::uint32 replication_;
  ::google::protobuf::uint32 filebuffersize_;
  ::google::protobuf::uint64 trashinterval_;
  bool encryptdatatransfer_;
  ::google::protobuf::uint32 policyid_;
  int checksumtype_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class DirectoryListingProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.DirectoryListingProto) */ {
 public:
  DirectoryListingProto();
  virtual ~DirectoryListingProto();

  DirectoryListingProto(const DirectoryListingProto& from);

  inline DirectoryListingProto& operator=(const DirectoryListingProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  DirectoryListingProto(DirectoryListingProto&& from) noexcept
    : DirectoryListingProto() {
    *this = ::std::move(from);
  }

  inline DirectoryListingProto& operator=(DirectoryListingProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const DirectoryListingProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const DirectoryListingProto* internal_default_instance() {
    return reinterpret_cast<const DirectoryListingProto*>(
               &_DirectoryListingProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    34;

  void Swap(DirectoryListingProto* other);
  friend void swap(DirectoryListingProto& a, DirectoryListingProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline DirectoryListingProto* New() const final {
    return CreateMaybeMessage<DirectoryListingProto>(NULL);
  }

  DirectoryListingProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<DirectoryListingProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const DirectoryListingProto& from);
  void MergeFrom(const DirectoryListingProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(DirectoryListingProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.hdfs.HdfsFileStatusProto partialListing = 1;
  int partiallisting_size() const;
  void clear_partiallisting();
  static const int kPartialListingFieldNumber = 1;
  ::hadoop::hdfs::HdfsFileStatusProto* mutable_partiallisting(int index);
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::HdfsFileStatusProto >*
      mutable_partiallisting();
  const ::hadoop::hdfs::HdfsFileStatusProto& partiallisting(int index) const;
  ::hadoop::hdfs::HdfsFileStatusProto* add_partiallisting();
  const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::HdfsFileStatusProto >&
      partiallisting() const;

  // required uint32 remainingEntries = 2;
  bool has_remainingentries() const;
  void clear_remainingentries();
  static const int kRemainingEntriesFieldNumber = 2;
  ::google::protobuf::uint32 remainingentries() const;
  void set_remainingentries(::google::protobuf::uint32 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.DirectoryListingProto)
 private:
  void set_has_remainingentries();
  void clear_has_remainingentries();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::HdfsFileStatusProto > partiallisting_;
  ::google::protobuf::uint32 remainingentries_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class RemoteExceptionProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.RemoteExceptionProto) */ {
 public:
  RemoteExceptionProto();
  virtual ~RemoteExceptionProto();

  RemoteExceptionProto(const RemoteExceptionProto& from);

  inline RemoteExceptionProto& operator=(const RemoteExceptionProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  RemoteExceptionProto(RemoteExceptionProto&& from) noexcept
    : RemoteExceptionProto() {
    *this = ::std::move(from);
  }

  inline RemoteExceptionProto& operator=(RemoteExceptionProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const RemoteExceptionProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const RemoteExceptionProto* internal_default_instance() {
    return reinterpret_cast<const RemoteExceptionProto*>(
               &_RemoteExceptionProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    35;

  void Swap(RemoteExceptionProto* other);
  friend void swap(RemoteExceptionProto& a, RemoteExceptionProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline RemoteExceptionProto* New() const final {
    return CreateMaybeMessage<RemoteExceptionProto>(NULL);
  }

  RemoteExceptionProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<RemoteExceptionProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const RemoteExceptionProto& from);
  void MergeFrom(const RemoteExceptionProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(RemoteExceptionProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required string className = 1;
  bool has_classname() const;
  void clear_classname();
  static const int kClassNameFieldNumber = 1;
  const ::std::string& classname() const;
  void set_classname(const ::std::string& value);
  #if LANG_CXX11
  void set_classname(::std::string&& value);
  #endif
  void set_classname(const char* value);
  void set_classname(const char* value, size_t size);
  ::std::string* mutable_classname();
  ::std::string* release_classname();
  void set_allocated_classname(::std::string* classname);

  // optional string message = 2;
  bool has_message() const;
  void clear_message();
  static const int kMessageFieldNumber = 2;
  const ::std::string& message() const;
  void set_message(const ::std::string& value);
  #if LANG_CXX11
  void set_message(::std::string&& value);
  #endif
  void set_message(const char* value);
  void set_message(const char* value, size_t size);
  ::std::string* mutable_message();
  ::std::string* release_message();
  void set_allocated_message(::std::string* message);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.RemoteExceptionProto)
 private:
  void set_has_classname();
  void clear_has_classname();
  void set_has_message();
  void clear_has_message();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr classname_;
  ::google::protobuf::internal::ArenaStringPtr message_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class BatchedDirectoryListingProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.BatchedDirectoryListingProto) */ {
 public:
  BatchedDirectoryListingProto();
  virtual ~BatchedDirectoryListingProto();

  BatchedDirectoryListingProto(const BatchedDirectoryListingProto& from);

  inline BatchedDirectoryListingProto& operator=(const BatchedDirectoryListingProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  BatchedDirectoryListingProto(BatchedDirectoryListingProto&& from) noexcept
    : BatchedDirectoryListingProto() {
    *this = ::std::move(from);
  }

  inline BatchedDirectoryListingProto& operator=(BatchedDirectoryListingProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const BatchedDirectoryListingProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const BatchedDirectoryListingProto* internal_default_instance() {
    return reinterpret_cast<const BatchedDirectoryListingProto*>(
               &_BatchedDirectoryListingProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    36;

  void Swap(BatchedDirectoryListingProto* other);
  friend void swap(BatchedDirectoryListingProto& a, BatchedDirectoryListingProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline BatchedDirectoryListingProto* New() const final {
    return CreateMaybeMessage<BatchedDirectoryListingProto>(NULL);
  }

  BatchedDirectoryListingProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<BatchedDirectoryListingProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const BatchedDirectoryListingProto& from);
  void MergeFrom(const BatchedDirectoryListingProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(BatchedDirectoryListingProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.hdfs.HdfsFileStatusProto partialListing = 1;
  int partiallisting_size() const;
  void clear_partiallisting();
  static const int kPartialListingFieldNumber = 1;
  ::hadoop::hdfs::HdfsFileStatusProto* mutable_partiallisting(int index);
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::HdfsFileStatusProto >*
      mutable_partiallisting();
  const ::hadoop::hdfs::HdfsFileStatusProto& partiallisting(int index) const;
  ::hadoop::hdfs::HdfsFileStatusProto* add_partiallisting();
  const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::HdfsFileStatusProto >&
      partiallisting() const;

  // optional .hadoop.hdfs.RemoteExceptionProto exception = 3;
  bool has_exception() const;
  void clear_exception();
  static const int kExceptionFieldNumber = 3;
  private:
  const ::hadoop::hdfs::RemoteExceptionProto& _internal_exception() const;
  public:
  const ::hadoop::hdfs::RemoteExceptionProto& exception() const;
  ::hadoop::hdfs::RemoteExceptionProto* release_exception();
  ::hadoop::hdfs::RemoteExceptionProto* mutable_exception();
  void set_allocated_exception(::hadoop::hdfs::RemoteExceptionProto* exception);

  // required uint32 parentIdx = 2;
  bool has_parentidx() const;
  void clear_parentidx();
  static const int kParentIdxFieldNumber = 2;
  ::google::protobuf::uint32 parentidx() const;
  void set_parentidx(::google::protobuf::uint32 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.BatchedDirectoryListingProto)
 private:
  void set_has_parentidx();
  void clear_has_parentidx();
  void set_has_exception();
  void clear_has_exception();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::HdfsFileStatusProto > partiallisting_;
  ::hadoop::hdfs::RemoteExceptionProto* exception_;
  ::google::protobuf::uint32 parentidx_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class SnapshottableDirectoryStatusProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.SnapshottableDirectoryStatusProto) */ {
 public:
  SnapshottableDirectoryStatusProto();
  virtual ~SnapshottableDirectoryStatusProto();

  SnapshottableDirectoryStatusProto(const SnapshottableDirectoryStatusProto& from);

  inline SnapshottableDirectoryStatusProto& operator=(const SnapshottableDirectoryStatusProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  SnapshottableDirectoryStatusProto(SnapshottableDirectoryStatusProto&& from) noexcept
    : SnapshottableDirectoryStatusProto() {
    *this = ::std::move(from);
  }

  inline SnapshottableDirectoryStatusProto& operator=(SnapshottableDirectoryStatusProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const SnapshottableDirectoryStatusProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const SnapshottableDirectoryStatusProto* internal_default_instance() {
    return reinterpret_cast<const SnapshottableDirectoryStatusProto*>(
               &_SnapshottableDirectoryStatusProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    37;

  void Swap(SnapshottableDirectoryStatusProto* other);
  friend void swap(SnapshottableDirectoryStatusProto& a, SnapshottableDirectoryStatusProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline SnapshottableDirectoryStatusProto* New() const final {
    return CreateMaybeMessage<SnapshottableDirectoryStatusProto>(NULL);
  }

  SnapshottableDirectoryStatusProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<SnapshottableDirectoryStatusProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const SnapshottableDirectoryStatusProto& from);
  void MergeFrom(const SnapshottableDirectoryStatusProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(SnapshottableDirectoryStatusProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required bytes parent_fullpath = 4;
  bool has_parent_fullpath() const;
  void clear_parent_fullpath();
  static const int kParentFullpathFieldNumber = 4;
  const ::std::string& parent_fullpath() const;
  void set_parent_fullpath(const ::std::string& value);
  #if LANG_CXX11
  void set_parent_fullpath(::std::string&& value);
  #endif
  void set_parent_fullpath(const char* value);
  void set_parent_fullpath(const void* value, size_t size);
  ::std::string* mutable_parent_fullpath();
  ::std::string* release_parent_fullpath();
  void set_allocated_parent_fullpath(::std::string* parent_fullpath);

  // required .hadoop.hdfs.HdfsFileStatusProto dirStatus = 1;
  bool has_dirstatus() const;
  void clear_dirstatus();
  static const int kDirStatusFieldNumber = 1;
  private:
  const ::hadoop::hdfs::HdfsFileStatusProto& _internal_dirstatus() const;
  public:
  const ::hadoop::hdfs::HdfsFileStatusProto& dirstatus() const;
  ::hadoop::hdfs::HdfsFileStatusProto* release_dirstatus();
  ::hadoop::hdfs::HdfsFileStatusProto* mutable_dirstatus();
  void set_allocated_dirstatus(::hadoop::hdfs::HdfsFileStatusProto* dirstatus);

  // required uint32 snapshot_quota = 2;
  bool has_snapshot_quota() const;
  void clear_snapshot_quota();
  static const int kSnapshotQuotaFieldNumber = 2;
  ::google::protobuf::uint32 snapshot_quota() const;
  void set_snapshot_quota(::google::protobuf::uint32 value);

  // required uint32 snapshot_number = 3;
  bool has_snapshot_number() const;
  void clear_snapshot_number();
  static const int kSnapshotNumberFieldNumber = 3;
  ::google::protobuf::uint32 snapshot_number() const;
  void set_snapshot_number(::google::protobuf::uint32 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.SnapshottableDirectoryStatusProto)
 private:
  void set_has_dirstatus();
  void clear_has_dirstatus();
  void set_has_snapshot_quota();
  void clear_has_snapshot_quota();
  void set_has_snapshot_number();
  void clear_has_snapshot_number();
  void set_has_parent_fullpath();
  void clear_has_parent_fullpath();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr parent_fullpath_;
  ::hadoop::hdfs::HdfsFileStatusProto* dirstatus_;
  ::google::protobuf::uint32 snapshot_quota_;
  ::google::protobuf::uint32 snapshot_number_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class SnapshottableDirectoryListingProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.SnapshottableDirectoryListingProto) */ {
 public:
  SnapshottableDirectoryListingProto();
  virtual ~SnapshottableDirectoryListingProto();

  SnapshottableDirectoryListingProto(const SnapshottableDirectoryListingProto& from);

  inline SnapshottableDirectoryListingProto& operator=(const SnapshottableDirectoryListingProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  SnapshottableDirectoryListingProto(SnapshottableDirectoryListingProto&& from) noexcept
    : SnapshottableDirectoryListingProto() {
    *this = ::std::move(from);
  }

  inline SnapshottableDirectoryListingProto& operator=(SnapshottableDirectoryListingProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const SnapshottableDirectoryListingProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const SnapshottableDirectoryListingProto* internal_default_instance() {
    return reinterpret_cast<const SnapshottableDirectoryListingProto*>(
               &_SnapshottableDirectoryListingProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    38;

  void Swap(SnapshottableDirectoryListingProto* other);
  friend void swap(SnapshottableDirectoryListingProto& a, SnapshottableDirectoryListingProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline SnapshottableDirectoryListingProto* New() const final {
    return CreateMaybeMessage<SnapshottableDirectoryListingProto>(NULL);
  }

  SnapshottableDirectoryListingProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<SnapshottableDirectoryListingProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const SnapshottableDirectoryListingProto& from);
  void MergeFrom(const SnapshottableDirectoryListingProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(SnapshottableDirectoryListingProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.hdfs.SnapshottableDirectoryStatusProto snapshottableDirListing = 1;
  int snapshottabledirlisting_size() const;
  void clear_snapshottabledirlisting();
  static const int kSnapshottableDirListingFieldNumber = 1;
  ::hadoop::hdfs::SnapshottableDirectoryStatusProto* mutable_snapshottabledirlisting(int index);
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::SnapshottableDirectoryStatusProto >*
      mutable_snapshottabledirlisting();
  const ::hadoop::hdfs::SnapshottableDirectoryStatusProto& snapshottabledirlisting(int index) const;
  ::hadoop::hdfs::SnapshottableDirectoryStatusProto* add_snapshottabledirlisting();
  const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::SnapshottableDirectoryStatusProto >&
      snapshottabledirlisting() const;

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.SnapshottableDirectoryListingProto)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::SnapshottableDirectoryStatusProto > snapshottabledirlisting_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class SnapshotDiffReportEntryProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.SnapshotDiffReportEntryProto) */ {
 public:
  SnapshotDiffReportEntryProto();
  virtual ~SnapshotDiffReportEntryProto();

  SnapshotDiffReportEntryProto(const SnapshotDiffReportEntryProto& from);

  inline SnapshotDiffReportEntryProto& operator=(const SnapshotDiffReportEntryProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  SnapshotDiffReportEntryProto(SnapshotDiffReportEntryProto&& from) noexcept
    : SnapshotDiffReportEntryProto() {
    *this = ::std::move(from);
  }

  inline SnapshotDiffReportEntryProto& operator=(SnapshotDiffReportEntryProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const SnapshotDiffReportEntryProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const SnapshotDiffReportEntryProto* internal_default_instance() {
    return reinterpret_cast<const SnapshotDiffReportEntryProto*>(
               &_SnapshotDiffReportEntryProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    39;

  void Swap(SnapshotDiffReportEntryProto* other);
  friend void swap(SnapshotDiffReportEntryProto& a, SnapshotDiffReportEntryProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline SnapshotDiffReportEntryProto* New() const final {
    return CreateMaybeMessage<SnapshotDiffReportEntryProto>(NULL);
  }

  SnapshotDiffReportEntryProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<SnapshotDiffReportEntryProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const SnapshotDiffReportEntryProto& from);
  void MergeFrom(const SnapshotDiffReportEntryProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(SnapshotDiffReportEntryProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required bytes fullpath = 1;
  bool has_fullpath() const;
  void clear_fullpath();
  static const int kFullpathFieldNumber = 1;
  const ::std::string& fullpath() const;
  void set_fullpath(const ::std::string& value);
  #if LANG_CXX11
  void set_fullpath(::std::string&& value);
  #endif
  void set_fullpath(const char* value);
  void set_fullpath(const void* value, size_t size);
  ::std::string* mutable_fullpath();
  ::std::string* release_fullpath();
  void set_allocated_fullpath(::std::string* fullpath);

  // required string modificationLabel = 2;
  bool has_modificationlabel() const;
  void clear_modificationlabel();
  static const int kModificationLabelFieldNumber = 2;
  const ::std::string& modificationlabel() const;
  void set_modificationlabel(const ::std::string& value);
  #if LANG_CXX11
  void set_modificationlabel(::std::string&& value);
  #endif
  void set_modificationlabel(const char* value);
  void set_modificationlabel(const char* value, size_t size);
  ::std::string* mutable_modificationlabel();
  ::std::string* release_modificationlabel();
  void set_allocated_modificationlabel(::std::string* modificationlabel);

  // optional bytes targetPath = 3;
  bool has_targetpath() const;
  void clear_targetpath();
  static const int kTargetPathFieldNumber = 3;
  const ::std::string& targetpath() const;
  void set_targetpath(const ::std::string& value);
  #if LANG_CXX11
  void set_targetpath(::std::string&& value);
  #endif
  void set_targetpath(const char* value);
  void set_targetpath(const void* value, size_t size);
  ::std::string* mutable_targetpath();
  ::std::string* release_targetpath();
  void set_allocated_targetpath(::std::string* targetpath);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.SnapshotDiffReportEntryProto)
 private:
  void set_has_fullpath();
  void clear_has_fullpath();
  void set_has_modificationlabel();
  void clear_has_modificationlabel();
  void set_has_targetpath();
  void clear_has_targetpath();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr fullpath_;
  ::google::protobuf::internal::ArenaStringPtr modificationlabel_;
  ::google::protobuf::internal::ArenaStringPtr targetpath_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class SnapshotDiffReportProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.SnapshotDiffReportProto) */ {
 public:
  SnapshotDiffReportProto();
  virtual ~SnapshotDiffReportProto();

  SnapshotDiffReportProto(const SnapshotDiffReportProto& from);

  inline SnapshotDiffReportProto& operator=(const SnapshotDiffReportProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  SnapshotDiffReportProto(SnapshotDiffReportProto&& from) noexcept
    : SnapshotDiffReportProto() {
    *this = ::std::move(from);
  }

  inline SnapshotDiffReportProto& operator=(SnapshotDiffReportProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const SnapshotDiffReportProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const SnapshotDiffReportProto* internal_default_instance() {
    return reinterpret_cast<const SnapshotDiffReportProto*>(
               &_SnapshotDiffReportProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    40;

  void Swap(SnapshotDiffReportProto* other);
  friend void swap(SnapshotDiffReportProto& a, SnapshotDiffReportProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline SnapshotDiffReportProto* New() const final {
    return CreateMaybeMessage<SnapshotDiffReportProto>(NULL);
  }

  SnapshotDiffReportProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<SnapshotDiffReportProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const SnapshotDiffReportProto& from);
  void MergeFrom(const SnapshotDiffReportProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(SnapshotDiffReportProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.hdfs.SnapshotDiffReportEntryProto diffReportEntries = 4;
  int diffreportentries_size() const;
  void clear_diffreportentries();
  static const int kDiffReportEntriesFieldNumber = 4;
  ::hadoop::hdfs::SnapshotDiffReportEntryProto* mutable_diffreportentries(int index);
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::SnapshotDiffReportEntryProto >*
      mutable_diffreportentries();
  const ::hadoop::hdfs::SnapshotDiffReportEntryProto& diffreportentries(int index) const;
  ::hadoop::hdfs::SnapshotDiffReportEntryProto* add_diffreportentries();
  const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::SnapshotDiffReportEntryProto >&
      diffreportentries() const;

  // required string snapshotRoot = 1;
  bool has_snapshotroot() const;
  void clear_snapshotroot();
  static const int kSnapshotRootFieldNumber = 1;
  const ::std::string& snapshotroot() const;
  void set_snapshotroot(const ::std::string& value);
  #if LANG_CXX11
  void set_snapshotroot(::std::string&& value);
  #endif
  void set_snapshotroot(const char* value);
  void set_snapshotroot(const char* value, size_t size);
  ::std::string* mutable_snapshotroot();
  ::std::string* release_snapshotroot();
  void set_allocated_snapshotroot(::std::string* snapshotroot);

  // required string fromSnapshot = 2;
  bool has_fromsnapshot() const;
  void clear_fromsnapshot();
  static const int kFromSnapshotFieldNumber = 2;
  const ::std::string& fromsnapshot() const;
  void set_fromsnapshot(const ::std::string& value);
  #if LANG_CXX11
  void set_fromsnapshot(::std::string&& value);
  #endif
  void set_fromsnapshot(const char* value);
  void set_fromsnapshot(const char* value, size_t size);
  ::std::string* mutable_fromsnapshot();
  ::std::string* release_fromsnapshot();
  void set_allocated_fromsnapshot(::std::string* fromsnapshot);

  // required string toSnapshot = 3;
  bool has_tosnapshot() const;
  void clear_tosnapshot();
  static const int kToSnapshotFieldNumber = 3;
  const ::std::string& tosnapshot() const;
  void set_tosnapshot(const ::std::string& value);
  #if LANG_CXX11
  void set_tosnapshot(::std::string&& value);
  #endif
  void set_tosnapshot(const char* value);
  void set_tosnapshot(const char* value, size_t size);
  ::std::string* mutable_tosnapshot();
  ::std::string* release_tosnapshot();
  void set_allocated_tosnapshot(::std::string* tosnapshot);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.SnapshotDiffReportProto)
 private:
  void set_has_snapshotroot();
  void clear_has_snapshotroot();
  void set_has_fromsnapshot();
  void clear_has_fromsnapshot();
  void set_has_tosnapshot();
  void clear_has_tosnapshot();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::SnapshotDiffReportEntryProto > diffreportentries_;
  ::google::protobuf::internal::ArenaStringPtr snapshotroot_;
  ::google::protobuf::internal::ArenaStringPtr fromsnapshot_;
  ::google::protobuf::internal::ArenaStringPtr tosnapshot_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class SnapshotDiffReportListingEntryProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.SnapshotDiffReportListingEntryProto) */ {
 public:
  SnapshotDiffReportListingEntryProto();
  virtual ~SnapshotDiffReportListingEntryProto();

  SnapshotDiffReportListingEntryProto(const SnapshotDiffReportListingEntryProto& from);

  inline SnapshotDiffReportListingEntryProto& operator=(const SnapshotDiffReportListingEntryProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  SnapshotDiffReportListingEntryProto(SnapshotDiffReportListingEntryProto&& from) noexcept
    : SnapshotDiffReportListingEntryProto() {
    *this = ::std::move(from);
  }

  inline SnapshotDiffReportListingEntryProto& operator=(SnapshotDiffReportListingEntryProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const SnapshotDiffReportListingEntryProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const SnapshotDiffReportListingEntryProto* internal_default_instance() {
    return reinterpret_cast<const SnapshotDiffReportListingEntryProto*>(
               &_SnapshotDiffReportListingEntryProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    41;

  void Swap(SnapshotDiffReportListingEntryProto* other);
  friend void swap(SnapshotDiffReportListingEntryProto& a, SnapshotDiffReportListingEntryProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline SnapshotDiffReportListingEntryProto* New() const final {
    return CreateMaybeMessage<SnapshotDiffReportListingEntryProto>(NULL);
  }

  SnapshotDiffReportListingEntryProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<SnapshotDiffReportListingEntryProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const SnapshotDiffReportListingEntryProto& from);
  void MergeFrom(const SnapshotDiffReportListingEntryProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(SnapshotDiffReportListingEntryProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required bytes fullpath = 1;
  bool has_fullpath() const;
  void clear_fullpath();
  static const int kFullpathFieldNumber = 1;
  const ::std::string& fullpath() const;
  void set_fullpath(const ::std::string& value);
  #if LANG_CXX11
  void set_fullpath(::std::string&& value);
  #endif
  void set_fullpath(const char* value);
  void set_fullpath(const void* value, size_t size);
  ::std::string* mutable_fullpath();
  ::std::string* release_fullpath();
  void set_allocated_fullpath(::std::string* fullpath);

  // optional bytes targetPath = 4;
  bool has_targetpath() const;
  void clear_targetpath();
  static const int kTargetPathFieldNumber = 4;
  const ::std::string& targetpath() const;
  void set_targetpath(const ::std::string& value);
  #if LANG_CXX11
  void set_targetpath(::std::string&& value);
  #endif
  void set_targetpath(const char* value);
  void set_targetpath(const void* value, size_t size);
  ::std::string* mutable_targetpath();
  ::std::string* release_targetpath();
  void set_allocated_targetpath(::std::string* targetpath);

  // required uint64 dirId = 2;
  bool has_dirid() const;
  void clear_dirid();
  static const int kDirIdFieldNumber = 2;
  ::google::protobuf::uint64 dirid() const;
  void set_dirid(::google::protobuf::uint64 value);

  // optional uint64 fileId = 5;
  bool has_fileid() const;
  void clear_fileid();
  static const int kFileIdFieldNumber = 5;
  ::google::protobuf::uint64 fileid() const;
  void set_fileid(::google::protobuf::uint64 value);

  // required bool isReference = 3;
  bool has_isreference() const;
  void clear_isreference();
  static const int kIsReferenceFieldNumber = 3;
  bool isreference() const;
  void set_isreference(bool value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.SnapshotDiffReportListingEntryProto)
 private:
  void set_has_fullpath();
  void clear_has_fullpath();
  void set_has_dirid();
  void clear_has_dirid();
  void set_has_isreference();
  void clear_has_isreference();
  void set_has_targetpath();
  void clear_has_targetpath();
  void set_has_fileid();
  void clear_has_fileid();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr fullpath_;
  ::google::protobuf::internal::ArenaStringPtr targetpath_;
  ::google::protobuf::uint64 dirid_;
  ::google::protobuf::uint64 fileid_;
  bool isreference_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class SnapshotDiffReportCursorProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.SnapshotDiffReportCursorProto) */ {
 public:
  SnapshotDiffReportCursorProto();
  virtual ~SnapshotDiffReportCursorProto();

  SnapshotDiffReportCursorProto(const SnapshotDiffReportCursorProto& from);

  inline SnapshotDiffReportCursorProto& operator=(const SnapshotDiffReportCursorProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  SnapshotDiffReportCursorProto(SnapshotDiffReportCursorProto&& from) noexcept
    : SnapshotDiffReportCursorProto() {
    *this = ::std::move(from);
  }

  inline SnapshotDiffReportCursorProto& operator=(SnapshotDiffReportCursorProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const SnapshotDiffReportCursorProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const SnapshotDiffReportCursorProto* internal_default_instance() {
    return reinterpret_cast<const SnapshotDiffReportCursorProto*>(
               &_SnapshotDiffReportCursorProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    42;

  void Swap(SnapshotDiffReportCursorProto* other);
  friend void swap(SnapshotDiffReportCursorProto& a, SnapshotDiffReportCursorProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline SnapshotDiffReportCursorProto* New() const final {
    return CreateMaybeMessage<SnapshotDiffReportCursorProto>(NULL);
  }

  SnapshotDiffReportCursorProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<SnapshotDiffReportCursorProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const SnapshotDiffReportCursorProto& from);
  void MergeFrom(const SnapshotDiffReportCursorProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(SnapshotDiffReportCursorProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required bytes startPath = 1;
  bool has_startpath() const;
  void clear_startpath();
  static const int kStartPathFieldNumber = 1;
  const ::std::string& startpath() const;
  void set_startpath(const ::std::string& value);
  #if LANG_CXX11
  void set_startpath(::std::string&& value);
  #endif
  void set_startpath(const char* value);
  void set_startpath(const void* value, size_t size);
  ::std::string* mutable_startpath();
  ::std::string* release_startpath();
  void set_allocated_startpath(::std::string* startpath);

  // required int32 index = 2 [default = -1];
  bool has_index() const;
  void clear_index();
  static const int kIndexFieldNumber = 2;
  ::google::protobuf::int32 index() const;
  void set_index(::google::protobuf::int32 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.SnapshotDiffReportCursorProto)
 private:
  void set_has_startpath();
  void clear_has_startpath();
  void set_has_index();
  void clear_has_index();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr startpath_;
  ::google::protobuf::int32 index_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class SnapshotDiffReportListingProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.SnapshotDiffReportListingProto) */ {
 public:
  SnapshotDiffReportListingProto();
  virtual ~SnapshotDiffReportListingProto();

  SnapshotDiffReportListingProto(const SnapshotDiffReportListingProto& from);

  inline SnapshotDiffReportListingProto& operator=(const SnapshotDiffReportListingProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  SnapshotDiffReportListingProto(SnapshotDiffReportListingProto&& from) noexcept
    : SnapshotDiffReportListingProto() {
    *this = ::std::move(from);
  }

  inline SnapshotDiffReportListingProto& operator=(SnapshotDiffReportListingProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const SnapshotDiffReportListingProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const SnapshotDiffReportListingProto* internal_default_instance() {
    return reinterpret_cast<const SnapshotDiffReportListingProto*>(
               &_SnapshotDiffReportListingProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    43;

  void Swap(SnapshotDiffReportListingProto* other);
  friend void swap(SnapshotDiffReportListingProto& a, SnapshotDiffReportListingProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline SnapshotDiffReportListingProto* New() const final {
    return CreateMaybeMessage<SnapshotDiffReportListingProto>(NULL);
  }

  SnapshotDiffReportListingProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<SnapshotDiffReportListingProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const SnapshotDiffReportListingProto& from);
  void MergeFrom(const SnapshotDiffReportListingProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(SnapshotDiffReportListingProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.hdfs.SnapshotDiffReportListingEntryProto modifiedEntries = 1;
  int modifiedentries_size() const;
  void clear_modifiedentries();
  static const int kModifiedEntriesFieldNumber = 1;
  ::hadoop::hdfs::SnapshotDiffReportListingEntryProto* mutable_modifiedentries(int index);
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::SnapshotDiffReportListingEntryProto >*
      mutable_modifiedentries();
  const ::hadoop::hdfs::SnapshotDiffReportListingEntryProto& modifiedentries(int index) const;
  ::hadoop::hdfs::SnapshotDiffReportListingEntryProto* add_modifiedentries();
  const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::SnapshotDiffReportListingEntryProto >&
      modifiedentries() const;

  // repeated .hadoop.hdfs.SnapshotDiffReportListingEntryProto createdEntries = 2;
  int createdentries_size() const;
  void clear_createdentries();
  static const int kCreatedEntriesFieldNumber = 2;
  ::hadoop::hdfs::SnapshotDiffReportListingEntryProto* mutable_createdentries(int index);
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::SnapshotDiffReportListingEntryProto >*
      mutable_createdentries();
  const ::hadoop::hdfs::SnapshotDiffReportListingEntryProto& createdentries(int index) const;
  ::hadoop::hdfs::SnapshotDiffReportListingEntryProto* add_createdentries();
  const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::SnapshotDiffReportListingEntryProto >&
      createdentries() const;

  // repeated .hadoop.hdfs.SnapshotDiffReportListingEntryProto deletedEntries = 3;
  int deletedentries_size() const;
  void clear_deletedentries();
  static const int kDeletedEntriesFieldNumber = 3;
  ::hadoop::hdfs::SnapshotDiffReportListingEntryProto* mutable_deletedentries(int index);
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::SnapshotDiffReportListingEntryProto >*
      mutable_deletedentries();
  const ::hadoop::hdfs::SnapshotDiffReportListingEntryProto& deletedentries(int index) const;
  ::hadoop::hdfs::SnapshotDiffReportListingEntryProto* add_deletedentries();
  const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::SnapshotDiffReportListingEntryProto >&
      deletedentries() const;

  // optional .hadoop.hdfs.SnapshotDiffReportCursorProto cursor = 5;
  bool has_cursor() const;
  void clear_cursor();
  static const int kCursorFieldNumber = 5;
  private:
  const ::hadoop::hdfs::SnapshotDiffReportCursorProto& _internal_cursor() const;
  public:
  const ::hadoop::hdfs::SnapshotDiffReportCursorProto& cursor() const;
  ::hadoop::hdfs::SnapshotDiffReportCursorProto* release_cursor();
  ::hadoop::hdfs::SnapshotDiffReportCursorProto* mutable_cursor();
  void set_allocated_cursor(::hadoop::hdfs::SnapshotDiffReportCursorProto* cursor);

  // required bool isFromEarlier = 4;
  bool has_isfromearlier() const;
  void clear_isfromearlier();
  static const int kIsFromEarlierFieldNumber = 4;
  bool isfromearlier() const;
  void set_isfromearlier(bool value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.SnapshotDiffReportListingProto)
 private:
  void set_has_isfromearlier();
  void clear_has_isfromearlier();
  void set_has_cursor();
  void clear_has_cursor();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::SnapshotDiffReportListingEntryProto > modifiedentries_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::SnapshotDiffReportListingEntryProto > createdentries_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::SnapshotDiffReportListingEntryProto > deletedentries_;
  ::hadoop::hdfs::SnapshotDiffReportCursorProto* cursor_;
  bool isfromearlier_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class BlockProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.BlockProto) */ {
 public:
  BlockProto();
  virtual ~BlockProto();

  BlockProto(const BlockProto& from);

  inline BlockProto& operator=(const BlockProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  BlockProto(BlockProto&& from) noexcept
    : BlockProto() {
    *this = ::std::move(from);
  }

  inline BlockProto& operator=(BlockProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const BlockProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const BlockProto* internal_default_instance() {
    return reinterpret_cast<const BlockProto*>(
               &_BlockProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    44;

  void Swap(BlockProto* other);
  friend void swap(BlockProto& a, BlockProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline BlockProto* New() const final {
    return CreateMaybeMessage<BlockProto>(NULL);
  }

  BlockProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<BlockProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const BlockProto& from);
  void MergeFrom(const BlockProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(BlockProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required uint64 blockId = 1;
  bool has_blockid() const;
  void clear_blockid();
  static const int kBlockIdFieldNumber = 1;
  ::google::protobuf::uint64 blockid() const;
  void set_blockid(::google::protobuf::uint64 value);

  // required uint64 genStamp = 2;
  bool has_genstamp() const;
  void clear_genstamp();
  static const int kGenStampFieldNumber = 2;
  ::google::protobuf::uint64 genstamp() const;
  void set_genstamp(::google::protobuf::uint64 value);

  // optional uint64 numBytes = 3 [default = 0];
  bool has_numbytes() const;
  void clear_numbytes();
  static const int kNumBytesFieldNumber = 3;
  ::google::protobuf::uint64 numbytes() const;
  void set_numbytes(::google::protobuf::uint64 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.BlockProto)
 private:
  void set_has_blockid();
  void clear_has_blockid();
  void set_has_genstamp();
  void clear_has_genstamp();
  void set_has_numbytes();
  void clear_has_numbytes();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::uint64 blockid_;
  ::google::protobuf::uint64 genstamp_;
  ::google::protobuf::uint64 numbytes_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class SnapshotInfoProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.SnapshotInfoProto) */ {
 public:
  SnapshotInfoProto();
  virtual ~SnapshotInfoProto();

  SnapshotInfoProto(const SnapshotInfoProto& from);

  inline SnapshotInfoProto& operator=(const SnapshotInfoProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  SnapshotInfoProto(SnapshotInfoProto&& from) noexcept
    : SnapshotInfoProto() {
    *this = ::std::move(from);
  }

  inline SnapshotInfoProto& operator=(SnapshotInfoProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const SnapshotInfoProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const SnapshotInfoProto* internal_default_instance() {
    return reinterpret_cast<const SnapshotInfoProto*>(
               &_SnapshotInfoProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    45;

  void Swap(SnapshotInfoProto* other);
  friend void swap(SnapshotInfoProto& a, SnapshotInfoProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline SnapshotInfoProto* New() const final {
    return CreateMaybeMessage<SnapshotInfoProto>(NULL);
  }

  SnapshotInfoProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<SnapshotInfoProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const SnapshotInfoProto& from);
  void MergeFrom(const SnapshotInfoProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(SnapshotInfoProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required string snapshotName = 1;
  bool has_snapshotname() const;
  void clear_snapshotname();
  static const int kSnapshotNameFieldNumber = 1;
  const ::std::string& snapshotname() const;
  void set_snapshotname(const ::std::string& value);
  #if LANG_CXX11
  void set_snapshotname(::std::string&& value);
  #endif
  void set_snapshotname(const char* value);
  void set_snapshotname(const char* value, size_t size);
  ::std::string* mutable_snapshotname();
  ::std::string* release_snapshotname();
  void set_allocated_snapshotname(::std::string* snapshotname);

  // required string snapshotRoot = 2;
  bool has_snapshotroot() const;
  void clear_snapshotroot();
  static const int kSnapshotRootFieldNumber = 2;
  const ::std::string& snapshotroot() const;
  void set_snapshotroot(const ::std::string& value);
  #if LANG_CXX11
  void set_snapshotroot(::std::string&& value);
  #endif
  void set_snapshotroot(const char* value);
  void set_snapshotroot(const char* value, size_t size);
  ::std::string* mutable_snapshotroot();
  ::std::string* release_snapshotroot();
  void set_allocated_snapshotroot(::std::string* snapshotroot);

  // required string owner = 4;
  bool has_owner() const;
  void clear_owner();
  static const int kOwnerFieldNumber = 4;
  const ::std::string& owner() const;
  void set_owner(const ::std::string& value);
  #if LANG_CXX11
  void set_owner(::std::string&& value);
  #endif
  void set_owner(const char* value);
  void set_owner(const char* value, size_t size);
  ::std::string* mutable_owner();
  ::std::string* release_owner();
  void set_allocated_owner(::std::string* owner);

  // required string group = 5;
  bool has_group() const;
  void clear_group();
  static const int kGroupFieldNumber = 5;
  const ::std::string& group() const;
  void set_group(const ::std::string& value);
  #if LANG_CXX11
  void set_group(::std::string&& value);
  #endif
  void set_group(const char* value);
  void set_group(const char* value, size_t size);
  ::std::string* mutable_group();
  ::std::string* release_group();
  void set_allocated_group(::std::string* group);

  // required string createTime = 6;
  bool has_createtime() const;
  void clear_createtime();
  static const int kCreateTimeFieldNumber = 6;
  const ::std::string& createtime() const;
  void set_createtime(const ::std::string& value);
  #if LANG_CXX11
  void set_createtime(::std::string&& value);
  #endif
  void set_createtime(const char* value);
  void set_createtime(const char* value, size_t size);
  ::std::string* mutable_createtime();
  ::std::string* release_createtime();
  void set_allocated_createtime(::std::string* createtime);

  // required .hadoop.hdfs.FsPermissionProto permission = 3;
  bool has_permission() const;
  void clear_permission();
  static const int kPermissionFieldNumber = 3;
  private:
  const ::hadoop::hdfs::FsPermissionProto& _internal_permission() const;
  public:
  const ::hadoop::hdfs::FsPermissionProto& permission() const;
  ::hadoop::hdfs::FsPermissionProto* release_permission();
  ::hadoop::hdfs::FsPermissionProto* mutable_permission();
  void set_allocated_permission(::hadoop::hdfs::FsPermissionProto* permission);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.SnapshotInfoProto)
 private:
  void set_has_snapshotname();
  void clear_has_snapshotname();
  void set_has_snapshotroot();
  void clear_has_snapshotroot();
  void set_has_permission();
  void clear_has_permission();
  void set_has_owner();
  void clear_has_owner();
  void set_has_group();
  void clear_has_group();
  void set_has_createtime();
  void clear_has_createtime();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr snapshotname_;
  ::google::protobuf::internal::ArenaStringPtr snapshotroot_;
  ::google::protobuf::internal::ArenaStringPtr owner_;
  ::google::protobuf::internal::ArenaStringPtr group_;
  ::google::protobuf::internal::ArenaStringPtr createtime_;
  ::hadoop::hdfs::FsPermissionProto* permission_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class RollingUpgradeStatusProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.RollingUpgradeStatusProto) */ {
 public:
  RollingUpgradeStatusProto();
  virtual ~RollingUpgradeStatusProto();

  RollingUpgradeStatusProto(const RollingUpgradeStatusProto& from);

  inline RollingUpgradeStatusProto& operator=(const RollingUpgradeStatusProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  RollingUpgradeStatusProto(RollingUpgradeStatusProto&& from) noexcept
    : RollingUpgradeStatusProto() {
    *this = ::std::move(from);
  }

  inline RollingUpgradeStatusProto& operator=(RollingUpgradeStatusProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const RollingUpgradeStatusProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const RollingUpgradeStatusProto* internal_default_instance() {
    return reinterpret_cast<const RollingUpgradeStatusProto*>(
               &_RollingUpgradeStatusProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    46;

  void Swap(RollingUpgradeStatusProto* other);
  friend void swap(RollingUpgradeStatusProto& a, RollingUpgradeStatusProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline RollingUpgradeStatusProto* New() const final {
    return CreateMaybeMessage<RollingUpgradeStatusProto>(NULL);
  }

  RollingUpgradeStatusProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<RollingUpgradeStatusProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const RollingUpgradeStatusProto& from);
  void MergeFrom(const RollingUpgradeStatusProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(RollingUpgradeStatusProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required string blockPoolId = 1;
  bool has_blockpoolid() const;
  void clear_blockpoolid();
  static const int kBlockPoolIdFieldNumber = 1;
  const ::std::string& blockpoolid() const;
  void set_blockpoolid(const ::std::string& value);
  #if LANG_CXX11
  void set_blockpoolid(::std::string&& value);
  #endif
  void set_blockpoolid(const char* value);
  void set_blockpoolid(const char* value, size_t size);
  ::std::string* mutable_blockpoolid();
  ::std::string* release_blockpoolid();
  void set_allocated_blockpoolid(::std::string* blockpoolid);

  // optional bool finalized = 2 [default = false];
  bool has_finalized() const;
  void clear_finalized();
  static const int kFinalizedFieldNumber = 2;
  bool finalized() const;
  void set_finalized(bool value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.RollingUpgradeStatusProto)
 private:
  void set_has_blockpoolid();
  void clear_has_blockpoolid();
  void set_has_finalized();
  void clear_has_finalized();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr blockpoolid_;
  bool finalized_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class StorageUuidsProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.StorageUuidsProto) */ {
 public:
  StorageUuidsProto();
  virtual ~StorageUuidsProto();

  StorageUuidsProto(const StorageUuidsProto& from);

  inline StorageUuidsProto& operator=(const StorageUuidsProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  StorageUuidsProto(StorageUuidsProto&& from) noexcept
    : StorageUuidsProto() {
    *this = ::std::move(from);
  }

  inline StorageUuidsProto& operator=(StorageUuidsProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const StorageUuidsProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const StorageUuidsProto* internal_default_instance() {
    return reinterpret_cast<const StorageUuidsProto*>(
               &_StorageUuidsProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    47;

  void Swap(StorageUuidsProto* other);
  friend void swap(StorageUuidsProto& a, StorageUuidsProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline StorageUuidsProto* New() const final {
    return CreateMaybeMessage<StorageUuidsProto>(NULL);
  }

  StorageUuidsProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<StorageUuidsProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const StorageUuidsProto& from);
  void MergeFrom(const StorageUuidsProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(StorageUuidsProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated string storageUuids = 1;
  int storageuuids_size() const;
  void clear_storageuuids();
  static const int kStorageUuidsFieldNumber = 1;
  const ::std::string& storageuuids(int index) const;
  ::std::string* mutable_storageuuids(int index);
  void set_storageuuids(int index, const ::std::string& value);
  #if LANG_CXX11
  void set_storageuuids(int index, ::std::string&& value);
  #endif
  void set_storageuuids(int index, const char* value);
  void set_storageuuids(int index, const char* value, size_t size);
  ::std::string* add_storageuuids();
  void add_storageuuids(const ::std::string& value);
  #if LANG_CXX11
  void add_storageuuids(::std::string&& value);
  #endif
  void add_storageuuids(const char* value);
  void add_storageuuids(const char* value, size_t size);
  const ::google::protobuf::RepeatedPtrField< ::std::string>& storageuuids() const;
  ::google::protobuf::RepeatedPtrField< ::std::string>* mutable_storageuuids();

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.StorageUuidsProto)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::RepeatedPtrField< ::std::string> storageuuids_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class BlockTokenSecretProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.BlockTokenSecretProto) */ {
 public:
  BlockTokenSecretProto();
  virtual ~BlockTokenSecretProto();

  BlockTokenSecretProto(const BlockTokenSecretProto& from);

  inline BlockTokenSecretProto& operator=(const BlockTokenSecretProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  BlockTokenSecretProto(BlockTokenSecretProto&& from) noexcept
    : BlockTokenSecretProto() {
    *this = ::std::move(from);
  }

  inline BlockTokenSecretProto& operator=(BlockTokenSecretProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const BlockTokenSecretProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const BlockTokenSecretProto* internal_default_instance() {
    return reinterpret_cast<const BlockTokenSecretProto*>(
               &_BlockTokenSecretProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    48;

  void Swap(BlockTokenSecretProto* other);
  friend void swap(BlockTokenSecretProto& a, BlockTokenSecretProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline BlockTokenSecretProto* New() const final {
    return CreateMaybeMessage<BlockTokenSecretProto>(NULL);
  }

  BlockTokenSecretProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<BlockTokenSecretProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const BlockTokenSecretProto& from);
  void MergeFrom(const BlockTokenSecretProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(BlockTokenSecretProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.hdfs.AccessModeProto modes = 6;
  int modes_size() const;
  void clear_modes();
  static const int kModesFieldNumber = 6;
  ::hadoop::hdfs::AccessModeProto modes(int index) const;
  void set_modes(int index, ::hadoop::hdfs::AccessModeProto value);
  void add_modes(::hadoop::hdfs::AccessModeProto value);
  const ::google::protobuf::RepeatedField<int>& modes() const;
  ::google::protobuf::RepeatedField<int>* mutable_modes();

  // repeated .hadoop.hdfs.StorageTypeProto storageTypes = 7;
  int storagetypes_size() const;
  void clear_storagetypes();
  static const int kStorageTypesFieldNumber = 7;
  ::hadoop::hdfs::StorageTypeProto storagetypes(int index) const;
  void set_storagetypes(int index, ::hadoop::hdfs::StorageTypeProto value);
  void add_storagetypes(::hadoop::hdfs::StorageTypeProto value);
  const ::google::protobuf::RepeatedField<int>& storagetypes() const;
  ::google::protobuf::RepeatedField<int>* mutable_storagetypes();

  // repeated string storageIds = 8;
  int storageids_size() const;
  void clear_storageids();
  static const int kStorageIdsFieldNumber = 8;
  const ::std::string& storageids(int index) const;
  ::std::string* mutable_storageids(int index);
  void set_storageids(int index, const ::std::string& value);
  #if LANG_CXX11
  void set_storageids(int index, ::std::string&& value);
  #endif
  void set_storageids(int index, const char* value);
  void set_storageids(int index, const char* value, size_t size);
  ::std::string* add_storageids();
  void add_storageids(const ::std::string& value);
  #if LANG_CXX11
  void add_storageids(::std::string&& value);
  #endif
  void add_storageids(const char* value);
  void add_storageids(const char* value, size_t size);
  const ::google::protobuf::RepeatedPtrField< ::std::string>& storageids() const;
  ::google::protobuf::RepeatedPtrField< ::std::string>* mutable_storageids();

  // optional string userId = 3;
  bool has_userid() const;
  void clear_userid();
  static const int kUserIdFieldNumber = 3;
  const ::std::string& userid() const;
  void set_userid(const ::std::string& value);
  #if LANG_CXX11
  void set_userid(::std::string&& value);
  #endif
  void set_userid(const char* value);
  void set_userid(const char* value, size_t size);
  ::std::string* mutable_userid();
  ::std::string* release_userid();
  void set_allocated_userid(::std::string* userid);

  // optional string blockPoolId = 4;
  bool has_blockpoolid() const;
  void clear_blockpoolid();
  static const int kBlockPoolIdFieldNumber = 4;
  const ::std::string& blockpoolid() const;
  void set_blockpoolid(const ::std::string& value);
  #if LANG_CXX11
  void set_blockpoolid(::std::string&& value);
  #endif
  void set_blockpoolid(const char* value);
  void set_blockpoolid(const char* value, size_t size);
  ::std::string* mutable_blockpoolid();
  ::std::string* release_blockpoolid();
  void set_allocated_blockpoolid(::std::string* blockpoolid);

  // optional bytes handshakeSecret = 9;
  bool has_handshakesecret() const;
  void clear_handshakesecret();
  static const int kHandshakeSecretFieldNumber = 9;
  const ::std::string& handshakesecret() const;
  void set_handshakesecret(const ::std::string& value);
  #if LANG_CXX11
  void set_handshakesecret(::std::string&& value);
  #endif
  void set_handshakesecret(const char* value);
  void set_handshakesecret(const void* value, size_t size);
  ::std::string* mutable_handshakesecret();
  ::std::string* release_handshakesecret();
  void set_allocated_handshakesecret(::std::string* handshakesecret);

  // optional uint64 expiryDate = 1;
  bool has_expirydate() const;
  void clear_expirydate();
  static const int kExpiryDateFieldNumber = 1;
  ::google::protobuf::uint64 expirydate() const;
  void set_expirydate(::google::protobuf::uint64 value);

  // optional uint64 blockId = 5;
  bool has_blockid() const;
  void clear_blockid();
  static const int kBlockIdFieldNumber = 5;
  ::google::protobuf::uint64 blockid() const;
  void set_blockid(::google::protobuf::uint64 value);

  // optional uint32 keyId = 2;
  bool has_keyid() const;
  void clear_keyid();
  static const int kKeyIdFieldNumber = 2;
  ::google::protobuf::uint32 keyid() const;
  void set_keyid(::google::protobuf::uint32 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.BlockTokenSecretProto)
 private:
  void set_has_expirydate();
  void clear_has_expirydate();
  void set_has_keyid();
  void clear_has_keyid();
  void set_has_userid();
  void clear_has_userid();
  void set_has_blockpoolid();
  void clear_has_blockpoolid();
  void set_has_blockid();
  void clear_has_blockid();
  void set_has_handshakesecret();
  void clear_has_handshakesecret();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::RepeatedField<int> modes_;
  ::google::protobuf::RepeatedField<int> storagetypes_;
  ::google::protobuf::RepeatedPtrField< ::std::string> storageids_;
  ::google::protobuf::internal::ArenaStringPtr userid_;
  ::google::protobuf::internal::ArenaStringPtr blockpoolid_;
  ::google::protobuf::internal::ArenaStringPtr handshakesecret_;
  ::google::protobuf::uint64 expirydate_;
  ::google::protobuf::uint64 blockid_;
  ::google::protobuf::uint32 keyid_;
  friend struct ::protobuf_hdfs_2eproto::TableStruct;
};
// ===================================================================


// ===================================================================

#ifdef __GNUC__
  #pragma GCC diagnostic push
  #pragma GCC diagnostic ignored "-Wstrict-aliasing"
#endif  // __GNUC__
// ExtendedBlockProto

// required string poolId = 1;
inline bool ExtendedBlockProto::has_poolid() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ExtendedBlockProto::set_has_poolid() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ExtendedBlockProto::clear_has_poolid() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ExtendedBlockProto::clear_poolid() {
  poolid_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_poolid();
}
inline const ::std::string& ExtendedBlockProto::poolid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ExtendedBlockProto.poolId)
  return poolid_.GetNoArena();
}
inline void ExtendedBlockProto::set_poolid(const ::std::string& value) {
  set_has_poolid();
  poolid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ExtendedBlockProto.poolId)
}
#if LANG_CXX11
inline void ExtendedBlockProto::set_poolid(::std::string&& value) {
  set_has_poolid();
  poolid_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.ExtendedBlockProto.poolId)
}
#endif
inline void ExtendedBlockProto::set_poolid(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_poolid();
  poolid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.ExtendedBlockProto.poolId)
}
inline void ExtendedBlockProto::set_poolid(const char* value, size_t size) {
  set_has_poolid();
  poolid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.ExtendedBlockProto.poolId)
}
inline ::std::string* ExtendedBlockProto::mutable_poolid() {
  set_has_poolid();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.ExtendedBlockProto.poolId)
  return poolid_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* ExtendedBlockProto::release_poolid() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.ExtendedBlockProto.poolId)
  if (!has_poolid()) {
    return NULL;
  }
  clear_has_poolid();
  return poolid_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void ExtendedBlockProto::set_allocated_poolid(::std::string* poolid) {
  if (poolid != NULL) {
    set_has_poolid();
  } else {
    clear_has_poolid();
  }
  poolid_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), poolid);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.ExtendedBlockProto.poolId)
}

// required uint64 blockId = 2;
inline bool ExtendedBlockProto::has_blockid() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ExtendedBlockProto::set_has_blockid() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ExtendedBlockProto::clear_has_blockid() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ExtendedBlockProto::clear_blockid() {
  blockid_ = GOOGLE_ULONGLONG(0);
  clear_has_blockid();
}
inline ::google::protobuf::uint64 ExtendedBlockProto::blockid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ExtendedBlockProto.blockId)
  return blockid_;
}
inline void ExtendedBlockProto::set_blockid(::google::protobuf::uint64 value) {
  set_has_blockid();
  blockid_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ExtendedBlockProto.blockId)
}

// required uint64 generationStamp = 3;
inline bool ExtendedBlockProto::has_generationstamp() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void ExtendedBlockProto::set_has_generationstamp() {
  _has_bits_[0] |= 0x00000004u;
}
inline void ExtendedBlockProto::clear_has_generationstamp() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void ExtendedBlockProto::clear_generationstamp() {
  generationstamp_ = GOOGLE_ULONGLONG(0);
  clear_has_generationstamp();
}
inline ::google::protobuf::uint64 ExtendedBlockProto::generationstamp() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ExtendedBlockProto.generationStamp)
  return generationstamp_;
}
inline void ExtendedBlockProto::set_generationstamp(::google::protobuf::uint64 value) {
  set_has_generationstamp();
  generationstamp_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ExtendedBlockProto.generationStamp)
}

// optional uint64 numBytes = 4 [default = 0];
inline bool ExtendedBlockProto::has_numbytes() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void ExtendedBlockProto::set_has_numbytes() {
  _has_bits_[0] |= 0x00000008u;
}
inline void ExtendedBlockProto::clear_has_numbytes() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void ExtendedBlockProto::clear_numbytes() {
  numbytes_ = GOOGLE_ULONGLONG(0);
  clear_has_numbytes();
}
inline ::google::protobuf::uint64 ExtendedBlockProto::numbytes() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ExtendedBlockProto.numBytes)
  return numbytes_;
}
inline void ExtendedBlockProto::set_numbytes(::google::protobuf::uint64 value) {
  set_has_numbytes();
  numbytes_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ExtendedBlockProto.numBytes)
}

// -------------------------------------------------------------------

// ProvidedStorageLocationProto

// required string path = 1;
inline bool ProvidedStorageLocationProto::has_path() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ProvidedStorageLocationProto::set_has_path() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ProvidedStorageLocationProto::clear_has_path() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ProvidedStorageLocationProto::clear_path() {
  path_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_path();
}
inline const ::std::string& ProvidedStorageLocationProto::path() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ProvidedStorageLocationProto.path)
  return path_.GetNoArena();
}
inline void ProvidedStorageLocationProto::set_path(const ::std::string& value) {
  set_has_path();
  path_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ProvidedStorageLocationProto.path)
}
#if LANG_CXX11
inline void ProvidedStorageLocationProto::set_path(::std::string&& value) {
  set_has_path();
  path_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.ProvidedStorageLocationProto.path)
}
#endif
inline void ProvidedStorageLocationProto::set_path(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_path();
  path_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.ProvidedStorageLocationProto.path)
}
inline void ProvidedStorageLocationProto::set_path(const char* value, size_t size) {
  set_has_path();
  path_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.ProvidedStorageLocationProto.path)
}
inline ::std::string* ProvidedStorageLocationProto::mutable_path() {
  set_has_path();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.ProvidedStorageLocationProto.path)
  return path_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* ProvidedStorageLocationProto::release_path() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.ProvidedStorageLocationProto.path)
  if (!has_path()) {
    return NULL;
  }
  clear_has_path();
  return path_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void ProvidedStorageLocationProto::set_allocated_path(::std::string* path) {
  if (path != NULL) {
    set_has_path();
  } else {
    clear_has_path();
  }
  path_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), path);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.ProvidedStorageLocationProto.path)
}

// required int64 offset = 2;
inline bool ProvidedStorageLocationProto::has_offset() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void ProvidedStorageLocationProto::set_has_offset() {
  _has_bits_[0] |= 0x00000004u;
}
inline void ProvidedStorageLocationProto::clear_has_offset() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void ProvidedStorageLocationProto::clear_offset() {
  offset_ = GOOGLE_LONGLONG(0);
  clear_has_offset();
}
inline ::google::protobuf::int64 ProvidedStorageLocationProto::offset() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ProvidedStorageLocationProto.offset)
  return offset_;
}
inline void ProvidedStorageLocationProto::set_offset(::google::protobuf::int64 value) {
  set_has_offset();
  offset_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ProvidedStorageLocationProto.offset)
}

// required int64 length = 3;
inline bool ProvidedStorageLocationProto::has_length() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void ProvidedStorageLocationProto::set_has_length() {
  _has_bits_[0] |= 0x00000008u;
}
inline void ProvidedStorageLocationProto::clear_has_length() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void ProvidedStorageLocationProto::clear_length() {
  length_ = GOOGLE_LONGLONG(0);
  clear_has_length();
}
inline ::google::protobuf::int64 ProvidedStorageLocationProto::length() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ProvidedStorageLocationProto.length)
  return length_;
}
inline void ProvidedStorageLocationProto::set_length(::google::protobuf::int64 value) {
  set_has_length();
  length_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ProvidedStorageLocationProto.length)
}

// required bytes nonce = 4;
inline bool ProvidedStorageLocationProto::has_nonce() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ProvidedStorageLocationProto::set_has_nonce() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ProvidedStorageLocationProto::clear_has_nonce() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ProvidedStorageLocationProto::clear_nonce() {
  nonce_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_nonce();
}
inline const ::std::string& ProvidedStorageLocationProto::nonce() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ProvidedStorageLocationProto.nonce)
  return nonce_.GetNoArena();
}
inline void ProvidedStorageLocationProto::set_nonce(const ::std::string& value) {
  set_has_nonce();
  nonce_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ProvidedStorageLocationProto.nonce)
}
#if LANG_CXX11
inline void ProvidedStorageLocationProto::set_nonce(::std::string&& value) {
  set_has_nonce();
  nonce_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.ProvidedStorageLocationProto.nonce)
}
#endif
inline void ProvidedStorageLocationProto::set_nonce(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_nonce();
  nonce_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.ProvidedStorageLocationProto.nonce)
}
inline void ProvidedStorageLocationProto::set_nonce(const void* value, size_t size) {
  set_has_nonce();
  nonce_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.ProvidedStorageLocationProto.nonce)
}
inline ::std::string* ProvidedStorageLocationProto::mutable_nonce() {
  set_has_nonce();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.ProvidedStorageLocationProto.nonce)
  return nonce_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* ProvidedStorageLocationProto::release_nonce() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.ProvidedStorageLocationProto.nonce)
  if (!has_nonce()) {
    return NULL;
  }
  clear_has_nonce();
  return nonce_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void ProvidedStorageLocationProto::set_allocated_nonce(::std::string* nonce) {
  if (nonce != NULL) {
    set_has_nonce();
  } else {
    clear_has_nonce();
  }
  nonce_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), nonce);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.ProvidedStorageLocationProto.nonce)
}

// -------------------------------------------------------------------

// DatanodeIDProto

// required string ipAddr = 1;
inline bool DatanodeIDProto::has_ipaddr() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void DatanodeIDProto::set_has_ipaddr() {
  _has_bits_[0] |= 0x00000001u;
}
inline void DatanodeIDProto::clear_has_ipaddr() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void DatanodeIDProto::clear_ipaddr() {
  ipaddr_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_ipaddr();
}
inline const ::std::string& DatanodeIDProto::ipaddr() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeIDProto.ipAddr)
  return ipaddr_.GetNoArena();
}
inline void DatanodeIDProto::set_ipaddr(const ::std::string& value) {
  set_has_ipaddr();
  ipaddr_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeIDProto.ipAddr)
}
#if LANG_CXX11
inline void DatanodeIDProto::set_ipaddr(::std::string&& value) {
  set_has_ipaddr();
  ipaddr_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.DatanodeIDProto.ipAddr)
}
#endif
inline void DatanodeIDProto::set_ipaddr(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_ipaddr();
  ipaddr_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.DatanodeIDProto.ipAddr)
}
inline void DatanodeIDProto::set_ipaddr(const char* value, size_t size) {
  set_has_ipaddr();
  ipaddr_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.DatanodeIDProto.ipAddr)
}
inline ::std::string* DatanodeIDProto::mutable_ipaddr() {
  set_has_ipaddr();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.DatanodeIDProto.ipAddr)
  return ipaddr_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* DatanodeIDProto::release_ipaddr() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.DatanodeIDProto.ipAddr)
  if (!has_ipaddr()) {
    return NULL;
  }
  clear_has_ipaddr();
  return ipaddr_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void DatanodeIDProto::set_allocated_ipaddr(::std::string* ipaddr) {
  if (ipaddr != NULL) {
    set_has_ipaddr();
  } else {
    clear_has_ipaddr();
  }
  ipaddr_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ipaddr);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.DatanodeIDProto.ipAddr)
}

// required string hostName = 2;
inline bool DatanodeIDProto::has_hostname() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void DatanodeIDProto::set_has_hostname() {
  _has_bits_[0] |= 0x00000002u;
}
inline void DatanodeIDProto::clear_has_hostname() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void DatanodeIDProto::clear_hostname() {
  hostname_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_hostname();
}
inline const ::std::string& DatanodeIDProto::hostname() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeIDProto.hostName)
  return hostname_.GetNoArena();
}
inline void DatanodeIDProto::set_hostname(const ::std::string& value) {
  set_has_hostname();
  hostname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeIDProto.hostName)
}
#if LANG_CXX11
inline void DatanodeIDProto::set_hostname(::std::string&& value) {
  set_has_hostname();
  hostname_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.DatanodeIDProto.hostName)
}
#endif
inline void DatanodeIDProto::set_hostname(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_hostname();
  hostname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.DatanodeIDProto.hostName)
}
inline void DatanodeIDProto::set_hostname(const char* value, size_t size) {
  set_has_hostname();
  hostname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.DatanodeIDProto.hostName)
}
inline ::std::string* DatanodeIDProto::mutable_hostname() {
  set_has_hostname();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.DatanodeIDProto.hostName)
  return hostname_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* DatanodeIDProto::release_hostname() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.DatanodeIDProto.hostName)
  if (!has_hostname()) {
    return NULL;
  }
  clear_has_hostname();
  return hostname_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void DatanodeIDProto::set_allocated_hostname(::std::string* hostname) {
  if (hostname != NULL) {
    set_has_hostname();
  } else {
    clear_has_hostname();
  }
  hostname_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), hostname);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.DatanodeIDProto.hostName)
}

// required string datanodeUuid = 3;
inline bool DatanodeIDProto::has_datanodeuuid() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void DatanodeIDProto::set_has_datanodeuuid() {
  _has_bits_[0] |= 0x00000004u;
}
inline void DatanodeIDProto::clear_has_datanodeuuid() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void DatanodeIDProto::clear_datanodeuuid() {
  datanodeuuid_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_datanodeuuid();
}
inline const ::std::string& DatanodeIDProto::datanodeuuid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeIDProto.datanodeUuid)
  return datanodeuuid_.GetNoArena();
}
inline void DatanodeIDProto::set_datanodeuuid(const ::std::string& value) {
  set_has_datanodeuuid();
  datanodeuuid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeIDProto.datanodeUuid)
}
#if LANG_CXX11
inline void DatanodeIDProto::set_datanodeuuid(::std::string&& value) {
  set_has_datanodeuuid();
  datanodeuuid_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.DatanodeIDProto.datanodeUuid)
}
#endif
inline void DatanodeIDProto::set_datanodeuuid(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_datanodeuuid();
  datanodeuuid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.DatanodeIDProto.datanodeUuid)
}
inline void DatanodeIDProto::set_datanodeuuid(const char* value, size_t size) {
  set_has_datanodeuuid();
  datanodeuuid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.DatanodeIDProto.datanodeUuid)
}
inline ::std::string* DatanodeIDProto::mutable_datanodeuuid() {
  set_has_datanodeuuid();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.DatanodeIDProto.datanodeUuid)
  return datanodeuuid_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* DatanodeIDProto::release_datanodeuuid() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.DatanodeIDProto.datanodeUuid)
  if (!has_datanodeuuid()) {
    return NULL;
  }
  clear_has_datanodeuuid();
  return datanodeuuid_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void DatanodeIDProto::set_allocated_datanodeuuid(::std::string* datanodeuuid) {
  if (datanodeuuid != NULL) {
    set_has_datanodeuuid();
  } else {
    clear_has_datanodeuuid();
  }
  datanodeuuid_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), datanodeuuid);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.DatanodeIDProto.datanodeUuid)
}

// required uint32 xferPort = 4;
inline bool DatanodeIDProto::has_xferport() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void DatanodeIDProto::set_has_xferport() {
  _has_bits_[0] |= 0x00000008u;
}
inline void DatanodeIDProto::clear_has_xferport() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void DatanodeIDProto::clear_xferport() {
  xferport_ = 0u;
  clear_has_xferport();
}
inline ::google::protobuf::uint32 DatanodeIDProto::xferport() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeIDProto.xferPort)
  return xferport_;
}
inline void DatanodeIDProto::set_xferport(::google::protobuf::uint32 value) {
  set_has_xferport();
  xferport_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeIDProto.xferPort)
}

// required uint32 infoPort = 5;
inline bool DatanodeIDProto::has_infoport() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void DatanodeIDProto::set_has_infoport() {
  _has_bits_[0] |= 0x00000010u;
}
inline void DatanodeIDProto::clear_has_infoport() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void DatanodeIDProto::clear_infoport() {
  infoport_ = 0u;
  clear_has_infoport();
}
inline ::google::protobuf::uint32 DatanodeIDProto::infoport() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeIDProto.infoPort)
  return infoport_;
}
inline void DatanodeIDProto::set_infoport(::google::protobuf::uint32 value) {
  set_has_infoport();
  infoport_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeIDProto.infoPort)
}

// required uint32 ipcPort = 6;
inline bool DatanodeIDProto::has_ipcport() const {
  return (_has_bits_[0] & 0x00000020u) != 0;
}
inline void DatanodeIDProto::set_has_ipcport() {
  _has_bits_[0] |= 0x00000020u;
}
inline void DatanodeIDProto::clear_has_ipcport() {
  _has_bits_[0] &= ~0x00000020u;
}
inline void DatanodeIDProto::clear_ipcport() {
  ipcport_ = 0u;
  clear_has_ipcport();
}
inline ::google::protobuf::uint32 DatanodeIDProto::ipcport() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeIDProto.ipcPort)
  return ipcport_;
}
inline void DatanodeIDProto::set_ipcport(::google::protobuf::uint32 value) {
  set_has_ipcport();
  ipcport_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeIDProto.ipcPort)
}

// optional uint32 infoSecurePort = 7 [default = 0];
inline bool DatanodeIDProto::has_infosecureport() const {
  return (_has_bits_[0] & 0x00000040u) != 0;
}
inline void DatanodeIDProto::set_has_infosecureport() {
  _has_bits_[0] |= 0x00000040u;
}
inline void DatanodeIDProto::clear_has_infosecureport() {
  _has_bits_[0] &= ~0x00000040u;
}
inline void DatanodeIDProto::clear_infosecureport() {
  infosecureport_ = 0u;
  clear_has_infosecureport();
}
inline ::google::protobuf::uint32 DatanodeIDProto::infosecureport() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeIDProto.infoSecurePort)
  return infosecureport_;
}
inline void DatanodeIDProto::set_infosecureport(::google::protobuf::uint32 value) {
  set_has_infosecureport();
  infosecureport_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeIDProto.infoSecurePort)
}

// -------------------------------------------------------------------

// DatanodeLocalInfoProto

// required string softwareVersion = 1;
inline bool DatanodeLocalInfoProto::has_softwareversion() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void DatanodeLocalInfoProto::set_has_softwareversion() {
  _has_bits_[0] |= 0x00000001u;
}
inline void DatanodeLocalInfoProto::clear_has_softwareversion() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void DatanodeLocalInfoProto::clear_softwareversion() {
  softwareversion_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_softwareversion();
}
inline const ::std::string& DatanodeLocalInfoProto::softwareversion() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeLocalInfoProto.softwareVersion)
  return softwareversion_.GetNoArena();
}
inline void DatanodeLocalInfoProto::set_softwareversion(const ::std::string& value) {
  set_has_softwareversion();
  softwareversion_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeLocalInfoProto.softwareVersion)
}
#if LANG_CXX11
inline void DatanodeLocalInfoProto::set_softwareversion(::std::string&& value) {
  set_has_softwareversion();
  softwareversion_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.DatanodeLocalInfoProto.softwareVersion)
}
#endif
inline void DatanodeLocalInfoProto::set_softwareversion(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_softwareversion();
  softwareversion_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.DatanodeLocalInfoProto.softwareVersion)
}
inline void DatanodeLocalInfoProto::set_softwareversion(const char* value, size_t size) {
  set_has_softwareversion();
  softwareversion_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.DatanodeLocalInfoProto.softwareVersion)
}
inline ::std::string* DatanodeLocalInfoProto::mutable_softwareversion() {
  set_has_softwareversion();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.DatanodeLocalInfoProto.softwareVersion)
  return softwareversion_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* DatanodeLocalInfoProto::release_softwareversion() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.DatanodeLocalInfoProto.softwareVersion)
  if (!has_softwareversion()) {
    return NULL;
  }
  clear_has_softwareversion();
  return softwareversion_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void DatanodeLocalInfoProto::set_allocated_softwareversion(::std::string* softwareversion) {
  if (softwareversion != NULL) {
    set_has_softwareversion();
  } else {
    clear_has_softwareversion();
  }
  softwareversion_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), softwareversion);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.DatanodeLocalInfoProto.softwareVersion)
}

// required string configVersion = 2;
inline bool DatanodeLocalInfoProto::has_configversion() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void DatanodeLocalInfoProto::set_has_configversion() {
  _has_bits_[0] |= 0x00000002u;
}
inline void DatanodeLocalInfoProto::clear_has_configversion() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void DatanodeLocalInfoProto::clear_configversion() {
  configversion_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_configversion();
}
inline const ::std::string& DatanodeLocalInfoProto::configversion() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeLocalInfoProto.configVersion)
  return configversion_.GetNoArena();
}
inline void DatanodeLocalInfoProto::set_configversion(const ::std::string& value) {
  set_has_configversion();
  configversion_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeLocalInfoProto.configVersion)
}
#if LANG_CXX11
inline void DatanodeLocalInfoProto::set_configversion(::std::string&& value) {
  set_has_configversion();
  configversion_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.DatanodeLocalInfoProto.configVersion)
}
#endif
inline void DatanodeLocalInfoProto::set_configversion(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_configversion();
  configversion_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.DatanodeLocalInfoProto.configVersion)
}
inline void DatanodeLocalInfoProto::set_configversion(const char* value, size_t size) {
  set_has_configversion();
  configversion_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.DatanodeLocalInfoProto.configVersion)
}
inline ::std::string* DatanodeLocalInfoProto::mutable_configversion() {
  set_has_configversion();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.DatanodeLocalInfoProto.configVersion)
  return configversion_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* DatanodeLocalInfoProto::release_configversion() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.DatanodeLocalInfoProto.configVersion)
  if (!has_configversion()) {
    return NULL;
  }
  clear_has_configversion();
  return configversion_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void DatanodeLocalInfoProto::set_allocated_configversion(::std::string* configversion) {
  if (configversion != NULL) {
    set_has_configversion();
  } else {
    clear_has_configversion();
  }
  configversion_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), configversion);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.DatanodeLocalInfoProto.configVersion)
}

// required uint64 uptime = 3;
inline bool DatanodeLocalInfoProto::has_uptime() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void DatanodeLocalInfoProto::set_has_uptime() {
  _has_bits_[0] |= 0x00000004u;
}
inline void DatanodeLocalInfoProto::clear_has_uptime() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void DatanodeLocalInfoProto::clear_uptime() {
  uptime_ = GOOGLE_ULONGLONG(0);
  clear_has_uptime();
}
inline ::google::protobuf::uint64 DatanodeLocalInfoProto::uptime() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeLocalInfoProto.uptime)
  return uptime_;
}
inline void DatanodeLocalInfoProto::set_uptime(::google::protobuf::uint64 value) {
  set_has_uptime();
  uptime_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeLocalInfoProto.uptime)
}

// -------------------------------------------------------------------

// DatanodeVolumeInfoProto

// required string path = 1;
inline bool DatanodeVolumeInfoProto::has_path() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void DatanodeVolumeInfoProto::set_has_path() {
  _has_bits_[0] |= 0x00000001u;
}
inline void DatanodeVolumeInfoProto::clear_has_path() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void DatanodeVolumeInfoProto::clear_path() {
  path_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_path();
}
inline const ::std::string& DatanodeVolumeInfoProto::path() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeVolumeInfoProto.path)
  return path_.GetNoArena();
}
inline void DatanodeVolumeInfoProto::set_path(const ::std::string& value) {
  set_has_path();
  path_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeVolumeInfoProto.path)
}
#if LANG_CXX11
inline void DatanodeVolumeInfoProto::set_path(::std::string&& value) {
  set_has_path();
  path_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.DatanodeVolumeInfoProto.path)
}
#endif
inline void DatanodeVolumeInfoProto::set_path(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_path();
  path_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.DatanodeVolumeInfoProto.path)
}
inline void DatanodeVolumeInfoProto::set_path(const char* value, size_t size) {
  set_has_path();
  path_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.DatanodeVolumeInfoProto.path)
}
inline ::std::string* DatanodeVolumeInfoProto::mutable_path() {
  set_has_path();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.DatanodeVolumeInfoProto.path)
  return path_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* DatanodeVolumeInfoProto::release_path() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.DatanodeVolumeInfoProto.path)
  if (!has_path()) {
    return NULL;
  }
  clear_has_path();
  return path_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void DatanodeVolumeInfoProto::set_allocated_path(::std::string* path) {
  if (path != NULL) {
    set_has_path();
  } else {
    clear_has_path();
  }
  path_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), path);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.DatanodeVolumeInfoProto.path)
}

// required .hadoop.hdfs.StorageTypeProto storageType = 2;
inline bool DatanodeVolumeInfoProto::has_storagetype() const {
  return (_has_bits_[0] & 0x00000040u) != 0;
}
inline void DatanodeVolumeInfoProto::set_has_storagetype() {
  _has_bits_[0] |= 0x00000040u;
}
inline void DatanodeVolumeInfoProto::clear_has_storagetype() {
  _has_bits_[0] &= ~0x00000040u;
}
inline void DatanodeVolumeInfoProto::clear_storagetype() {
  storagetype_ = 1;
  clear_has_storagetype();
}
inline ::hadoop::hdfs::StorageTypeProto DatanodeVolumeInfoProto::storagetype() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeVolumeInfoProto.storageType)
  return static_cast< ::hadoop::hdfs::StorageTypeProto >(storagetype_);
}
inline void DatanodeVolumeInfoProto::set_storagetype(::hadoop::hdfs::StorageTypeProto value) {
  assert(::hadoop::hdfs::StorageTypeProto_IsValid(value));
  set_has_storagetype();
  storagetype_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeVolumeInfoProto.storageType)
}

// required uint64 usedSpace = 3;
inline bool DatanodeVolumeInfoProto::has_usedspace() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void DatanodeVolumeInfoProto::set_has_usedspace() {
  _has_bits_[0] |= 0x00000002u;
}
inline void DatanodeVolumeInfoProto::clear_has_usedspace() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void DatanodeVolumeInfoProto::clear_usedspace() {
  usedspace_ = GOOGLE_ULONGLONG(0);
  clear_has_usedspace();
}
inline ::google::protobuf::uint64 DatanodeVolumeInfoProto::usedspace() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeVolumeInfoProto.usedSpace)
  return usedspace_;
}
inline void DatanodeVolumeInfoProto::set_usedspace(::google::protobuf::uint64 value) {
  set_has_usedspace();
  usedspace_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeVolumeInfoProto.usedSpace)
}

// required uint64 freeSpace = 4;
inline bool DatanodeVolumeInfoProto::has_freespace() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void DatanodeVolumeInfoProto::set_has_freespace() {
  _has_bits_[0] |= 0x00000004u;
}
inline void DatanodeVolumeInfoProto::clear_has_freespace() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void DatanodeVolumeInfoProto::clear_freespace() {
  freespace_ = GOOGLE_ULONGLONG(0);
  clear_has_freespace();
}
inline ::google::protobuf::uint64 DatanodeVolumeInfoProto::freespace() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeVolumeInfoProto.freeSpace)
  return freespace_;
}
inline void DatanodeVolumeInfoProto::set_freespace(::google::protobuf::uint64 value) {
  set_has_freespace();
  freespace_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeVolumeInfoProto.freeSpace)
}

// required uint64 reservedSpace = 5;
inline bool DatanodeVolumeInfoProto::has_reservedspace() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void DatanodeVolumeInfoProto::set_has_reservedspace() {
  _has_bits_[0] |= 0x00000008u;
}
inline void DatanodeVolumeInfoProto::clear_has_reservedspace() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void DatanodeVolumeInfoProto::clear_reservedspace() {
  reservedspace_ = GOOGLE_ULONGLONG(0);
  clear_has_reservedspace();
}
inline ::google::protobuf::uint64 DatanodeVolumeInfoProto::reservedspace() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeVolumeInfoProto.reservedSpace)
  return reservedspace_;
}
inline void DatanodeVolumeInfoProto::set_reservedspace(::google::protobuf::uint64 value) {
  set_has_reservedspace();
  reservedspace_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeVolumeInfoProto.reservedSpace)
}

// required uint64 reservedSpaceForReplicas = 6;
inline bool DatanodeVolumeInfoProto::has_reservedspaceforreplicas() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void DatanodeVolumeInfoProto::set_has_reservedspaceforreplicas() {
  _has_bits_[0] |= 0x00000010u;
}
inline void DatanodeVolumeInfoProto::clear_has_reservedspaceforreplicas() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void DatanodeVolumeInfoProto::clear_reservedspaceforreplicas() {
  reservedspaceforreplicas_ = GOOGLE_ULONGLONG(0);
  clear_has_reservedspaceforreplicas();
}
inline ::google::protobuf::uint64 DatanodeVolumeInfoProto::reservedspaceforreplicas() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeVolumeInfoProto.reservedSpaceForReplicas)
  return reservedspaceforreplicas_;
}
inline void DatanodeVolumeInfoProto::set_reservedspaceforreplicas(::google::protobuf::uint64 value) {
  set_has_reservedspaceforreplicas();
  reservedspaceforreplicas_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeVolumeInfoProto.reservedSpaceForReplicas)
}

// required uint64 numBlocks = 7;
inline bool DatanodeVolumeInfoProto::has_numblocks() const {
  return (_has_bits_[0] & 0x00000020u) != 0;
}
inline void DatanodeVolumeInfoProto::set_has_numblocks() {
  _has_bits_[0] |= 0x00000020u;
}
inline void DatanodeVolumeInfoProto::clear_has_numblocks() {
  _has_bits_[0] &= ~0x00000020u;
}
inline void DatanodeVolumeInfoProto::clear_numblocks() {
  numblocks_ = GOOGLE_ULONGLONG(0);
  clear_has_numblocks();
}
inline ::google::protobuf::uint64 DatanodeVolumeInfoProto::numblocks() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeVolumeInfoProto.numBlocks)
  return numblocks_;
}
inline void DatanodeVolumeInfoProto::set_numblocks(::google::protobuf::uint64 value) {
  set_has_numblocks();
  numblocks_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeVolumeInfoProto.numBlocks)
}

// -------------------------------------------------------------------

// DatanodeInfosProto

// repeated .hadoop.hdfs.DatanodeInfoProto datanodes = 1;
inline int DatanodeInfosProto::datanodes_size() const {
  return datanodes_.size();
}
inline void DatanodeInfosProto::clear_datanodes() {
  datanodes_.Clear();
}
inline ::hadoop::hdfs::DatanodeInfoProto* DatanodeInfosProto::mutable_datanodes(int index) {
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.DatanodeInfosProto.datanodes)
  return datanodes_.Mutable(index);
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::DatanodeInfoProto >*
DatanodeInfosProto::mutable_datanodes() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.DatanodeInfosProto.datanodes)
  return &datanodes_;
}
inline const ::hadoop::hdfs::DatanodeInfoProto& DatanodeInfosProto::datanodes(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeInfosProto.datanodes)
  return datanodes_.Get(index);
}
inline ::hadoop::hdfs::DatanodeInfoProto* DatanodeInfosProto::add_datanodes() {
  // @@protoc_insertion_point(field_add:hadoop.hdfs.DatanodeInfosProto.datanodes)
  return datanodes_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::DatanodeInfoProto >&
DatanodeInfosProto::datanodes() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.DatanodeInfosProto.datanodes)
  return datanodes_;
}

// -------------------------------------------------------------------

// DatanodeInfoProto

// required .hadoop.hdfs.DatanodeIDProto id = 1;
inline bool DatanodeInfoProto::has_id() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void DatanodeInfoProto::set_has_id() {
  _has_bits_[0] |= 0x00000004u;
}
inline void DatanodeInfoProto::clear_has_id() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void DatanodeInfoProto::clear_id() {
  if (id_ != NULL) id_->Clear();
  clear_has_id();
}
inline const ::hadoop::hdfs::DatanodeIDProto& DatanodeInfoProto::_internal_id() const {
  return *id_;
}
inline const ::hadoop::hdfs::DatanodeIDProto& DatanodeInfoProto::id() const {
  const ::hadoop::hdfs::DatanodeIDProto* p = id_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeInfoProto.id)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::DatanodeIDProto*>(
      &::hadoop::hdfs::_DatanodeIDProto_default_instance_);
}
inline ::hadoop::hdfs::DatanodeIDProto* DatanodeInfoProto::release_id() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.DatanodeInfoProto.id)
  clear_has_id();
  ::hadoop::hdfs::DatanodeIDProto* temp = id_;
  id_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::DatanodeIDProto* DatanodeInfoProto::mutable_id() {
  set_has_id();
  if (id_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::DatanodeIDProto>(GetArenaNoVirtual());
    id_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.DatanodeInfoProto.id)
  return id_;
}
inline void DatanodeInfoProto::set_allocated_id(::hadoop::hdfs::DatanodeIDProto* id) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete id_;
  }
  if (id) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      id = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, id, submessage_arena);
    }
    set_has_id();
  } else {
    clear_has_id();
  }
  id_ = id;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.DatanodeInfoProto.id)
}

// optional uint64 capacity = 2 [default = 0];
inline bool DatanodeInfoProto::has_capacity() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void DatanodeInfoProto::set_has_capacity() {
  _has_bits_[0] |= 0x00000008u;
}
inline void DatanodeInfoProto::clear_has_capacity() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void DatanodeInfoProto::clear_capacity() {
  capacity_ = GOOGLE_ULONGLONG(0);
  clear_has_capacity();
}
inline ::google::protobuf::uint64 DatanodeInfoProto::capacity() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeInfoProto.capacity)
  return capacity_;
}
inline void DatanodeInfoProto::set_capacity(::google::protobuf::uint64 value) {
  set_has_capacity();
  capacity_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeInfoProto.capacity)
}

// optional uint64 dfsUsed = 3 [default = 0];
inline bool DatanodeInfoProto::has_dfsused() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void DatanodeInfoProto::set_has_dfsused() {
  _has_bits_[0] |= 0x00000010u;
}
inline void DatanodeInfoProto::clear_has_dfsused() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void DatanodeInfoProto::clear_dfsused() {
  dfsused_ = GOOGLE_ULONGLONG(0);
  clear_has_dfsused();
}
inline ::google::protobuf::uint64 DatanodeInfoProto::dfsused() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeInfoProto.dfsUsed)
  return dfsused_;
}
inline void DatanodeInfoProto::set_dfsused(::google::protobuf::uint64 value) {
  set_has_dfsused();
  dfsused_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeInfoProto.dfsUsed)
}

// optional uint64 remaining = 4 [default = 0];
inline bool DatanodeInfoProto::has_remaining() const {
  return (_has_bits_[0] & 0x00000020u) != 0;
}
inline void DatanodeInfoProto::set_has_remaining() {
  _has_bits_[0] |= 0x00000020u;
}
inline void DatanodeInfoProto::clear_has_remaining() {
  _has_bits_[0] &= ~0x00000020u;
}
inline void DatanodeInfoProto::clear_remaining() {
  remaining_ = GOOGLE_ULONGLONG(0);
  clear_has_remaining();
}
inline ::google::protobuf::uint64 DatanodeInfoProto::remaining() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeInfoProto.remaining)
  return remaining_;
}
inline void DatanodeInfoProto::set_remaining(::google::protobuf::uint64 value) {
  set_has_remaining();
  remaining_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeInfoProto.remaining)
}

// optional uint64 blockPoolUsed = 5 [default = 0];
inline bool DatanodeInfoProto::has_blockpoolused() const {
  return (_has_bits_[0] & 0x00000040u) != 0;
}
inline void DatanodeInfoProto::set_has_blockpoolused() {
  _has_bits_[0] |= 0x00000040u;
}
inline void DatanodeInfoProto::clear_has_blockpoolused() {
  _has_bits_[0] &= ~0x00000040u;
}
inline void DatanodeInfoProto::clear_blockpoolused() {
  blockpoolused_ = GOOGLE_ULONGLONG(0);
  clear_has_blockpoolused();
}
inline ::google::protobuf::uint64 DatanodeInfoProto::blockpoolused() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeInfoProto.blockPoolUsed)
  return blockpoolused_;
}
inline void DatanodeInfoProto::set_blockpoolused(::google::protobuf::uint64 value) {
  set_has_blockpoolused();
  blockpoolused_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeInfoProto.blockPoolUsed)
}

// optional uint64 lastUpdate = 6 [default = 0];
inline bool DatanodeInfoProto::has_lastupdate() const {
  return (_has_bits_[0] & 0x00000080u) != 0;
}
inline void DatanodeInfoProto::set_has_lastupdate() {
  _has_bits_[0] |= 0x00000080u;
}
inline void DatanodeInfoProto::clear_has_lastupdate() {
  _has_bits_[0] &= ~0x00000080u;
}
inline void DatanodeInfoProto::clear_lastupdate() {
  lastupdate_ = GOOGLE_ULONGLONG(0);
  clear_has_lastupdate();
}
inline ::google::protobuf::uint64 DatanodeInfoProto::lastupdate() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeInfoProto.lastUpdate)
  return lastupdate_;
}
inline void DatanodeInfoProto::set_lastupdate(::google::protobuf::uint64 value) {
  set_has_lastupdate();
  lastupdate_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeInfoProto.lastUpdate)
}

// optional uint32 xceiverCount = 7 [default = 0];
inline bool DatanodeInfoProto::has_xceivercount() const {
  return (_has_bits_[0] & 0x00000100u) != 0;
}
inline void DatanodeInfoProto::set_has_xceivercount() {
  _has_bits_[0] |= 0x00000100u;
}
inline void DatanodeInfoProto::clear_has_xceivercount() {
  _has_bits_[0] &= ~0x00000100u;
}
inline void DatanodeInfoProto::clear_xceivercount() {
  xceivercount_ = 0u;
  clear_has_xceivercount();
}
inline ::google::protobuf::uint32 DatanodeInfoProto::xceivercount() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeInfoProto.xceiverCount)
  return xceivercount_;
}
inline void DatanodeInfoProto::set_xceivercount(::google::protobuf::uint32 value) {
  set_has_xceivercount();
  xceivercount_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeInfoProto.xceiverCount)
}

// optional string location = 8;
inline bool DatanodeInfoProto::has_location() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void DatanodeInfoProto::set_has_location() {
  _has_bits_[0] |= 0x00000001u;
}
inline void DatanodeInfoProto::clear_has_location() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void DatanodeInfoProto::clear_location() {
  location_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_location();
}
inline const ::std::string& DatanodeInfoProto::location() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeInfoProto.location)
  return location_.GetNoArena();
}
inline void DatanodeInfoProto::set_location(const ::std::string& value) {
  set_has_location();
  location_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeInfoProto.location)
}
#if LANG_CXX11
inline void DatanodeInfoProto::set_location(::std::string&& value) {
  set_has_location();
  location_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.DatanodeInfoProto.location)
}
#endif
inline void DatanodeInfoProto::set_location(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_location();
  location_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.DatanodeInfoProto.location)
}
inline void DatanodeInfoProto::set_location(const char* value, size_t size) {
  set_has_location();
  location_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.DatanodeInfoProto.location)
}
inline ::std::string* DatanodeInfoProto::mutable_location() {
  set_has_location();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.DatanodeInfoProto.location)
  return location_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* DatanodeInfoProto::release_location() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.DatanodeInfoProto.location)
  if (!has_location()) {
    return NULL;
  }
  clear_has_location();
  return location_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void DatanodeInfoProto::set_allocated_location(::std::string* location) {
  if (location != NULL) {
    set_has_location();
  } else {
    clear_has_location();
  }
  location_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), location);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.DatanodeInfoProto.location)
}

// optional uint64 nonDfsUsed = 9;
inline bool DatanodeInfoProto::has_nondfsused() const {
  return (_has_bits_[0] & 0x00000400u) != 0;
}
inline void DatanodeInfoProto::set_has_nondfsused() {
  _has_bits_[0] |= 0x00000400u;
}
inline void DatanodeInfoProto::clear_has_nondfsused() {
  _has_bits_[0] &= ~0x00000400u;
}
inline void DatanodeInfoProto::clear_nondfsused() {
  nondfsused_ = GOOGLE_ULONGLONG(0);
  clear_has_nondfsused();
}
inline ::google::protobuf::uint64 DatanodeInfoProto::nondfsused() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeInfoProto.nonDfsUsed)
  return nondfsused_;
}
inline void DatanodeInfoProto::set_nondfsused(::google::protobuf::uint64 value) {
  set_has_nondfsused();
  nondfsused_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeInfoProto.nonDfsUsed)
}

// optional .hadoop.hdfs.DatanodeInfoProto.AdminState adminState = 10 [default = NORMAL];
inline bool DatanodeInfoProto::has_adminstate() const {
  return (_has_bits_[0] & 0x00000200u) != 0;
}
inline void DatanodeInfoProto::set_has_adminstate() {
  _has_bits_[0] |= 0x00000200u;
}
inline void DatanodeInfoProto::clear_has_adminstate() {
  _has_bits_[0] &= ~0x00000200u;
}
inline void DatanodeInfoProto::clear_adminstate() {
  adminstate_ = 0;
  clear_has_adminstate();
}
inline ::hadoop::hdfs::DatanodeInfoProto_AdminState DatanodeInfoProto::adminstate() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeInfoProto.adminState)
  return static_cast< ::hadoop::hdfs::DatanodeInfoProto_AdminState >(adminstate_);
}
inline void DatanodeInfoProto::set_adminstate(::hadoop::hdfs::DatanodeInfoProto_AdminState value) {
  assert(::hadoop::hdfs::DatanodeInfoProto_AdminState_IsValid(value));
  set_has_adminstate();
  adminstate_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeInfoProto.adminState)
}

// optional uint64 cacheCapacity = 11 [default = 0];
inline bool DatanodeInfoProto::has_cachecapacity() const {
  return (_has_bits_[0] & 0x00000800u) != 0;
}
inline void DatanodeInfoProto::set_has_cachecapacity() {
  _has_bits_[0] |= 0x00000800u;
}
inline void DatanodeInfoProto::clear_has_cachecapacity() {
  _has_bits_[0] &= ~0x00000800u;
}
inline void DatanodeInfoProto::clear_cachecapacity() {
  cachecapacity_ = GOOGLE_ULONGLONG(0);
  clear_has_cachecapacity();
}
inline ::google::protobuf::uint64 DatanodeInfoProto::cachecapacity() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeInfoProto.cacheCapacity)
  return cachecapacity_;
}
inline void DatanodeInfoProto::set_cachecapacity(::google::protobuf::uint64 value) {
  set_has_cachecapacity();
  cachecapacity_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeInfoProto.cacheCapacity)
}

// optional uint64 cacheUsed = 12 [default = 0];
inline bool DatanodeInfoProto::has_cacheused() const {
  return (_has_bits_[0] & 0x00001000u) != 0;
}
inline void DatanodeInfoProto::set_has_cacheused() {
  _has_bits_[0] |= 0x00001000u;
}
inline void DatanodeInfoProto::clear_has_cacheused() {
  _has_bits_[0] &= ~0x00001000u;
}
inline void DatanodeInfoProto::clear_cacheused() {
  cacheused_ = GOOGLE_ULONGLONG(0);
  clear_has_cacheused();
}
inline ::google::protobuf::uint64 DatanodeInfoProto::cacheused() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeInfoProto.cacheUsed)
  return cacheused_;
}
inline void DatanodeInfoProto::set_cacheused(::google::protobuf::uint64 value) {
  set_has_cacheused();
  cacheused_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeInfoProto.cacheUsed)
}

// optional uint64 lastUpdateMonotonic = 13 [default = 0];
inline bool DatanodeInfoProto::has_lastupdatemonotonic() const {
  return (_has_bits_[0] & 0x00002000u) != 0;
}
inline void DatanodeInfoProto::set_has_lastupdatemonotonic() {
  _has_bits_[0] |= 0x00002000u;
}
inline void DatanodeInfoProto::clear_has_lastupdatemonotonic() {
  _has_bits_[0] &= ~0x00002000u;
}
inline void DatanodeInfoProto::clear_lastupdatemonotonic() {
  lastupdatemonotonic_ = GOOGLE_ULONGLONG(0);
  clear_has_lastupdatemonotonic();
}
inline ::google::protobuf::uint64 DatanodeInfoProto::lastupdatemonotonic() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeInfoProto.lastUpdateMonotonic)
  return lastupdatemonotonic_;
}
inline void DatanodeInfoProto::set_lastupdatemonotonic(::google::protobuf::uint64 value) {
  set_has_lastupdatemonotonic();
  lastupdatemonotonic_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeInfoProto.lastUpdateMonotonic)
}

// optional string upgradeDomain = 14;
inline bool DatanodeInfoProto::has_upgradedomain() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void DatanodeInfoProto::set_has_upgradedomain() {
  _has_bits_[0] |= 0x00000002u;
}
inline void DatanodeInfoProto::clear_has_upgradedomain() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void DatanodeInfoProto::clear_upgradedomain() {
  upgradedomain_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_upgradedomain();
}
inline const ::std::string& DatanodeInfoProto::upgradedomain() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeInfoProto.upgradeDomain)
  return upgradedomain_.GetNoArena();
}
inline void DatanodeInfoProto::set_upgradedomain(const ::std::string& value) {
  set_has_upgradedomain();
  upgradedomain_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeInfoProto.upgradeDomain)
}
#if LANG_CXX11
inline void DatanodeInfoProto::set_upgradedomain(::std::string&& value) {
  set_has_upgradedomain();
  upgradedomain_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.DatanodeInfoProto.upgradeDomain)
}
#endif
inline void DatanodeInfoProto::set_upgradedomain(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_upgradedomain();
  upgradedomain_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.DatanodeInfoProto.upgradeDomain)
}
inline void DatanodeInfoProto::set_upgradedomain(const char* value, size_t size) {
  set_has_upgradedomain();
  upgradedomain_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.DatanodeInfoProto.upgradeDomain)
}
inline ::std::string* DatanodeInfoProto::mutable_upgradedomain() {
  set_has_upgradedomain();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.DatanodeInfoProto.upgradeDomain)
  return upgradedomain_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* DatanodeInfoProto::release_upgradedomain() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.DatanodeInfoProto.upgradeDomain)
  if (!has_upgradedomain()) {
    return NULL;
  }
  clear_has_upgradedomain();
  return upgradedomain_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void DatanodeInfoProto::set_allocated_upgradedomain(::std::string* upgradedomain) {
  if (upgradedomain != NULL) {
    set_has_upgradedomain();
  } else {
    clear_has_upgradedomain();
  }
  upgradedomain_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), upgradedomain);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.DatanodeInfoProto.upgradeDomain)
}

// optional uint64 lastBlockReportTime = 15 [default = 0];
inline bool DatanodeInfoProto::has_lastblockreporttime() const {
  return (_has_bits_[0] & 0x00004000u) != 0;
}
inline void DatanodeInfoProto::set_has_lastblockreporttime() {
  _has_bits_[0] |= 0x00004000u;
}
inline void DatanodeInfoProto::clear_has_lastblockreporttime() {
  _has_bits_[0] &= ~0x00004000u;
}
inline void DatanodeInfoProto::clear_lastblockreporttime() {
  lastblockreporttime_ = GOOGLE_ULONGLONG(0);
  clear_has_lastblockreporttime();
}
inline ::google::protobuf::uint64 DatanodeInfoProto::lastblockreporttime() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeInfoProto.lastBlockReportTime)
  return lastblockreporttime_;
}
inline void DatanodeInfoProto::set_lastblockreporttime(::google::protobuf::uint64 value) {
  set_has_lastblockreporttime();
  lastblockreporttime_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeInfoProto.lastBlockReportTime)
}

// optional uint64 lastBlockReportMonotonic = 16 [default = 0];
inline bool DatanodeInfoProto::has_lastblockreportmonotonic() const {
  return (_has_bits_[0] & 0x00008000u) != 0;
}
inline void DatanodeInfoProto::set_has_lastblockreportmonotonic() {
  _has_bits_[0] |= 0x00008000u;
}
inline void DatanodeInfoProto::clear_has_lastblockreportmonotonic() {
  _has_bits_[0] &= ~0x00008000u;
}
inline void DatanodeInfoProto::clear_lastblockreportmonotonic() {
  lastblockreportmonotonic_ = GOOGLE_ULONGLONG(0);
  clear_has_lastblockreportmonotonic();
}
inline ::google::protobuf::uint64 DatanodeInfoProto::lastblockreportmonotonic() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeInfoProto.lastBlockReportMonotonic)
  return lastblockreportmonotonic_;
}
inline void DatanodeInfoProto::set_lastblockreportmonotonic(::google::protobuf::uint64 value) {
  set_has_lastblockreportmonotonic();
  lastblockreportmonotonic_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeInfoProto.lastBlockReportMonotonic)
}

// optional uint32 numBlocks = 17 [default = 0];
inline bool DatanodeInfoProto::has_numblocks() const {
  return (_has_bits_[0] & 0x00010000u) != 0;
}
inline void DatanodeInfoProto::set_has_numblocks() {
  _has_bits_[0] |= 0x00010000u;
}
inline void DatanodeInfoProto::clear_has_numblocks() {
  _has_bits_[0] &= ~0x00010000u;
}
inline void DatanodeInfoProto::clear_numblocks() {
  numblocks_ = 0u;
  clear_has_numblocks();
}
inline ::google::protobuf::uint32 DatanodeInfoProto::numblocks() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeInfoProto.numBlocks)
  return numblocks_;
}
inline void DatanodeInfoProto::set_numblocks(::google::protobuf::uint32 value) {
  set_has_numblocks();
  numblocks_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeInfoProto.numBlocks)
}

// -------------------------------------------------------------------

// DatanodeStorageProto

// required string storageUuid = 1;
inline bool DatanodeStorageProto::has_storageuuid() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void DatanodeStorageProto::set_has_storageuuid() {
  _has_bits_[0] |= 0x00000001u;
}
inline void DatanodeStorageProto::clear_has_storageuuid() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void DatanodeStorageProto::clear_storageuuid() {
  storageuuid_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_storageuuid();
}
inline const ::std::string& DatanodeStorageProto::storageuuid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeStorageProto.storageUuid)
  return storageuuid_.GetNoArena();
}
inline void DatanodeStorageProto::set_storageuuid(const ::std::string& value) {
  set_has_storageuuid();
  storageuuid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeStorageProto.storageUuid)
}
#if LANG_CXX11
inline void DatanodeStorageProto::set_storageuuid(::std::string&& value) {
  set_has_storageuuid();
  storageuuid_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.DatanodeStorageProto.storageUuid)
}
#endif
inline void DatanodeStorageProto::set_storageuuid(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_storageuuid();
  storageuuid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.DatanodeStorageProto.storageUuid)
}
inline void DatanodeStorageProto::set_storageuuid(const char* value, size_t size) {
  set_has_storageuuid();
  storageuuid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.DatanodeStorageProto.storageUuid)
}
inline ::std::string* DatanodeStorageProto::mutable_storageuuid() {
  set_has_storageuuid();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.DatanodeStorageProto.storageUuid)
  return storageuuid_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* DatanodeStorageProto::release_storageuuid() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.DatanodeStorageProto.storageUuid)
  if (!has_storageuuid()) {
    return NULL;
  }
  clear_has_storageuuid();
  return storageuuid_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void DatanodeStorageProto::set_allocated_storageuuid(::std::string* storageuuid) {
  if (storageuuid != NULL) {
    set_has_storageuuid();
  } else {
    clear_has_storageuuid();
  }
  storageuuid_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), storageuuid);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.DatanodeStorageProto.storageUuid)
}

// optional .hadoop.hdfs.DatanodeStorageProto.StorageState state = 2 [default = NORMAL];
inline bool DatanodeStorageProto::has_state() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void DatanodeStorageProto::set_has_state() {
  _has_bits_[0] |= 0x00000002u;
}
inline void DatanodeStorageProto::clear_has_state() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void DatanodeStorageProto::clear_state() {
  state_ = 0;
  clear_has_state();
}
inline ::hadoop::hdfs::DatanodeStorageProto_StorageState DatanodeStorageProto::state() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeStorageProto.state)
  return static_cast< ::hadoop::hdfs::DatanodeStorageProto_StorageState >(state_);
}
inline void DatanodeStorageProto::set_state(::hadoop::hdfs::DatanodeStorageProto_StorageState value) {
  assert(::hadoop::hdfs::DatanodeStorageProto_StorageState_IsValid(value));
  set_has_state();
  state_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeStorageProto.state)
}

// optional .hadoop.hdfs.StorageTypeProto storageType = 3 [default = DISK];
inline bool DatanodeStorageProto::has_storagetype() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void DatanodeStorageProto::set_has_storagetype() {
  _has_bits_[0] |= 0x00000004u;
}
inline void DatanodeStorageProto::clear_has_storagetype() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void DatanodeStorageProto::clear_storagetype() {
  storagetype_ = 1;
  clear_has_storagetype();
}
inline ::hadoop::hdfs::StorageTypeProto DatanodeStorageProto::storagetype() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DatanodeStorageProto.storageType)
  return static_cast< ::hadoop::hdfs::StorageTypeProto >(storagetype_);
}
inline void DatanodeStorageProto::set_storagetype(::hadoop::hdfs::StorageTypeProto value) {
  assert(::hadoop::hdfs::StorageTypeProto_IsValid(value));
  set_has_storagetype();
  storagetype_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DatanodeStorageProto.storageType)
}

// -------------------------------------------------------------------

// StorageReportProto

// required string storageUuid = 1 [deprecated = true];
inline bool StorageReportProto::has_storageuuid() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void StorageReportProto::set_has_storageuuid() {
  _has_bits_[0] |= 0x00000001u;
}
inline void StorageReportProto::clear_has_storageuuid() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void StorageReportProto::clear_storageuuid() {
  storageuuid_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_storageuuid();
}
inline const ::std::string& StorageReportProto::storageuuid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.StorageReportProto.storageUuid)
  return storageuuid_.GetNoArena();
}
inline void StorageReportProto::set_storageuuid(const ::std::string& value) {
  set_has_storageuuid();
  storageuuid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.StorageReportProto.storageUuid)
}
#if LANG_CXX11
inline void StorageReportProto::set_storageuuid(::std::string&& value) {
  set_has_storageuuid();
  storageuuid_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.StorageReportProto.storageUuid)
}
#endif
inline void StorageReportProto::set_storageuuid(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_storageuuid();
  storageuuid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.StorageReportProto.storageUuid)
}
inline void StorageReportProto::set_storageuuid(const char* value, size_t size) {
  set_has_storageuuid();
  storageuuid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.StorageReportProto.storageUuid)
}
inline ::std::string* StorageReportProto::mutable_storageuuid() {
  set_has_storageuuid();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.StorageReportProto.storageUuid)
  return storageuuid_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* StorageReportProto::release_storageuuid() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.StorageReportProto.storageUuid)
  if (!has_storageuuid()) {
    return NULL;
  }
  clear_has_storageuuid();
  return storageuuid_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void StorageReportProto::set_allocated_storageuuid(::std::string* storageuuid) {
  if (storageuuid != NULL) {
    set_has_storageuuid();
  } else {
    clear_has_storageuuid();
  }
  storageuuid_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), storageuuid);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.StorageReportProto.storageUuid)
}

// optional bool failed = 2 [default = false];
inline bool StorageReportProto::has_failed() const {
  return (_has_bits_[0] & 0x00000080u) != 0;
}
inline void StorageReportProto::set_has_failed() {
  _has_bits_[0] |= 0x00000080u;
}
inline void StorageReportProto::clear_has_failed() {
  _has_bits_[0] &= ~0x00000080u;
}
inline void StorageReportProto::clear_failed() {
  failed_ = false;
  clear_has_failed();
}
inline bool StorageReportProto::failed() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.StorageReportProto.failed)
  return failed_;
}
inline void StorageReportProto::set_failed(bool value) {
  set_has_failed();
  failed_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.StorageReportProto.failed)
}

// optional uint64 capacity = 3 [default = 0];
inline bool StorageReportProto::has_capacity() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void StorageReportProto::set_has_capacity() {
  _has_bits_[0] |= 0x00000004u;
}
inline void StorageReportProto::clear_has_capacity() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void StorageReportProto::clear_capacity() {
  capacity_ = GOOGLE_ULONGLONG(0);
  clear_has_capacity();
}
inline ::google::protobuf::uint64 StorageReportProto::capacity() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.StorageReportProto.capacity)
  return capacity_;
}
inline void StorageReportProto::set_capacity(::google::protobuf::uint64 value) {
  set_has_capacity();
  capacity_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.StorageReportProto.capacity)
}

// optional uint64 dfsUsed = 4 [default = 0];
inline bool StorageReportProto::has_dfsused() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void StorageReportProto::set_has_dfsused() {
  _has_bits_[0] |= 0x00000008u;
}
inline void StorageReportProto::clear_has_dfsused() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void StorageReportProto::clear_dfsused() {
  dfsused_ = GOOGLE_ULONGLONG(0);
  clear_has_dfsused();
}
inline ::google::protobuf::uint64 StorageReportProto::dfsused() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.StorageReportProto.dfsUsed)
  return dfsused_;
}
inline void StorageReportProto::set_dfsused(::google::protobuf::uint64 value) {
  set_has_dfsused();
  dfsused_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.StorageReportProto.dfsUsed)
}

// optional uint64 remaining = 5 [default = 0];
inline bool StorageReportProto::has_remaining() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void StorageReportProto::set_has_remaining() {
  _has_bits_[0] |= 0x00000010u;
}
inline void StorageReportProto::clear_has_remaining() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void StorageReportProto::clear_remaining() {
  remaining_ = GOOGLE_ULONGLONG(0);
  clear_has_remaining();
}
inline ::google::protobuf::uint64 StorageReportProto::remaining() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.StorageReportProto.remaining)
  return remaining_;
}
inline void StorageReportProto::set_remaining(::google::protobuf::uint64 value) {
  set_has_remaining();
  remaining_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.StorageReportProto.remaining)
}

// optional uint64 blockPoolUsed = 6 [default = 0];
inline bool StorageReportProto::has_blockpoolused() const {
  return (_has_bits_[0] & 0x00000020u) != 0;
}
inline void StorageReportProto::set_has_blockpoolused() {
  _has_bits_[0] |= 0x00000020u;
}
inline void StorageReportProto::clear_has_blockpoolused() {
  _has_bits_[0] &= ~0x00000020u;
}
inline void StorageReportProto::clear_blockpoolused() {
  blockpoolused_ = GOOGLE_ULONGLONG(0);
  clear_has_blockpoolused();
}
inline ::google::protobuf::uint64 StorageReportProto::blockpoolused() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.StorageReportProto.blockPoolUsed)
  return blockpoolused_;
}
inline void StorageReportProto::set_blockpoolused(::google::protobuf::uint64 value) {
  set_has_blockpoolused();
  blockpoolused_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.StorageReportProto.blockPoolUsed)
}

// optional .hadoop.hdfs.DatanodeStorageProto storage = 7;
inline bool StorageReportProto::has_storage() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void StorageReportProto::set_has_storage() {
  _has_bits_[0] |= 0x00000002u;
}
inline void StorageReportProto::clear_has_storage() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void StorageReportProto::clear_storage() {
  if (storage_ != NULL) storage_->Clear();
  clear_has_storage();
}
inline const ::hadoop::hdfs::DatanodeStorageProto& StorageReportProto::_internal_storage() const {
  return *storage_;
}
inline const ::hadoop::hdfs::DatanodeStorageProto& StorageReportProto::storage() const {
  const ::hadoop::hdfs::DatanodeStorageProto* p = storage_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.StorageReportProto.storage)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::DatanodeStorageProto*>(
      &::hadoop::hdfs::_DatanodeStorageProto_default_instance_);
}
inline ::hadoop::hdfs::DatanodeStorageProto* StorageReportProto::release_storage() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.StorageReportProto.storage)
  clear_has_storage();
  ::hadoop::hdfs::DatanodeStorageProto* temp = storage_;
  storage_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::DatanodeStorageProto* StorageReportProto::mutable_storage() {
  set_has_storage();
  if (storage_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::DatanodeStorageProto>(GetArenaNoVirtual());
    storage_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.StorageReportProto.storage)
  return storage_;
}
inline void StorageReportProto::set_allocated_storage(::hadoop::hdfs::DatanodeStorageProto* storage) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete storage_;
  }
  if (storage) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      storage = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, storage, submessage_arena);
    }
    set_has_storage();
  } else {
    clear_has_storage();
  }
  storage_ = storage;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.StorageReportProto.storage)
}

// optional uint64 nonDfsUsed = 8;
inline bool StorageReportProto::has_nondfsused() const {
  return (_has_bits_[0] & 0x00000040u) != 0;
}
inline void StorageReportProto::set_has_nondfsused() {
  _has_bits_[0] |= 0x00000040u;
}
inline void StorageReportProto::clear_has_nondfsused() {
  _has_bits_[0] &= ~0x00000040u;
}
inline void StorageReportProto::clear_nondfsused() {
  nondfsused_ = GOOGLE_ULONGLONG(0);
  clear_has_nondfsused();
}
inline ::google::protobuf::uint64 StorageReportProto::nondfsused() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.StorageReportProto.nonDfsUsed)
  return nondfsused_;
}
inline void StorageReportProto::set_nondfsused(::google::protobuf::uint64 value) {
  set_has_nondfsused();
  nondfsused_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.StorageReportProto.nonDfsUsed)
}

// -------------------------------------------------------------------

// ContentSummaryProto

// required uint64 length = 1;
inline bool ContentSummaryProto::has_length() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void ContentSummaryProto::set_has_length() {
  _has_bits_[0] |= 0x00000004u;
}
inline void ContentSummaryProto::clear_has_length() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void ContentSummaryProto::clear_length() {
  length_ = GOOGLE_ULONGLONG(0);
  clear_has_length();
}
inline ::google::protobuf::uint64 ContentSummaryProto::length() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ContentSummaryProto.length)
  return length_;
}
inline void ContentSummaryProto::set_length(::google::protobuf::uint64 value) {
  set_has_length();
  length_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ContentSummaryProto.length)
}

// required uint64 fileCount = 2;
inline bool ContentSummaryProto::has_filecount() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void ContentSummaryProto::set_has_filecount() {
  _has_bits_[0] |= 0x00000008u;
}
inline void ContentSummaryProto::clear_has_filecount() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void ContentSummaryProto::clear_filecount() {
  filecount_ = GOOGLE_ULONGLONG(0);
  clear_has_filecount();
}
inline ::google::protobuf::uint64 ContentSummaryProto::filecount() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ContentSummaryProto.fileCount)
  return filecount_;
}
inline void ContentSummaryProto::set_filecount(::google::protobuf::uint64 value) {
  set_has_filecount();
  filecount_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ContentSummaryProto.fileCount)
}

// required uint64 directoryCount = 3;
inline bool ContentSummaryProto::has_directorycount() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void ContentSummaryProto::set_has_directorycount() {
  _has_bits_[0] |= 0x00000010u;
}
inline void ContentSummaryProto::clear_has_directorycount() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void ContentSummaryProto::clear_directorycount() {
  directorycount_ = GOOGLE_ULONGLONG(0);
  clear_has_directorycount();
}
inline ::google::protobuf::uint64 ContentSummaryProto::directorycount() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ContentSummaryProto.directoryCount)
  return directorycount_;
}
inline void ContentSummaryProto::set_directorycount(::google::protobuf::uint64 value) {
  set_has_directorycount();
  directorycount_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ContentSummaryProto.directoryCount)
}

// required uint64 quota = 4;
inline bool ContentSummaryProto::has_quota() const {
  return (_has_bits_[0] & 0x00000020u) != 0;
}
inline void ContentSummaryProto::set_has_quota() {
  _has_bits_[0] |= 0x00000020u;
}
inline void ContentSummaryProto::clear_has_quota() {
  _has_bits_[0] &= ~0x00000020u;
}
inline void ContentSummaryProto::clear_quota() {
  quota_ = GOOGLE_ULONGLONG(0);
  clear_has_quota();
}
inline ::google::protobuf::uint64 ContentSummaryProto::quota() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ContentSummaryProto.quota)
  return quota_;
}
inline void ContentSummaryProto::set_quota(::google::protobuf::uint64 value) {
  set_has_quota();
  quota_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ContentSummaryProto.quota)
}

// required uint64 spaceConsumed = 5;
inline bool ContentSummaryProto::has_spaceconsumed() const {
  return (_has_bits_[0] & 0x00000040u) != 0;
}
inline void ContentSummaryProto::set_has_spaceconsumed() {
  _has_bits_[0] |= 0x00000040u;
}
inline void ContentSummaryProto::clear_has_spaceconsumed() {
  _has_bits_[0] &= ~0x00000040u;
}
inline void ContentSummaryProto::clear_spaceconsumed() {
  spaceconsumed_ = GOOGLE_ULONGLONG(0);
  clear_has_spaceconsumed();
}
inline ::google::protobuf::uint64 ContentSummaryProto::spaceconsumed() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ContentSummaryProto.spaceConsumed)
  return spaceconsumed_;
}
inline void ContentSummaryProto::set_spaceconsumed(::google::protobuf::uint64 value) {
  set_has_spaceconsumed();
  spaceconsumed_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ContentSummaryProto.spaceConsumed)
}

// required uint64 spaceQuota = 6;
inline bool ContentSummaryProto::has_spacequota() const {
  return (_has_bits_[0] & 0x00000080u) != 0;
}
inline void ContentSummaryProto::set_has_spacequota() {
  _has_bits_[0] |= 0x00000080u;
}
inline void ContentSummaryProto::clear_has_spacequota() {
  _has_bits_[0] &= ~0x00000080u;
}
inline void ContentSummaryProto::clear_spacequota() {
  spacequota_ = GOOGLE_ULONGLONG(0);
  clear_has_spacequota();
}
inline ::google::protobuf::uint64 ContentSummaryProto::spacequota() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ContentSummaryProto.spaceQuota)
  return spacequota_;
}
inline void ContentSummaryProto::set_spacequota(::google::protobuf::uint64 value) {
  set_has_spacequota();
  spacequota_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ContentSummaryProto.spaceQuota)
}

// optional .hadoop.hdfs.StorageTypeQuotaInfosProto typeQuotaInfos = 7;
inline bool ContentSummaryProto::has_typequotainfos() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ContentSummaryProto::set_has_typequotainfos() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ContentSummaryProto::clear_has_typequotainfos() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ContentSummaryProto::clear_typequotainfos() {
  if (typequotainfos_ != NULL) typequotainfos_->Clear();
  clear_has_typequotainfos();
}
inline const ::hadoop::hdfs::StorageTypeQuotaInfosProto& ContentSummaryProto::_internal_typequotainfos() const {
  return *typequotainfos_;
}
inline const ::hadoop::hdfs::StorageTypeQuotaInfosProto& ContentSummaryProto::typequotainfos() const {
  const ::hadoop::hdfs::StorageTypeQuotaInfosProto* p = typequotainfos_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ContentSummaryProto.typeQuotaInfos)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::StorageTypeQuotaInfosProto*>(
      &::hadoop::hdfs::_StorageTypeQuotaInfosProto_default_instance_);
}
inline ::hadoop::hdfs::StorageTypeQuotaInfosProto* ContentSummaryProto::release_typequotainfos() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.ContentSummaryProto.typeQuotaInfos)
  clear_has_typequotainfos();
  ::hadoop::hdfs::StorageTypeQuotaInfosProto* temp = typequotainfos_;
  typequotainfos_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::StorageTypeQuotaInfosProto* ContentSummaryProto::mutable_typequotainfos() {
  set_has_typequotainfos();
  if (typequotainfos_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::StorageTypeQuotaInfosProto>(GetArenaNoVirtual());
    typequotainfos_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.ContentSummaryProto.typeQuotaInfos)
  return typequotainfos_;
}
inline void ContentSummaryProto::set_allocated_typequotainfos(::hadoop::hdfs::StorageTypeQuotaInfosProto* typequotainfos) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete typequotainfos_;
  }
  if (typequotainfos) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      typequotainfos = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, typequotainfos, submessage_arena);
    }
    set_has_typequotainfos();
  } else {
    clear_has_typequotainfos();
  }
  typequotainfos_ = typequotainfos;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.ContentSummaryProto.typeQuotaInfos)
}

// optional uint64 snapshotLength = 8;
inline bool ContentSummaryProto::has_snapshotlength() const {
  return (_has_bits_[0] & 0x00000100u) != 0;
}
inline void ContentSummaryProto::set_has_snapshotlength() {
  _has_bits_[0] |= 0x00000100u;
}
inline void ContentSummaryProto::clear_has_snapshotlength() {
  _has_bits_[0] &= ~0x00000100u;
}
inline void ContentSummaryProto::clear_snapshotlength() {
  snapshotlength_ = GOOGLE_ULONGLONG(0);
  clear_has_snapshotlength();
}
inline ::google::protobuf::uint64 ContentSummaryProto::snapshotlength() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ContentSummaryProto.snapshotLength)
  return snapshotlength_;
}
inline void ContentSummaryProto::set_snapshotlength(::google::protobuf::uint64 value) {
  set_has_snapshotlength();
  snapshotlength_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ContentSummaryProto.snapshotLength)
}

// optional uint64 snapshotFileCount = 9;
inline bool ContentSummaryProto::has_snapshotfilecount() const {
  return (_has_bits_[0] & 0x00000200u) != 0;
}
inline void ContentSummaryProto::set_has_snapshotfilecount() {
  _has_bits_[0] |= 0x00000200u;
}
inline void ContentSummaryProto::clear_has_snapshotfilecount() {
  _has_bits_[0] &= ~0x00000200u;
}
inline void ContentSummaryProto::clear_snapshotfilecount() {
  snapshotfilecount_ = GOOGLE_ULONGLONG(0);
  clear_has_snapshotfilecount();
}
inline ::google::protobuf::uint64 ContentSummaryProto::snapshotfilecount() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ContentSummaryProto.snapshotFileCount)
  return snapshotfilecount_;
}
inline void ContentSummaryProto::set_snapshotfilecount(::google::protobuf::uint64 value) {
  set_has_snapshotfilecount();
  snapshotfilecount_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ContentSummaryProto.snapshotFileCount)
}

// optional uint64 snapshotDirectoryCount = 10;
inline bool ContentSummaryProto::has_snapshotdirectorycount() const {
  return (_has_bits_[0] & 0x00000400u) != 0;
}
inline void ContentSummaryProto::set_has_snapshotdirectorycount() {
  _has_bits_[0] |= 0x00000400u;
}
inline void ContentSummaryProto::clear_has_snapshotdirectorycount() {
  _has_bits_[0] &= ~0x00000400u;
}
inline void ContentSummaryProto::clear_snapshotdirectorycount() {
  snapshotdirectorycount_ = GOOGLE_ULONGLONG(0);
  clear_has_snapshotdirectorycount();
}
inline ::google::protobuf::uint64 ContentSummaryProto::snapshotdirectorycount() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ContentSummaryProto.snapshotDirectoryCount)
  return snapshotdirectorycount_;
}
inline void ContentSummaryProto::set_snapshotdirectorycount(::google::protobuf::uint64 value) {
  set_has_snapshotdirectorycount();
  snapshotdirectorycount_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ContentSummaryProto.snapshotDirectoryCount)
}

// optional uint64 snapshotSpaceConsumed = 11;
inline bool ContentSummaryProto::has_snapshotspaceconsumed() const {
  return (_has_bits_[0] & 0x00000800u) != 0;
}
inline void ContentSummaryProto::set_has_snapshotspaceconsumed() {
  _has_bits_[0] |= 0x00000800u;
}
inline void ContentSummaryProto::clear_has_snapshotspaceconsumed() {
  _has_bits_[0] &= ~0x00000800u;
}
inline void ContentSummaryProto::clear_snapshotspaceconsumed() {
  snapshotspaceconsumed_ = GOOGLE_ULONGLONG(0);
  clear_has_snapshotspaceconsumed();
}
inline ::google::protobuf::uint64 ContentSummaryProto::snapshotspaceconsumed() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ContentSummaryProto.snapshotSpaceConsumed)
  return snapshotspaceconsumed_;
}
inline void ContentSummaryProto::set_snapshotspaceconsumed(::google::protobuf::uint64 value) {
  set_has_snapshotspaceconsumed();
  snapshotspaceconsumed_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ContentSummaryProto.snapshotSpaceConsumed)
}

// optional string erasureCodingPolicy = 12;
inline bool ContentSummaryProto::has_erasurecodingpolicy() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ContentSummaryProto::set_has_erasurecodingpolicy() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ContentSummaryProto::clear_has_erasurecodingpolicy() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ContentSummaryProto::clear_erasurecodingpolicy() {
  erasurecodingpolicy_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_erasurecodingpolicy();
}
inline const ::std::string& ContentSummaryProto::erasurecodingpolicy() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ContentSummaryProto.erasureCodingPolicy)
  return erasurecodingpolicy_.GetNoArena();
}
inline void ContentSummaryProto::set_erasurecodingpolicy(const ::std::string& value) {
  set_has_erasurecodingpolicy();
  erasurecodingpolicy_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ContentSummaryProto.erasureCodingPolicy)
}
#if LANG_CXX11
inline void ContentSummaryProto::set_erasurecodingpolicy(::std::string&& value) {
  set_has_erasurecodingpolicy();
  erasurecodingpolicy_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.ContentSummaryProto.erasureCodingPolicy)
}
#endif
inline void ContentSummaryProto::set_erasurecodingpolicy(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_erasurecodingpolicy();
  erasurecodingpolicy_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.ContentSummaryProto.erasureCodingPolicy)
}
inline void ContentSummaryProto::set_erasurecodingpolicy(const char* value, size_t size) {
  set_has_erasurecodingpolicy();
  erasurecodingpolicy_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.ContentSummaryProto.erasureCodingPolicy)
}
inline ::std::string* ContentSummaryProto::mutable_erasurecodingpolicy() {
  set_has_erasurecodingpolicy();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.ContentSummaryProto.erasureCodingPolicy)
  return erasurecodingpolicy_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* ContentSummaryProto::release_erasurecodingpolicy() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.ContentSummaryProto.erasureCodingPolicy)
  if (!has_erasurecodingpolicy()) {
    return NULL;
  }
  clear_has_erasurecodingpolicy();
  return erasurecodingpolicy_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void ContentSummaryProto::set_allocated_erasurecodingpolicy(::std::string* erasurecodingpolicy) {
  if (erasurecodingpolicy != NULL) {
    set_has_erasurecodingpolicy();
  } else {
    clear_has_erasurecodingpolicy();
  }
  erasurecodingpolicy_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), erasurecodingpolicy);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.ContentSummaryProto.erasureCodingPolicy)
}

// -------------------------------------------------------------------

// QuotaUsageProto

// required uint64 fileAndDirectoryCount = 1;
inline bool QuotaUsageProto::has_fileanddirectorycount() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void QuotaUsageProto::set_has_fileanddirectorycount() {
  _has_bits_[0] |= 0x00000002u;
}
inline void QuotaUsageProto::clear_has_fileanddirectorycount() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void QuotaUsageProto::clear_fileanddirectorycount() {
  fileanddirectorycount_ = GOOGLE_ULONGLONG(0);
  clear_has_fileanddirectorycount();
}
inline ::google::protobuf::uint64 QuotaUsageProto::fileanddirectorycount() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.QuotaUsageProto.fileAndDirectoryCount)
  return fileanddirectorycount_;
}
inline void QuotaUsageProto::set_fileanddirectorycount(::google::protobuf::uint64 value) {
  set_has_fileanddirectorycount();
  fileanddirectorycount_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.QuotaUsageProto.fileAndDirectoryCount)
}

// required uint64 quota = 2;
inline bool QuotaUsageProto::has_quota() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void QuotaUsageProto::set_has_quota() {
  _has_bits_[0] |= 0x00000004u;
}
inline void QuotaUsageProto::clear_has_quota() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void QuotaUsageProto::clear_quota() {
  quota_ = GOOGLE_ULONGLONG(0);
  clear_has_quota();
}
inline ::google::protobuf::uint64 QuotaUsageProto::quota() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.QuotaUsageProto.quota)
  return quota_;
}
inline void QuotaUsageProto::set_quota(::google::protobuf::uint64 value) {
  set_has_quota();
  quota_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.QuotaUsageProto.quota)
}

// required uint64 spaceConsumed = 3;
inline bool QuotaUsageProto::has_spaceconsumed() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void QuotaUsageProto::set_has_spaceconsumed() {
  _has_bits_[0] |= 0x00000008u;
}
inline void QuotaUsageProto::clear_has_spaceconsumed() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void QuotaUsageProto::clear_spaceconsumed() {
  spaceconsumed_ = GOOGLE_ULONGLONG(0);
  clear_has_spaceconsumed();
}
inline ::google::protobuf::uint64 QuotaUsageProto::spaceconsumed() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.QuotaUsageProto.spaceConsumed)
  return spaceconsumed_;
}
inline void QuotaUsageProto::set_spaceconsumed(::google::protobuf::uint64 value) {
  set_has_spaceconsumed();
  spaceconsumed_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.QuotaUsageProto.spaceConsumed)
}

// required uint64 spaceQuota = 4;
inline bool QuotaUsageProto::has_spacequota() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void QuotaUsageProto::set_has_spacequota() {
  _has_bits_[0] |= 0x00000010u;
}
inline void QuotaUsageProto::clear_has_spacequota() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void QuotaUsageProto::clear_spacequota() {
  spacequota_ = GOOGLE_ULONGLONG(0);
  clear_has_spacequota();
}
inline ::google::protobuf::uint64 QuotaUsageProto::spacequota() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.QuotaUsageProto.spaceQuota)
  return spacequota_;
}
inline void QuotaUsageProto::set_spacequota(::google::protobuf::uint64 value) {
  set_has_spacequota();
  spacequota_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.QuotaUsageProto.spaceQuota)
}

// optional .hadoop.hdfs.StorageTypeQuotaInfosProto typeQuotaInfos = 5;
inline bool QuotaUsageProto::has_typequotainfos() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void QuotaUsageProto::set_has_typequotainfos() {
  _has_bits_[0] |= 0x00000001u;
}
inline void QuotaUsageProto::clear_has_typequotainfos() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void QuotaUsageProto::clear_typequotainfos() {
  if (typequotainfos_ != NULL) typequotainfos_->Clear();
  clear_has_typequotainfos();
}
inline const ::hadoop::hdfs::StorageTypeQuotaInfosProto& QuotaUsageProto::_internal_typequotainfos() const {
  return *typequotainfos_;
}
inline const ::hadoop::hdfs::StorageTypeQuotaInfosProto& QuotaUsageProto::typequotainfos() const {
  const ::hadoop::hdfs::StorageTypeQuotaInfosProto* p = typequotainfos_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.QuotaUsageProto.typeQuotaInfos)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::StorageTypeQuotaInfosProto*>(
      &::hadoop::hdfs::_StorageTypeQuotaInfosProto_default_instance_);
}
inline ::hadoop::hdfs::StorageTypeQuotaInfosProto* QuotaUsageProto::release_typequotainfos() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.QuotaUsageProto.typeQuotaInfos)
  clear_has_typequotainfos();
  ::hadoop::hdfs::StorageTypeQuotaInfosProto* temp = typequotainfos_;
  typequotainfos_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::StorageTypeQuotaInfosProto* QuotaUsageProto::mutable_typequotainfos() {
  set_has_typequotainfos();
  if (typequotainfos_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::StorageTypeQuotaInfosProto>(GetArenaNoVirtual());
    typequotainfos_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.QuotaUsageProto.typeQuotaInfos)
  return typequotainfos_;
}
inline void QuotaUsageProto::set_allocated_typequotainfos(::hadoop::hdfs::StorageTypeQuotaInfosProto* typequotainfos) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete typequotainfos_;
  }
  if (typequotainfos) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      typequotainfos = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, typequotainfos, submessage_arena);
    }
    set_has_typequotainfos();
  } else {
    clear_has_typequotainfos();
  }
  typequotainfos_ = typequotainfos;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.QuotaUsageProto.typeQuotaInfos)
}

// -------------------------------------------------------------------

// StorageTypeQuotaInfosProto

// repeated .hadoop.hdfs.StorageTypeQuotaInfoProto typeQuotaInfo = 1;
inline int StorageTypeQuotaInfosProto::typequotainfo_size() const {
  return typequotainfo_.size();
}
inline void StorageTypeQuotaInfosProto::clear_typequotainfo() {
  typequotainfo_.Clear();
}
inline ::hadoop::hdfs::StorageTypeQuotaInfoProto* StorageTypeQuotaInfosProto::mutable_typequotainfo(int index) {
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.StorageTypeQuotaInfosProto.typeQuotaInfo)
  return typequotainfo_.Mutable(index);
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::StorageTypeQuotaInfoProto >*
StorageTypeQuotaInfosProto::mutable_typequotainfo() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.StorageTypeQuotaInfosProto.typeQuotaInfo)
  return &typequotainfo_;
}
inline const ::hadoop::hdfs::StorageTypeQuotaInfoProto& StorageTypeQuotaInfosProto::typequotainfo(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.StorageTypeQuotaInfosProto.typeQuotaInfo)
  return typequotainfo_.Get(index);
}
inline ::hadoop::hdfs::StorageTypeQuotaInfoProto* StorageTypeQuotaInfosProto::add_typequotainfo() {
  // @@protoc_insertion_point(field_add:hadoop.hdfs.StorageTypeQuotaInfosProto.typeQuotaInfo)
  return typequotainfo_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::StorageTypeQuotaInfoProto >&
StorageTypeQuotaInfosProto::typequotainfo() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.StorageTypeQuotaInfosProto.typeQuotaInfo)
  return typequotainfo_;
}

// -------------------------------------------------------------------

// StorageTypeQuotaInfoProto

// optional .hadoop.hdfs.StorageTypeProto type = 1 [default = DISK];
inline bool StorageTypeQuotaInfoProto::has_type() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void StorageTypeQuotaInfoProto::set_has_type() {
  _has_bits_[0] |= 0x00000004u;
}
inline void StorageTypeQuotaInfoProto::clear_has_type() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void StorageTypeQuotaInfoProto::clear_type() {
  type_ = 1;
  clear_has_type();
}
inline ::hadoop::hdfs::StorageTypeProto StorageTypeQuotaInfoProto::type() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.StorageTypeQuotaInfoProto.type)
  return static_cast< ::hadoop::hdfs::StorageTypeProto >(type_);
}
inline void StorageTypeQuotaInfoProto::set_type(::hadoop::hdfs::StorageTypeProto value) {
  assert(::hadoop::hdfs::StorageTypeProto_IsValid(value));
  set_has_type();
  type_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.StorageTypeQuotaInfoProto.type)
}

// required uint64 quota = 2;
inline bool StorageTypeQuotaInfoProto::has_quota() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void StorageTypeQuotaInfoProto::set_has_quota() {
  _has_bits_[0] |= 0x00000001u;
}
inline void StorageTypeQuotaInfoProto::clear_has_quota() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void StorageTypeQuotaInfoProto::clear_quota() {
  quota_ = GOOGLE_ULONGLONG(0);
  clear_has_quota();
}
inline ::google::protobuf::uint64 StorageTypeQuotaInfoProto::quota() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.StorageTypeQuotaInfoProto.quota)
  return quota_;
}
inline void StorageTypeQuotaInfoProto::set_quota(::google::protobuf::uint64 value) {
  set_has_quota();
  quota_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.StorageTypeQuotaInfoProto.quota)
}

// required uint64 consumed = 3;
inline bool StorageTypeQuotaInfoProto::has_consumed() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void StorageTypeQuotaInfoProto::set_has_consumed() {
  _has_bits_[0] |= 0x00000002u;
}
inline void StorageTypeQuotaInfoProto::clear_has_consumed() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void StorageTypeQuotaInfoProto::clear_consumed() {
  consumed_ = GOOGLE_ULONGLONG(0);
  clear_has_consumed();
}
inline ::google::protobuf::uint64 StorageTypeQuotaInfoProto::consumed() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.StorageTypeQuotaInfoProto.consumed)
  return consumed_;
}
inline void StorageTypeQuotaInfoProto::set_consumed(::google::protobuf::uint64 value) {
  set_has_consumed();
  consumed_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.StorageTypeQuotaInfoProto.consumed)
}

// -------------------------------------------------------------------

// CorruptFileBlocksProto

// repeated string files = 1;
inline int CorruptFileBlocksProto::files_size() const {
  return files_.size();
}
inline void CorruptFileBlocksProto::clear_files() {
  files_.Clear();
}
inline const ::std::string& CorruptFileBlocksProto::files(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.CorruptFileBlocksProto.files)
  return files_.Get(index);
}
inline ::std::string* CorruptFileBlocksProto::mutable_files(int index) {
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.CorruptFileBlocksProto.files)
  return files_.Mutable(index);
}
inline void CorruptFileBlocksProto::set_files(int index, const ::std::string& value) {
  // @@protoc_insertion_point(field_set:hadoop.hdfs.CorruptFileBlocksProto.files)
  files_.Mutable(index)->assign(value);
}
#if LANG_CXX11
inline void CorruptFileBlocksProto::set_files(int index, ::std::string&& value) {
  // @@protoc_insertion_point(field_set:hadoop.hdfs.CorruptFileBlocksProto.files)
  files_.Mutable(index)->assign(std::move(value));
}
#endif
inline void CorruptFileBlocksProto::set_files(int index, const char* value) {
  GOOGLE_DCHECK(value != NULL);
  files_.Mutable(index)->assign(value);
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.CorruptFileBlocksProto.files)
}
inline void CorruptFileBlocksProto::set_files(int index, const char* value, size_t size) {
  files_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.CorruptFileBlocksProto.files)
}
inline ::std::string* CorruptFileBlocksProto::add_files() {
  // @@protoc_insertion_point(field_add_mutable:hadoop.hdfs.CorruptFileBlocksProto.files)
  return files_.Add();
}
inline void CorruptFileBlocksProto::add_files(const ::std::string& value) {
  files_.Add()->assign(value);
  // @@protoc_insertion_point(field_add:hadoop.hdfs.CorruptFileBlocksProto.files)
}
#if LANG_CXX11
inline void CorruptFileBlocksProto::add_files(::std::string&& value) {
  files_.Add(std::move(value));
  // @@protoc_insertion_point(field_add:hadoop.hdfs.CorruptFileBlocksProto.files)
}
#endif
inline void CorruptFileBlocksProto::add_files(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  files_.Add()->assign(value);
  // @@protoc_insertion_point(field_add_char:hadoop.hdfs.CorruptFileBlocksProto.files)
}
inline void CorruptFileBlocksProto::add_files(const char* value, size_t size) {
  files_.Add()->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_add_pointer:hadoop.hdfs.CorruptFileBlocksProto.files)
}
inline const ::google::protobuf::RepeatedPtrField< ::std::string>&
CorruptFileBlocksProto::files() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.CorruptFileBlocksProto.files)
  return files_;
}
inline ::google::protobuf::RepeatedPtrField< ::std::string>*
CorruptFileBlocksProto::mutable_files() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.CorruptFileBlocksProto.files)
  return &files_;
}

// required string cookie = 2;
inline bool CorruptFileBlocksProto::has_cookie() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void CorruptFileBlocksProto::set_has_cookie() {
  _has_bits_[0] |= 0x00000001u;
}
inline void CorruptFileBlocksProto::clear_has_cookie() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void CorruptFileBlocksProto::clear_cookie() {
  cookie_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_cookie();
}
inline const ::std::string& CorruptFileBlocksProto::cookie() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.CorruptFileBlocksProto.cookie)
  return cookie_.GetNoArena();
}
inline void CorruptFileBlocksProto::set_cookie(const ::std::string& value) {
  set_has_cookie();
  cookie_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.CorruptFileBlocksProto.cookie)
}
#if LANG_CXX11
inline void CorruptFileBlocksProto::set_cookie(::std::string&& value) {
  set_has_cookie();
  cookie_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.CorruptFileBlocksProto.cookie)
}
#endif
inline void CorruptFileBlocksProto::set_cookie(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_cookie();
  cookie_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.CorruptFileBlocksProto.cookie)
}
inline void CorruptFileBlocksProto::set_cookie(const char* value, size_t size) {
  set_has_cookie();
  cookie_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.CorruptFileBlocksProto.cookie)
}
inline ::std::string* CorruptFileBlocksProto::mutable_cookie() {
  set_has_cookie();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.CorruptFileBlocksProto.cookie)
  return cookie_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* CorruptFileBlocksProto::release_cookie() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.CorruptFileBlocksProto.cookie)
  if (!has_cookie()) {
    return NULL;
  }
  clear_has_cookie();
  return cookie_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void CorruptFileBlocksProto::set_allocated_cookie(::std::string* cookie) {
  if (cookie != NULL) {
    set_has_cookie();
  } else {
    clear_has_cookie();
  }
  cookie_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), cookie);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.CorruptFileBlocksProto.cookie)
}

// -------------------------------------------------------------------

// StorageTypesProto

// repeated .hadoop.hdfs.StorageTypeProto storageTypes = 1;
inline int StorageTypesProto::storagetypes_size() const {
  return storagetypes_.size();
}
inline void StorageTypesProto::clear_storagetypes() {
  storagetypes_.Clear();
}
inline ::hadoop::hdfs::StorageTypeProto StorageTypesProto::storagetypes(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.StorageTypesProto.storageTypes)
  return static_cast< ::hadoop::hdfs::StorageTypeProto >(storagetypes_.Get(index));
}
inline void StorageTypesProto::set_storagetypes(int index, ::hadoop::hdfs::StorageTypeProto value) {
  assert(::hadoop::hdfs::StorageTypeProto_IsValid(value));
  storagetypes_.Set(index, value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.StorageTypesProto.storageTypes)
}
inline void StorageTypesProto::add_storagetypes(::hadoop::hdfs::StorageTypeProto value) {
  assert(::hadoop::hdfs::StorageTypeProto_IsValid(value));
  storagetypes_.Add(value);
  // @@protoc_insertion_point(field_add:hadoop.hdfs.StorageTypesProto.storageTypes)
}
inline const ::google::protobuf::RepeatedField<int>&
StorageTypesProto::storagetypes() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.StorageTypesProto.storageTypes)
  return storagetypes_;
}
inline ::google::protobuf::RepeatedField<int>*
StorageTypesProto::mutable_storagetypes() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.StorageTypesProto.storageTypes)
  return &storagetypes_;
}

// -------------------------------------------------------------------

// BlockStoragePolicyProto

// required uint32 policyId = 1;
inline bool BlockStoragePolicyProto::has_policyid() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void BlockStoragePolicyProto::set_has_policyid() {
  _has_bits_[0] |= 0x00000010u;
}
inline void BlockStoragePolicyProto::clear_has_policyid() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void BlockStoragePolicyProto::clear_policyid() {
  policyid_ = 0u;
  clear_has_policyid();
}
inline ::google::protobuf::uint32 BlockStoragePolicyProto::policyid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockStoragePolicyProto.policyId)
  return policyid_;
}
inline void BlockStoragePolicyProto::set_policyid(::google::protobuf::uint32 value) {
  set_has_policyid();
  policyid_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockStoragePolicyProto.policyId)
}

// required string name = 2;
inline bool BlockStoragePolicyProto::has_name() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void BlockStoragePolicyProto::set_has_name() {
  _has_bits_[0] |= 0x00000001u;
}
inline void BlockStoragePolicyProto::clear_has_name() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void BlockStoragePolicyProto::clear_name() {
  name_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_name();
}
inline const ::std::string& BlockStoragePolicyProto::name() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockStoragePolicyProto.name)
  return name_.GetNoArena();
}
inline void BlockStoragePolicyProto::set_name(const ::std::string& value) {
  set_has_name();
  name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockStoragePolicyProto.name)
}
#if LANG_CXX11
inline void BlockStoragePolicyProto::set_name(::std::string&& value) {
  set_has_name();
  name_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.BlockStoragePolicyProto.name)
}
#endif
inline void BlockStoragePolicyProto::set_name(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_name();
  name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.BlockStoragePolicyProto.name)
}
inline void BlockStoragePolicyProto::set_name(const char* value, size_t size) {
  set_has_name();
  name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.BlockStoragePolicyProto.name)
}
inline ::std::string* BlockStoragePolicyProto::mutable_name() {
  set_has_name();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.BlockStoragePolicyProto.name)
  return name_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* BlockStoragePolicyProto::release_name() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.BlockStoragePolicyProto.name)
  if (!has_name()) {
    return NULL;
  }
  clear_has_name();
  return name_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void BlockStoragePolicyProto::set_allocated_name(::std::string* name) {
  if (name != NULL) {
    set_has_name();
  } else {
    clear_has_name();
  }
  name_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), name);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.BlockStoragePolicyProto.name)
}

// required .hadoop.hdfs.StorageTypesProto creationPolicy = 3;
inline bool BlockStoragePolicyProto::has_creationpolicy() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void BlockStoragePolicyProto::set_has_creationpolicy() {
  _has_bits_[0] |= 0x00000002u;
}
inline void BlockStoragePolicyProto::clear_has_creationpolicy() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void BlockStoragePolicyProto::clear_creationpolicy() {
  if (creationpolicy_ != NULL) creationpolicy_->Clear();
  clear_has_creationpolicy();
}
inline const ::hadoop::hdfs::StorageTypesProto& BlockStoragePolicyProto::_internal_creationpolicy() const {
  return *creationpolicy_;
}
inline const ::hadoop::hdfs::StorageTypesProto& BlockStoragePolicyProto::creationpolicy() const {
  const ::hadoop::hdfs::StorageTypesProto* p = creationpolicy_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockStoragePolicyProto.creationPolicy)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::StorageTypesProto*>(
      &::hadoop::hdfs::_StorageTypesProto_default_instance_);
}
inline ::hadoop::hdfs::StorageTypesProto* BlockStoragePolicyProto::release_creationpolicy() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.BlockStoragePolicyProto.creationPolicy)
  clear_has_creationpolicy();
  ::hadoop::hdfs::StorageTypesProto* temp = creationpolicy_;
  creationpolicy_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::StorageTypesProto* BlockStoragePolicyProto::mutable_creationpolicy() {
  set_has_creationpolicy();
  if (creationpolicy_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::StorageTypesProto>(GetArenaNoVirtual());
    creationpolicy_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.BlockStoragePolicyProto.creationPolicy)
  return creationpolicy_;
}
inline void BlockStoragePolicyProto::set_allocated_creationpolicy(::hadoop::hdfs::StorageTypesProto* creationpolicy) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete creationpolicy_;
  }
  if (creationpolicy) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      creationpolicy = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, creationpolicy, submessage_arena);
    }
    set_has_creationpolicy();
  } else {
    clear_has_creationpolicy();
  }
  creationpolicy_ = creationpolicy;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.BlockStoragePolicyProto.creationPolicy)
}

// optional .hadoop.hdfs.StorageTypesProto creationFallbackPolicy = 4;
inline bool BlockStoragePolicyProto::has_creationfallbackpolicy() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void BlockStoragePolicyProto::set_has_creationfallbackpolicy() {
  _has_bits_[0] |= 0x00000004u;
}
inline void BlockStoragePolicyProto::clear_has_creationfallbackpolicy() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void BlockStoragePolicyProto::clear_creationfallbackpolicy() {
  if (creationfallbackpolicy_ != NULL) creationfallbackpolicy_->Clear();
  clear_has_creationfallbackpolicy();
}
inline const ::hadoop::hdfs::StorageTypesProto& BlockStoragePolicyProto::_internal_creationfallbackpolicy() const {
  return *creationfallbackpolicy_;
}
inline const ::hadoop::hdfs::StorageTypesProto& BlockStoragePolicyProto::creationfallbackpolicy() const {
  const ::hadoop::hdfs::StorageTypesProto* p = creationfallbackpolicy_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockStoragePolicyProto.creationFallbackPolicy)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::StorageTypesProto*>(
      &::hadoop::hdfs::_StorageTypesProto_default_instance_);
}
inline ::hadoop::hdfs::StorageTypesProto* BlockStoragePolicyProto::release_creationfallbackpolicy() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.BlockStoragePolicyProto.creationFallbackPolicy)
  clear_has_creationfallbackpolicy();
  ::hadoop::hdfs::StorageTypesProto* temp = creationfallbackpolicy_;
  creationfallbackpolicy_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::StorageTypesProto* BlockStoragePolicyProto::mutable_creationfallbackpolicy() {
  set_has_creationfallbackpolicy();
  if (creationfallbackpolicy_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::StorageTypesProto>(GetArenaNoVirtual());
    creationfallbackpolicy_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.BlockStoragePolicyProto.creationFallbackPolicy)
  return creationfallbackpolicy_;
}
inline void BlockStoragePolicyProto::set_allocated_creationfallbackpolicy(::hadoop::hdfs::StorageTypesProto* creationfallbackpolicy) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete creationfallbackpolicy_;
  }
  if (creationfallbackpolicy) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      creationfallbackpolicy = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, creationfallbackpolicy, submessage_arena);
    }
    set_has_creationfallbackpolicy();
  } else {
    clear_has_creationfallbackpolicy();
  }
  creationfallbackpolicy_ = creationfallbackpolicy;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.BlockStoragePolicyProto.creationFallbackPolicy)
}

// optional .hadoop.hdfs.StorageTypesProto replicationFallbackPolicy = 5;
inline bool BlockStoragePolicyProto::has_replicationfallbackpolicy() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void BlockStoragePolicyProto::set_has_replicationfallbackpolicy() {
  _has_bits_[0] |= 0x00000008u;
}
inline void BlockStoragePolicyProto::clear_has_replicationfallbackpolicy() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void BlockStoragePolicyProto::clear_replicationfallbackpolicy() {
  if (replicationfallbackpolicy_ != NULL) replicationfallbackpolicy_->Clear();
  clear_has_replicationfallbackpolicy();
}
inline const ::hadoop::hdfs::StorageTypesProto& BlockStoragePolicyProto::_internal_replicationfallbackpolicy() const {
  return *replicationfallbackpolicy_;
}
inline const ::hadoop::hdfs::StorageTypesProto& BlockStoragePolicyProto::replicationfallbackpolicy() const {
  const ::hadoop::hdfs::StorageTypesProto* p = replicationfallbackpolicy_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockStoragePolicyProto.replicationFallbackPolicy)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::StorageTypesProto*>(
      &::hadoop::hdfs::_StorageTypesProto_default_instance_);
}
inline ::hadoop::hdfs::StorageTypesProto* BlockStoragePolicyProto::release_replicationfallbackpolicy() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.BlockStoragePolicyProto.replicationFallbackPolicy)
  clear_has_replicationfallbackpolicy();
  ::hadoop::hdfs::StorageTypesProto* temp = replicationfallbackpolicy_;
  replicationfallbackpolicy_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::StorageTypesProto* BlockStoragePolicyProto::mutable_replicationfallbackpolicy() {
  set_has_replicationfallbackpolicy();
  if (replicationfallbackpolicy_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::StorageTypesProto>(GetArenaNoVirtual());
    replicationfallbackpolicy_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.BlockStoragePolicyProto.replicationFallbackPolicy)
  return replicationfallbackpolicy_;
}
inline void BlockStoragePolicyProto::set_allocated_replicationfallbackpolicy(::hadoop::hdfs::StorageTypesProto* replicationfallbackpolicy) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete replicationfallbackpolicy_;
  }
  if (replicationfallbackpolicy) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      replicationfallbackpolicy = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, replicationfallbackpolicy, submessage_arena);
    }
    set_has_replicationfallbackpolicy();
  } else {
    clear_has_replicationfallbackpolicy();
  }
  replicationfallbackpolicy_ = replicationfallbackpolicy;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.BlockStoragePolicyProto.replicationFallbackPolicy)
}

// -------------------------------------------------------------------

// LocatedBlockProto

// required .hadoop.hdfs.ExtendedBlockProto b = 1;
inline bool LocatedBlockProto::has_b() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void LocatedBlockProto::set_has_b() {
  _has_bits_[0] |= 0x00000002u;
}
inline void LocatedBlockProto::clear_has_b() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void LocatedBlockProto::clear_b() {
  if (b_ != NULL) b_->Clear();
  clear_has_b();
}
inline const ::hadoop::hdfs::ExtendedBlockProto& LocatedBlockProto::_internal_b() const {
  return *b_;
}
inline const ::hadoop::hdfs::ExtendedBlockProto& LocatedBlockProto::b() const {
  const ::hadoop::hdfs::ExtendedBlockProto* p = b_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.LocatedBlockProto.b)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::ExtendedBlockProto*>(
      &::hadoop::hdfs::_ExtendedBlockProto_default_instance_);
}
inline ::hadoop::hdfs::ExtendedBlockProto* LocatedBlockProto::release_b() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.LocatedBlockProto.b)
  clear_has_b();
  ::hadoop::hdfs::ExtendedBlockProto* temp = b_;
  b_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::ExtendedBlockProto* LocatedBlockProto::mutable_b() {
  set_has_b();
  if (b_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::ExtendedBlockProto>(GetArenaNoVirtual());
    b_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.LocatedBlockProto.b)
  return b_;
}
inline void LocatedBlockProto::set_allocated_b(::hadoop::hdfs::ExtendedBlockProto* b) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete b_;
  }
  if (b) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      b = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, b, submessage_arena);
    }
    set_has_b();
  } else {
    clear_has_b();
  }
  b_ = b;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.LocatedBlockProto.b)
}

// required uint64 offset = 2;
inline bool LocatedBlockProto::has_offset() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void LocatedBlockProto::set_has_offset() {
  _has_bits_[0] |= 0x00000008u;
}
inline void LocatedBlockProto::clear_has_offset() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void LocatedBlockProto::clear_offset() {
  offset_ = GOOGLE_ULONGLONG(0);
  clear_has_offset();
}
inline ::google::protobuf::uint64 LocatedBlockProto::offset() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.LocatedBlockProto.offset)
  return offset_;
}
inline void LocatedBlockProto::set_offset(::google::protobuf::uint64 value) {
  set_has_offset();
  offset_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.LocatedBlockProto.offset)
}

// repeated .hadoop.hdfs.DatanodeInfoProto locs = 3;
inline int LocatedBlockProto::locs_size() const {
  return locs_.size();
}
inline void LocatedBlockProto::clear_locs() {
  locs_.Clear();
}
inline ::hadoop::hdfs::DatanodeInfoProto* LocatedBlockProto::mutable_locs(int index) {
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.LocatedBlockProto.locs)
  return locs_.Mutable(index);
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::DatanodeInfoProto >*
LocatedBlockProto::mutable_locs() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.LocatedBlockProto.locs)
  return &locs_;
}
inline const ::hadoop::hdfs::DatanodeInfoProto& LocatedBlockProto::locs(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.LocatedBlockProto.locs)
  return locs_.Get(index);
}
inline ::hadoop::hdfs::DatanodeInfoProto* LocatedBlockProto::add_locs() {
  // @@protoc_insertion_point(field_add:hadoop.hdfs.LocatedBlockProto.locs)
  return locs_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::DatanodeInfoProto >&
LocatedBlockProto::locs() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.LocatedBlockProto.locs)
  return locs_;
}

// required bool corrupt = 4;
inline bool LocatedBlockProto::has_corrupt() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void LocatedBlockProto::set_has_corrupt() {
  _has_bits_[0] |= 0x00000010u;
}
inline void LocatedBlockProto::clear_has_corrupt() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void LocatedBlockProto::clear_corrupt() {
  corrupt_ = false;
  clear_has_corrupt();
}
inline bool LocatedBlockProto::corrupt() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.LocatedBlockProto.corrupt)
  return corrupt_;
}
inline void LocatedBlockProto::set_corrupt(bool value) {
  set_has_corrupt();
  corrupt_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.LocatedBlockProto.corrupt)
}

// required .hadoop.common.TokenProto blockToken = 5;
inline bool LocatedBlockProto::has_blocktoken() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void LocatedBlockProto::set_has_blocktoken() {
  _has_bits_[0] |= 0x00000004u;
}
inline void LocatedBlockProto::clear_has_blocktoken() {
  _has_bits_[0] &= ~0x00000004u;
}
inline const ::hadoop::common::TokenProto& LocatedBlockProto::_internal_blocktoken() const {
  return *blocktoken_;
}
inline const ::hadoop::common::TokenProto& LocatedBlockProto::blocktoken() const {
  const ::hadoop::common::TokenProto* p = blocktoken_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.LocatedBlockProto.blockToken)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::common::TokenProto*>(
      &::hadoop::common::_TokenProto_default_instance_);
}
inline ::hadoop::common::TokenProto* LocatedBlockProto::release_blocktoken() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.LocatedBlockProto.blockToken)
  clear_has_blocktoken();
  ::hadoop::common::TokenProto* temp = blocktoken_;
  blocktoken_ = NULL;
  return temp;
}
inline ::hadoop::common::TokenProto* LocatedBlockProto::mutable_blocktoken() {
  set_has_blocktoken();
  if (blocktoken_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::common::TokenProto>(GetArenaNoVirtual());
    blocktoken_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.LocatedBlockProto.blockToken)
  return blocktoken_;
}
inline void LocatedBlockProto::set_allocated_blocktoken(::hadoop::common::TokenProto* blocktoken) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete reinterpret_cast< ::google::protobuf::MessageLite*>(blocktoken_);
  }
  if (blocktoken) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      blocktoken = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, blocktoken, submessage_arena);
    }
    set_has_blocktoken();
  } else {
    clear_has_blocktoken();
  }
  blocktoken_ = blocktoken;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.LocatedBlockProto.blockToken)
}

// repeated bool isCached = 6 [packed = true];
inline int LocatedBlockProto::iscached_size() const {
  return iscached_.size();
}
inline void LocatedBlockProto::clear_iscached() {
  iscached_.Clear();
}
inline bool LocatedBlockProto::iscached(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.LocatedBlockProto.isCached)
  return iscached_.Get(index);
}
inline void LocatedBlockProto::set_iscached(int index, bool value) {
  iscached_.Set(index, value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.LocatedBlockProto.isCached)
}
inline void LocatedBlockProto::add_iscached(bool value) {
  iscached_.Add(value);
  // @@protoc_insertion_point(field_add:hadoop.hdfs.LocatedBlockProto.isCached)
}
inline const ::google::protobuf::RepeatedField< bool >&
LocatedBlockProto::iscached() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.LocatedBlockProto.isCached)
  return iscached_;
}
inline ::google::protobuf::RepeatedField< bool >*
LocatedBlockProto::mutable_iscached() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.LocatedBlockProto.isCached)
  return &iscached_;
}

// repeated .hadoop.hdfs.StorageTypeProto storageTypes = 7;
inline int LocatedBlockProto::storagetypes_size() const {
  return storagetypes_.size();
}
inline void LocatedBlockProto::clear_storagetypes() {
  storagetypes_.Clear();
}
inline ::hadoop::hdfs::StorageTypeProto LocatedBlockProto::storagetypes(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.LocatedBlockProto.storageTypes)
  return static_cast< ::hadoop::hdfs::StorageTypeProto >(storagetypes_.Get(index));
}
inline void LocatedBlockProto::set_storagetypes(int index, ::hadoop::hdfs::StorageTypeProto value) {
  assert(::hadoop::hdfs::StorageTypeProto_IsValid(value));
  storagetypes_.Set(index, value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.LocatedBlockProto.storageTypes)
}
inline void LocatedBlockProto::add_storagetypes(::hadoop::hdfs::StorageTypeProto value) {
  assert(::hadoop::hdfs::StorageTypeProto_IsValid(value));
  storagetypes_.Add(value);
  // @@protoc_insertion_point(field_add:hadoop.hdfs.LocatedBlockProto.storageTypes)
}
inline const ::google::protobuf::RepeatedField<int>&
LocatedBlockProto::storagetypes() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.LocatedBlockProto.storageTypes)
  return storagetypes_;
}
inline ::google::protobuf::RepeatedField<int>*
LocatedBlockProto::mutable_storagetypes() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.LocatedBlockProto.storageTypes)
  return &storagetypes_;
}

// repeated string storageIDs = 8;
inline int LocatedBlockProto::storageids_size() const {
  return storageids_.size();
}
inline void LocatedBlockProto::clear_storageids() {
  storageids_.Clear();
}
inline const ::std::string& LocatedBlockProto::storageids(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.LocatedBlockProto.storageIDs)
  return storageids_.Get(index);
}
inline ::std::string* LocatedBlockProto::mutable_storageids(int index) {
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.LocatedBlockProto.storageIDs)
  return storageids_.Mutable(index);
}
inline void LocatedBlockProto::set_storageids(int index, const ::std::string& value) {
  // @@protoc_insertion_point(field_set:hadoop.hdfs.LocatedBlockProto.storageIDs)
  storageids_.Mutable(index)->assign(value);
}
#if LANG_CXX11
inline void LocatedBlockProto::set_storageids(int index, ::std::string&& value) {
  // @@protoc_insertion_point(field_set:hadoop.hdfs.LocatedBlockProto.storageIDs)
  storageids_.Mutable(index)->assign(std::move(value));
}
#endif
inline void LocatedBlockProto::set_storageids(int index, const char* value) {
  GOOGLE_DCHECK(value != NULL);
  storageids_.Mutable(index)->assign(value);
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.LocatedBlockProto.storageIDs)
}
inline void LocatedBlockProto::set_storageids(int index, const char* value, size_t size) {
  storageids_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.LocatedBlockProto.storageIDs)
}
inline ::std::string* LocatedBlockProto::add_storageids() {
  // @@protoc_insertion_point(field_add_mutable:hadoop.hdfs.LocatedBlockProto.storageIDs)
  return storageids_.Add();
}
inline void LocatedBlockProto::add_storageids(const ::std::string& value) {
  storageids_.Add()->assign(value);
  // @@protoc_insertion_point(field_add:hadoop.hdfs.LocatedBlockProto.storageIDs)
}
#if LANG_CXX11
inline void LocatedBlockProto::add_storageids(::std::string&& value) {
  storageids_.Add(std::move(value));
  // @@protoc_insertion_point(field_add:hadoop.hdfs.LocatedBlockProto.storageIDs)
}
#endif
inline void LocatedBlockProto::add_storageids(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  storageids_.Add()->assign(value);
  // @@protoc_insertion_point(field_add_char:hadoop.hdfs.LocatedBlockProto.storageIDs)
}
inline void LocatedBlockProto::add_storageids(const char* value, size_t size) {
  storageids_.Add()->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_add_pointer:hadoop.hdfs.LocatedBlockProto.storageIDs)
}
inline const ::google::protobuf::RepeatedPtrField< ::std::string>&
LocatedBlockProto::storageids() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.LocatedBlockProto.storageIDs)
  return storageids_;
}
inline ::google::protobuf::RepeatedPtrField< ::std::string>*
LocatedBlockProto::mutable_storageids() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.LocatedBlockProto.storageIDs)
  return &storageids_;
}

// optional bytes blockIndices = 9;
inline bool LocatedBlockProto::has_blockindices() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void LocatedBlockProto::set_has_blockindices() {
  _has_bits_[0] |= 0x00000001u;
}
inline void LocatedBlockProto::clear_has_blockindices() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void LocatedBlockProto::clear_blockindices() {
  blockindices_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_blockindices();
}
inline const ::std::string& LocatedBlockProto::blockindices() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.LocatedBlockProto.blockIndices)
  return blockindices_.GetNoArena();
}
inline void LocatedBlockProto::set_blockindices(const ::std::string& value) {
  set_has_blockindices();
  blockindices_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.LocatedBlockProto.blockIndices)
}
#if LANG_CXX11
inline void LocatedBlockProto::set_blockindices(::std::string&& value) {
  set_has_blockindices();
  blockindices_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.LocatedBlockProto.blockIndices)
}
#endif
inline void LocatedBlockProto::set_blockindices(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_blockindices();
  blockindices_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.LocatedBlockProto.blockIndices)
}
inline void LocatedBlockProto::set_blockindices(const void* value, size_t size) {
  set_has_blockindices();
  blockindices_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.LocatedBlockProto.blockIndices)
}
inline ::std::string* LocatedBlockProto::mutable_blockindices() {
  set_has_blockindices();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.LocatedBlockProto.blockIndices)
  return blockindices_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* LocatedBlockProto::release_blockindices() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.LocatedBlockProto.blockIndices)
  if (!has_blockindices()) {
    return NULL;
  }
  clear_has_blockindices();
  return blockindices_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void LocatedBlockProto::set_allocated_blockindices(::std::string* blockindices) {
  if (blockindices != NULL) {
    set_has_blockindices();
  } else {
    clear_has_blockindices();
  }
  blockindices_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), blockindices);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.LocatedBlockProto.blockIndices)
}

// repeated .hadoop.common.TokenProto blockTokens = 10;
inline int LocatedBlockProto::blocktokens_size() const {
  return blocktokens_.size();
}
inline ::hadoop::common::TokenProto* LocatedBlockProto::mutable_blocktokens(int index) {
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.LocatedBlockProto.blockTokens)
  return blocktokens_.Mutable(index);
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::common::TokenProto >*
LocatedBlockProto::mutable_blocktokens() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.LocatedBlockProto.blockTokens)
  return &blocktokens_;
}
inline const ::hadoop::common::TokenProto& LocatedBlockProto::blocktokens(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.LocatedBlockProto.blockTokens)
  return blocktokens_.Get(index);
}
inline ::hadoop::common::TokenProto* LocatedBlockProto::add_blocktokens() {
  // @@protoc_insertion_point(field_add:hadoop.hdfs.LocatedBlockProto.blockTokens)
  return blocktokens_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::common::TokenProto >&
LocatedBlockProto::blocktokens() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.LocatedBlockProto.blockTokens)
  return blocktokens_;
}

// -------------------------------------------------------------------

// BatchedListingKeyProto

// required bytes checksum = 1;
inline bool BatchedListingKeyProto::has_checksum() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void BatchedListingKeyProto::set_has_checksum() {
  _has_bits_[0] |= 0x00000001u;
}
inline void BatchedListingKeyProto::clear_has_checksum() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void BatchedListingKeyProto::clear_checksum() {
  checksum_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_checksum();
}
inline const ::std::string& BatchedListingKeyProto::checksum() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BatchedListingKeyProto.checksum)
  return checksum_.GetNoArena();
}
inline void BatchedListingKeyProto::set_checksum(const ::std::string& value) {
  set_has_checksum();
  checksum_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BatchedListingKeyProto.checksum)
}
#if LANG_CXX11
inline void BatchedListingKeyProto::set_checksum(::std::string&& value) {
  set_has_checksum();
  checksum_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.BatchedListingKeyProto.checksum)
}
#endif
inline void BatchedListingKeyProto::set_checksum(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_checksum();
  checksum_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.BatchedListingKeyProto.checksum)
}
inline void BatchedListingKeyProto::set_checksum(const void* value, size_t size) {
  set_has_checksum();
  checksum_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.BatchedListingKeyProto.checksum)
}
inline ::std::string* BatchedListingKeyProto::mutable_checksum() {
  set_has_checksum();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.BatchedListingKeyProto.checksum)
  return checksum_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* BatchedListingKeyProto::release_checksum() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.BatchedListingKeyProto.checksum)
  if (!has_checksum()) {
    return NULL;
  }
  clear_has_checksum();
  return checksum_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void BatchedListingKeyProto::set_allocated_checksum(::std::string* checksum) {
  if (checksum != NULL) {
    set_has_checksum();
  } else {
    clear_has_checksum();
  }
  checksum_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), checksum);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.BatchedListingKeyProto.checksum)
}

// required uint32 pathIndex = 2;
inline bool BatchedListingKeyProto::has_pathindex() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void BatchedListingKeyProto::set_has_pathindex() {
  _has_bits_[0] |= 0x00000004u;
}
inline void BatchedListingKeyProto::clear_has_pathindex() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void BatchedListingKeyProto::clear_pathindex() {
  pathindex_ = 0u;
  clear_has_pathindex();
}
inline ::google::protobuf::uint32 BatchedListingKeyProto::pathindex() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BatchedListingKeyProto.pathIndex)
  return pathindex_;
}
inline void BatchedListingKeyProto::set_pathindex(::google::protobuf::uint32 value) {
  set_has_pathindex();
  pathindex_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BatchedListingKeyProto.pathIndex)
}

// required bytes startAfter = 3;
inline bool BatchedListingKeyProto::has_startafter() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void BatchedListingKeyProto::set_has_startafter() {
  _has_bits_[0] |= 0x00000002u;
}
inline void BatchedListingKeyProto::clear_has_startafter() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void BatchedListingKeyProto::clear_startafter() {
  startafter_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_startafter();
}
inline const ::std::string& BatchedListingKeyProto::startafter() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BatchedListingKeyProto.startAfter)
  return startafter_.GetNoArena();
}
inline void BatchedListingKeyProto::set_startafter(const ::std::string& value) {
  set_has_startafter();
  startafter_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BatchedListingKeyProto.startAfter)
}
#if LANG_CXX11
inline void BatchedListingKeyProto::set_startafter(::std::string&& value) {
  set_has_startafter();
  startafter_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.BatchedListingKeyProto.startAfter)
}
#endif
inline void BatchedListingKeyProto::set_startafter(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_startafter();
  startafter_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.BatchedListingKeyProto.startAfter)
}
inline void BatchedListingKeyProto::set_startafter(const void* value, size_t size) {
  set_has_startafter();
  startafter_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.BatchedListingKeyProto.startAfter)
}
inline ::std::string* BatchedListingKeyProto::mutable_startafter() {
  set_has_startafter();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.BatchedListingKeyProto.startAfter)
  return startafter_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* BatchedListingKeyProto::release_startafter() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.BatchedListingKeyProto.startAfter)
  if (!has_startafter()) {
    return NULL;
  }
  clear_has_startafter();
  return startafter_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void BatchedListingKeyProto::set_allocated_startafter(::std::string* startafter) {
  if (startafter != NULL) {
    set_has_startafter();
  } else {
    clear_has_startafter();
  }
  startafter_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), startafter);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.BatchedListingKeyProto.startAfter)
}

// -------------------------------------------------------------------

// DataEncryptionKeyProto

// required uint32 keyId = 1;
inline bool DataEncryptionKeyProto::has_keyid() const {
  return (_has_bits_[0] & 0x00000020u) != 0;
}
inline void DataEncryptionKeyProto::set_has_keyid() {
  _has_bits_[0] |= 0x00000020u;
}
inline void DataEncryptionKeyProto::clear_has_keyid() {
  _has_bits_[0] &= ~0x00000020u;
}
inline void DataEncryptionKeyProto::clear_keyid() {
  keyid_ = 0u;
  clear_has_keyid();
}
inline ::google::protobuf::uint32 DataEncryptionKeyProto::keyid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DataEncryptionKeyProto.keyId)
  return keyid_;
}
inline void DataEncryptionKeyProto::set_keyid(::google::protobuf::uint32 value) {
  set_has_keyid();
  keyid_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DataEncryptionKeyProto.keyId)
}

// required string blockPoolId = 2;
inline bool DataEncryptionKeyProto::has_blockpoolid() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void DataEncryptionKeyProto::set_has_blockpoolid() {
  _has_bits_[0] |= 0x00000001u;
}
inline void DataEncryptionKeyProto::clear_has_blockpoolid() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void DataEncryptionKeyProto::clear_blockpoolid() {
  blockpoolid_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_blockpoolid();
}
inline const ::std::string& DataEncryptionKeyProto::blockpoolid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DataEncryptionKeyProto.blockPoolId)
  return blockpoolid_.GetNoArena();
}
inline void DataEncryptionKeyProto::set_blockpoolid(const ::std::string& value) {
  set_has_blockpoolid();
  blockpoolid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DataEncryptionKeyProto.blockPoolId)
}
#if LANG_CXX11
inline void DataEncryptionKeyProto::set_blockpoolid(::std::string&& value) {
  set_has_blockpoolid();
  blockpoolid_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.DataEncryptionKeyProto.blockPoolId)
}
#endif
inline void DataEncryptionKeyProto::set_blockpoolid(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_blockpoolid();
  blockpoolid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.DataEncryptionKeyProto.blockPoolId)
}
inline void DataEncryptionKeyProto::set_blockpoolid(const char* value, size_t size) {
  set_has_blockpoolid();
  blockpoolid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.DataEncryptionKeyProto.blockPoolId)
}
inline ::std::string* DataEncryptionKeyProto::mutable_blockpoolid() {
  set_has_blockpoolid();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.DataEncryptionKeyProto.blockPoolId)
  return blockpoolid_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* DataEncryptionKeyProto::release_blockpoolid() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.DataEncryptionKeyProto.blockPoolId)
  if (!has_blockpoolid()) {
    return NULL;
  }
  clear_has_blockpoolid();
  return blockpoolid_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void DataEncryptionKeyProto::set_allocated_blockpoolid(::std::string* blockpoolid) {
  if (blockpoolid != NULL) {
    set_has_blockpoolid();
  } else {
    clear_has_blockpoolid();
  }
  blockpoolid_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), blockpoolid);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.DataEncryptionKeyProto.blockPoolId)
}

// required bytes nonce = 3;
inline bool DataEncryptionKeyProto::has_nonce() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void DataEncryptionKeyProto::set_has_nonce() {
  _has_bits_[0] |= 0x00000002u;
}
inline void DataEncryptionKeyProto::clear_has_nonce() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void DataEncryptionKeyProto::clear_nonce() {
  nonce_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_nonce();
}
inline const ::std::string& DataEncryptionKeyProto::nonce() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DataEncryptionKeyProto.nonce)
  return nonce_.GetNoArena();
}
inline void DataEncryptionKeyProto::set_nonce(const ::std::string& value) {
  set_has_nonce();
  nonce_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DataEncryptionKeyProto.nonce)
}
#if LANG_CXX11
inline void DataEncryptionKeyProto::set_nonce(::std::string&& value) {
  set_has_nonce();
  nonce_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.DataEncryptionKeyProto.nonce)
}
#endif
inline void DataEncryptionKeyProto::set_nonce(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_nonce();
  nonce_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.DataEncryptionKeyProto.nonce)
}
inline void DataEncryptionKeyProto::set_nonce(const void* value, size_t size) {
  set_has_nonce();
  nonce_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.DataEncryptionKeyProto.nonce)
}
inline ::std::string* DataEncryptionKeyProto::mutable_nonce() {
  set_has_nonce();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.DataEncryptionKeyProto.nonce)
  return nonce_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* DataEncryptionKeyProto::release_nonce() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.DataEncryptionKeyProto.nonce)
  if (!has_nonce()) {
    return NULL;
  }
  clear_has_nonce();
  return nonce_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void DataEncryptionKeyProto::set_allocated_nonce(::std::string* nonce) {
  if (nonce != NULL) {
    set_has_nonce();
  } else {
    clear_has_nonce();
  }
  nonce_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), nonce);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.DataEncryptionKeyProto.nonce)
}

// required bytes encryptionKey = 4;
inline bool DataEncryptionKeyProto::has_encryptionkey() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void DataEncryptionKeyProto::set_has_encryptionkey() {
  _has_bits_[0] |= 0x00000004u;
}
inline void DataEncryptionKeyProto::clear_has_encryptionkey() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void DataEncryptionKeyProto::clear_encryptionkey() {
  encryptionkey_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_encryptionkey();
}
inline const ::std::string& DataEncryptionKeyProto::encryptionkey() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DataEncryptionKeyProto.encryptionKey)
  return encryptionkey_.GetNoArena();
}
inline void DataEncryptionKeyProto::set_encryptionkey(const ::std::string& value) {
  set_has_encryptionkey();
  encryptionkey_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DataEncryptionKeyProto.encryptionKey)
}
#if LANG_CXX11
inline void DataEncryptionKeyProto::set_encryptionkey(::std::string&& value) {
  set_has_encryptionkey();
  encryptionkey_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.DataEncryptionKeyProto.encryptionKey)
}
#endif
inline void DataEncryptionKeyProto::set_encryptionkey(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_encryptionkey();
  encryptionkey_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.DataEncryptionKeyProto.encryptionKey)
}
inline void DataEncryptionKeyProto::set_encryptionkey(const void* value, size_t size) {
  set_has_encryptionkey();
  encryptionkey_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.DataEncryptionKeyProto.encryptionKey)
}
inline ::std::string* DataEncryptionKeyProto::mutable_encryptionkey() {
  set_has_encryptionkey();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.DataEncryptionKeyProto.encryptionKey)
  return encryptionkey_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* DataEncryptionKeyProto::release_encryptionkey() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.DataEncryptionKeyProto.encryptionKey)
  if (!has_encryptionkey()) {
    return NULL;
  }
  clear_has_encryptionkey();
  return encryptionkey_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void DataEncryptionKeyProto::set_allocated_encryptionkey(::std::string* encryptionkey) {
  if (encryptionkey != NULL) {
    set_has_encryptionkey();
  } else {
    clear_has_encryptionkey();
  }
  encryptionkey_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), encryptionkey);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.DataEncryptionKeyProto.encryptionKey)
}

// required uint64 expiryDate = 5;
inline bool DataEncryptionKeyProto::has_expirydate() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void DataEncryptionKeyProto::set_has_expirydate() {
  _has_bits_[0] |= 0x00000010u;
}
inline void DataEncryptionKeyProto::clear_has_expirydate() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void DataEncryptionKeyProto::clear_expirydate() {
  expirydate_ = GOOGLE_ULONGLONG(0);
  clear_has_expirydate();
}
inline ::google::protobuf::uint64 DataEncryptionKeyProto::expirydate() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DataEncryptionKeyProto.expiryDate)
  return expirydate_;
}
inline void DataEncryptionKeyProto::set_expirydate(::google::protobuf::uint64 value) {
  set_has_expirydate();
  expirydate_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DataEncryptionKeyProto.expiryDate)
}

// optional string encryptionAlgorithm = 6;
inline bool DataEncryptionKeyProto::has_encryptionalgorithm() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void DataEncryptionKeyProto::set_has_encryptionalgorithm() {
  _has_bits_[0] |= 0x00000008u;
}
inline void DataEncryptionKeyProto::clear_has_encryptionalgorithm() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void DataEncryptionKeyProto::clear_encryptionalgorithm() {
  encryptionalgorithm_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_encryptionalgorithm();
}
inline const ::std::string& DataEncryptionKeyProto::encryptionalgorithm() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DataEncryptionKeyProto.encryptionAlgorithm)
  return encryptionalgorithm_.GetNoArena();
}
inline void DataEncryptionKeyProto::set_encryptionalgorithm(const ::std::string& value) {
  set_has_encryptionalgorithm();
  encryptionalgorithm_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DataEncryptionKeyProto.encryptionAlgorithm)
}
#if LANG_CXX11
inline void DataEncryptionKeyProto::set_encryptionalgorithm(::std::string&& value) {
  set_has_encryptionalgorithm();
  encryptionalgorithm_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.DataEncryptionKeyProto.encryptionAlgorithm)
}
#endif
inline void DataEncryptionKeyProto::set_encryptionalgorithm(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_encryptionalgorithm();
  encryptionalgorithm_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.DataEncryptionKeyProto.encryptionAlgorithm)
}
inline void DataEncryptionKeyProto::set_encryptionalgorithm(const char* value, size_t size) {
  set_has_encryptionalgorithm();
  encryptionalgorithm_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.DataEncryptionKeyProto.encryptionAlgorithm)
}
inline ::std::string* DataEncryptionKeyProto::mutable_encryptionalgorithm() {
  set_has_encryptionalgorithm();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.DataEncryptionKeyProto.encryptionAlgorithm)
  return encryptionalgorithm_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* DataEncryptionKeyProto::release_encryptionalgorithm() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.DataEncryptionKeyProto.encryptionAlgorithm)
  if (!has_encryptionalgorithm()) {
    return NULL;
  }
  clear_has_encryptionalgorithm();
  return encryptionalgorithm_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void DataEncryptionKeyProto::set_allocated_encryptionalgorithm(::std::string* encryptionalgorithm) {
  if (encryptionalgorithm != NULL) {
    set_has_encryptionalgorithm();
  } else {
    clear_has_encryptionalgorithm();
  }
  encryptionalgorithm_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), encryptionalgorithm);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.DataEncryptionKeyProto.encryptionAlgorithm)
}

// -------------------------------------------------------------------

// FileEncryptionInfoProto

// required .hadoop.hdfs.CipherSuiteProto suite = 1;
inline bool FileEncryptionInfoProto::has_suite() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void FileEncryptionInfoProto::set_has_suite() {
  _has_bits_[0] |= 0x00000010u;
}
inline void FileEncryptionInfoProto::clear_has_suite() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void FileEncryptionInfoProto::clear_suite() {
  suite_ = 1;
  clear_has_suite();
}
inline ::hadoop::hdfs::CipherSuiteProto FileEncryptionInfoProto::suite() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.FileEncryptionInfoProto.suite)
  return static_cast< ::hadoop::hdfs::CipherSuiteProto >(suite_);
}
inline void FileEncryptionInfoProto::set_suite(::hadoop::hdfs::CipherSuiteProto value) {
  assert(::hadoop::hdfs::CipherSuiteProto_IsValid(value));
  set_has_suite();
  suite_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.FileEncryptionInfoProto.suite)
}

// required .hadoop.hdfs.CryptoProtocolVersionProto cryptoProtocolVersion = 2;
inline bool FileEncryptionInfoProto::has_cryptoprotocolversion() const {
  return (_has_bits_[0] & 0x00000020u) != 0;
}
inline void FileEncryptionInfoProto::set_has_cryptoprotocolversion() {
  _has_bits_[0] |= 0x00000020u;
}
inline void FileEncryptionInfoProto::clear_has_cryptoprotocolversion() {
  _has_bits_[0] &= ~0x00000020u;
}
inline void FileEncryptionInfoProto::clear_cryptoprotocolversion() {
  cryptoprotocolversion_ = 1;
  clear_has_cryptoprotocolversion();
}
inline ::hadoop::hdfs::CryptoProtocolVersionProto FileEncryptionInfoProto::cryptoprotocolversion() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.FileEncryptionInfoProto.cryptoProtocolVersion)
  return static_cast< ::hadoop::hdfs::CryptoProtocolVersionProto >(cryptoprotocolversion_);
}
inline void FileEncryptionInfoProto::set_cryptoprotocolversion(::hadoop::hdfs::CryptoProtocolVersionProto value) {
  assert(::hadoop::hdfs::CryptoProtocolVersionProto_IsValid(value));
  set_has_cryptoprotocolversion();
  cryptoprotocolversion_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.FileEncryptionInfoProto.cryptoProtocolVersion)
}

// required bytes key = 3;
inline bool FileEncryptionInfoProto::has_key() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void FileEncryptionInfoProto::set_has_key() {
  _has_bits_[0] |= 0x00000001u;
}
inline void FileEncryptionInfoProto::clear_has_key() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void FileEncryptionInfoProto::clear_key() {
  key_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_key();
}
inline const ::std::string& FileEncryptionInfoProto::key() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.FileEncryptionInfoProto.key)
  return key_.GetNoArena();
}
inline void FileEncryptionInfoProto::set_key(const ::std::string& value) {
  set_has_key();
  key_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.FileEncryptionInfoProto.key)
}
#if LANG_CXX11
inline void FileEncryptionInfoProto::set_key(::std::string&& value) {
  set_has_key();
  key_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.FileEncryptionInfoProto.key)
}
#endif
inline void FileEncryptionInfoProto::set_key(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_key();
  key_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.FileEncryptionInfoProto.key)
}
inline void FileEncryptionInfoProto::set_key(const void* value, size_t size) {
  set_has_key();
  key_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.FileEncryptionInfoProto.key)
}
inline ::std::string* FileEncryptionInfoProto::mutable_key() {
  set_has_key();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.FileEncryptionInfoProto.key)
  return key_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* FileEncryptionInfoProto::release_key() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.FileEncryptionInfoProto.key)
  if (!has_key()) {
    return NULL;
  }
  clear_has_key();
  return key_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void FileEncryptionInfoProto::set_allocated_key(::std::string* key) {
  if (key != NULL) {
    set_has_key();
  } else {
    clear_has_key();
  }
  key_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), key);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.FileEncryptionInfoProto.key)
}

// required bytes iv = 4;
inline bool FileEncryptionInfoProto::has_iv() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void FileEncryptionInfoProto::set_has_iv() {
  _has_bits_[0] |= 0x00000002u;
}
inline void FileEncryptionInfoProto::clear_has_iv() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void FileEncryptionInfoProto::clear_iv() {
  iv_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_iv();
}
inline const ::std::string& FileEncryptionInfoProto::iv() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.FileEncryptionInfoProto.iv)
  return iv_.GetNoArena();
}
inline void FileEncryptionInfoProto::set_iv(const ::std::string& value) {
  set_has_iv();
  iv_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.FileEncryptionInfoProto.iv)
}
#if LANG_CXX11
inline void FileEncryptionInfoProto::set_iv(::std::string&& value) {
  set_has_iv();
  iv_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.FileEncryptionInfoProto.iv)
}
#endif
inline void FileEncryptionInfoProto::set_iv(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_iv();
  iv_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.FileEncryptionInfoProto.iv)
}
inline void FileEncryptionInfoProto::set_iv(const void* value, size_t size) {
  set_has_iv();
  iv_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.FileEncryptionInfoProto.iv)
}
inline ::std::string* FileEncryptionInfoProto::mutable_iv() {
  set_has_iv();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.FileEncryptionInfoProto.iv)
  return iv_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* FileEncryptionInfoProto::release_iv() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.FileEncryptionInfoProto.iv)
  if (!has_iv()) {
    return NULL;
  }
  clear_has_iv();
  return iv_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void FileEncryptionInfoProto::set_allocated_iv(::std::string* iv) {
  if (iv != NULL) {
    set_has_iv();
  } else {
    clear_has_iv();
  }
  iv_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), iv);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.FileEncryptionInfoProto.iv)
}

// required string keyName = 5;
inline bool FileEncryptionInfoProto::has_keyname() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void FileEncryptionInfoProto::set_has_keyname() {
  _has_bits_[0] |= 0x00000004u;
}
inline void FileEncryptionInfoProto::clear_has_keyname() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void FileEncryptionInfoProto::clear_keyname() {
  keyname_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_keyname();
}
inline const ::std::string& FileEncryptionInfoProto::keyname() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.FileEncryptionInfoProto.keyName)
  return keyname_.GetNoArena();
}
inline void FileEncryptionInfoProto::set_keyname(const ::std::string& value) {
  set_has_keyname();
  keyname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.FileEncryptionInfoProto.keyName)
}
#if LANG_CXX11
inline void FileEncryptionInfoProto::set_keyname(::std::string&& value) {
  set_has_keyname();
  keyname_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.FileEncryptionInfoProto.keyName)
}
#endif
inline void FileEncryptionInfoProto::set_keyname(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_keyname();
  keyname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.FileEncryptionInfoProto.keyName)
}
inline void FileEncryptionInfoProto::set_keyname(const char* value, size_t size) {
  set_has_keyname();
  keyname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.FileEncryptionInfoProto.keyName)
}
inline ::std::string* FileEncryptionInfoProto::mutable_keyname() {
  set_has_keyname();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.FileEncryptionInfoProto.keyName)
  return keyname_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* FileEncryptionInfoProto::release_keyname() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.FileEncryptionInfoProto.keyName)
  if (!has_keyname()) {
    return NULL;
  }
  clear_has_keyname();
  return keyname_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void FileEncryptionInfoProto::set_allocated_keyname(::std::string* keyname) {
  if (keyname != NULL) {
    set_has_keyname();
  } else {
    clear_has_keyname();
  }
  keyname_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), keyname);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.FileEncryptionInfoProto.keyName)
}

// required string ezKeyVersionName = 6;
inline bool FileEncryptionInfoProto::has_ezkeyversionname() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void FileEncryptionInfoProto::set_has_ezkeyversionname() {
  _has_bits_[0] |= 0x00000008u;
}
inline void FileEncryptionInfoProto::clear_has_ezkeyversionname() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void FileEncryptionInfoProto::clear_ezkeyversionname() {
  ezkeyversionname_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_ezkeyversionname();
}
inline const ::std::string& FileEncryptionInfoProto::ezkeyversionname() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.FileEncryptionInfoProto.ezKeyVersionName)
  return ezkeyversionname_.GetNoArena();
}
inline void FileEncryptionInfoProto::set_ezkeyversionname(const ::std::string& value) {
  set_has_ezkeyversionname();
  ezkeyversionname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.FileEncryptionInfoProto.ezKeyVersionName)
}
#if LANG_CXX11
inline void FileEncryptionInfoProto::set_ezkeyversionname(::std::string&& value) {
  set_has_ezkeyversionname();
  ezkeyversionname_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.FileEncryptionInfoProto.ezKeyVersionName)
}
#endif
inline void FileEncryptionInfoProto::set_ezkeyversionname(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_ezkeyversionname();
  ezkeyversionname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.FileEncryptionInfoProto.ezKeyVersionName)
}
inline void FileEncryptionInfoProto::set_ezkeyversionname(const char* value, size_t size) {
  set_has_ezkeyversionname();
  ezkeyversionname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.FileEncryptionInfoProto.ezKeyVersionName)
}
inline ::std::string* FileEncryptionInfoProto::mutable_ezkeyversionname() {
  set_has_ezkeyversionname();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.FileEncryptionInfoProto.ezKeyVersionName)
  return ezkeyversionname_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* FileEncryptionInfoProto::release_ezkeyversionname() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.FileEncryptionInfoProto.ezKeyVersionName)
  if (!has_ezkeyversionname()) {
    return NULL;
  }
  clear_has_ezkeyversionname();
  return ezkeyversionname_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void FileEncryptionInfoProto::set_allocated_ezkeyversionname(::std::string* ezkeyversionname) {
  if (ezkeyversionname != NULL) {
    set_has_ezkeyversionname();
  } else {
    clear_has_ezkeyversionname();
  }
  ezkeyversionname_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ezkeyversionname);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.FileEncryptionInfoProto.ezKeyVersionName)
}

// -------------------------------------------------------------------

// PerFileEncryptionInfoProto

// required bytes key = 1;
inline bool PerFileEncryptionInfoProto::has_key() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void PerFileEncryptionInfoProto::set_has_key() {
  _has_bits_[0] |= 0x00000001u;
}
inline void PerFileEncryptionInfoProto::clear_has_key() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void PerFileEncryptionInfoProto::clear_key() {
  key_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_key();
}
inline const ::std::string& PerFileEncryptionInfoProto::key() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.PerFileEncryptionInfoProto.key)
  return key_.GetNoArena();
}
inline void PerFileEncryptionInfoProto::set_key(const ::std::string& value) {
  set_has_key();
  key_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.PerFileEncryptionInfoProto.key)
}
#if LANG_CXX11
inline void PerFileEncryptionInfoProto::set_key(::std::string&& value) {
  set_has_key();
  key_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.PerFileEncryptionInfoProto.key)
}
#endif
inline void PerFileEncryptionInfoProto::set_key(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_key();
  key_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.PerFileEncryptionInfoProto.key)
}
inline void PerFileEncryptionInfoProto::set_key(const void* value, size_t size) {
  set_has_key();
  key_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.PerFileEncryptionInfoProto.key)
}
inline ::std::string* PerFileEncryptionInfoProto::mutable_key() {
  set_has_key();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.PerFileEncryptionInfoProto.key)
  return key_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* PerFileEncryptionInfoProto::release_key() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.PerFileEncryptionInfoProto.key)
  if (!has_key()) {
    return NULL;
  }
  clear_has_key();
  return key_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void PerFileEncryptionInfoProto::set_allocated_key(::std::string* key) {
  if (key != NULL) {
    set_has_key();
  } else {
    clear_has_key();
  }
  key_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), key);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.PerFileEncryptionInfoProto.key)
}

// required bytes iv = 2;
inline bool PerFileEncryptionInfoProto::has_iv() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void PerFileEncryptionInfoProto::set_has_iv() {
  _has_bits_[0] |= 0x00000002u;
}
inline void PerFileEncryptionInfoProto::clear_has_iv() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void PerFileEncryptionInfoProto::clear_iv() {
  iv_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_iv();
}
inline const ::std::string& PerFileEncryptionInfoProto::iv() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.PerFileEncryptionInfoProto.iv)
  return iv_.GetNoArena();
}
inline void PerFileEncryptionInfoProto::set_iv(const ::std::string& value) {
  set_has_iv();
  iv_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.PerFileEncryptionInfoProto.iv)
}
#if LANG_CXX11
inline void PerFileEncryptionInfoProto::set_iv(::std::string&& value) {
  set_has_iv();
  iv_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.PerFileEncryptionInfoProto.iv)
}
#endif
inline void PerFileEncryptionInfoProto::set_iv(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_iv();
  iv_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.PerFileEncryptionInfoProto.iv)
}
inline void PerFileEncryptionInfoProto::set_iv(const void* value, size_t size) {
  set_has_iv();
  iv_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.PerFileEncryptionInfoProto.iv)
}
inline ::std::string* PerFileEncryptionInfoProto::mutable_iv() {
  set_has_iv();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.PerFileEncryptionInfoProto.iv)
  return iv_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* PerFileEncryptionInfoProto::release_iv() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.PerFileEncryptionInfoProto.iv)
  if (!has_iv()) {
    return NULL;
  }
  clear_has_iv();
  return iv_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void PerFileEncryptionInfoProto::set_allocated_iv(::std::string* iv) {
  if (iv != NULL) {
    set_has_iv();
  } else {
    clear_has_iv();
  }
  iv_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), iv);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.PerFileEncryptionInfoProto.iv)
}

// required string ezKeyVersionName = 3;
inline bool PerFileEncryptionInfoProto::has_ezkeyversionname() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void PerFileEncryptionInfoProto::set_has_ezkeyversionname() {
  _has_bits_[0] |= 0x00000004u;
}
inline void PerFileEncryptionInfoProto::clear_has_ezkeyversionname() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void PerFileEncryptionInfoProto::clear_ezkeyversionname() {
  ezkeyversionname_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_ezkeyversionname();
}
inline const ::std::string& PerFileEncryptionInfoProto::ezkeyversionname() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.PerFileEncryptionInfoProto.ezKeyVersionName)
  return ezkeyversionname_.GetNoArena();
}
inline void PerFileEncryptionInfoProto::set_ezkeyversionname(const ::std::string& value) {
  set_has_ezkeyversionname();
  ezkeyversionname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.PerFileEncryptionInfoProto.ezKeyVersionName)
}
#if LANG_CXX11
inline void PerFileEncryptionInfoProto::set_ezkeyversionname(::std::string&& value) {
  set_has_ezkeyversionname();
  ezkeyversionname_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.PerFileEncryptionInfoProto.ezKeyVersionName)
}
#endif
inline void PerFileEncryptionInfoProto::set_ezkeyversionname(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_ezkeyversionname();
  ezkeyversionname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.PerFileEncryptionInfoProto.ezKeyVersionName)
}
inline void PerFileEncryptionInfoProto::set_ezkeyversionname(const char* value, size_t size) {
  set_has_ezkeyversionname();
  ezkeyversionname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.PerFileEncryptionInfoProto.ezKeyVersionName)
}
inline ::std::string* PerFileEncryptionInfoProto::mutable_ezkeyversionname() {
  set_has_ezkeyversionname();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.PerFileEncryptionInfoProto.ezKeyVersionName)
  return ezkeyversionname_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* PerFileEncryptionInfoProto::release_ezkeyversionname() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.PerFileEncryptionInfoProto.ezKeyVersionName)
  if (!has_ezkeyversionname()) {
    return NULL;
  }
  clear_has_ezkeyversionname();
  return ezkeyversionname_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void PerFileEncryptionInfoProto::set_allocated_ezkeyversionname(::std::string* ezkeyversionname) {
  if (ezkeyversionname != NULL) {
    set_has_ezkeyversionname();
  } else {
    clear_has_ezkeyversionname();
  }
  ezkeyversionname_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ezkeyversionname);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.PerFileEncryptionInfoProto.ezKeyVersionName)
}

// -------------------------------------------------------------------

// ZoneEncryptionInfoProto

// required .hadoop.hdfs.CipherSuiteProto suite = 1;
inline bool ZoneEncryptionInfoProto::has_suite() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void ZoneEncryptionInfoProto::set_has_suite() {
  _has_bits_[0] |= 0x00000004u;
}
inline void ZoneEncryptionInfoProto::clear_has_suite() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void ZoneEncryptionInfoProto::clear_suite() {
  suite_ = 1;
  clear_has_suite();
}
inline ::hadoop::hdfs::CipherSuiteProto ZoneEncryptionInfoProto::suite() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ZoneEncryptionInfoProto.suite)
  return static_cast< ::hadoop::hdfs::CipherSuiteProto >(suite_);
}
inline void ZoneEncryptionInfoProto::set_suite(::hadoop::hdfs::CipherSuiteProto value) {
  assert(::hadoop::hdfs::CipherSuiteProto_IsValid(value));
  set_has_suite();
  suite_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ZoneEncryptionInfoProto.suite)
}

// required .hadoop.hdfs.CryptoProtocolVersionProto cryptoProtocolVersion = 2;
inline bool ZoneEncryptionInfoProto::has_cryptoprotocolversion() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void ZoneEncryptionInfoProto::set_has_cryptoprotocolversion() {
  _has_bits_[0] |= 0x00000008u;
}
inline void ZoneEncryptionInfoProto::clear_has_cryptoprotocolversion() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void ZoneEncryptionInfoProto::clear_cryptoprotocolversion() {
  cryptoprotocolversion_ = 1;
  clear_has_cryptoprotocolversion();
}
inline ::hadoop::hdfs::CryptoProtocolVersionProto ZoneEncryptionInfoProto::cryptoprotocolversion() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ZoneEncryptionInfoProto.cryptoProtocolVersion)
  return static_cast< ::hadoop::hdfs::CryptoProtocolVersionProto >(cryptoprotocolversion_);
}
inline void ZoneEncryptionInfoProto::set_cryptoprotocolversion(::hadoop::hdfs::CryptoProtocolVersionProto value) {
  assert(::hadoop::hdfs::CryptoProtocolVersionProto_IsValid(value));
  set_has_cryptoprotocolversion();
  cryptoprotocolversion_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ZoneEncryptionInfoProto.cryptoProtocolVersion)
}

// required string keyName = 3;
inline bool ZoneEncryptionInfoProto::has_keyname() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ZoneEncryptionInfoProto::set_has_keyname() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ZoneEncryptionInfoProto::clear_has_keyname() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ZoneEncryptionInfoProto::clear_keyname() {
  keyname_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_keyname();
}
inline const ::std::string& ZoneEncryptionInfoProto::keyname() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ZoneEncryptionInfoProto.keyName)
  return keyname_.GetNoArena();
}
inline void ZoneEncryptionInfoProto::set_keyname(const ::std::string& value) {
  set_has_keyname();
  keyname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ZoneEncryptionInfoProto.keyName)
}
#if LANG_CXX11
inline void ZoneEncryptionInfoProto::set_keyname(::std::string&& value) {
  set_has_keyname();
  keyname_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.ZoneEncryptionInfoProto.keyName)
}
#endif
inline void ZoneEncryptionInfoProto::set_keyname(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_keyname();
  keyname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.ZoneEncryptionInfoProto.keyName)
}
inline void ZoneEncryptionInfoProto::set_keyname(const char* value, size_t size) {
  set_has_keyname();
  keyname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.ZoneEncryptionInfoProto.keyName)
}
inline ::std::string* ZoneEncryptionInfoProto::mutable_keyname() {
  set_has_keyname();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.ZoneEncryptionInfoProto.keyName)
  return keyname_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* ZoneEncryptionInfoProto::release_keyname() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.ZoneEncryptionInfoProto.keyName)
  if (!has_keyname()) {
    return NULL;
  }
  clear_has_keyname();
  return keyname_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void ZoneEncryptionInfoProto::set_allocated_keyname(::std::string* keyname) {
  if (keyname != NULL) {
    set_has_keyname();
  } else {
    clear_has_keyname();
  }
  keyname_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), keyname);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.ZoneEncryptionInfoProto.keyName)
}

// optional .hadoop.hdfs.ReencryptionInfoProto reencryptionProto = 4;
inline bool ZoneEncryptionInfoProto::has_reencryptionproto() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ZoneEncryptionInfoProto::set_has_reencryptionproto() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ZoneEncryptionInfoProto::clear_has_reencryptionproto() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ZoneEncryptionInfoProto::clear_reencryptionproto() {
  if (reencryptionproto_ != NULL) reencryptionproto_->Clear();
  clear_has_reencryptionproto();
}
inline const ::hadoop::hdfs::ReencryptionInfoProto& ZoneEncryptionInfoProto::_internal_reencryptionproto() const {
  return *reencryptionproto_;
}
inline const ::hadoop::hdfs::ReencryptionInfoProto& ZoneEncryptionInfoProto::reencryptionproto() const {
  const ::hadoop::hdfs::ReencryptionInfoProto* p = reencryptionproto_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ZoneEncryptionInfoProto.reencryptionProto)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::ReencryptionInfoProto*>(
      &::hadoop::hdfs::_ReencryptionInfoProto_default_instance_);
}
inline ::hadoop::hdfs::ReencryptionInfoProto* ZoneEncryptionInfoProto::release_reencryptionproto() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.ZoneEncryptionInfoProto.reencryptionProto)
  clear_has_reencryptionproto();
  ::hadoop::hdfs::ReencryptionInfoProto* temp = reencryptionproto_;
  reencryptionproto_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::ReencryptionInfoProto* ZoneEncryptionInfoProto::mutable_reencryptionproto() {
  set_has_reencryptionproto();
  if (reencryptionproto_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::ReencryptionInfoProto>(GetArenaNoVirtual());
    reencryptionproto_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.ZoneEncryptionInfoProto.reencryptionProto)
  return reencryptionproto_;
}
inline void ZoneEncryptionInfoProto::set_allocated_reencryptionproto(::hadoop::hdfs::ReencryptionInfoProto* reencryptionproto) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete reencryptionproto_;
  }
  if (reencryptionproto) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      reencryptionproto = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, reencryptionproto, submessage_arena);
    }
    set_has_reencryptionproto();
  } else {
    clear_has_reencryptionproto();
  }
  reencryptionproto_ = reencryptionproto;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.ZoneEncryptionInfoProto.reencryptionProto)
}

// -------------------------------------------------------------------

// ReencryptionInfoProto

// required string ezKeyVersionName = 1;
inline bool ReencryptionInfoProto::has_ezkeyversionname() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ReencryptionInfoProto::set_has_ezkeyversionname() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ReencryptionInfoProto::clear_has_ezkeyversionname() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ReencryptionInfoProto::clear_ezkeyversionname() {
  ezkeyversionname_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_ezkeyversionname();
}
inline const ::std::string& ReencryptionInfoProto::ezkeyversionname() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ReencryptionInfoProto.ezKeyVersionName)
  return ezkeyversionname_.GetNoArena();
}
inline void ReencryptionInfoProto::set_ezkeyversionname(const ::std::string& value) {
  set_has_ezkeyversionname();
  ezkeyversionname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ReencryptionInfoProto.ezKeyVersionName)
}
#if LANG_CXX11
inline void ReencryptionInfoProto::set_ezkeyversionname(::std::string&& value) {
  set_has_ezkeyversionname();
  ezkeyversionname_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.ReencryptionInfoProto.ezKeyVersionName)
}
#endif
inline void ReencryptionInfoProto::set_ezkeyversionname(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_ezkeyversionname();
  ezkeyversionname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.ReencryptionInfoProto.ezKeyVersionName)
}
inline void ReencryptionInfoProto::set_ezkeyversionname(const char* value, size_t size) {
  set_has_ezkeyversionname();
  ezkeyversionname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.ReencryptionInfoProto.ezKeyVersionName)
}
inline ::std::string* ReencryptionInfoProto::mutable_ezkeyversionname() {
  set_has_ezkeyversionname();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.ReencryptionInfoProto.ezKeyVersionName)
  return ezkeyversionname_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* ReencryptionInfoProto::release_ezkeyversionname() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.ReencryptionInfoProto.ezKeyVersionName)
  if (!has_ezkeyversionname()) {
    return NULL;
  }
  clear_has_ezkeyversionname();
  return ezkeyversionname_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void ReencryptionInfoProto::set_allocated_ezkeyversionname(::std::string* ezkeyversionname) {
  if (ezkeyversionname != NULL) {
    set_has_ezkeyversionname();
  } else {
    clear_has_ezkeyversionname();
  }
  ezkeyversionname_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ezkeyversionname);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.ReencryptionInfoProto.ezKeyVersionName)
}

// required uint64 submissionTime = 2;
inline bool ReencryptionInfoProto::has_submissiontime() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void ReencryptionInfoProto::set_has_submissiontime() {
  _has_bits_[0] |= 0x00000004u;
}
inline void ReencryptionInfoProto::clear_has_submissiontime() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void ReencryptionInfoProto::clear_submissiontime() {
  submissiontime_ = GOOGLE_ULONGLONG(0);
  clear_has_submissiontime();
}
inline ::google::protobuf::uint64 ReencryptionInfoProto::submissiontime() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ReencryptionInfoProto.submissionTime)
  return submissiontime_;
}
inline void ReencryptionInfoProto::set_submissiontime(::google::protobuf::uint64 value) {
  set_has_submissiontime();
  submissiontime_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ReencryptionInfoProto.submissionTime)
}

// required bool canceled = 3;
inline bool ReencryptionInfoProto::has_canceled() const {
  return (_has_bits_[0] & 0x00000040u) != 0;
}
inline void ReencryptionInfoProto::set_has_canceled() {
  _has_bits_[0] |= 0x00000040u;
}
inline void ReencryptionInfoProto::clear_has_canceled() {
  _has_bits_[0] &= ~0x00000040u;
}
inline void ReencryptionInfoProto::clear_canceled() {
  canceled_ = false;
  clear_has_canceled();
}
inline bool ReencryptionInfoProto::canceled() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ReencryptionInfoProto.canceled)
  return canceled_;
}
inline void ReencryptionInfoProto::set_canceled(bool value) {
  set_has_canceled();
  canceled_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ReencryptionInfoProto.canceled)
}

// required int64 numReencrypted = 4;
inline bool ReencryptionInfoProto::has_numreencrypted() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void ReencryptionInfoProto::set_has_numreencrypted() {
  _has_bits_[0] |= 0x00000008u;
}
inline void ReencryptionInfoProto::clear_has_numreencrypted() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void ReencryptionInfoProto::clear_numreencrypted() {
  numreencrypted_ = GOOGLE_LONGLONG(0);
  clear_has_numreencrypted();
}
inline ::google::protobuf::int64 ReencryptionInfoProto::numreencrypted() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ReencryptionInfoProto.numReencrypted)
  return numreencrypted_;
}
inline void ReencryptionInfoProto::set_numreencrypted(::google::protobuf::int64 value) {
  set_has_numreencrypted();
  numreencrypted_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ReencryptionInfoProto.numReencrypted)
}

// required int64 numFailures = 5;
inline bool ReencryptionInfoProto::has_numfailures() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void ReencryptionInfoProto::set_has_numfailures() {
  _has_bits_[0] |= 0x00000010u;
}
inline void ReencryptionInfoProto::clear_has_numfailures() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void ReencryptionInfoProto::clear_numfailures() {
  numfailures_ = GOOGLE_LONGLONG(0);
  clear_has_numfailures();
}
inline ::google::protobuf::int64 ReencryptionInfoProto::numfailures() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ReencryptionInfoProto.numFailures)
  return numfailures_;
}
inline void ReencryptionInfoProto::set_numfailures(::google::protobuf::int64 value) {
  set_has_numfailures();
  numfailures_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ReencryptionInfoProto.numFailures)
}

// optional uint64 completionTime = 6;
inline bool ReencryptionInfoProto::has_completiontime() const {
  return (_has_bits_[0] & 0x00000020u) != 0;
}
inline void ReencryptionInfoProto::set_has_completiontime() {
  _has_bits_[0] |= 0x00000020u;
}
inline void ReencryptionInfoProto::clear_has_completiontime() {
  _has_bits_[0] &= ~0x00000020u;
}
inline void ReencryptionInfoProto::clear_completiontime() {
  completiontime_ = GOOGLE_ULONGLONG(0);
  clear_has_completiontime();
}
inline ::google::protobuf::uint64 ReencryptionInfoProto::completiontime() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ReencryptionInfoProto.completionTime)
  return completiontime_;
}
inline void ReencryptionInfoProto::set_completiontime(::google::protobuf::uint64 value) {
  set_has_completiontime();
  completiontime_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ReencryptionInfoProto.completionTime)
}

// optional string lastFile = 7;
inline bool ReencryptionInfoProto::has_lastfile() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ReencryptionInfoProto::set_has_lastfile() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ReencryptionInfoProto::clear_has_lastfile() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ReencryptionInfoProto::clear_lastfile() {
  lastfile_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_lastfile();
}
inline const ::std::string& ReencryptionInfoProto::lastfile() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ReencryptionInfoProto.lastFile)
  return lastfile_.GetNoArena();
}
inline void ReencryptionInfoProto::set_lastfile(const ::std::string& value) {
  set_has_lastfile();
  lastfile_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ReencryptionInfoProto.lastFile)
}
#if LANG_CXX11
inline void ReencryptionInfoProto::set_lastfile(::std::string&& value) {
  set_has_lastfile();
  lastfile_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.ReencryptionInfoProto.lastFile)
}
#endif
inline void ReencryptionInfoProto::set_lastfile(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_lastfile();
  lastfile_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.ReencryptionInfoProto.lastFile)
}
inline void ReencryptionInfoProto::set_lastfile(const char* value, size_t size) {
  set_has_lastfile();
  lastfile_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.ReencryptionInfoProto.lastFile)
}
inline ::std::string* ReencryptionInfoProto::mutable_lastfile() {
  set_has_lastfile();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.ReencryptionInfoProto.lastFile)
  return lastfile_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* ReencryptionInfoProto::release_lastfile() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.ReencryptionInfoProto.lastFile)
  if (!has_lastfile()) {
    return NULL;
  }
  clear_has_lastfile();
  return lastfile_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void ReencryptionInfoProto::set_allocated_lastfile(::std::string* lastfile) {
  if (lastfile != NULL) {
    set_has_lastfile();
  } else {
    clear_has_lastfile();
  }
  lastfile_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), lastfile);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.ReencryptionInfoProto.lastFile)
}

// -------------------------------------------------------------------

// CipherOptionProto

// required .hadoop.hdfs.CipherSuiteProto suite = 1;
inline bool CipherOptionProto::has_suite() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void CipherOptionProto::set_has_suite() {
  _has_bits_[0] |= 0x00000010u;
}
inline void CipherOptionProto::clear_has_suite() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void CipherOptionProto::clear_suite() {
  suite_ = 1;
  clear_has_suite();
}
inline ::hadoop::hdfs::CipherSuiteProto CipherOptionProto::suite() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.CipherOptionProto.suite)
  return static_cast< ::hadoop::hdfs::CipherSuiteProto >(suite_);
}
inline void CipherOptionProto::set_suite(::hadoop::hdfs::CipherSuiteProto value) {
  assert(::hadoop::hdfs::CipherSuiteProto_IsValid(value));
  set_has_suite();
  suite_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.CipherOptionProto.suite)
}

// optional bytes inKey = 2;
inline bool CipherOptionProto::has_inkey() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void CipherOptionProto::set_has_inkey() {
  _has_bits_[0] |= 0x00000001u;
}
inline void CipherOptionProto::clear_has_inkey() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void CipherOptionProto::clear_inkey() {
  inkey_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_inkey();
}
inline const ::std::string& CipherOptionProto::inkey() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.CipherOptionProto.inKey)
  return inkey_.GetNoArena();
}
inline void CipherOptionProto::set_inkey(const ::std::string& value) {
  set_has_inkey();
  inkey_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.CipherOptionProto.inKey)
}
#if LANG_CXX11
inline void CipherOptionProto::set_inkey(::std::string&& value) {
  set_has_inkey();
  inkey_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.CipherOptionProto.inKey)
}
#endif
inline void CipherOptionProto::set_inkey(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_inkey();
  inkey_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.CipherOptionProto.inKey)
}
inline void CipherOptionProto::set_inkey(const void* value, size_t size) {
  set_has_inkey();
  inkey_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.CipherOptionProto.inKey)
}
inline ::std::string* CipherOptionProto::mutable_inkey() {
  set_has_inkey();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.CipherOptionProto.inKey)
  return inkey_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* CipherOptionProto::release_inkey() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.CipherOptionProto.inKey)
  if (!has_inkey()) {
    return NULL;
  }
  clear_has_inkey();
  return inkey_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void CipherOptionProto::set_allocated_inkey(::std::string* inkey) {
  if (inkey != NULL) {
    set_has_inkey();
  } else {
    clear_has_inkey();
  }
  inkey_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), inkey);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.CipherOptionProto.inKey)
}

// optional bytes inIv = 3;
inline bool CipherOptionProto::has_iniv() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void CipherOptionProto::set_has_iniv() {
  _has_bits_[0] |= 0x00000002u;
}
inline void CipherOptionProto::clear_has_iniv() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void CipherOptionProto::clear_iniv() {
  iniv_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_iniv();
}
inline const ::std::string& CipherOptionProto::iniv() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.CipherOptionProto.inIv)
  return iniv_.GetNoArena();
}
inline void CipherOptionProto::set_iniv(const ::std::string& value) {
  set_has_iniv();
  iniv_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.CipherOptionProto.inIv)
}
#if LANG_CXX11
inline void CipherOptionProto::set_iniv(::std::string&& value) {
  set_has_iniv();
  iniv_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.CipherOptionProto.inIv)
}
#endif
inline void CipherOptionProto::set_iniv(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_iniv();
  iniv_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.CipherOptionProto.inIv)
}
inline void CipherOptionProto::set_iniv(const void* value, size_t size) {
  set_has_iniv();
  iniv_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.CipherOptionProto.inIv)
}
inline ::std::string* CipherOptionProto::mutable_iniv() {
  set_has_iniv();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.CipherOptionProto.inIv)
  return iniv_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* CipherOptionProto::release_iniv() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.CipherOptionProto.inIv)
  if (!has_iniv()) {
    return NULL;
  }
  clear_has_iniv();
  return iniv_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void CipherOptionProto::set_allocated_iniv(::std::string* iniv) {
  if (iniv != NULL) {
    set_has_iniv();
  } else {
    clear_has_iniv();
  }
  iniv_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), iniv);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.CipherOptionProto.inIv)
}

// optional bytes outKey = 4;
inline bool CipherOptionProto::has_outkey() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void CipherOptionProto::set_has_outkey() {
  _has_bits_[0] |= 0x00000004u;
}
inline void CipherOptionProto::clear_has_outkey() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void CipherOptionProto::clear_outkey() {
  outkey_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_outkey();
}
inline const ::std::string& CipherOptionProto::outkey() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.CipherOptionProto.outKey)
  return outkey_.GetNoArena();
}
inline void CipherOptionProto::set_outkey(const ::std::string& value) {
  set_has_outkey();
  outkey_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.CipherOptionProto.outKey)
}
#if LANG_CXX11
inline void CipherOptionProto::set_outkey(::std::string&& value) {
  set_has_outkey();
  outkey_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.CipherOptionProto.outKey)
}
#endif
inline void CipherOptionProto::set_outkey(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_outkey();
  outkey_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.CipherOptionProto.outKey)
}
inline void CipherOptionProto::set_outkey(const void* value, size_t size) {
  set_has_outkey();
  outkey_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.CipherOptionProto.outKey)
}
inline ::std::string* CipherOptionProto::mutable_outkey() {
  set_has_outkey();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.CipherOptionProto.outKey)
  return outkey_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* CipherOptionProto::release_outkey() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.CipherOptionProto.outKey)
  if (!has_outkey()) {
    return NULL;
  }
  clear_has_outkey();
  return outkey_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void CipherOptionProto::set_allocated_outkey(::std::string* outkey) {
  if (outkey != NULL) {
    set_has_outkey();
  } else {
    clear_has_outkey();
  }
  outkey_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), outkey);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.CipherOptionProto.outKey)
}

// optional bytes outIv = 5;
inline bool CipherOptionProto::has_outiv() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void CipherOptionProto::set_has_outiv() {
  _has_bits_[0] |= 0x00000008u;
}
inline void CipherOptionProto::clear_has_outiv() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void CipherOptionProto::clear_outiv() {
  outiv_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_outiv();
}
inline const ::std::string& CipherOptionProto::outiv() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.CipherOptionProto.outIv)
  return outiv_.GetNoArena();
}
inline void CipherOptionProto::set_outiv(const ::std::string& value) {
  set_has_outiv();
  outiv_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.CipherOptionProto.outIv)
}
#if LANG_CXX11
inline void CipherOptionProto::set_outiv(::std::string&& value) {
  set_has_outiv();
  outiv_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.CipherOptionProto.outIv)
}
#endif
inline void CipherOptionProto::set_outiv(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_outiv();
  outiv_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.CipherOptionProto.outIv)
}
inline void CipherOptionProto::set_outiv(const void* value, size_t size) {
  set_has_outiv();
  outiv_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.CipherOptionProto.outIv)
}
inline ::std::string* CipherOptionProto::mutable_outiv() {
  set_has_outiv();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.CipherOptionProto.outIv)
  return outiv_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* CipherOptionProto::release_outiv() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.CipherOptionProto.outIv)
  if (!has_outiv()) {
    return NULL;
  }
  clear_has_outiv();
  return outiv_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void CipherOptionProto::set_allocated_outiv(::std::string* outiv) {
  if (outiv != NULL) {
    set_has_outiv();
  } else {
    clear_has_outiv();
  }
  outiv_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), outiv);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.CipherOptionProto.outIv)
}

// -------------------------------------------------------------------

// LocatedBlocksProto

// required uint64 fileLength = 1;
inline bool LocatedBlocksProto::has_filelength() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void LocatedBlocksProto::set_has_filelength() {
  _has_bits_[0] |= 0x00000008u;
}
inline void LocatedBlocksProto::clear_has_filelength() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void LocatedBlocksProto::clear_filelength() {
  filelength_ = GOOGLE_ULONGLONG(0);
  clear_has_filelength();
}
inline ::google::protobuf::uint64 LocatedBlocksProto::filelength() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.LocatedBlocksProto.fileLength)
  return filelength_;
}
inline void LocatedBlocksProto::set_filelength(::google::protobuf::uint64 value) {
  set_has_filelength();
  filelength_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.LocatedBlocksProto.fileLength)
}

// repeated .hadoop.hdfs.LocatedBlockProto blocks = 2;
inline int LocatedBlocksProto::blocks_size() const {
  return blocks_.size();
}
inline void LocatedBlocksProto::clear_blocks() {
  blocks_.Clear();
}
inline ::hadoop::hdfs::LocatedBlockProto* LocatedBlocksProto::mutable_blocks(int index) {
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.LocatedBlocksProto.blocks)
  return blocks_.Mutable(index);
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::LocatedBlockProto >*
LocatedBlocksProto::mutable_blocks() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.LocatedBlocksProto.blocks)
  return &blocks_;
}
inline const ::hadoop::hdfs::LocatedBlockProto& LocatedBlocksProto::blocks(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.LocatedBlocksProto.blocks)
  return blocks_.Get(index);
}
inline ::hadoop::hdfs::LocatedBlockProto* LocatedBlocksProto::add_blocks() {
  // @@protoc_insertion_point(field_add:hadoop.hdfs.LocatedBlocksProto.blocks)
  return blocks_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::LocatedBlockProto >&
LocatedBlocksProto::blocks() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.LocatedBlocksProto.blocks)
  return blocks_;
}

// required bool underConstruction = 3;
inline bool LocatedBlocksProto::has_underconstruction() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void LocatedBlocksProto::set_has_underconstruction() {
  _has_bits_[0] |= 0x00000010u;
}
inline void LocatedBlocksProto::clear_has_underconstruction() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void LocatedBlocksProto::clear_underconstruction() {
  underconstruction_ = false;
  clear_has_underconstruction();
}
inline bool LocatedBlocksProto::underconstruction() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.LocatedBlocksProto.underConstruction)
  return underconstruction_;
}
inline void LocatedBlocksProto::set_underconstruction(bool value) {
  set_has_underconstruction();
  underconstruction_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.LocatedBlocksProto.underConstruction)
}

// optional .hadoop.hdfs.LocatedBlockProto lastBlock = 4;
inline bool LocatedBlocksProto::has_lastblock() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void LocatedBlocksProto::set_has_lastblock() {
  _has_bits_[0] |= 0x00000001u;
}
inline void LocatedBlocksProto::clear_has_lastblock() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void LocatedBlocksProto::clear_lastblock() {
  if (lastblock_ != NULL) lastblock_->Clear();
  clear_has_lastblock();
}
inline const ::hadoop::hdfs::LocatedBlockProto& LocatedBlocksProto::_internal_lastblock() const {
  return *lastblock_;
}
inline const ::hadoop::hdfs::LocatedBlockProto& LocatedBlocksProto::lastblock() const {
  const ::hadoop::hdfs::LocatedBlockProto* p = lastblock_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.LocatedBlocksProto.lastBlock)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::LocatedBlockProto*>(
      &::hadoop::hdfs::_LocatedBlockProto_default_instance_);
}
inline ::hadoop::hdfs::LocatedBlockProto* LocatedBlocksProto::release_lastblock() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.LocatedBlocksProto.lastBlock)
  clear_has_lastblock();
  ::hadoop::hdfs::LocatedBlockProto* temp = lastblock_;
  lastblock_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::LocatedBlockProto* LocatedBlocksProto::mutable_lastblock() {
  set_has_lastblock();
  if (lastblock_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::LocatedBlockProto>(GetArenaNoVirtual());
    lastblock_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.LocatedBlocksProto.lastBlock)
  return lastblock_;
}
inline void LocatedBlocksProto::set_allocated_lastblock(::hadoop::hdfs::LocatedBlockProto* lastblock) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete lastblock_;
  }
  if (lastblock) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      lastblock = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, lastblock, submessage_arena);
    }
    set_has_lastblock();
  } else {
    clear_has_lastblock();
  }
  lastblock_ = lastblock;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.LocatedBlocksProto.lastBlock)
}

// required bool isLastBlockComplete = 5;
inline bool LocatedBlocksProto::has_islastblockcomplete() const {
  return (_has_bits_[0] & 0x00000020u) != 0;
}
inline void LocatedBlocksProto::set_has_islastblockcomplete() {
  _has_bits_[0] |= 0x00000020u;
}
inline void LocatedBlocksProto::clear_has_islastblockcomplete() {
  _has_bits_[0] &= ~0x00000020u;
}
inline void LocatedBlocksProto::clear_islastblockcomplete() {
  islastblockcomplete_ = false;
  clear_has_islastblockcomplete();
}
inline bool LocatedBlocksProto::islastblockcomplete() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.LocatedBlocksProto.isLastBlockComplete)
  return islastblockcomplete_;
}
inline void LocatedBlocksProto::set_islastblockcomplete(bool value) {
  set_has_islastblockcomplete();
  islastblockcomplete_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.LocatedBlocksProto.isLastBlockComplete)
}

// optional .hadoop.hdfs.FileEncryptionInfoProto fileEncryptionInfo = 6;
inline bool LocatedBlocksProto::has_fileencryptioninfo() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void LocatedBlocksProto::set_has_fileencryptioninfo() {
  _has_bits_[0] |= 0x00000002u;
}
inline void LocatedBlocksProto::clear_has_fileencryptioninfo() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void LocatedBlocksProto::clear_fileencryptioninfo() {
  if (fileencryptioninfo_ != NULL) fileencryptioninfo_->Clear();
  clear_has_fileencryptioninfo();
}
inline const ::hadoop::hdfs::FileEncryptionInfoProto& LocatedBlocksProto::_internal_fileencryptioninfo() const {
  return *fileencryptioninfo_;
}
inline const ::hadoop::hdfs::FileEncryptionInfoProto& LocatedBlocksProto::fileencryptioninfo() const {
  const ::hadoop::hdfs::FileEncryptionInfoProto* p = fileencryptioninfo_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.LocatedBlocksProto.fileEncryptionInfo)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::FileEncryptionInfoProto*>(
      &::hadoop::hdfs::_FileEncryptionInfoProto_default_instance_);
}
inline ::hadoop::hdfs::FileEncryptionInfoProto* LocatedBlocksProto::release_fileencryptioninfo() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.LocatedBlocksProto.fileEncryptionInfo)
  clear_has_fileencryptioninfo();
  ::hadoop::hdfs::FileEncryptionInfoProto* temp = fileencryptioninfo_;
  fileencryptioninfo_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::FileEncryptionInfoProto* LocatedBlocksProto::mutable_fileencryptioninfo() {
  set_has_fileencryptioninfo();
  if (fileencryptioninfo_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::FileEncryptionInfoProto>(GetArenaNoVirtual());
    fileencryptioninfo_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.LocatedBlocksProto.fileEncryptionInfo)
  return fileencryptioninfo_;
}
inline void LocatedBlocksProto::set_allocated_fileencryptioninfo(::hadoop::hdfs::FileEncryptionInfoProto* fileencryptioninfo) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete fileencryptioninfo_;
  }
  if (fileencryptioninfo) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      fileencryptioninfo = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, fileencryptioninfo, submessage_arena);
    }
    set_has_fileencryptioninfo();
  } else {
    clear_has_fileencryptioninfo();
  }
  fileencryptioninfo_ = fileencryptioninfo;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.LocatedBlocksProto.fileEncryptionInfo)
}

// optional .hadoop.hdfs.ErasureCodingPolicyProto ecPolicy = 7;
inline bool LocatedBlocksProto::has_ecpolicy() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void LocatedBlocksProto::set_has_ecpolicy() {
  _has_bits_[0] |= 0x00000004u;
}
inline void LocatedBlocksProto::clear_has_ecpolicy() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void LocatedBlocksProto::clear_ecpolicy() {
  if (ecpolicy_ != NULL) ecpolicy_->Clear();
  clear_has_ecpolicy();
}
inline const ::hadoop::hdfs::ErasureCodingPolicyProto& LocatedBlocksProto::_internal_ecpolicy() const {
  return *ecpolicy_;
}
inline const ::hadoop::hdfs::ErasureCodingPolicyProto& LocatedBlocksProto::ecpolicy() const {
  const ::hadoop::hdfs::ErasureCodingPolicyProto* p = ecpolicy_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.LocatedBlocksProto.ecPolicy)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::ErasureCodingPolicyProto*>(
      &::hadoop::hdfs::_ErasureCodingPolicyProto_default_instance_);
}
inline ::hadoop::hdfs::ErasureCodingPolicyProto* LocatedBlocksProto::release_ecpolicy() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.LocatedBlocksProto.ecPolicy)
  clear_has_ecpolicy();
  ::hadoop::hdfs::ErasureCodingPolicyProto* temp = ecpolicy_;
  ecpolicy_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::ErasureCodingPolicyProto* LocatedBlocksProto::mutable_ecpolicy() {
  set_has_ecpolicy();
  if (ecpolicy_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::ErasureCodingPolicyProto>(GetArenaNoVirtual());
    ecpolicy_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.LocatedBlocksProto.ecPolicy)
  return ecpolicy_;
}
inline void LocatedBlocksProto::set_allocated_ecpolicy(::hadoop::hdfs::ErasureCodingPolicyProto* ecpolicy) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete ecpolicy_;
  }
  if (ecpolicy) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      ecpolicy = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, ecpolicy, submessage_arena);
    }
    set_has_ecpolicy();
  } else {
    clear_has_ecpolicy();
  }
  ecpolicy_ = ecpolicy;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.LocatedBlocksProto.ecPolicy)
}

// -------------------------------------------------------------------

// ECSchemaOptionEntryProto

// required string key = 1;
inline bool ECSchemaOptionEntryProto::has_key() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ECSchemaOptionEntryProto::set_has_key() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ECSchemaOptionEntryProto::clear_has_key() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ECSchemaOptionEntryProto::clear_key() {
  key_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_key();
}
inline const ::std::string& ECSchemaOptionEntryProto::key() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ECSchemaOptionEntryProto.key)
  return key_.GetNoArena();
}
inline void ECSchemaOptionEntryProto::set_key(const ::std::string& value) {
  set_has_key();
  key_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ECSchemaOptionEntryProto.key)
}
#if LANG_CXX11
inline void ECSchemaOptionEntryProto::set_key(::std::string&& value) {
  set_has_key();
  key_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.ECSchemaOptionEntryProto.key)
}
#endif
inline void ECSchemaOptionEntryProto::set_key(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_key();
  key_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.ECSchemaOptionEntryProto.key)
}
inline void ECSchemaOptionEntryProto::set_key(const char* value, size_t size) {
  set_has_key();
  key_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.ECSchemaOptionEntryProto.key)
}
inline ::std::string* ECSchemaOptionEntryProto::mutable_key() {
  set_has_key();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.ECSchemaOptionEntryProto.key)
  return key_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* ECSchemaOptionEntryProto::release_key() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.ECSchemaOptionEntryProto.key)
  if (!has_key()) {
    return NULL;
  }
  clear_has_key();
  return key_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void ECSchemaOptionEntryProto::set_allocated_key(::std::string* key) {
  if (key != NULL) {
    set_has_key();
  } else {
    clear_has_key();
  }
  key_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), key);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.ECSchemaOptionEntryProto.key)
}

// required string value = 2;
inline bool ECSchemaOptionEntryProto::has_value() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ECSchemaOptionEntryProto::set_has_value() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ECSchemaOptionEntryProto::clear_has_value() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ECSchemaOptionEntryProto::clear_value() {
  value_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_value();
}
inline const ::std::string& ECSchemaOptionEntryProto::value() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ECSchemaOptionEntryProto.value)
  return value_.GetNoArena();
}
inline void ECSchemaOptionEntryProto::set_value(const ::std::string& value) {
  set_has_value();
  value_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ECSchemaOptionEntryProto.value)
}
#if LANG_CXX11
inline void ECSchemaOptionEntryProto::set_value(::std::string&& value) {
  set_has_value();
  value_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.ECSchemaOptionEntryProto.value)
}
#endif
inline void ECSchemaOptionEntryProto::set_value(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_value();
  value_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.ECSchemaOptionEntryProto.value)
}
inline void ECSchemaOptionEntryProto::set_value(const char* value, size_t size) {
  set_has_value();
  value_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.ECSchemaOptionEntryProto.value)
}
inline ::std::string* ECSchemaOptionEntryProto::mutable_value() {
  set_has_value();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.ECSchemaOptionEntryProto.value)
  return value_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* ECSchemaOptionEntryProto::release_value() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.ECSchemaOptionEntryProto.value)
  if (!has_value()) {
    return NULL;
  }
  clear_has_value();
  return value_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void ECSchemaOptionEntryProto::set_allocated_value(::std::string* value) {
  if (value != NULL) {
    set_has_value();
  } else {
    clear_has_value();
  }
  value_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.ECSchemaOptionEntryProto.value)
}

// -------------------------------------------------------------------

// ECSchemaProto

// required string codecName = 1;
inline bool ECSchemaProto::has_codecname() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ECSchemaProto::set_has_codecname() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ECSchemaProto::clear_has_codecname() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ECSchemaProto::clear_codecname() {
  codecname_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_codecname();
}
inline const ::std::string& ECSchemaProto::codecname() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ECSchemaProto.codecName)
  return codecname_.GetNoArena();
}
inline void ECSchemaProto::set_codecname(const ::std::string& value) {
  set_has_codecname();
  codecname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ECSchemaProto.codecName)
}
#if LANG_CXX11
inline void ECSchemaProto::set_codecname(::std::string&& value) {
  set_has_codecname();
  codecname_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.ECSchemaProto.codecName)
}
#endif
inline void ECSchemaProto::set_codecname(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_codecname();
  codecname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.ECSchemaProto.codecName)
}
inline void ECSchemaProto::set_codecname(const char* value, size_t size) {
  set_has_codecname();
  codecname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.ECSchemaProto.codecName)
}
inline ::std::string* ECSchemaProto::mutable_codecname() {
  set_has_codecname();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.ECSchemaProto.codecName)
  return codecname_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* ECSchemaProto::release_codecname() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.ECSchemaProto.codecName)
  if (!has_codecname()) {
    return NULL;
  }
  clear_has_codecname();
  return codecname_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void ECSchemaProto::set_allocated_codecname(::std::string* codecname) {
  if (codecname != NULL) {
    set_has_codecname();
  } else {
    clear_has_codecname();
  }
  codecname_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), codecname);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.ECSchemaProto.codecName)
}

// required uint32 dataUnits = 2;
inline bool ECSchemaProto::has_dataunits() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ECSchemaProto::set_has_dataunits() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ECSchemaProto::clear_has_dataunits() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ECSchemaProto::clear_dataunits() {
  dataunits_ = 0u;
  clear_has_dataunits();
}
inline ::google::protobuf::uint32 ECSchemaProto::dataunits() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ECSchemaProto.dataUnits)
  return dataunits_;
}
inline void ECSchemaProto::set_dataunits(::google::protobuf::uint32 value) {
  set_has_dataunits();
  dataunits_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ECSchemaProto.dataUnits)
}

// required uint32 parityUnits = 3;
inline bool ECSchemaProto::has_parityunits() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void ECSchemaProto::set_has_parityunits() {
  _has_bits_[0] |= 0x00000004u;
}
inline void ECSchemaProto::clear_has_parityunits() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void ECSchemaProto::clear_parityunits() {
  parityunits_ = 0u;
  clear_has_parityunits();
}
inline ::google::protobuf::uint32 ECSchemaProto::parityunits() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ECSchemaProto.parityUnits)
  return parityunits_;
}
inline void ECSchemaProto::set_parityunits(::google::protobuf::uint32 value) {
  set_has_parityunits();
  parityunits_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ECSchemaProto.parityUnits)
}

// repeated .hadoop.hdfs.ECSchemaOptionEntryProto options = 4;
inline int ECSchemaProto::options_size() const {
  return options_.size();
}
inline void ECSchemaProto::clear_options() {
  options_.Clear();
}
inline ::hadoop::hdfs::ECSchemaOptionEntryProto* ECSchemaProto::mutable_options(int index) {
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.ECSchemaProto.options)
  return options_.Mutable(index);
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::ECSchemaOptionEntryProto >*
ECSchemaProto::mutable_options() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.ECSchemaProto.options)
  return &options_;
}
inline const ::hadoop::hdfs::ECSchemaOptionEntryProto& ECSchemaProto::options(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ECSchemaProto.options)
  return options_.Get(index);
}
inline ::hadoop::hdfs::ECSchemaOptionEntryProto* ECSchemaProto::add_options() {
  // @@protoc_insertion_point(field_add:hadoop.hdfs.ECSchemaProto.options)
  return options_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::ECSchemaOptionEntryProto >&
ECSchemaProto::options() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.ECSchemaProto.options)
  return options_;
}

// -------------------------------------------------------------------

// ErasureCodingPolicyProto

// optional string name = 1;
inline bool ErasureCodingPolicyProto::has_name() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ErasureCodingPolicyProto::set_has_name() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ErasureCodingPolicyProto::clear_has_name() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ErasureCodingPolicyProto::clear_name() {
  name_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_name();
}
inline const ::std::string& ErasureCodingPolicyProto::name() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ErasureCodingPolicyProto.name)
  return name_.GetNoArena();
}
inline void ErasureCodingPolicyProto::set_name(const ::std::string& value) {
  set_has_name();
  name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ErasureCodingPolicyProto.name)
}
#if LANG_CXX11
inline void ErasureCodingPolicyProto::set_name(::std::string&& value) {
  set_has_name();
  name_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.ErasureCodingPolicyProto.name)
}
#endif
inline void ErasureCodingPolicyProto::set_name(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_name();
  name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.ErasureCodingPolicyProto.name)
}
inline void ErasureCodingPolicyProto::set_name(const char* value, size_t size) {
  set_has_name();
  name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.ErasureCodingPolicyProto.name)
}
inline ::std::string* ErasureCodingPolicyProto::mutable_name() {
  set_has_name();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.ErasureCodingPolicyProto.name)
  return name_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* ErasureCodingPolicyProto::release_name() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.ErasureCodingPolicyProto.name)
  if (!has_name()) {
    return NULL;
  }
  clear_has_name();
  return name_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void ErasureCodingPolicyProto::set_allocated_name(::std::string* name) {
  if (name != NULL) {
    set_has_name();
  } else {
    clear_has_name();
  }
  name_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), name);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.ErasureCodingPolicyProto.name)
}

// optional .hadoop.hdfs.ECSchemaProto schema = 2;
inline bool ErasureCodingPolicyProto::has_schema() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ErasureCodingPolicyProto::set_has_schema() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ErasureCodingPolicyProto::clear_has_schema() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ErasureCodingPolicyProto::clear_schema() {
  if (schema_ != NULL) schema_->Clear();
  clear_has_schema();
}
inline const ::hadoop::hdfs::ECSchemaProto& ErasureCodingPolicyProto::_internal_schema() const {
  return *schema_;
}
inline const ::hadoop::hdfs::ECSchemaProto& ErasureCodingPolicyProto::schema() const {
  const ::hadoop::hdfs::ECSchemaProto* p = schema_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ErasureCodingPolicyProto.schema)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::ECSchemaProto*>(
      &::hadoop::hdfs::_ECSchemaProto_default_instance_);
}
inline ::hadoop::hdfs::ECSchemaProto* ErasureCodingPolicyProto::release_schema() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.ErasureCodingPolicyProto.schema)
  clear_has_schema();
  ::hadoop::hdfs::ECSchemaProto* temp = schema_;
  schema_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::ECSchemaProto* ErasureCodingPolicyProto::mutable_schema() {
  set_has_schema();
  if (schema_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::ECSchemaProto>(GetArenaNoVirtual());
    schema_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.ErasureCodingPolicyProto.schema)
  return schema_;
}
inline void ErasureCodingPolicyProto::set_allocated_schema(::hadoop::hdfs::ECSchemaProto* schema) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete schema_;
  }
  if (schema) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      schema = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, schema, submessage_arena);
    }
    set_has_schema();
  } else {
    clear_has_schema();
  }
  schema_ = schema;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.ErasureCodingPolicyProto.schema)
}

// optional uint32 cellSize = 3;
inline bool ErasureCodingPolicyProto::has_cellsize() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void ErasureCodingPolicyProto::set_has_cellsize() {
  _has_bits_[0] |= 0x00000004u;
}
inline void ErasureCodingPolicyProto::clear_has_cellsize() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void ErasureCodingPolicyProto::clear_cellsize() {
  cellsize_ = 0u;
  clear_has_cellsize();
}
inline ::google::protobuf::uint32 ErasureCodingPolicyProto::cellsize() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ErasureCodingPolicyProto.cellSize)
  return cellsize_;
}
inline void ErasureCodingPolicyProto::set_cellsize(::google::protobuf::uint32 value) {
  set_has_cellsize();
  cellsize_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ErasureCodingPolicyProto.cellSize)
}

// required uint32 id = 4;
inline bool ErasureCodingPolicyProto::has_id() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void ErasureCodingPolicyProto::set_has_id() {
  _has_bits_[0] |= 0x00000008u;
}
inline void ErasureCodingPolicyProto::clear_has_id() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void ErasureCodingPolicyProto::clear_id() {
  id_ = 0u;
  clear_has_id();
}
inline ::google::protobuf::uint32 ErasureCodingPolicyProto::id() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ErasureCodingPolicyProto.id)
  return id_;
}
inline void ErasureCodingPolicyProto::set_id(::google::protobuf::uint32 value) {
  set_has_id();
  id_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ErasureCodingPolicyProto.id)
}

// optional .hadoop.hdfs.ErasureCodingPolicyState state = 5 [default = ENABLED];
inline bool ErasureCodingPolicyProto::has_state() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void ErasureCodingPolicyProto::set_has_state() {
  _has_bits_[0] |= 0x00000010u;
}
inline void ErasureCodingPolicyProto::clear_has_state() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void ErasureCodingPolicyProto::clear_state() {
  state_ = 2;
  clear_has_state();
}
inline ::hadoop::hdfs::ErasureCodingPolicyState ErasureCodingPolicyProto::state() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ErasureCodingPolicyProto.state)
  return static_cast< ::hadoop::hdfs::ErasureCodingPolicyState >(state_);
}
inline void ErasureCodingPolicyProto::set_state(::hadoop::hdfs::ErasureCodingPolicyState value) {
  assert(::hadoop::hdfs::ErasureCodingPolicyState_IsValid(value));
  set_has_state();
  state_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ErasureCodingPolicyProto.state)
}

// -------------------------------------------------------------------

// AddErasureCodingPolicyResponseProto

// required .hadoop.hdfs.ErasureCodingPolicyProto policy = 1;
inline bool AddErasureCodingPolicyResponseProto::has_policy() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void AddErasureCodingPolicyResponseProto::set_has_policy() {
  _has_bits_[0] |= 0x00000002u;
}
inline void AddErasureCodingPolicyResponseProto::clear_has_policy() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void AddErasureCodingPolicyResponseProto::clear_policy() {
  if (policy_ != NULL) policy_->Clear();
  clear_has_policy();
}
inline const ::hadoop::hdfs::ErasureCodingPolicyProto& AddErasureCodingPolicyResponseProto::_internal_policy() const {
  return *policy_;
}
inline const ::hadoop::hdfs::ErasureCodingPolicyProto& AddErasureCodingPolicyResponseProto::policy() const {
  const ::hadoop::hdfs::ErasureCodingPolicyProto* p = policy_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.AddErasureCodingPolicyResponseProto.policy)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::ErasureCodingPolicyProto*>(
      &::hadoop::hdfs::_ErasureCodingPolicyProto_default_instance_);
}
inline ::hadoop::hdfs::ErasureCodingPolicyProto* AddErasureCodingPolicyResponseProto::release_policy() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.AddErasureCodingPolicyResponseProto.policy)
  clear_has_policy();
  ::hadoop::hdfs::ErasureCodingPolicyProto* temp = policy_;
  policy_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::ErasureCodingPolicyProto* AddErasureCodingPolicyResponseProto::mutable_policy() {
  set_has_policy();
  if (policy_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::ErasureCodingPolicyProto>(GetArenaNoVirtual());
    policy_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.AddErasureCodingPolicyResponseProto.policy)
  return policy_;
}
inline void AddErasureCodingPolicyResponseProto::set_allocated_policy(::hadoop::hdfs::ErasureCodingPolicyProto* policy) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete policy_;
  }
  if (policy) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      policy = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, policy, submessage_arena);
    }
    set_has_policy();
  } else {
    clear_has_policy();
  }
  policy_ = policy;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.AddErasureCodingPolicyResponseProto.policy)
}

// required bool succeed = 2;
inline bool AddErasureCodingPolicyResponseProto::has_succeed() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void AddErasureCodingPolicyResponseProto::set_has_succeed() {
  _has_bits_[0] |= 0x00000004u;
}
inline void AddErasureCodingPolicyResponseProto::clear_has_succeed() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void AddErasureCodingPolicyResponseProto::clear_succeed() {
  succeed_ = false;
  clear_has_succeed();
}
inline bool AddErasureCodingPolicyResponseProto::succeed() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.AddErasureCodingPolicyResponseProto.succeed)
  return succeed_;
}
inline void AddErasureCodingPolicyResponseProto::set_succeed(bool value) {
  set_has_succeed();
  succeed_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.AddErasureCodingPolicyResponseProto.succeed)
}

// optional string errorMsg = 3;
inline bool AddErasureCodingPolicyResponseProto::has_errormsg() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void AddErasureCodingPolicyResponseProto::set_has_errormsg() {
  _has_bits_[0] |= 0x00000001u;
}
inline void AddErasureCodingPolicyResponseProto::clear_has_errormsg() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void AddErasureCodingPolicyResponseProto::clear_errormsg() {
  errormsg_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_errormsg();
}
inline const ::std::string& AddErasureCodingPolicyResponseProto::errormsg() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.AddErasureCodingPolicyResponseProto.errorMsg)
  return errormsg_.GetNoArena();
}
inline void AddErasureCodingPolicyResponseProto::set_errormsg(const ::std::string& value) {
  set_has_errormsg();
  errormsg_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.AddErasureCodingPolicyResponseProto.errorMsg)
}
#if LANG_CXX11
inline void AddErasureCodingPolicyResponseProto::set_errormsg(::std::string&& value) {
  set_has_errormsg();
  errormsg_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.AddErasureCodingPolicyResponseProto.errorMsg)
}
#endif
inline void AddErasureCodingPolicyResponseProto::set_errormsg(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_errormsg();
  errormsg_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.AddErasureCodingPolicyResponseProto.errorMsg)
}
inline void AddErasureCodingPolicyResponseProto::set_errormsg(const char* value, size_t size) {
  set_has_errormsg();
  errormsg_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.AddErasureCodingPolicyResponseProto.errorMsg)
}
inline ::std::string* AddErasureCodingPolicyResponseProto::mutable_errormsg() {
  set_has_errormsg();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.AddErasureCodingPolicyResponseProto.errorMsg)
  return errormsg_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* AddErasureCodingPolicyResponseProto::release_errormsg() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.AddErasureCodingPolicyResponseProto.errorMsg)
  if (!has_errormsg()) {
    return NULL;
  }
  clear_has_errormsg();
  return errormsg_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void AddErasureCodingPolicyResponseProto::set_allocated_errormsg(::std::string* errormsg) {
  if (errormsg != NULL) {
    set_has_errormsg();
  } else {
    clear_has_errormsg();
  }
  errormsg_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), errormsg);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.AddErasureCodingPolicyResponseProto.errorMsg)
}

// -------------------------------------------------------------------

// ECTopologyVerifierResultProto

// required string resultMessage = 1;
inline bool ECTopologyVerifierResultProto::has_resultmessage() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ECTopologyVerifierResultProto::set_has_resultmessage() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ECTopologyVerifierResultProto::clear_has_resultmessage() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ECTopologyVerifierResultProto::clear_resultmessage() {
  resultmessage_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_resultmessage();
}
inline const ::std::string& ECTopologyVerifierResultProto::resultmessage() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ECTopologyVerifierResultProto.resultMessage)
  return resultmessage_.GetNoArena();
}
inline void ECTopologyVerifierResultProto::set_resultmessage(const ::std::string& value) {
  set_has_resultmessage();
  resultmessage_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ECTopologyVerifierResultProto.resultMessage)
}
#if LANG_CXX11
inline void ECTopologyVerifierResultProto::set_resultmessage(::std::string&& value) {
  set_has_resultmessage();
  resultmessage_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.ECTopologyVerifierResultProto.resultMessage)
}
#endif
inline void ECTopologyVerifierResultProto::set_resultmessage(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_resultmessage();
  resultmessage_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.ECTopologyVerifierResultProto.resultMessage)
}
inline void ECTopologyVerifierResultProto::set_resultmessage(const char* value, size_t size) {
  set_has_resultmessage();
  resultmessage_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.ECTopologyVerifierResultProto.resultMessage)
}
inline ::std::string* ECTopologyVerifierResultProto::mutable_resultmessage() {
  set_has_resultmessage();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.ECTopologyVerifierResultProto.resultMessage)
  return resultmessage_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* ECTopologyVerifierResultProto::release_resultmessage() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.ECTopologyVerifierResultProto.resultMessage)
  if (!has_resultmessage()) {
    return NULL;
  }
  clear_has_resultmessage();
  return resultmessage_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void ECTopologyVerifierResultProto::set_allocated_resultmessage(::std::string* resultmessage) {
  if (resultmessage != NULL) {
    set_has_resultmessage();
  } else {
    clear_has_resultmessage();
  }
  resultmessage_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), resultmessage);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.ECTopologyVerifierResultProto.resultMessage)
}

// required bool isSupported = 2;
inline bool ECTopologyVerifierResultProto::has_issupported() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ECTopologyVerifierResultProto::set_has_issupported() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ECTopologyVerifierResultProto::clear_has_issupported() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ECTopologyVerifierResultProto::clear_issupported() {
  issupported_ = false;
  clear_has_issupported();
}
inline bool ECTopologyVerifierResultProto::issupported() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ECTopologyVerifierResultProto.isSupported)
  return issupported_;
}
inline void ECTopologyVerifierResultProto::set_issupported(bool value) {
  set_has_issupported();
  issupported_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ECTopologyVerifierResultProto.isSupported)
}

// -------------------------------------------------------------------

// HdfsPathHandleProto

// optional uint64 inodeId = 1;
inline bool HdfsPathHandleProto::has_inodeid() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void HdfsPathHandleProto::set_has_inodeid() {
  _has_bits_[0] |= 0x00000002u;
}
inline void HdfsPathHandleProto::clear_has_inodeid() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void HdfsPathHandleProto::clear_inodeid() {
  inodeid_ = GOOGLE_ULONGLONG(0);
  clear_has_inodeid();
}
inline ::google::protobuf::uint64 HdfsPathHandleProto::inodeid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.HdfsPathHandleProto.inodeId)
  return inodeid_;
}
inline void HdfsPathHandleProto::set_inodeid(::google::protobuf::uint64 value) {
  set_has_inodeid();
  inodeid_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.HdfsPathHandleProto.inodeId)
}

// optional uint64 mtime = 2;
inline bool HdfsPathHandleProto::has_mtime() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void HdfsPathHandleProto::set_has_mtime() {
  _has_bits_[0] |= 0x00000004u;
}
inline void HdfsPathHandleProto::clear_has_mtime() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void HdfsPathHandleProto::clear_mtime() {
  mtime_ = GOOGLE_ULONGLONG(0);
  clear_has_mtime();
}
inline ::google::protobuf::uint64 HdfsPathHandleProto::mtime() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.HdfsPathHandleProto.mtime)
  return mtime_;
}
inline void HdfsPathHandleProto::set_mtime(::google::protobuf::uint64 value) {
  set_has_mtime();
  mtime_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.HdfsPathHandleProto.mtime)
}

// optional string path = 3;
inline bool HdfsPathHandleProto::has_path() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void HdfsPathHandleProto::set_has_path() {
  _has_bits_[0] |= 0x00000001u;
}
inline void HdfsPathHandleProto::clear_has_path() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void HdfsPathHandleProto::clear_path() {
  path_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_path();
}
inline const ::std::string& HdfsPathHandleProto::path() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.HdfsPathHandleProto.path)
  return path_.GetNoArena();
}
inline void HdfsPathHandleProto::set_path(const ::std::string& value) {
  set_has_path();
  path_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.HdfsPathHandleProto.path)
}
#if LANG_CXX11
inline void HdfsPathHandleProto::set_path(::std::string&& value) {
  set_has_path();
  path_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.HdfsPathHandleProto.path)
}
#endif
inline void HdfsPathHandleProto::set_path(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_path();
  path_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.HdfsPathHandleProto.path)
}
inline void HdfsPathHandleProto::set_path(const char* value, size_t size) {
  set_has_path();
  path_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.HdfsPathHandleProto.path)
}
inline ::std::string* HdfsPathHandleProto::mutable_path() {
  set_has_path();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.HdfsPathHandleProto.path)
  return path_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* HdfsPathHandleProto::release_path() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.HdfsPathHandleProto.path)
  if (!has_path()) {
    return NULL;
  }
  clear_has_path();
  return path_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void HdfsPathHandleProto::set_allocated_path(::std::string* path) {
  if (path != NULL) {
    set_has_path();
  } else {
    clear_has_path();
  }
  path_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), path);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.HdfsPathHandleProto.path)
}

// -------------------------------------------------------------------

// HdfsFileStatusProto

// required .hadoop.hdfs.HdfsFileStatusProto.FileType fileType = 1;
inline bool HdfsFileStatusProto::has_filetype() const {
  return (_has_bits_[0] & 0x00010000u) != 0;
}
inline void HdfsFileStatusProto::set_has_filetype() {
  _has_bits_[0] |= 0x00010000u;
}
inline void HdfsFileStatusProto::clear_has_filetype() {
  _has_bits_[0] &= ~0x00010000u;
}
inline void HdfsFileStatusProto::clear_filetype() {
  filetype_ = 1;
  clear_has_filetype();
}
inline ::hadoop::hdfs::HdfsFileStatusProto_FileType HdfsFileStatusProto::filetype() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.HdfsFileStatusProto.fileType)
  return static_cast< ::hadoop::hdfs::HdfsFileStatusProto_FileType >(filetype_);
}
inline void HdfsFileStatusProto::set_filetype(::hadoop::hdfs::HdfsFileStatusProto_FileType value) {
  assert(::hadoop::hdfs::HdfsFileStatusProto_FileType_IsValid(value));
  set_has_filetype();
  filetype_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.HdfsFileStatusProto.fileType)
}

// required bytes path = 2;
inline bool HdfsFileStatusProto::has_path() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void HdfsFileStatusProto::set_has_path() {
  _has_bits_[0] |= 0x00000001u;
}
inline void HdfsFileStatusProto::clear_has_path() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void HdfsFileStatusProto::clear_path() {
  path_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_path();
}
inline const ::std::string& HdfsFileStatusProto::path() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.HdfsFileStatusProto.path)
  return path_.GetNoArena();
}
inline void HdfsFileStatusProto::set_path(const ::std::string& value) {
  set_has_path();
  path_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.HdfsFileStatusProto.path)
}
#if LANG_CXX11
inline void HdfsFileStatusProto::set_path(::std::string&& value) {
  set_has_path();
  path_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.HdfsFileStatusProto.path)
}
#endif
inline void HdfsFileStatusProto::set_path(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_path();
  path_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.HdfsFileStatusProto.path)
}
inline void HdfsFileStatusProto::set_path(const void* value, size_t size) {
  set_has_path();
  path_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.HdfsFileStatusProto.path)
}
inline ::std::string* HdfsFileStatusProto::mutable_path() {
  set_has_path();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.HdfsFileStatusProto.path)
  return path_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* HdfsFileStatusProto::release_path() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.HdfsFileStatusProto.path)
  if (!has_path()) {
    return NULL;
  }
  clear_has_path();
  return path_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void HdfsFileStatusProto::set_allocated_path(::std::string* path) {
  if (path != NULL) {
    set_has_path();
  } else {
    clear_has_path();
  }
  path_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), path);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.HdfsFileStatusProto.path)
}

// required uint64 length = 3;
inline bool HdfsFileStatusProto::has_length() const {
  return (_has_bits_[0] & 0x00000100u) != 0;
}
inline void HdfsFileStatusProto::set_has_length() {
  _has_bits_[0] |= 0x00000100u;
}
inline void HdfsFileStatusProto::clear_has_length() {
  _has_bits_[0] &= ~0x00000100u;
}
inline void HdfsFileStatusProto::clear_length() {
  length_ = GOOGLE_ULONGLONG(0);
  clear_has_length();
}
inline ::google::protobuf::uint64 HdfsFileStatusProto::length() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.HdfsFileStatusProto.length)
  return length_;
}
inline void HdfsFileStatusProto::set_length(::google::protobuf::uint64 value) {
  set_has_length();
  length_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.HdfsFileStatusProto.length)
}

// required .hadoop.hdfs.FsPermissionProto permission = 4;
inline bool HdfsFileStatusProto::has_permission() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void HdfsFileStatusProto::set_has_permission() {
  _has_bits_[0] |= 0x00000010u;
}
inline void HdfsFileStatusProto::clear_has_permission() {
  _has_bits_[0] &= ~0x00000010u;
}
inline const ::hadoop::hdfs::FsPermissionProto& HdfsFileStatusProto::_internal_permission() const {
  return *permission_;
}
inline const ::hadoop::hdfs::FsPermissionProto& HdfsFileStatusProto::permission() const {
  const ::hadoop::hdfs::FsPermissionProto* p = permission_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.HdfsFileStatusProto.permission)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::FsPermissionProto*>(
      &::hadoop::hdfs::_FsPermissionProto_default_instance_);
}
inline ::hadoop::hdfs::FsPermissionProto* HdfsFileStatusProto::release_permission() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.HdfsFileStatusProto.permission)
  clear_has_permission();
  ::hadoop::hdfs::FsPermissionProto* temp = permission_;
  permission_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::FsPermissionProto* HdfsFileStatusProto::mutable_permission() {
  set_has_permission();
  if (permission_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::FsPermissionProto>(GetArenaNoVirtual());
    permission_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.HdfsFileStatusProto.permission)
  return permission_;
}
inline void HdfsFileStatusProto::set_allocated_permission(::hadoop::hdfs::FsPermissionProto* permission) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete reinterpret_cast< ::google::protobuf::MessageLite*>(permission_);
  }
  if (permission) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      permission = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, permission, submessage_arena);
    }
    set_has_permission();
  } else {
    clear_has_permission();
  }
  permission_ = permission;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.HdfsFileStatusProto.permission)
}

// required string owner = 5;
inline bool HdfsFileStatusProto::has_owner() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void HdfsFileStatusProto::set_has_owner() {
  _has_bits_[0] |= 0x00000002u;
}
inline void HdfsFileStatusProto::clear_has_owner() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void HdfsFileStatusProto::clear_owner() {
  owner_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_owner();
}
inline const ::std::string& HdfsFileStatusProto::owner() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.HdfsFileStatusProto.owner)
  return owner_.GetNoArena();
}
inline void HdfsFileStatusProto::set_owner(const ::std::string& value) {
  set_has_owner();
  owner_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.HdfsFileStatusProto.owner)
}
#if LANG_CXX11
inline void HdfsFileStatusProto::set_owner(::std::string&& value) {
  set_has_owner();
  owner_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.HdfsFileStatusProto.owner)
}
#endif
inline void HdfsFileStatusProto::set_owner(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_owner();
  owner_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.HdfsFileStatusProto.owner)
}
inline void HdfsFileStatusProto::set_owner(const char* value, size_t size) {
  set_has_owner();
  owner_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.HdfsFileStatusProto.owner)
}
inline ::std::string* HdfsFileStatusProto::mutable_owner() {
  set_has_owner();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.HdfsFileStatusProto.owner)
  return owner_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* HdfsFileStatusProto::release_owner() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.HdfsFileStatusProto.owner)
  if (!has_owner()) {
    return NULL;
  }
  clear_has_owner();
  return owner_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void HdfsFileStatusProto::set_allocated_owner(::std::string* owner) {
  if (owner != NULL) {
    set_has_owner();
  } else {
    clear_has_owner();
  }
  owner_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), owner);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.HdfsFileStatusProto.owner)
}

// required string group = 6;
inline bool HdfsFileStatusProto::has_group() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void HdfsFileStatusProto::set_has_group() {
  _has_bits_[0] |= 0x00000004u;
}
inline void HdfsFileStatusProto::clear_has_group() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void HdfsFileStatusProto::clear_group() {
  group_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_group();
}
inline const ::std::string& HdfsFileStatusProto::group() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.HdfsFileStatusProto.group)
  return group_.GetNoArena();
}
inline void HdfsFileStatusProto::set_group(const ::std::string& value) {
  set_has_group();
  group_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.HdfsFileStatusProto.group)
}
#if LANG_CXX11
inline void HdfsFileStatusProto::set_group(::std::string&& value) {
  set_has_group();
  group_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.HdfsFileStatusProto.group)
}
#endif
inline void HdfsFileStatusProto::set_group(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_group();
  group_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.HdfsFileStatusProto.group)
}
inline void HdfsFileStatusProto::set_group(const char* value, size_t size) {
  set_has_group();
  group_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.HdfsFileStatusProto.group)
}
inline ::std::string* HdfsFileStatusProto::mutable_group() {
  set_has_group();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.HdfsFileStatusProto.group)
  return group_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* HdfsFileStatusProto::release_group() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.HdfsFileStatusProto.group)
  if (!has_group()) {
    return NULL;
  }
  clear_has_group();
  return group_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void HdfsFileStatusProto::set_allocated_group(::std::string* group) {
  if (group != NULL) {
    set_has_group();
  } else {
    clear_has_group();
  }
  group_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), group);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.HdfsFileStatusProto.group)
}

// required uint64 modification_time = 7;
inline bool HdfsFileStatusProto::has_modification_time() const {
  return (_has_bits_[0] & 0x00000200u) != 0;
}
inline void HdfsFileStatusProto::set_has_modification_time() {
  _has_bits_[0] |= 0x00000200u;
}
inline void HdfsFileStatusProto::clear_has_modification_time() {
  _has_bits_[0] &= ~0x00000200u;
}
inline void HdfsFileStatusProto::clear_modification_time() {
  modification_time_ = GOOGLE_ULONGLONG(0);
  clear_has_modification_time();
}
inline ::google::protobuf::uint64 HdfsFileStatusProto::modification_time() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.HdfsFileStatusProto.modification_time)
  return modification_time_;
}
inline void HdfsFileStatusProto::set_modification_time(::google::protobuf::uint64 value) {
  set_has_modification_time();
  modification_time_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.HdfsFileStatusProto.modification_time)
}

// required uint64 access_time = 8;
inline bool HdfsFileStatusProto::has_access_time() const {
  return (_has_bits_[0] & 0x00000400u) != 0;
}
inline void HdfsFileStatusProto::set_has_access_time() {
  _has_bits_[0] |= 0x00000400u;
}
inline void HdfsFileStatusProto::clear_has_access_time() {
  _has_bits_[0] &= ~0x00000400u;
}
inline void HdfsFileStatusProto::clear_access_time() {
  access_time_ = GOOGLE_ULONGLONG(0);
  clear_has_access_time();
}
inline ::google::protobuf::uint64 HdfsFileStatusProto::access_time() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.HdfsFileStatusProto.access_time)
  return access_time_;
}
inline void HdfsFileStatusProto::set_access_time(::google::protobuf::uint64 value) {
  set_has_access_time();
  access_time_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.HdfsFileStatusProto.access_time)
}

// optional bytes symlink = 9;
inline bool HdfsFileStatusProto::has_symlink() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void HdfsFileStatusProto::set_has_symlink() {
  _has_bits_[0] |= 0x00000008u;
}
inline void HdfsFileStatusProto::clear_has_symlink() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void HdfsFileStatusProto::clear_symlink() {
  symlink_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_symlink();
}
inline const ::std::string& HdfsFileStatusProto::symlink() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.HdfsFileStatusProto.symlink)
  return symlink_.GetNoArena();
}
inline void HdfsFileStatusProto::set_symlink(const ::std::string& value) {
  set_has_symlink();
  symlink_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.HdfsFileStatusProto.symlink)
}
#if LANG_CXX11
inline void HdfsFileStatusProto::set_symlink(::std::string&& value) {
  set_has_symlink();
  symlink_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.HdfsFileStatusProto.symlink)
}
#endif
inline void HdfsFileStatusProto::set_symlink(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_symlink();
  symlink_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.HdfsFileStatusProto.symlink)
}
inline void HdfsFileStatusProto::set_symlink(const void* value, size_t size) {
  set_has_symlink();
  symlink_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.HdfsFileStatusProto.symlink)
}
inline ::std::string* HdfsFileStatusProto::mutable_symlink() {
  set_has_symlink();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.HdfsFileStatusProto.symlink)
  return symlink_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* HdfsFileStatusProto::release_symlink() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.HdfsFileStatusProto.symlink)
  if (!has_symlink()) {
    return NULL;
  }
  clear_has_symlink();
  return symlink_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void HdfsFileStatusProto::set_allocated_symlink(::std::string* symlink) {
  if (symlink != NULL) {
    set_has_symlink();
  } else {
    clear_has_symlink();
  }
  symlink_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), symlink);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.HdfsFileStatusProto.symlink)
}

// optional uint32 block_replication = 10 [default = 0];
inline bool HdfsFileStatusProto::has_block_replication() const {
  return (_has_bits_[0] & 0x00002000u) != 0;
}
inline void HdfsFileStatusProto::set_has_block_replication() {
  _has_bits_[0] |= 0x00002000u;
}
inline void HdfsFileStatusProto::clear_has_block_replication() {
  _has_bits_[0] &= ~0x00002000u;
}
inline void HdfsFileStatusProto::clear_block_replication() {
  block_replication_ = 0u;
  clear_has_block_replication();
}
inline ::google::protobuf::uint32 HdfsFileStatusProto::block_replication() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.HdfsFileStatusProto.block_replication)
  return block_replication_;
}
inline void HdfsFileStatusProto::set_block_replication(::google::protobuf::uint32 value) {
  set_has_block_replication();
  block_replication_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.HdfsFileStatusProto.block_replication)
}

// optional uint64 blocksize = 11 [default = 0];
inline bool HdfsFileStatusProto::has_blocksize() const {
  return (_has_bits_[0] & 0x00000800u) != 0;
}
inline void HdfsFileStatusProto::set_has_blocksize() {
  _has_bits_[0] |= 0x00000800u;
}
inline void HdfsFileStatusProto::clear_has_blocksize() {
  _has_bits_[0] &= ~0x00000800u;
}
inline void HdfsFileStatusProto::clear_blocksize() {
  blocksize_ = GOOGLE_ULONGLONG(0);
  clear_has_blocksize();
}
inline ::google::protobuf::uint64 HdfsFileStatusProto::blocksize() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.HdfsFileStatusProto.blocksize)
  return blocksize_;
}
inline void HdfsFileStatusProto::set_blocksize(::google::protobuf::uint64 value) {
  set_has_blocksize();
  blocksize_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.HdfsFileStatusProto.blocksize)
}

// optional .hadoop.hdfs.LocatedBlocksProto locations = 12;
inline bool HdfsFileStatusProto::has_locations() const {
  return (_has_bits_[0] & 0x00000020u) != 0;
}
inline void HdfsFileStatusProto::set_has_locations() {
  _has_bits_[0] |= 0x00000020u;
}
inline void HdfsFileStatusProto::clear_has_locations() {
  _has_bits_[0] &= ~0x00000020u;
}
inline void HdfsFileStatusProto::clear_locations() {
  if (locations_ != NULL) locations_->Clear();
  clear_has_locations();
}
inline const ::hadoop::hdfs::LocatedBlocksProto& HdfsFileStatusProto::_internal_locations() const {
  return *locations_;
}
inline const ::hadoop::hdfs::LocatedBlocksProto& HdfsFileStatusProto::locations() const {
  const ::hadoop::hdfs::LocatedBlocksProto* p = locations_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.HdfsFileStatusProto.locations)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::LocatedBlocksProto*>(
      &::hadoop::hdfs::_LocatedBlocksProto_default_instance_);
}
inline ::hadoop::hdfs::LocatedBlocksProto* HdfsFileStatusProto::release_locations() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.HdfsFileStatusProto.locations)
  clear_has_locations();
  ::hadoop::hdfs::LocatedBlocksProto* temp = locations_;
  locations_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::LocatedBlocksProto* HdfsFileStatusProto::mutable_locations() {
  set_has_locations();
  if (locations_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::LocatedBlocksProto>(GetArenaNoVirtual());
    locations_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.HdfsFileStatusProto.locations)
  return locations_;
}
inline void HdfsFileStatusProto::set_allocated_locations(::hadoop::hdfs::LocatedBlocksProto* locations) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete locations_;
  }
  if (locations) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      locations = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, locations, submessage_arena);
    }
    set_has_locations();
  } else {
    clear_has_locations();
  }
  locations_ = locations;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.HdfsFileStatusProto.locations)
}

// optional uint64 fileId = 13 [default = 0];
inline bool HdfsFileStatusProto::has_fileid() const {
  return (_has_bits_[0] & 0x00001000u) != 0;
}
inline void HdfsFileStatusProto::set_has_fileid() {
  _has_bits_[0] |= 0x00001000u;
}
inline void HdfsFileStatusProto::clear_has_fileid() {
  _has_bits_[0] &= ~0x00001000u;
}
inline void HdfsFileStatusProto::clear_fileid() {
  fileid_ = GOOGLE_ULONGLONG(0);
  clear_has_fileid();
}
inline ::google::protobuf::uint64 HdfsFileStatusProto::fileid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.HdfsFileStatusProto.fileId)
  return fileid_;
}
inline void HdfsFileStatusProto::set_fileid(::google::protobuf::uint64 value) {
  set_has_fileid();
  fileid_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.HdfsFileStatusProto.fileId)
}

// optional int32 childrenNum = 14 [default = -1];
inline bool HdfsFileStatusProto::has_childrennum() const {
  return (_has_bits_[0] & 0x00020000u) != 0;
}
inline void HdfsFileStatusProto::set_has_childrennum() {
  _has_bits_[0] |= 0x00020000u;
}
inline void HdfsFileStatusProto::clear_has_childrennum() {
  _has_bits_[0] &= ~0x00020000u;
}
inline void HdfsFileStatusProto::clear_childrennum() {
  childrennum_ = -1;
  clear_has_childrennum();
}
inline ::google::protobuf::int32 HdfsFileStatusProto::childrennum() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.HdfsFileStatusProto.childrenNum)
  return childrennum_;
}
inline void HdfsFileStatusProto::set_childrennum(::google::protobuf::int32 value) {
  set_has_childrennum();
  childrennum_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.HdfsFileStatusProto.childrenNum)
}

// optional .hadoop.hdfs.FileEncryptionInfoProto fileEncryptionInfo = 15;
inline bool HdfsFileStatusProto::has_fileencryptioninfo() const {
  return (_has_bits_[0] & 0x00000040u) != 0;
}
inline void HdfsFileStatusProto::set_has_fileencryptioninfo() {
  _has_bits_[0] |= 0x00000040u;
}
inline void HdfsFileStatusProto::clear_has_fileencryptioninfo() {
  _has_bits_[0] &= ~0x00000040u;
}
inline void HdfsFileStatusProto::clear_fileencryptioninfo() {
  if (fileencryptioninfo_ != NULL) fileencryptioninfo_->Clear();
  clear_has_fileencryptioninfo();
}
inline const ::hadoop::hdfs::FileEncryptionInfoProto& HdfsFileStatusProto::_internal_fileencryptioninfo() const {
  return *fileencryptioninfo_;
}
inline const ::hadoop::hdfs::FileEncryptionInfoProto& HdfsFileStatusProto::fileencryptioninfo() const {
  const ::hadoop::hdfs::FileEncryptionInfoProto* p = fileencryptioninfo_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.HdfsFileStatusProto.fileEncryptionInfo)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::FileEncryptionInfoProto*>(
      &::hadoop::hdfs::_FileEncryptionInfoProto_default_instance_);
}
inline ::hadoop::hdfs::FileEncryptionInfoProto* HdfsFileStatusProto::release_fileencryptioninfo() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.HdfsFileStatusProto.fileEncryptionInfo)
  clear_has_fileencryptioninfo();
  ::hadoop::hdfs::FileEncryptionInfoProto* temp = fileencryptioninfo_;
  fileencryptioninfo_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::FileEncryptionInfoProto* HdfsFileStatusProto::mutable_fileencryptioninfo() {
  set_has_fileencryptioninfo();
  if (fileencryptioninfo_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::FileEncryptionInfoProto>(GetArenaNoVirtual());
    fileencryptioninfo_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.HdfsFileStatusProto.fileEncryptionInfo)
  return fileencryptioninfo_;
}
inline void HdfsFileStatusProto::set_allocated_fileencryptioninfo(::hadoop::hdfs::FileEncryptionInfoProto* fileencryptioninfo) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete fileencryptioninfo_;
  }
  if (fileencryptioninfo) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      fileencryptioninfo = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, fileencryptioninfo, submessage_arena);
    }
    set_has_fileencryptioninfo();
  } else {
    clear_has_fileencryptioninfo();
  }
  fileencryptioninfo_ = fileencryptioninfo;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.HdfsFileStatusProto.fileEncryptionInfo)
}

// optional uint32 storagePolicy = 16 [default = 0];
inline bool HdfsFileStatusProto::has_storagepolicy() const {
  return (_has_bits_[0] & 0x00004000u) != 0;
}
inline void HdfsFileStatusProto::set_has_storagepolicy() {
  _has_bits_[0] |= 0x00004000u;
}
inline void HdfsFileStatusProto::clear_has_storagepolicy() {
  _has_bits_[0] &= ~0x00004000u;
}
inline void HdfsFileStatusProto::clear_storagepolicy() {
  storagepolicy_ = 0u;
  clear_has_storagepolicy();
}
inline ::google::protobuf::uint32 HdfsFileStatusProto::storagepolicy() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.HdfsFileStatusProto.storagePolicy)
  return storagepolicy_;
}
inline void HdfsFileStatusProto::set_storagepolicy(::google::protobuf::uint32 value) {
  set_has_storagepolicy();
  storagepolicy_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.HdfsFileStatusProto.storagePolicy)
}

// optional .hadoop.hdfs.ErasureCodingPolicyProto ecPolicy = 17;
inline bool HdfsFileStatusProto::has_ecpolicy() const {
  return (_has_bits_[0] & 0x00000080u) != 0;
}
inline void HdfsFileStatusProto::set_has_ecpolicy() {
  _has_bits_[0] |= 0x00000080u;
}
inline void HdfsFileStatusProto::clear_has_ecpolicy() {
  _has_bits_[0] &= ~0x00000080u;
}
inline void HdfsFileStatusProto::clear_ecpolicy() {
  if (ecpolicy_ != NULL) ecpolicy_->Clear();
  clear_has_ecpolicy();
}
inline const ::hadoop::hdfs::ErasureCodingPolicyProto& HdfsFileStatusProto::_internal_ecpolicy() const {
  return *ecpolicy_;
}
inline const ::hadoop::hdfs::ErasureCodingPolicyProto& HdfsFileStatusProto::ecpolicy() const {
  const ::hadoop::hdfs::ErasureCodingPolicyProto* p = ecpolicy_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.HdfsFileStatusProto.ecPolicy)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::ErasureCodingPolicyProto*>(
      &::hadoop::hdfs::_ErasureCodingPolicyProto_default_instance_);
}
inline ::hadoop::hdfs::ErasureCodingPolicyProto* HdfsFileStatusProto::release_ecpolicy() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.HdfsFileStatusProto.ecPolicy)
  clear_has_ecpolicy();
  ::hadoop::hdfs::ErasureCodingPolicyProto* temp = ecpolicy_;
  ecpolicy_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::ErasureCodingPolicyProto* HdfsFileStatusProto::mutable_ecpolicy() {
  set_has_ecpolicy();
  if (ecpolicy_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::ErasureCodingPolicyProto>(GetArenaNoVirtual());
    ecpolicy_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.HdfsFileStatusProto.ecPolicy)
  return ecpolicy_;
}
inline void HdfsFileStatusProto::set_allocated_ecpolicy(::hadoop::hdfs::ErasureCodingPolicyProto* ecpolicy) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete ecpolicy_;
  }
  if (ecpolicy) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      ecpolicy = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, ecpolicy, submessage_arena);
    }
    set_has_ecpolicy();
  } else {
    clear_has_ecpolicy();
  }
  ecpolicy_ = ecpolicy;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.HdfsFileStatusProto.ecPolicy)
}

// optional uint32 flags = 18 [default = 0];
inline bool HdfsFileStatusProto::has_flags() const {
  return (_has_bits_[0] & 0x00008000u) != 0;
}
inline void HdfsFileStatusProto::set_has_flags() {
  _has_bits_[0] |= 0x00008000u;
}
inline void HdfsFileStatusProto::clear_has_flags() {
  _has_bits_[0] &= ~0x00008000u;
}
inline void HdfsFileStatusProto::clear_flags() {
  flags_ = 0u;
  clear_has_flags();
}
inline ::google::protobuf::uint32 HdfsFileStatusProto::flags() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.HdfsFileStatusProto.flags)
  return flags_;
}
inline void HdfsFileStatusProto::set_flags(::google::protobuf::uint32 value) {
  set_has_flags();
  flags_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.HdfsFileStatusProto.flags)
}

// -------------------------------------------------------------------

// BlockChecksumOptionsProto

// optional .hadoop.hdfs.BlockChecksumTypeProto blockChecksumType = 1 [default = MD5CRC];
inline bool BlockChecksumOptionsProto::has_blockchecksumtype() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void BlockChecksumOptionsProto::set_has_blockchecksumtype() {
  _has_bits_[0] |= 0x00000002u;
}
inline void BlockChecksumOptionsProto::clear_has_blockchecksumtype() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void BlockChecksumOptionsProto::clear_blockchecksumtype() {
  blockchecksumtype_ = 1;
  clear_has_blockchecksumtype();
}
inline ::hadoop::hdfs::BlockChecksumTypeProto BlockChecksumOptionsProto::blockchecksumtype() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockChecksumOptionsProto.blockChecksumType)
  return static_cast< ::hadoop::hdfs::BlockChecksumTypeProto >(blockchecksumtype_);
}
inline void BlockChecksumOptionsProto::set_blockchecksumtype(::hadoop::hdfs::BlockChecksumTypeProto value) {
  assert(::hadoop::hdfs::BlockChecksumTypeProto_IsValid(value));
  set_has_blockchecksumtype();
  blockchecksumtype_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockChecksumOptionsProto.blockChecksumType)
}

// optional uint64 stripeLength = 2;
inline bool BlockChecksumOptionsProto::has_stripelength() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void BlockChecksumOptionsProto::set_has_stripelength() {
  _has_bits_[0] |= 0x00000001u;
}
inline void BlockChecksumOptionsProto::clear_has_stripelength() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void BlockChecksumOptionsProto::clear_stripelength() {
  stripelength_ = GOOGLE_ULONGLONG(0);
  clear_has_stripelength();
}
inline ::google::protobuf::uint64 BlockChecksumOptionsProto::stripelength() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockChecksumOptionsProto.stripeLength)
  return stripelength_;
}
inline void BlockChecksumOptionsProto::set_stripelength(::google::protobuf::uint64 value) {
  set_has_stripelength();
  stripelength_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockChecksumOptionsProto.stripeLength)
}

// -------------------------------------------------------------------

// FsServerDefaultsProto

// required uint64 blockSize = 1;
inline bool FsServerDefaultsProto::has_blocksize() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void FsServerDefaultsProto::set_has_blocksize() {
  _has_bits_[0] |= 0x00000002u;
}
inline void FsServerDefaultsProto::clear_has_blocksize() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void FsServerDefaultsProto::clear_blocksize() {
  blocksize_ = GOOGLE_ULONGLONG(0);
  clear_has_blocksize();
}
inline ::google::protobuf::uint64 FsServerDefaultsProto::blocksize() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.FsServerDefaultsProto.blockSize)
  return blocksize_;
}
inline void FsServerDefaultsProto::set_blocksize(::google::protobuf::uint64 value) {
  set_has_blocksize();
  blocksize_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.FsServerDefaultsProto.blockSize)
}

// required uint32 bytesPerChecksum = 2;
inline bool FsServerDefaultsProto::has_bytesperchecksum() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void FsServerDefaultsProto::set_has_bytesperchecksum() {
  _has_bits_[0] |= 0x00000004u;
}
inline void FsServerDefaultsProto::clear_has_bytesperchecksum() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void FsServerDefaultsProto::clear_bytesperchecksum() {
  bytesperchecksum_ = 0u;
  clear_has_bytesperchecksum();
}
inline ::google::protobuf::uint32 FsServerDefaultsProto::bytesperchecksum() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.FsServerDefaultsProto.bytesPerChecksum)
  return bytesperchecksum_;
}
inline void FsServerDefaultsProto::set_bytesperchecksum(::google::protobuf::uint32 value) {
  set_has_bytesperchecksum();
  bytesperchecksum_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.FsServerDefaultsProto.bytesPerChecksum)
}

// required uint32 writePacketSize = 3;
inline bool FsServerDefaultsProto::has_writepacketsize() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void FsServerDefaultsProto::set_has_writepacketsize() {
  _has_bits_[0] |= 0x00000008u;
}
inline void FsServerDefaultsProto::clear_has_writepacketsize() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void FsServerDefaultsProto::clear_writepacketsize() {
  writepacketsize_ = 0u;
  clear_has_writepacketsize();
}
inline ::google::protobuf::uint32 FsServerDefaultsProto::writepacketsize() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.FsServerDefaultsProto.writePacketSize)
  return writepacketsize_;
}
inline void FsServerDefaultsProto::set_writepacketsize(::google::protobuf::uint32 value) {
  set_has_writepacketsize();
  writepacketsize_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.FsServerDefaultsProto.writePacketSize)
}

// required uint32 replication = 4;
inline bool FsServerDefaultsProto::has_replication() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void FsServerDefaultsProto::set_has_replication() {
  _has_bits_[0] |= 0x00000010u;
}
inline void FsServerDefaultsProto::clear_has_replication() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void FsServerDefaultsProto::clear_replication() {
  replication_ = 0u;
  clear_has_replication();
}
inline ::google::protobuf::uint32 FsServerDefaultsProto::replication() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.FsServerDefaultsProto.replication)
  return replication_;
}
inline void FsServerDefaultsProto::set_replication(::google::protobuf::uint32 value) {
  set_has_replication();
  replication_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.FsServerDefaultsProto.replication)
}

// required uint32 fileBufferSize = 5;
inline bool FsServerDefaultsProto::has_filebuffersize() const {
  return (_has_bits_[0] & 0x00000020u) != 0;
}
inline void FsServerDefaultsProto::set_has_filebuffersize() {
  _has_bits_[0] |= 0x00000020u;
}
inline void FsServerDefaultsProto::clear_has_filebuffersize() {
  _has_bits_[0] &= ~0x00000020u;
}
inline void FsServerDefaultsProto::clear_filebuffersize() {
  filebuffersize_ = 0u;
  clear_has_filebuffersize();
}
inline ::google::protobuf::uint32 FsServerDefaultsProto::filebuffersize() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.FsServerDefaultsProto.fileBufferSize)
  return filebuffersize_;
}
inline void FsServerDefaultsProto::set_filebuffersize(::google::protobuf::uint32 value) {
  set_has_filebuffersize();
  filebuffersize_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.FsServerDefaultsProto.fileBufferSize)
}

// optional bool encryptDataTransfer = 6 [default = false];
inline bool FsServerDefaultsProto::has_encryptdatatransfer() const {
  return (_has_bits_[0] & 0x00000080u) != 0;
}
inline void FsServerDefaultsProto::set_has_encryptdatatransfer() {
  _has_bits_[0] |= 0x00000080u;
}
inline void FsServerDefaultsProto::clear_has_encryptdatatransfer() {
  _has_bits_[0] &= ~0x00000080u;
}
inline void FsServerDefaultsProto::clear_encryptdatatransfer() {
  encryptdatatransfer_ = false;
  clear_has_encryptdatatransfer();
}
inline bool FsServerDefaultsProto::encryptdatatransfer() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.FsServerDefaultsProto.encryptDataTransfer)
  return encryptdatatransfer_;
}
inline void FsServerDefaultsProto::set_encryptdatatransfer(bool value) {
  set_has_encryptdatatransfer();
  encryptdatatransfer_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.FsServerDefaultsProto.encryptDataTransfer)
}

// optional uint64 trashInterval = 7 [default = 0];
inline bool FsServerDefaultsProto::has_trashinterval() const {
  return (_has_bits_[0] & 0x00000040u) != 0;
}
inline void FsServerDefaultsProto::set_has_trashinterval() {
  _has_bits_[0] |= 0x00000040u;
}
inline void FsServerDefaultsProto::clear_has_trashinterval() {
  _has_bits_[0] &= ~0x00000040u;
}
inline void FsServerDefaultsProto::clear_trashinterval() {
  trashinterval_ = GOOGLE_ULONGLONG(0);
  clear_has_trashinterval();
}
inline ::google::protobuf::uint64 FsServerDefaultsProto::trashinterval() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.FsServerDefaultsProto.trashInterval)
  return trashinterval_;
}
inline void FsServerDefaultsProto::set_trashinterval(::google::protobuf::uint64 value) {
  set_has_trashinterval();
  trashinterval_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.FsServerDefaultsProto.trashInterval)
}

// optional .hadoop.hdfs.ChecksumTypeProto checksumType = 8 [default = CHECKSUM_CRC32];
inline bool FsServerDefaultsProto::has_checksumtype() const {
  return (_has_bits_[0] & 0x00000200u) != 0;
}
inline void FsServerDefaultsProto::set_has_checksumtype() {
  _has_bits_[0] |= 0x00000200u;
}
inline void FsServerDefaultsProto::clear_has_checksumtype() {
  _has_bits_[0] &= ~0x00000200u;
}
inline void FsServerDefaultsProto::clear_checksumtype() {
  checksumtype_ = 1;
  clear_has_checksumtype();
}
inline ::hadoop::hdfs::ChecksumTypeProto FsServerDefaultsProto::checksumtype() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.FsServerDefaultsProto.checksumType)
  return static_cast< ::hadoop::hdfs::ChecksumTypeProto >(checksumtype_);
}
inline void FsServerDefaultsProto::set_checksumtype(::hadoop::hdfs::ChecksumTypeProto value) {
  assert(::hadoop::hdfs::ChecksumTypeProto_IsValid(value));
  set_has_checksumtype();
  checksumtype_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.FsServerDefaultsProto.checksumType)
}

// optional string keyProviderUri = 9;
inline bool FsServerDefaultsProto::has_keyprovideruri() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void FsServerDefaultsProto::set_has_keyprovideruri() {
  _has_bits_[0] |= 0x00000001u;
}
inline void FsServerDefaultsProto::clear_has_keyprovideruri() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void FsServerDefaultsProto::clear_keyprovideruri() {
  keyprovideruri_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_keyprovideruri();
}
inline const ::std::string& FsServerDefaultsProto::keyprovideruri() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.FsServerDefaultsProto.keyProviderUri)
  return keyprovideruri_.GetNoArena();
}
inline void FsServerDefaultsProto::set_keyprovideruri(const ::std::string& value) {
  set_has_keyprovideruri();
  keyprovideruri_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.FsServerDefaultsProto.keyProviderUri)
}
#if LANG_CXX11
inline void FsServerDefaultsProto::set_keyprovideruri(::std::string&& value) {
  set_has_keyprovideruri();
  keyprovideruri_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.FsServerDefaultsProto.keyProviderUri)
}
#endif
inline void FsServerDefaultsProto::set_keyprovideruri(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_keyprovideruri();
  keyprovideruri_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.FsServerDefaultsProto.keyProviderUri)
}
inline void FsServerDefaultsProto::set_keyprovideruri(const char* value, size_t size) {
  set_has_keyprovideruri();
  keyprovideruri_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.FsServerDefaultsProto.keyProviderUri)
}
inline ::std::string* FsServerDefaultsProto::mutable_keyprovideruri() {
  set_has_keyprovideruri();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.FsServerDefaultsProto.keyProviderUri)
  return keyprovideruri_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* FsServerDefaultsProto::release_keyprovideruri() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.FsServerDefaultsProto.keyProviderUri)
  if (!has_keyprovideruri()) {
    return NULL;
  }
  clear_has_keyprovideruri();
  return keyprovideruri_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void FsServerDefaultsProto::set_allocated_keyprovideruri(::std::string* keyprovideruri) {
  if (keyprovideruri != NULL) {
    set_has_keyprovideruri();
  } else {
    clear_has_keyprovideruri();
  }
  keyprovideruri_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), keyprovideruri);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.FsServerDefaultsProto.keyProviderUri)
}

// optional uint32 policyId = 10 [default = 0];
inline bool FsServerDefaultsProto::has_policyid() const {
  return (_has_bits_[0] & 0x00000100u) != 0;
}
inline void FsServerDefaultsProto::set_has_policyid() {
  _has_bits_[0] |= 0x00000100u;
}
inline void FsServerDefaultsProto::clear_has_policyid() {
  _has_bits_[0] &= ~0x00000100u;
}
inline void FsServerDefaultsProto::clear_policyid() {
  policyid_ = 0u;
  clear_has_policyid();
}
inline ::google::protobuf::uint32 FsServerDefaultsProto::policyid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.FsServerDefaultsProto.policyId)
  return policyid_;
}
inline void FsServerDefaultsProto::set_policyid(::google::protobuf::uint32 value) {
  set_has_policyid();
  policyid_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.FsServerDefaultsProto.policyId)
}

// -------------------------------------------------------------------

// DirectoryListingProto

// repeated .hadoop.hdfs.HdfsFileStatusProto partialListing = 1;
inline int DirectoryListingProto::partiallisting_size() const {
  return partiallisting_.size();
}
inline void DirectoryListingProto::clear_partiallisting() {
  partiallisting_.Clear();
}
inline ::hadoop::hdfs::HdfsFileStatusProto* DirectoryListingProto::mutable_partiallisting(int index) {
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.DirectoryListingProto.partialListing)
  return partiallisting_.Mutable(index);
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::HdfsFileStatusProto >*
DirectoryListingProto::mutable_partiallisting() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.DirectoryListingProto.partialListing)
  return &partiallisting_;
}
inline const ::hadoop::hdfs::HdfsFileStatusProto& DirectoryListingProto::partiallisting(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DirectoryListingProto.partialListing)
  return partiallisting_.Get(index);
}
inline ::hadoop::hdfs::HdfsFileStatusProto* DirectoryListingProto::add_partiallisting() {
  // @@protoc_insertion_point(field_add:hadoop.hdfs.DirectoryListingProto.partialListing)
  return partiallisting_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::HdfsFileStatusProto >&
DirectoryListingProto::partiallisting() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.DirectoryListingProto.partialListing)
  return partiallisting_;
}

// required uint32 remainingEntries = 2;
inline bool DirectoryListingProto::has_remainingentries() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void DirectoryListingProto::set_has_remainingentries() {
  _has_bits_[0] |= 0x00000001u;
}
inline void DirectoryListingProto::clear_has_remainingentries() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void DirectoryListingProto::clear_remainingentries() {
  remainingentries_ = 0u;
  clear_has_remainingentries();
}
inline ::google::protobuf::uint32 DirectoryListingProto::remainingentries() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DirectoryListingProto.remainingEntries)
  return remainingentries_;
}
inline void DirectoryListingProto::set_remainingentries(::google::protobuf::uint32 value) {
  set_has_remainingentries();
  remainingentries_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DirectoryListingProto.remainingEntries)
}

// -------------------------------------------------------------------

// RemoteExceptionProto

// required string className = 1;
inline bool RemoteExceptionProto::has_classname() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void RemoteExceptionProto::set_has_classname() {
  _has_bits_[0] |= 0x00000001u;
}
inline void RemoteExceptionProto::clear_has_classname() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void RemoteExceptionProto::clear_classname() {
  classname_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_classname();
}
inline const ::std::string& RemoteExceptionProto::classname() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.RemoteExceptionProto.className)
  return classname_.GetNoArena();
}
inline void RemoteExceptionProto::set_classname(const ::std::string& value) {
  set_has_classname();
  classname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.RemoteExceptionProto.className)
}
#if LANG_CXX11
inline void RemoteExceptionProto::set_classname(::std::string&& value) {
  set_has_classname();
  classname_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.RemoteExceptionProto.className)
}
#endif
inline void RemoteExceptionProto::set_classname(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_classname();
  classname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.RemoteExceptionProto.className)
}
inline void RemoteExceptionProto::set_classname(const char* value, size_t size) {
  set_has_classname();
  classname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.RemoteExceptionProto.className)
}
inline ::std::string* RemoteExceptionProto::mutable_classname() {
  set_has_classname();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.RemoteExceptionProto.className)
  return classname_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* RemoteExceptionProto::release_classname() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.RemoteExceptionProto.className)
  if (!has_classname()) {
    return NULL;
  }
  clear_has_classname();
  return classname_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void RemoteExceptionProto::set_allocated_classname(::std::string* classname) {
  if (classname != NULL) {
    set_has_classname();
  } else {
    clear_has_classname();
  }
  classname_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), classname);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.RemoteExceptionProto.className)
}

// optional string message = 2;
inline bool RemoteExceptionProto::has_message() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void RemoteExceptionProto::set_has_message() {
  _has_bits_[0] |= 0x00000002u;
}
inline void RemoteExceptionProto::clear_has_message() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void RemoteExceptionProto::clear_message() {
  message_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_message();
}
inline const ::std::string& RemoteExceptionProto::message() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.RemoteExceptionProto.message)
  return message_.GetNoArena();
}
inline void RemoteExceptionProto::set_message(const ::std::string& value) {
  set_has_message();
  message_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.RemoteExceptionProto.message)
}
#if LANG_CXX11
inline void RemoteExceptionProto::set_message(::std::string&& value) {
  set_has_message();
  message_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.RemoteExceptionProto.message)
}
#endif
inline void RemoteExceptionProto::set_message(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_message();
  message_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.RemoteExceptionProto.message)
}
inline void RemoteExceptionProto::set_message(const char* value, size_t size) {
  set_has_message();
  message_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.RemoteExceptionProto.message)
}
inline ::std::string* RemoteExceptionProto::mutable_message() {
  set_has_message();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.RemoteExceptionProto.message)
  return message_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* RemoteExceptionProto::release_message() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.RemoteExceptionProto.message)
  if (!has_message()) {
    return NULL;
  }
  clear_has_message();
  return message_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void RemoteExceptionProto::set_allocated_message(::std::string* message) {
  if (message != NULL) {
    set_has_message();
  } else {
    clear_has_message();
  }
  message_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), message);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.RemoteExceptionProto.message)
}

// -------------------------------------------------------------------

// BatchedDirectoryListingProto

// repeated .hadoop.hdfs.HdfsFileStatusProto partialListing = 1;
inline int BatchedDirectoryListingProto::partiallisting_size() const {
  return partiallisting_.size();
}
inline void BatchedDirectoryListingProto::clear_partiallisting() {
  partiallisting_.Clear();
}
inline ::hadoop::hdfs::HdfsFileStatusProto* BatchedDirectoryListingProto::mutable_partiallisting(int index) {
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.BatchedDirectoryListingProto.partialListing)
  return partiallisting_.Mutable(index);
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::HdfsFileStatusProto >*
BatchedDirectoryListingProto::mutable_partiallisting() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.BatchedDirectoryListingProto.partialListing)
  return &partiallisting_;
}
inline const ::hadoop::hdfs::HdfsFileStatusProto& BatchedDirectoryListingProto::partiallisting(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BatchedDirectoryListingProto.partialListing)
  return partiallisting_.Get(index);
}
inline ::hadoop::hdfs::HdfsFileStatusProto* BatchedDirectoryListingProto::add_partiallisting() {
  // @@protoc_insertion_point(field_add:hadoop.hdfs.BatchedDirectoryListingProto.partialListing)
  return partiallisting_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::HdfsFileStatusProto >&
BatchedDirectoryListingProto::partiallisting() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.BatchedDirectoryListingProto.partialListing)
  return partiallisting_;
}

// required uint32 parentIdx = 2;
inline bool BatchedDirectoryListingProto::has_parentidx() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void BatchedDirectoryListingProto::set_has_parentidx() {
  _has_bits_[0] |= 0x00000002u;
}
inline void BatchedDirectoryListingProto::clear_has_parentidx() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void BatchedDirectoryListingProto::clear_parentidx() {
  parentidx_ = 0u;
  clear_has_parentidx();
}
inline ::google::protobuf::uint32 BatchedDirectoryListingProto::parentidx() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BatchedDirectoryListingProto.parentIdx)
  return parentidx_;
}
inline void BatchedDirectoryListingProto::set_parentidx(::google::protobuf::uint32 value) {
  set_has_parentidx();
  parentidx_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BatchedDirectoryListingProto.parentIdx)
}

// optional .hadoop.hdfs.RemoteExceptionProto exception = 3;
inline bool BatchedDirectoryListingProto::has_exception() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void BatchedDirectoryListingProto::set_has_exception() {
  _has_bits_[0] |= 0x00000001u;
}
inline void BatchedDirectoryListingProto::clear_has_exception() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void BatchedDirectoryListingProto::clear_exception() {
  if (exception_ != NULL) exception_->Clear();
  clear_has_exception();
}
inline const ::hadoop::hdfs::RemoteExceptionProto& BatchedDirectoryListingProto::_internal_exception() const {
  return *exception_;
}
inline const ::hadoop::hdfs::RemoteExceptionProto& BatchedDirectoryListingProto::exception() const {
  const ::hadoop::hdfs::RemoteExceptionProto* p = exception_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BatchedDirectoryListingProto.exception)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::RemoteExceptionProto*>(
      &::hadoop::hdfs::_RemoteExceptionProto_default_instance_);
}
inline ::hadoop::hdfs::RemoteExceptionProto* BatchedDirectoryListingProto::release_exception() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.BatchedDirectoryListingProto.exception)
  clear_has_exception();
  ::hadoop::hdfs::RemoteExceptionProto* temp = exception_;
  exception_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::RemoteExceptionProto* BatchedDirectoryListingProto::mutable_exception() {
  set_has_exception();
  if (exception_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::RemoteExceptionProto>(GetArenaNoVirtual());
    exception_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.BatchedDirectoryListingProto.exception)
  return exception_;
}
inline void BatchedDirectoryListingProto::set_allocated_exception(::hadoop::hdfs::RemoteExceptionProto* exception) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete exception_;
  }
  if (exception) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      exception = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, exception, submessage_arena);
    }
    set_has_exception();
  } else {
    clear_has_exception();
  }
  exception_ = exception;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.BatchedDirectoryListingProto.exception)
}

// -------------------------------------------------------------------

// SnapshottableDirectoryStatusProto

// required .hadoop.hdfs.HdfsFileStatusProto dirStatus = 1;
inline bool SnapshottableDirectoryStatusProto::has_dirstatus() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void SnapshottableDirectoryStatusProto::set_has_dirstatus() {
  _has_bits_[0] |= 0x00000002u;
}
inline void SnapshottableDirectoryStatusProto::clear_has_dirstatus() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void SnapshottableDirectoryStatusProto::clear_dirstatus() {
  if (dirstatus_ != NULL) dirstatus_->Clear();
  clear_has_dirstatus();
}
inline const ::hadoop::hdfs::HdfsFileStatusProto& SnapshottableDirectoryStatusProto::_internal_dirstatus() const {
  return *dirstatus_;
}
inline const ::hadoop::hdfs::HdfsFileStatusProto& SnapshottableDirectoryStatusProto::dirstatus() const {
  const ::hadoop::hdfs::HdfsFileStatusProto* p = dirstatus_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshottableDirectoryStatusProto.dirStatus)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::HdfsFileStatusProto*>(
      &::hadoop::hdfs::_HdfsFileStatusProto_default_instance_);
}
inline ::hadoop::hdfs::HdfsFileStatusProto* SnapshottableDirectoryStatusProto::release_dirstatus() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.SnapshottableDirectoryStatusProto.dirStatus)
  clear_has_dirstatus();
  ::hadoop::hdfs::HdfsFileStatusProto* temp = dirstatus_;
  dirstatus_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::HdfsFileStatusProto* SnapshottableDirectoryStatusProto::mutable_dirstatus() {
  set_has_dirstatus();
  if (dirstatus_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::HdfsFileStatusProto>(GetArenaNoVirtual());
    dirstatus_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.SnapshottableDirectoryStatusProto.dirStatus)
  return dirstatus_;
}
inline void SnapshottableDirectoryStatusProto::set_allocated_dirstatus(::hadoop::hdfs::HdfsFileStatusProto* dirstatus) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete dirstatus_;
  }
  if (dirstatus) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      dirstatus = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, dirstatus, submessage_arena);
    }
    set_has_dirstatus();
  } else {
    clear_has_dirstatus();
  }
  dirstatus_ = dirstatus;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.SnapshottableDirectoryStatusProto.dirStatus)
}

// required uint32 snapshot_quota = 2;
inline bool SnapshottableDirectoryStatusProto::has_snapshot_quota() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void SnapshottableDirectoryStatusProto::set_has_snapshot_quota() {
  _has_bits_[0] |= 0x00000004u;
}
inline void SnapshottableDirectoryStatusProto::clear_has_snapshot_quota() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void SnapshottableDirectoryStatusProto::clear_snapshot_quota() {
  snapshot_quota_ = 0u;
  clear_has_snapshot_quota();
}
inline ::google::protobuf::uint32 SnapshottableDirectoryStatusProto::snapshot_quota() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshottableDirectoryStatusProto.snapshot_quota)
  return snapshot_quota_;
}
inline void SnapshottableDirectoryStatusProto::set_snapshot_quota(::google::protobuf::uint32 value) {
  set_has_snapshot_quota();
  snapshot_quota_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.SnapshottableDirectoryStatusProto.snapshot_quota)
}

// required uint32 snapshot_number = 3;
inline bool SnapshottableDirectoryStatusProto::has_snapshot_number() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void SnapshottableDirectoryStatusProto::set_has_snapshot_number() {
  _has_bits_[0] |= 0x00000008u;
}
inline void SnapshottableDirectoryStatusProto::clear_has_snapshot_number() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void SnapshottableDirectoryStatusProto::clear_snapshot_number() {
  snapshot_number_ = 0u;
  clear_has_snapshot_number();
}
inline ::google::protobuf::uint32 SnapshottableDirectoryStatusProto::snapshot_number() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshottableDirectoryStatusProto.snapshot_number)
  return snapshot_number_;
}
inline void SnapshottableDirectoryStatusProto::set_snapshot_number(::google::protobuf::uint32 value) {
  set_has_snapshot_number();
  snapshot_number_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.SnapshottableDirectoryStatusProto.snapshot_number)
}

// required bytes parent_fullpath = 4;
inline bool SnapshottableDirectoryStatusProto::has_parent_fullpath() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void SnapshottableDirectoryStatusProto::set_has_parent_fullpath() {
  _has_bits_[0] |= 0x00000001u;
}
inline void SnapshottableDirectoryStatusProto::clear_has_parent_fullpath() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void SnapshottableDirectoryStatusProto::clear_parent_fullpath() {
  parent_fullpath_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_parent_fullpath();
}
inline const ::std::string& SnapshottableDirectoryStatusProto::parent_fullpath() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshottableDirectoryStatusProto.parent_fullpath)
  return parent_fullpath_.GetNoArena();
}
inline void SnapshottableDirectoryStatusProto::set_parent_fullpath(const ::std::string& value) {
  set_has_parent_fullpath();
  parent_fullpath_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.SnapshottableDirectoryStatusProto.parent_fullpath)
}
#if LANG_CXX11
inline void SnapshottableDirectoryStatusProto::set_parent_fullpath(::std::string&& value) {
  set_has_parent_fullpath();
  parent_fullpath_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.SnapshottableDirectoryStatusProto.parent_fullpath)
}
#endif
inline void SnapshottableDirectoryStatusProto::set_parent_fullpath(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_parent_fullpath();
  parent_fullpath_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.SnapshottableDirectoryStatusProto.parent_fullpath)
}
inline void SnapshottableDirectoryStatusProto::set_parent_fullpath(const void* value, size_t size) {
  set_has_parent_fullpath();
  parent_fullpath_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.SnapshottableDirectoryStatusProto.parent_fullpath)
}
inline ::std::string* SnapshottableDirectoryStatusProto::mutable_parent_fullpath() {
  set_has_parent_fullpath();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.SnapshottableDirectoryStatusProto.parent_fullpath)
  return parent_fullpath_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* SnapshottableDirectoryStatusProto::release_parent_fullpath() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.SnapshottableDirectoryStatusProto.parent_fullpath)
  if (!has_parent_fullpath()) {
    return NULL;
  }
  clear_has_parent_fullpath();
  return parent_fullpath_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void SnapshottableDirectoryStatusProto::set_allocated_parent_fullpath(::std::string* parent_fullpath) {
  if (parent_fullpath != NULL) {
    set_has_parent_fullpath();
  } else {
    clear_has_parent_fullpath();
  }
  parent_fullpath_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), parent_fullpath);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.SnapshottableDirectoryStatusProto.parent_fullpath)
}

// -------------------------------------------------------------------

// SnapshottableDirectoryListingProto

// repeated .hadoop.hdfs.SnapshottableDirectoryStatusProto snapshottableDirListing = 1;
inline int SnapshottableDirectoryListingProto::snapshottabledirlisting_size() const {
  return snapshottabledirlisting_.size();
}
inline void SnapshottableDirectoryListingProto::clear_snapshottabledirlisting() {
  snapshottabledirlisting_.Clear();
}
inline ::hadoop::hdfs::SnapshottableDirectoryStatusProto* SnapshottableDirectoryListingProto::mutable_snapshottabledirlisting(int index) {
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.SnapshottableDirectoryListingProto.snapshottableDirListing)
  return snapshottabledirlisting_.Mutable(index);
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::SnapshottableDirectoryStatusProto >*
SnapshottableDirectoryListingProto::mutable_snapshottabledirlisting() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.SnapshottableDirectoryListingProto.snapshottableDirListing)
  return &snapshottabledirlisting_;
}
inline const ::hadoop::hdfs::SnapshottableDirectoryStatusProto& SnapshottableDirectoryListingProto::snapshottabledirlisting(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshottableDirectoryListingProto.snapshottableDirListing)
  return snapshottabledirlisting_.Get(index);
}
inline ::hadoop::hdfs::SnapshottableDirectoryStatusProto* SnapshottableDirectoryListingProto::add_snapshottabledirlisting() {
  // @@protoc_insertion_point(field_add:hadoop.hdfs.SnapshottableDirectoryListingProto.snapshottableDirListing)
  return snapshottabledirlisting_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::SnapshottableDirectoryStatusProto >&
SnapshottableDirectoryListingProto::snapshottabledirlisting() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.SnapshottableDirectoryListingProto.snapshottableDirListing)
  return snapshottabledirlisting_;
}

// -------------------------------------------------------------------

// SnapshotDiffReportEntryProto

// required bytes fullpath = 1;
inline bool SnapshotDiffReportEntryProto::has_fullpath() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void SnapshotDiffReportEntryProto::set_has_fullpath() {
  _has_bits_[0] |= 0x00000001u;
}
inline void SnapshotDiffReportEntryProto::clear_has_fullpath() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void SnapshotDiffReportEntryProto::clear_fullpath() {
  fullpath_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_fullpath();
}
inline const ::std::string& SnapshotDiffReportEntryProto::fullpath() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshotDiffReportEntryProto.fullpath)
  return fullpath_.GetNoArena();
}
inline void SnapshotDiffReportEntryProto::set_fullpath(const ::std::string& value) {
  set_has_fullpath();
  fullpath_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.SnapshotDiffReportEntryProto.fullpath)
}
#if LANG_CXX11
inline void SnapshotDiffReportEntryProto::set_fullpath(::std::string&& value) {
  set_has_fullpath();
  fullpath_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.SnapshotDiffReportEntryProto.fullpath)
}
#endif
inline void SnapshotDiffReportEntryProto::set_fullpath(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_fullpath();
  fullpath_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.SnapshotDiffReportEntryProto.fullpath)
}
inline void SnapshotDiffReportEntryProto::set_fullpath(const void* value, size_t size) {
  set_has_fullpath();
  fullpath_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.SnapshotDiffReportEntryProto.fullpath)
}
inline ::std::string* SnapshotDiffReportEntryProto::mutable_fullpath() {
  set_has_fullpath();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.SnapshotDiffReportEntryProto.fullpath)
  return fullpath_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* SnapshotDiffReportEntryProto::release_fullpath() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.SnapshotDiffReportEntryProto.fullpath)
  if (!has_fullpath()) {
    return NULL;
  }
  clear_has_fullpath();
  return fullpath_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void SnapshotDiffReportEntryProto::set_allocated_fullpath(::std::string* fullpath) {
  if (fullpath != NULL) {
    set_has_fullpath();
  } else {
    clear_has_fullpath();
  }
  fullpath_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), fullpath);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.SnapshotDiffReportEntryProto.fullpath)
}

// required string modificationLabel = 2;
inline bool SnapshotDiffReportEntryProto::has_modificationlabel() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void SnapshotDiffReportEntryProto::set_has_modificationlabel() {
  _has_bits_[0] |= 0x00000002u;
}
inline void SnapshotDiffReportEntryProto::clear_has_modificationlabel() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void SnapshotDiffReportEntryProto::clear_modificationlabel() {
  modificationlabel_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_modificationlabel();
}
inline const ::std::string& SnapshotDiffReportEntryProto::modificationlabel() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshotDiffReportEntryProto.modificationLabel)
  return modificationlabel_.GetNoArena();
}
inline void SnapshotDiffReportEntryProto::set_modificationlabel(const ::std::string& value) {
  set_has_modificationlabel();
  modificationlabel_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.SnapshotDiffReportEntryProto.modificationLabel)
}
#if LANG_CXX11
inline void SnapshotDiffReportEntryProto::set_modificationlabel(::std::string&& value) {
  set_has_modificationlabel();
  modificationlabel_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.SnapshotDiffReportEntryProto.modificationLabel)
}
#endif
inline void SnapshotDiffReportEntryProto::set_modificationlabel(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_modificationlabel();
  modificationlabel_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.SnapshotDiffReportEntryProto.modificationLabel)
}
inline void SnapshotDiffReportEntryProto::set_modificationlabel(const char* value, size_t size) {
  set_has_modificationlabel();
  modificationlabel_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.SnapshotDiffReportEntryProto.modificationLabel)
}
inline ::std::string* SnapshotDiffReportEntryProto::mutable_modificationlabel() {
  set_has_modificationlabel();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.SnapshotDiffReportEntryProto.modificationLabel)
  return modificationlabel_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* SnapshotDiffReportEntryProto::release_modificationlabel() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.SnapshotDiffReportEntryProto.modificationLabel)
  if (!has_modificationlabel()) {
    return NULL;
  }
  clear_has_modificationlabel();
  return modificationlabel_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void SnapshotDiffReportEntryProto::set_allocated_modificationlabel(::std::string* modificationlabel) {
  if (modificationlabel != NULL) {
    set_has_modificationlabel();
  } else {
    clear_has_modificationlabel();
  }
  modificationlabel_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), modificationlabel);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.SnapshotDiffReportEntryProto.modificationLabel)
}

// optional bytes targetPath = 3;
inline bool SnapshotDiffReportEntryProto::has_targetpath() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void SnapshotDiffReportEntryProto::set_has_targetpath() {
  _has_bits_[0] |= 0x00000004u;
}
inline void SnapshotDiffReportEntryProto::clear_has_targetpath() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void SnapshotDiffReportEntryProto::clear_targetpath() {
  targetpath_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_targetpath();
}
inline const ::std::string& SnapshotDiffReportEntryProto::targetpath() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshotDiffReportEntryProto.targetPath)
  return targetpath_.GetNoArena();
}
inline void SnapshotDiffReportEntryProto::set_targetpath(const ::std::string& value) {
  set_has_targetpath();
  targetpath_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.SnapshotDiffReportEntryProto.targetPath)
}
#if LANG_CXX11
inline void SnapshotDiffReportEntryProto::set_targetpath(::std::string&& value) {
  set_has_targetpath();
  targetpath_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.SnapshotDiffReportEntryProto.targetPath)
}
#endif
inline void SnapshotDiffReportEntryProto::set_targetpath(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_targetpath();
  targetpath_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.SnapshotDiffReportEntryProto.targetPath)
}
inline void SnapshotDiffReportEntryProto::set_targetpath(const void* value, size_t size) {
  set_has_targetpath();
  targetpath_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.SnapshotDiffReportEntryProto.targetPath)
}
inline ::std::string* SnapshotDiffReportEntryProto::mutable_targetpath() {
  set_has_targetpath();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.SnapshotDiffReportEntryProto.targetPath)
  return targetpath_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* SnapshotDiffReportEntryProto::release_targetpath() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.SnapshotDiffReportEntryProto.targetPath)
  if (!has_targetpath()) {
    return NULL;
  }
  clear_has_targetpath();
  return targetpath_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void SnapshotDiffReportEntryProto::set_allocated_targetpath(::std::string* targetpath) {
  if (targetpath != NULL) {
    set_has_targetpath();
  } else {
    clear_has_targetpath();
  }
  targetpath_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), targetpath);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.SnapshotDiffReportEntryProto.targetPath)
}

// -------------------------------------------------------------------

// SnapshotDiffReportProto

// required string snapshotRoot = 1;
inline bool SnapshotDiffReportProto::has_snapshotroot() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void SnapshotDiffReportProto::set_has_snapshotroot() {
  _has_bits_[0] |= 0x00000001u;
}
inline void SnapshotDiffReportProto::clear_has_snapshotroot() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void SnapshotDiffReportProto::clear_snapshotroot() {
  snapshotroot_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_snapshotroot();
}
inline const ::std::string& SnapshotDiffReportProto::snapshotroot() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshotDiffReportProto.snapshotRoot)
  return snapshotroot_.GetNoArena();
}
inline void SnapshotDiffReportProto::set_snapshotroot(const ::std::string& value) {
  set_has_snapshotroot();
  snapshotroot_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.SnapshotDiffReportProto.snapshotRoot)
}
#if LANG_CXX11
inline void SnapshotDiffReportProto::set_snapshotroot(::std::string&& value) {
  set_has_snapshotroot();
  snapshotroot_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.SnapshotDiffReportProto.snapshotRoot)
}
#endif
inline void SnapshotDiffReportProto::set_snapshotroot(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_snapshotroot();
  snapshotroot_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.SnapshotDiffReportProto.snapshotRoot)
}
inline void SnapshotDiffReportProto::set_snapshotroot(const char* value, size_t size) {
  set_has_snapshotroot();
  snapshotroot_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.SnapshotDiffReportProto.snapshotRoot)
}
inline ::std::string* SnapshotDiffReportProto::mutable_snapshotroot() {
  set_has_snapshotroot();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.SnapshotDiffReportProto.snapshotRoot)
  return snapshotroot_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* SnapshotDiffReportProto::release_snapshotroot() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.SnapshotDiffReportProto.snapshotRoot)
  if (!has_snapshotroot()) {
    return NULL;
  }
  clear_has_snapshotroot();
  return snapshotroot_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void SnapshotDiffReportProto::set_allocated_snapshotroot(::std::string* snapshotroot) {
  if (snapshotroot != NULL) {
    set_has_snapshotroot();
  } else {
    clear_has_snapshotroot();
  }
  snapshotroot_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), snapshotroot);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.SnapshotDiffReportProto.snapshotRoot)
}

// required string fromSnapshot = 2;
inline bool SnapshotDiffReportProto::has_fromsnapshot() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void SnapshotDiffReportProto::set_has_fromsnapshot() {
  _has_bits_[0] |= 0x00000002u;
}
inline void SnapshotDiffReportProto::clear_has_fromsnapshot() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void SnapshotDiffReportProto::clear_fromsnapshot() {
  fromsnapshot_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_fromsnapshot();
}
inline const ::std::string& SnapshotDiffReportProto::fromsnapshot() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshotDiffReportProto.fromSnapshot)
  return fromsnapshot_.GetNoArena();
}
inline void SnapshotDiffReportProto::set_fromsnapshot(const ::std::string& value) {
  set_has_fromsnapshot();
  fromsnapshot_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.SnapshotDiffReportProto.fromSnapshot)
}
#if LANG_CXX11
inline void SnapshotDiffReportProto::set_fromsnapshot(::std::string&& value) {
  set_has_fromsnapshot();
  fromsnapshot_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.SnapshotDiffReportProto.fromSnapshot)
}
#endif
inline void SnapshotDiffReportProto::set_fromsnapshot(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_fromsnapshot();
  fromsnapshot_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.SnapshotDiffReportProto.fromSnapshot)
}
inline void SnapshotDiffReportProto::set_fromsnapshot(const char* value, size_t size) {
  set_has_fromsnapshot();
  fromsnapshot_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.SnapshotDiffReportProto.fromSnapshot)
}
inline ::std::string* SnapshotDiffReportProto::mutable_fromsnapshot() {
  set_has_fromsnapshot();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.SnapshotDiffReportProto.fromSnapshot)
  return fromsnapshot_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* SnapshotDiffReportProto::release_fromsnapshot() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.SnapshotDiffReportProto.fromSnapshot)
  if (!has_fromsnapshot()) {
    return NULL;
  }
  clear_has_fromsnapshot();
  return fromsnapshot_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void SnapshotDiffReportProto::set_allocated_fromsnapshot(::std::string* fromsnapshot) {
  if (fromsnapshot != NULL) {
    set_has_fromsnapshot();
  } else {
    clear_has_fromsnapshot();
  }
  fromsnapshot_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), fromsnapshot);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.SnapshotDiffReportProto.fromSnapshot)
}

// required string toSnapshot = 3;
inline bool SnapshotDiffReportProto::has_tosnapshot() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void SnapshotDiffReportProto::set_has_tosnapshot() {
  _has_bits_[0] |= 0x00000004u;
}
inline void SnapshotDiffReportProto::clear_has_tosnapshot() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void SnapshotDiffReportProto::clear_tosnapshot() {
  tosnapshot_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_tosnapshot();
}
inline const ::std::string& SnapshotDiffReportProto::tosnapshot() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshotDiffReportProto.toSnapshot)
  return tosnapshot_.GetNoArena();
}
inline void SnapshotDiffReportProto::set_tosnapshot(const ::std::string& value) {
  set_has_tosnapshot();
  tosnapshot_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.SnapshotDiffReportProto.toSnapshot)
}
#if LANG_CXX11
inline void SnapshotDiffReportProto::set_tosnapshot(::std::string&& value) {
  set_has_tosnapshot();
  tosnapshot_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.SnapshotDiffReportProto.toSnapshot)
}
#endif
inline void SnapshotDiffReportProto::set_tosnapshot(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_tosnapshot();
  tosnapshot_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.SnapshotDiffReportProto.toSnapshot)
}
inline void SnapshotDiffReportProto::set_tosnapshot(const char* value, size_t size) {
  set_has_tosnapshot();
  tosnapshot_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.SnapshotDiffReportProto.toSnapshot)
}
inline ::std::string* SnapshotDiffReportProto::mutable_tosnapshot() {
  set_has_tosnapshot();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.SnapshotDiffReportProto.toSnapshot)
  return tosnapshot_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* SnapshotDiffReportProto::release_tosnapshot() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.SnapshotDiffReportProto.toSnapshot)
  if (!has_tosnapshot()) {
    return NULL;
  }
  clear_has_tosnapshot();
  return tosnapshot_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void SnapshotDiffReportProto::set_allocated_tosnapshot(::std::string* tosnapshot) {
  if (tosnapshot != NULL) {
    set_has_tosnapshot();
  } else {
    clear_has_tosnapshot();
  }
  tosnapshot_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), tosnapshot);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.SnapshotDiffReportProto.toSnapshot)
}

// repeated .hadoop.hdfs.SnapshotDiffReportEntryProto diffReportEntries = 4;
inline int SnapshotDiffReportProto::diffreportentries_size() const {
  return diffreportentries_.size();
}
inline void SnapshotDiffReportProto::clear_diffreportentries() {
  diffreportentries_.Clear();
}
inline ::hadoop::hdfs::SnapshotDiffReportEntryProto* SnapshotDiffReportProto::mutable_diffreportentries(int index) {
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.SnapshotDiffReportProto.diffReportEntries)
  return diffreportentries_.Mutable(index);
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::SnapshotDiffReportEntryProto >*
SnapshotDiffReportProto::mutable_diffreportentries() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.SnapshotDiffReportProto.diffReportEntries)
  return &diffreportentries_;
}
inline const ::hadoop::hdfs::SnapshotDiffReportEntryProto& SnapshotDiffReportProto::diffreportentries(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshotDiffReportProto.diffReportEntries)
  return diffreportentries_.Get(index);
}
inline ::hadoop::hdfs::SnapshotDiffReportEntryProto* SnapshotDiffReportProto::add_diffreportentries() {
  // @@protoc_insertion_point(field_add:hadoop.hdfs.SnapshotDiffReportProto.diffReportEntries)
  return diffreportentries_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::SnapshotDiffReportEntryProto >&
SnapshotDiffReportProto::diffreportentries() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.SnapshotDiffReportProto.diffReportEntries)
  return diffreportentries_;
}

// -------------------------------------------------------------------

// SnapshotDiffReportListingEntryProto

// required bytes fullpath = 1;
inline bool SnapshotDiffReportListingEntryProto::has_fullpath() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void SnapshotDiffReportListingEntryProto::set_has_fullpath() {
  _has_bits_[0] |= 0x00000001u;
}
inline void SnapshotDiffReportListingEntryProto::clear_has_fullpath() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void SnapshotDiffReportListingEntryProto::clear_fullpath() {
  fullpath_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_fullpath();
}
inline const ::std::string& SnapshotDiffReportListingEntryProto::fullpath() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshotDiffReportListingEntryProto.fullpath)
  return fullpath_.GetNoArena();
}
inline void SnapshotDiffReportListingEntryProto::set_fullpath(const ::std::string& value) {
  set_has_fullpath();
  fullpath_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.SnapshotDiffReportListingEntryProto.fullpath)
}
#if LANG_CXX11
inline void SnapshotDiffReportListingEntryProto::set_fullpath(::std::string&& value) {
  set_has_fullpath();
  fullpath_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.SnapshotDiffReportListingEntryProto.fullpath)
}
#endif
inline void SnapshotDiffReportListingEntryProto::set_fullpath(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_fullpath();
  fullpath_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.SnapshotDiffReportListingEntryProto.fullpath)
}
inline void SnapshotDiffReportListingEntryProto::set_fullpath(const void* value, size_t size) {
  set_has_fullpath();
  fullpath_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.SnapshotDiffReportListingEntryProto.fullpath)
}
inline ::std::string* SnapshotDiffReportListingEntryProto::mutable_fullpath() {
  set_has_fullpath();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.SnapshotDiffReportListingEntryProto.fullpath)
  return fullpath_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* SnapshotDiffReportListingEntryProto::release_fullpath() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.SnapshotDiffReportListingEntryProto.fullpath)
  if (!has_fullpath()) {
    return NULL;
  }
  clear_has_fullpath();
  return fullpath_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void SnapshotDiffReportListingEntryProto::set_allocated_fullpath(::std::string* fullpath) {
  if (fullpath != NULL) {
    set_has_fullpath();
  } else {
    clear_has_fullpath();
  }
  fullpath_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), fullpath);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.SnapshotDiffReportListingEntryProto.fullpath)
}

// required uint64 dirId = 2;
inline bool SnapshotDiffReportListingEntryProto::has_dirid() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void SnapshotDiffReportListingEntryProto::set_has_dirid() {
  _has_bits_[0] |= 0x00000004u;
}
inline void SnapshotDiffReportListingEntryProto::clear_has_dirid() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void SnapshotDiffReportListingEntryProto::clear_dirid() {
  dirid_ = GOOGLE_ULONGLONG(0);
  clear_has_dirid();
}
inline ::google::protobuf::uint64 SnapshotDiffReportListingEntryProto::dirid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshotDiffReportListingEntryProto.dirId)
  return dirid_;
}
inline void SnapshotDiffReportListingEntryProto::set_dirid(::google::protobuf::uint64 value) {
  set_has_dirid();
  dirid_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.SnapshotDiffReportListingEntryProto.dirId)
}

// required bool isReference = 3;
inline bool SnapshotDiffReportListingEntryProto::has_isreference() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void SnapshotDiffReportListingEntryProto::set_has_isreference() {
  _has_bits_[0] |= 0x00000010u;
}
inline void SnapshotDiffReportListingEntryProto::clear_has_isreference() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void SnapshotDiffReportListingEntryProto::clear_isreference() {
  isreference_ = false;
  clear_has_isreference();
}
inline bool SnapshotDiffReportListingEntryProto::isreference() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshotDiffReportListingEntryProto.isReference)
  return isreference_;
}
inline void SnapshotDiffReportListingEntryProto::set_isreference(bool value) {
  set_has_isreference();
  isreference_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.SnapshotDiffReportListingEntryProto.isReference)
}

// optional bytes targetPath = 4;
inline bool SnapshotDiffReportListingEntryProto::has_targetpath() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void SnapshotDiffReportListingEntryProto::set_has_targetpath() {
  _has_bits_[0] |= 0x00000002u;
}
inline void SnapshotDiffReportListingEntryProto::clear_has_targetpath() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void SnapshotDiffReportListingEntryProto::clear_targetpath() {
  targetpath_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_targetpath();
}
inline const ::std::string& SnapshotDiffReportListingEntryProto::targetpath() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshotDiffReportListingEntryProto.targetPath)
  return targetpath_.GetNoArena();
}
inline void SnapshotDiffReportListingEntryProto::set_targetpath(const ::std::string& value) {
  set_has_targetpath();
  targetpath_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.SnapshotDiffReportListingEntryProto.targetPath)
}
#if LANG_CXX11
inline void SnapshotDiffReportListingEntryProto::set_targetpath(::std::string&& value) {
  set_has_targetpath();
  targetpath_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.SnapshotDiffReportListingEntryProto.targetPath)
}
#endif
inline void SnapshotDiffReportListingEntryProto::set_targetpath(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_targetpath();
  targetpath_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.SnapshotDiffReportListingEntryProto.targetPath)
}
inline void SnapshotDiffReportListingEntryProto::set_targetpath(const void* value, size_t size) {
  set_has_targetpath();
  targetpath_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.SnapshotDiffReportListingEntryProto.targetPath)
}
inline ::std::string* SnapshotDiffReportListingEntryProto::mutable_targetpath() {
  set_has_targetpath();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.SnapshotDiffReportListingEntryProto.targetPath)
  return targetpath_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* SnapshotDiffReportListingEntryProto::release_targetpath() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.SnapshotDiffReportListingEntryProto.targetPath)
  if (!has_targetpath()) {
    return NULL;
  }
  clear_has_targetpath();
  return targetpath_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void SnapshotDiffReportListingEntryProto::set_allocated_targetpath(::std::string* targetpath) {
  if (targetpath != NULL) {
    set_has_targetpath();
  } else {
    clear_has_targetpath();
  }
  targetpath_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), targetpath);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.SnapshotDiffReportListingEntryProto.targetPath)
}

// optional uint64 fileId = 5;
inline bool SnapshotDiffReportListingEntryProto::has_fileid() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void SnapshotDiffReportListingEntryProto::set_has_fileid() {
  _has_bits_[0] |= 0x00000008u;
}
inline void SnapshotDiffReportListingEntryProto::clear_has_fileid() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void SnapshotDiffReportListingEntryProto::clear_fileid() {
  fileid_ = GOOGLE_ULONGLONG(0);
  clear_has_fileid();
}
inline ::google::protobuf::uint64 SnapshotDiffReportListingEntryProto::fileid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshotDiffReportListingEntryProto.fileId)
  return fileid_;
}
inline void SnapshotDiffReportListingEntryProto::set_fileid(::google::protobuf::uint64 value) {
  set_has_fileid();
  fileid_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.SnapshotDiffReportListingEntryProto.fileId)
}

// -------------------------------------------------------------------

// SnapshotDiffReportCursorProto

// required bytes startPath = 1;
inline bool SnapshotDiffReportCursorProto::has_startpath() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void SnapshotDiffReportCursorProto::set_has_startpath() {
  _has_bits_[0] |= 0x00000001u;
}
inline void SnapshotDiffReportCursorProto::clear_has_startpath() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void SnapshotDiffReportCursorProto::clear_startpath() {
  startpath_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_startpath();
}
inline const ::std::string& SnapshotDiffReportCursorProto::startpath() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshotDiffReportCursorProto.startPath)
  return startpath_.GetNoArena();
}
inline void SnapshotDiffReportCursorProto::set_startpath(const ::std::string& value) {
  set_has_startpath();
  startpath_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.SnapshotDiffReportCursorProto.startPath)
}
#if LANG_CXX11
inline void SnapshotDiffReportCursorProto::set_startpath(::std::string&& value) {
  set_has_startpath();
  startpath_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.SnapshotDiffReportCursorProto.startPath)
}
#endif
inline void SnapshotDiffReportCursorProto::set_startpath(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_startpath();
  startpath_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.SnapshotDiffReportCursorProto.startPath)
}
inline void SnapshotDiffReportCursorProto::set_startpath(const void* value, size_t size) {
  set_has_startpath();
  startpath_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.SnapshotDiffReportCursorProto.startPath)
}
inline ::std::string* SnapshotDiffReportCursorProto::mutable_startpath() {
  set_has_startpath();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.SnapshotDiffReportCursorProto.startPath)
  return startpath_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* SnapshotDiffReportCursorProto::release_startpath() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.SnapshotDiffReportCursorProto.startPath)
  if (!has_startpath()) {
    return NULL;
  }
  clear_has_startpath();
  return startpath_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void SnapshotDiffReportCursorProto::set_allocated_startpath(::std::string* startpath) {
  if (startpath != NULL) {
    set_has_startpath();
  } else {
    clear_has_startpath();
  }
  startpath_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), startpath);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.SnapshotDiffReportCursorProto.startPath)
}

// required int32 index = 2 [default = -1];
inline bool SnapshotDiffReportCursorProto::has_index() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void SnapshotDiffReportCursorProto::set_has_index() {
  _has_bits_[0] |= 0x00000002u;
}
inline void SnapshotDiffReportCursorProto::clear_has_index() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void SnapshotDiffReportCursorProto::clear_index() {
  index_ = -1;
  clear_has_index();
}
inline ::google::protobuf::int32 SnapshotDiffReportCursorProto::index() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshotDiffReportCursorProto.index)
  return index_;
}
inline void SnapshotDiffReportCursorProto::set_index(::google::protobuf::int32 value) {
  set_has_index();
  index_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.SnapshotDiffReportCursorProto.index)
}

// -------------------------------------------------------------------

// SnapshotDiffReportListingProto

// repeated .hadoop.hdfs.SnapshotDiffReportListingEntryProto modifiedEntries = 1;
inline int SnapshotDiffReportListingProto::modifiedentries_size() const {
  return modifiedentries_.size();
}
inline void SnapshotDiffReportListingProto::clear_modifiedentries() {
  modifiedentries_.Clear();
}
inline ::hadoop::hdfs::SnapshotDiffReportListingEntryProto* SnapshotDiffReportListingProto::mutable_modifiedentries(int index) {
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.SnapshotDiffReportListingProto.modifiedEntries)
  return modifiedentries_.Mutable(index);
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::SnapshotDiffReportListingEntryProto >*
SnapshotDiffReportListingProto::mutable_modifiedentries() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.SnapshotDiffReportListingProto.modifiedEntries)
  return &modifiedentries_;
}
inline const ::hadoop::hdfs::SnapshotDiffReportListingEntryProto& SnapshotDiffReportListingProto::modifiedentries(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshotDiffReportListingProto.modifiedEntries)
  return modifiedentries_.Get(index);
}
inline ::hadoop::hdfs::SnapshotDiffReportListingEntryProto* SnapshotDiffReportListingProto::add_modifiedentries() {
  // @@protoc_insertion_point(field_add:hadoop.hdfs.SnapshotDiffReportListingProto.modifiedEntries)
  return modifiedentries_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::SnapshotDiffReportListingEntryProto >&
SnapshotDiffReportListingProto::modifiedentries() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.SnapshotDiffReportListingProto.modifiedEntries)
  return modifiedentries_;
}

// repeated .hadoop.hdfs.SnapshotDiffReportListingEntryProto createdEntries = 2;
inline int SnapshotDiffReportListingProto::createdentries_size() const {
  return createdentries_.size();
}
inline void SnapshotDiffReportListingProto::clear_createdentries() {
  createdentries_.Clear();
}
inline ::hadoop::hdfs::SnapshotDiffReportListingEntryProto* SnapshotDiffReportListingProto::mutable_createdentries(int index) {
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.SnapshotDiffReportListingProto.createdEntries)
  return createdentries_.Mutable(index);
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::SnapshotDiffReportListingEntryProto >*
SnapshotDiffReportListingProto::mutable_createdentries() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.SnapshotDiffReportListingProto.createdEntries)
  return &createdentries_;
}
inline const ::hadoop::hdfs::SnapshotDiffReportListingEntryProto& SnapshotDiffReportListingProto::createdentries(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshotDiffReportListingProto.createdEntries)
  return createdentries_.Get(index);
}
inline ::hadoop::hdfs::SnapshotDiffReportListingEntryProto* SnapshotDiffReportListingProto::add_createdentries() {
  // @@protoc_insertion_point(field_add:hadoop.hdfs.SnapshotDiffReportListingProto.createdEntries)
  return createdentries_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::SnapshotDiffReportListingEntryProto >&
SnapshotDiffReportListingProto::createdentries() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.SnapshotDiffReportListingProto.createdEntries)
  return createdentries_;
}

// repeated .hadoop.hdfs.SnapshotDiffReportListingEntryProto deletedEntries = 3;
inline int SnapshotDiffReportListingProto::deletedentries_size() const {
  return deletedentries_.size();
}
inline void SnapshotDiffReportListingProto::clear_deletedentries() {
  deletedentries_.Clear();
}
inline ::hadoop::hdfs::SnapshotDiffReportListingEntryProto* SnapshotDiffReportListingProto::mutable_deletedentries(int index) {
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.SnapshotDiffReportListingProto.deletedEntries)
  return deletedentries_.Mutable(index);
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::SnapshotDiffReportListingEntryProto >*
SnapshotDiffReportListingProto::mutable_deletedentries() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.SnapshotDiffReportListingProto.deletedEntries)
  return &deletedentries_;
}
inline const ::hadoop::hdfs::SnapshotDiffReportListingEntryProto& SnapshotDiffReportListingProto::deletedentries(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshotDiffReportListingProto.deletedEntries)
  return deletedentries_.Get(index);
}
inline ::hadoop::hdfs::SnapshotDiffReportListingEntryProto* SnapshotDiffReportListingProto::add_deletedentries() {
  // @@protoc_insertion_point(field_add:hadoop.hdfs.SnapshotDiffReportListingProto.deletedEntries)
  return deletedentries_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::SnapshotDiffReportListingEntryProto >&
SnapshotDiffReportListingProto::deletedentries() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.SnapshotDiffReportListingProto.deletedEntries)
  return deletedentries_;
}

// required bool isFromEarlier = 4;
inline bool SnapshotDiffReportListingProto::has_isfromearlier() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void SnapshotDiffReportListingProto::set_has_isfromearlier() {
  _has_bits_[0] |= 0x00000002u;
}
inline void SnapshotDiffReportListingProto::clear_has_isfromearlier() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void SnapshotDiffReportListingProto::clear_isfromearlier() {
  isfromearlier_ = false;
  clear_has_isfromearlier();
}
inline bool SnapshotDiffReportListingProto::isfromearlier() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshotDiffReportListingProto.isFromEarlier)
  return isfromearlier_;
}
inline void SnapshotDiffReportListingProto::set_isfromearlier(bool value) {
  set_has_isfromearlier();
  isfromearlier_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.SnapshotDiffReportListingProto.isFromEarlier)
}

// optional .hadoop.hdfs.SnapshotDiffReportCursorProto cursor = 5;
inline bool SnapshotDiffReportListingProto::has_cursor() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void SnapshotDiffReportListingProto::set_has_cursor() {
  _has_bits_[0] |= 0x00000001u;
}
inline void SnapshotDiffReportListingProto::clear_has_cursor() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void SnapshotDiffReportListingProto::clear_cursor() {
  if (cursor_ != NULL) cursor_->Clear();
  clear_has_cursor();
}
inline const ::hadoop::hdfs::SnapshotDiffReportCursorProto& SnapshotDiffReportListingProto::_internal_cursor() const {
  return *cursor_;
}
inline const ::hadoop::hdfs::SnapshotDiffReportCursorProto& SnapshotDiffReportListingProto::cursor() const {
  const ::hadoop::hdfs::SnapshotDiffReportCursorProto* p = cursor_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshotDiffReportListingProto.cursor)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::SnapshotDiffReportCursorProto*>(
      &::hadoop::hdfs::_SnapshotDiffReportCursorProto_default_instance_);
}
inline ::hadoop::hdfs::SnapshotDiffReportCursorProto* SnapshotDiffReportListingProto::release_cursor() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.SnapshotDiffReportListingProto.cursor)
  clear_has_cursor();
  ::hadoop::hdfs::SnapshotDiffReportCursorProto* temp = cursor_;
  cursor_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::SnapshotDiffReportCursorProto* SnapshotDiffReportListingProto::mutable_cursor() {
  set_has_cursor();
  if (cursor_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::SnapshotDiffReportCursorProto>(GetArenaNoVirtual());
    cursor_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.SnapshotDiffReportListingProto.cursor)
  return cursor_;
}
inline void SnapshotDiffReportListingProto::set_allocated_cursor(::hadoop::hdfs::SnapshotDiffReportCursorProto* cursor) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete cursor_;
  }
  if (cursor) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      cursor = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, cursor, submessage_arena);
    }
    set_has_cursor();
  } else {
    clear_has_cursor();
  }
  cursor_ = cursor;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.SnapshotDiffReportListingProto.cursor)
}

// -------------------------------------------------------------------

// BlockProto

// required uint64 blockId = 1;
inline bool BlockProto::has_blockid() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void BlockProto::set_has_blockid() {
  _has_bits_[0] |= 0x00000001u;
}
inline void BlockProto::clear_has_blockid() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void BlockProto::clear_blockid() {
  blockid_ = GOOGLE_ULONGLONG(0);
  clear_has_blockid();
}
inline ::google::protobuf::uint64 BlockProto::blockid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockProto.blockId)
  return blockid_;
}
inline void BlockProto::set_blockid(::google::protobuf::uint64 value) {
  set_has_blockid();
  blockid_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockProto.blockId)
}

// required uint64 genStamp = 2;
inline bool BlockProto::has_genstamp() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void BlockProto::set_has_genstamp() {
  _has_bits_[0] |= 0x00000002u;
}
inline void BlockProto::clear_has_genstamp() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void BlockProto::clear_genstamp() {
  genstamp_ = GOOGLE_ULONGLONG(0);
  clear_has_genstamp();
}
inline ::google::protobuf::uint64 BlockProto::genstamp() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockProto.genStamp)
  return genstamp_;
}
inline void BlockProto::set_genstamp(::google::protobuf::uint64 value) {
  set_has_genstamp();
  genstamp_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockProto.genStamp)
}

// optional uint64 numBytes = 3 [default = 0];
inline bool BlockProto::has_numbytes() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void BlockProto::set_has_numbytes() {
  _has_bits_[0] |= 0x00000004u;
}
inline void BlockProto::clear_has_numbytes() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void BlockProto::clear_numbytes() {
  numbytes_ = GOOGLE_ULONGLONG(0);
  clear_has_numbytes();
}
inline ::google::protobuf::uint64 BlockProto::numbytes() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockProto.numBytes)
  return numbytes_;
}
inline void BlockProto::set_numbytes(::google::protobuf::uint64 value) {
  set_has_numbytes();
  numbytes_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockProto.numBytes)
}

// -------------------------------------------------------------------

// SnapshotInfoProto

// required string snapshotName = 1;
inline bool SnapshotInfoProto::has_snapshotname() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void SnapshotInfoProto::set_has_snapshotname() {
  _has_bits_[0] |= 0x00000001u;
}
inline void SnapshotInfoProto::clear_has_snapshotname() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void SnapshotInfoProto::clear_snapshotname() {
  snapshotname_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_snapshotname();
}
inline const ::std::string& SnapshotInfoProto::snapshotname() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshotInfoProto.snapshotName)
  return snapshotname_.GetNoArena();
}
inline void SnapshotInfoProto::set_snapshotname(const ::std::string& value) {
  set_has_snapshotname();
  snapshotname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.SnapshotInfoProto.snapshotName)
}
#if LANG_CXX11
inline void SnapshotInfoProto::set_snapshotname(::std::string&& value) {
  set_has_snapshotname();
  snapshotname_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.SnapshotInfoProto.snapshotName)
}
#endif
inline void SnapshotInfoProto::set_snapshotname(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_snapshotname();
  snapshotname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.SnapshotInfoProto.snapshotName)
}
inline void SnapshotInfoProto::set_snapshotname(const char* value, size_t size) {
  set_has_snapshotname();
  snapshotname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.SnapshotInfoProto.snapshotName)
}
inline ::std::string* SnapshotInfoProto::mutable_snapshotname() {
  set_has_snapshotname();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.SnapshotInfoProto.snapshotName)
  return snapshotname_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* SnapshotInfoProto::release_snapshotname() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.SnapshotInfoProto.snapshotName)
  if (!has_snapshotname()) {
    return NULL;
  }
  clear_has_snapshotname();
  return snapshotname_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void SnapshotInfoProto::set_allocated_snapshotname(::std::string* snapshotname) {
  if (snapshotname != NULL) {
    set_has_snapshotname();
  } else {
    clear_has_snapshotname();
  }
  snapshotname_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), snapshotname);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.SnapshotInfoProto.snapshotName)
}

// required string snapshotRoot = 2;
inline bool SnapshotInfoProto::has_snapshotroot() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void SnapshotInfoProto::set_has_snapshotroot() {
  _has_bits_[0] |= 0x00000002u;
}
inline void SnapshotInfoProto::clear_has_snapshotroot() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void SnapshotInfoProto::clear_snapshotroot() {
  snapshotroot_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_snapshotroot();
}
inline const ::std::string& SnapshotInfoProto::snapshotroot() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshotInfoProto.snapshotRoot)
  return snapshotroot_.GetNoArena();
}
inline void SnapshotInfoProto::set_snapshotroot(const ::std::string& value) {
  set_has_snapshotroot();
  snapshotroot_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.SnapshotInfoProto.snapshotRoot)
}
#if LANG_CXX11
inline void SnapshotInfoProto::set_snapshotroot(::std::string&& value) {
  set_has_snapshotroot();
  snapshotroot_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.SnapshotInfoProto.snapshotRoot)
}
#endif
inline void SnapshotInfoProto::set_snapshotroot(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_snapshotroot();
  snapshotroot_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.SnapshotInfoProto.snapshotRoot)
}
inline void SnapshotInfoProto::set_snapshotroot(const char* value, size_t size) {
  set_has_snapshotroot();
  snapshotroot_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.SnapshotInfoProto.snapshotRoot)
}
inline ::std::string* SnapshotInfoProto::mutable_snapshotroot() {
  set_has_snapshotroot();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.SnapshotInfoProto.snapshotRoot)
  return snapshotroot_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* SnapshotInfoProto::release_snapshotroot() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.SnapshotInfoProto.snapshotRoot)
  if (!has_snapshotroot()) {
    return NULL;
  }
  clear_has_snapshotroot();
  return snapshotroot_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void SnapshotInfoProto::set_allocated_snapshotroot(::std::string* snapshotroot) {
  if (snapshotroot != NULL) {
    set_has_snapshotroot();
  } else {
    clear_has_snapshotroot();
  }
  snapshotroot_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), snapshotroot);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.SnapshotInfoProto.snapshotRoot)
}

// required .hadoop.hdfs.FsPermissionProto permission = 3;
inline bool SnapshotInfoProto::has_permission() const {
  return (_has_bits_[0] & 0x00000020u) != 0;
}
inline void SnapshotInfoProto::set_has_permission() {
  _has_bits_[0] |= 0x00000020u;
}
inline void SnapshotInfoProto::clear_has_permission() {
  _has_bits_[0] &= ~0x00000020u;
}
inline const ::hadoop::hdfs::FsPermissionProto& SnapshotInfoProto::_internal_permission() const {
  return *permission_;
}
inline const ::hadoop::hdfs::FsPermissionProto& SnapshotInfoProto::permission() const {
  const ::hadoop::hdfs::FsPermissionProto* p = permission_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshotInfoProto.permission)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::FsPermissionProto*>(
      &::hadoop::hdfs::_FsPermissionProto_default_instance_);
}
inline ::hadoop::hdfs::FsPermissionProto* SnapshotInfoProto::release_permission() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.SnapshotInfoProto.permission)
  clear_has_permission();
  ::hadoop::hdfs::FsPermissionProto* temp = permission_;
  permission_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::FsPermissionProto* SnapshotInfoProto::mutable_permission() {
  set_has_permission();
  if (permission_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::FsPermissionProto>(GetArenaNoVirtual());
    permission_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.SnapshotInfoProto.permission)
  return permission_;
}
inline void SnapshotInfoProto::set_allocated_permission(::hadoop::hdfs::FsPermissionProto* permission) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete reinterpret_cast< ::google::protobuf::MessageLite*>(permission_);
  }
  if (permission) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      permission = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, permission, submessage_arena);
    }
    set_has_permission();
  } else {
    clear_has_permission();
  }
  permission_ = permission;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.SnapshotInfoProto.permission)
}

// required string owner = 4;
inline bool SnapshotInfoProto::has_owner() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void SnapshotInfoProto::set_has_owner() {
  _has_bits_[0] |= 0x00000004u;
}
inline void SnapshotInfoProto::clear_has_owner() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void SnapshotInfoProto::clear_owner() {
  owner_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_owner();
}
inline const ::std::string& SnapshotInfoProto::owner() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshotInfoProto.owner)
  return owner_.GetNoArena();
}
inline void SnapshotInfoProto::set_owner(const ::std::string& value) {
  set_has_owner();
  owner_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.SnapshotInfoProto.owner)
}
#if LANG_CXX11
inline void SnapshotInfoProto::set_owner(::std::string&& value) {
  set_has_owner();
  owner_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.SnapshotInfoProto.owner)
}
#endif
inline void SnapshotInfoProto::set_owner(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_owner();
  owner_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.SnapshotInfoProto.owner)
}
inline void SnapshotInfoProto::set_owner(const char* value, size_t size) {
  set_has_owner();
  owner_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.SnapshotInfoProto.owner)
}
inline ::std::string* SnapshotInfoProto::mutable_owner() {
  set_has_owner();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.SnapshotInfoProto.owner)
  return owner_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* SnapshotInfoProto::release_owner() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.SnapshotInfoProto.owner)
  if (!has_owner()) {
    return NULL;
  }
  clear_has_owner();
  return owner_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void SnapshotInfoProto::set_allocated_owner(::std::string* owner) {
  if (owner != NULL) {
    set_has_owner();
  } else {
    clear_has_owner();
  }
  owner_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), owner);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.SnapshotInfoProto.owner)
}

// required string group = 5;
inline bool SnapshotInfoProto::has_group() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void SnapshotInfoProto::set_has_group() {
  _has_bits_[0] |= 0x00000008u;
}
inline void SnapshotInfoProto::clear_has_group() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void SnapshotInfoProto::clear_group() {
  group_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_group();
}
inline const ::std::string& SnapshotInfoProto::group() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshotInfoProto.group)
  return group_.GetNoArena();
}
inline void SnapshotInfoProto::set_group(const ::std::string& value) {
  set_has_group();
  group_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.SnapshotInfoProto.group)
}
#if LANG_CXX11
inline void SnapshotInfoProto::set_group(::std::string&& value) {
  set_has_group();
  group_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.SnapshotInfoProto.group)
}
#endif
inline void SnapshotInfoProto::set_group(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_group();
  group_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.SnapshotInfoProto.group)
}
inline void SnapshotInfoProto::set_group(const char* value, size_t size) {
  set_has_group();
  group_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.SnapshotInfoProto.group)
}
inline ::std::string* SnapshotInfoProto::mutable_group() {
  set_has_group();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.SnapshotInfoProto.group)
  return group_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* SnapshotInfoProto::release_group() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.SnapshotInfoProto.group)
  if (!has_group()) {
    return NULL;
  }
  clear_has_group();
  return group_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void SnapshotInfoProto::set_allocated_group(::std::string* group) {
  if (group != NULL) {
    set_has_group();
  } else {
    clear_has_group();
  }
  group_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), group);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.SnapshotInfoProto.group)
}

// required string createTime = 6;
inline bool SnapshotInfoProto::has_createtime() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void SnapshotInfoProto::set_has_createtime() {
  _has_bits_[0] |= 0x00000010u;
}
inline void SnapshotInfoProto::clear_has_createtime() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void SnapshotInfoProto::clear_createtime() {
  createtime_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_createtime();
}
inline const ::std::string& SnapshotInfoProto::createtime() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.SnapshotInfoProto.createTime)
  return createtime_.GetNoArena();
}
inline void SnapshotInfoProto::set_createtime(const ::std::string& value) {
  set_has_createtime();
  createtime_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.SnapshotInfoProto.createTime)
}
#if LANG_CXX11
inline void SnapshotInfoProto::set_createtime(::std::string&& value) {
  set_has_createtime();
  createtime_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.SnapshotInfoProto.createTime)
}
#endif
inline void SnapshotInfoProto::set_createtime(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_createtime();
  createtime_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.SnapshotInfoProto.createTime)
}
inline void SnapshotInfoProto::set_createtime(const char* value, size_t size) {
  set_has_createtime();
  createtime_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.SnapshotInfoProto.createTime)
}
inline ::std::string* SnapshotInfoProto::mutable_createtime() {
  set_has_createtime();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.SnapshotInfoProto.createTime)
  return createtime_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* SnapshotInfoProto::release_createtime() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.SnapshotInfoProto.createTime)
  if (!has_createtime()) {
    return NULL;
  }
  clear_has_createtime();
  return createtime_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void SnapshotInfoProto::set_allocated_createtime(::std::string* createtime) {
  if (createtime != NULL) {
    set_has_createtime();
  } else {
    clear_has_createtime();
  }
  createtime_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), createtime);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.SnapshotInfoProto.createTime)
}

// -------------------------------------------------------------------

// RollingUpgradeStatusProto

// required string blockPoolId = 1;
inline bool RollingUpgradeStatusProto::has_blockpoolid() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void RollingUpgradeStatusProto::set_has_blockpoolid() {
  _has_bits_[0] |= 0x00000001u;
}
inline void RollingUpgradeStatusProto::clear_has_blockpoolid() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void RollingUpgradeStatusProto::clear_blockpoolid() {
  blockpoolid_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_blockpoolid();
}
inline const ::std::string& RollingUpgradeStatusProto::blockpoolid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.RollingUpgradeStatusProto.blockPoolId)
  return blockpoolid_.GetNoArena();
}
inline void RollingUpgradeStatusProto::set_blockpoolid(const ::std::string& value) {
  set_has_blockpoolid();
  blockpoolid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.RollingUpgradeStatusProto.blockPoolId)
}
#if LANG_CXX11
inline void RollingUpgradeStatusProto::set_blockpoolid(::std::string&& value) {
  set_has_blockpoolid();
  blockpoolid_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.RollingUpgradeStatusProto.blockPoolId)
}
#endif
inline void RollingUpgradeStatusProto::set_blockpoolid(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_blockpoolid();
  blockpoolid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.RollingUpgradeStatusProto.blockPoolId)
}
inline void RollingUpgradeStatusProto::set_blockpoolid(const char* value, size_t size) {
  set_has_blockpoolid();
  blockpoolid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.RollingUpgradeStatusProto.blockPoolId)
}
inline ::std::string* RollingUpgradeStatusProto::mutable_blockpoolid() {
  set_has_blockpoolid();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.RollingUpgradeStatusProto.blockPoolId)
  return blockpoolid_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* RollingUpgradeStatusProto::release_blockpoolid() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.RollingUpgradeStatusProto.blockPoolId)
  if (!has_blockpoolid()) {
    return NULL;
  }
  clear_has_blockpoolid();
  return blockpoolid_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void RollingUpgradeStatusProto::set_allocated_blockpoolid(::std::string* blockpoolid) {
  if (blockpoolid != NULL) {
    set_has_blockpoolid();
  } else {
    clear_has_blockpoolid();
  }
  blockpoolid_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), blockpoolid);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.RollingUpgradeStatusProto.blockPoolId)
}

// optional bool finalized = 2 [default = false];
inline bool RollingUpgradeStatusProto::has_finalized() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void RollingUpgradeStatusProto::set_has_finalized() {
  _has_bits_[0] |= 0x00000002u;
}
inline void RollingUpgradeStatusProto::clear_has_finalized() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void RollingUpgradeStatusProto::clear_finalized() {
  finalized_ = false;
  clear_has_finalized();
}
inline bool RollingUpgradeStatusProto::finalized() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.RollingUpgradeStatusProto.finalized)
  return finalized_;
}
inline void RollingUpgradeStatusProto::set_finalized(bool value) {
  set_has_finalized();
  finalized_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.RollingUpgradeStatusProto.finalized)
}

// -------------------------------------------------------------------

// StorageUuidsProto

// repeated string storageUuids = 1;
inline int StorageUuidsProto::storageuuids_size() const {
  return storageuuids_.size();
}
inline void StorageUuidsProto::clear_storageuuids() {
  storageuuids_.Clear();
}
inline const ::std::string& StorageUuidsProto::storageuuids(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.StorageUuidsProto.storageUuids)
  return storageuuids_.Get(index);
}
inline ::std::string* StorageUuidsProto::mutable_storageuuids(int index) {
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.StorageUuidsProto.storageUuids)
  return storageuuids_.Mutable(index);
}
inline void StorageUuidsProto::set_storageuuids(int index, const ::std::string& value) {
  // @@protoc_insertion_point(field_set:hadoop.hdfs.StorageUuidsProto.storageUuids)
  storageuuids_.Mutable(index)->assign(value);
}
#if LANG_CXX11
inline void StorageUuidsProto::set_storageuuids(int index, ::std::string&& value) {
  // @@protoc_insertion_point(field_set:hadoop.hdfs.StorageUuidsProto.storageUuids)
  storageuuids_.Mutable(index)->assign(std::move(value));
}
#endif
inline void StorageUuidsProto::set_storageuuids(int index, const char* value) {
  GOOGLE_DCHECK(value != NULL);
  storageuuids_.Mutable(index)->assign(value);
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.StorageUuidsProto.storageUuids)
}
inline void StorageUuidsProto::set_storageuuids(int index, const char* value, size_t size) {
  storageuuids_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.StorageUuidsProto.storageUuids)
}
inline ::std::string* StorageUuidsProto::add_storageuuids() {
  // @@protoc_insertion_point(field_add_mutable:hadoop.hdfs.StorageUuidsProto.storageUuids)
  return storageuuids_.Add();
}
inline void StorageUuidsProto::add_storageuuids(const ::std::string& value) {
  storageuuids_.Add()->assign(value);
  // @@protoc_insertion_point(field_add:hadoop.hdfs.StorageUuidsProto.storageUuids)
}
#if LANG_CXX11
inline void StorageUuidsProto::add_storageuuids(::std::string&& value) {
  storageuuids_.Add(std::move(value));
  // @@protoc_insertion_point(field_add:hadoop.hdfs.StorageUuidsProto.storageUuids)
}
#endif
inline void StorageUuidsProto::add_storageuuids(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  storageuuids_.Add()->assign(value);
  // @@protoc_insertion_point(field_add_char:hadoop.hdfs.StorageUuidsProto.storageUuids)
}
inline void StorageUuidsProto::add_storageuuids(const char* value, size_t size) {
  storageuuids_.Add()->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_add_pointer:hadoop.hdfs.StorageUuidsProto.storageUuids)
}
inline const ::google::protobuf::RepeatedPtrField< ::std::string>&
StorageUuidsProto::storageuuids() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.StorageUuidsProto.storageUuids)
  return storageuuids_;
}
inline ::google::protobuf::RepeatedPtrField< ::std::string>*
StorageUuidsProto::mutable_storageuuids() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.StorageUuidsProto.storageUuids)
  return &storageuuids_;
}

// -------------------------------------------------------------------

// BlockTokenSecretProto

// optional uint64 expiryDate = 1;
inline bool BlockTokenSecretProto::has_expirydate() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void BlockTokenSecretProto::set_has_expirydate() {
  _has_bits_[0] |= 0x00000008u;
}
inline void BlockTokenSecretProto::clear_has_expirydate() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void BlockTokenSecretProto::clear_expirydate() {
  expirydate_ = GOOGLE_ULONGLONG(0);
  clear_has_expirydate();
}
inline ::google::protobuf::uint64 BlockTokenSecretProto::expirydate() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockTokenSecretProto.expiryDate)
  return expirydate_;
}
inline void BlockTokenSecretProto::set_expirydate(::google::protobuf::uint64 value) {
  set_has_expirydate();
  expirydate_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockTokenSecretProto.expiryDate)
}

// optional uint32 keyId = 2;
inline bool BlockTokenSecretProto::has_keyid() const {
  return (_has_bits_[0] & 0x00000020u) != 0;
}
inline void BlockTokenSecretProto::set_has_keyid() {
  _has_bits_[0] |= 0x00000020u;
}
inline void BlockTokenSecretProto::clear_has_keyid() {
  _has_bits_[0] &= ~0x00000020u;
}
inline void BlockTokenSecretProto::clear_keyid() {
  keyid_ = 0u;
  clear_has_keyid();
}
inline ::google::protobuf::uint32 BlockTokenSecretProto::keyid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockTokenSecretProto.keyId)
  return keyid_;
}
inline void BlockTokenSecretProto::set_keyid(::google::protobuf::uint32 value) {
  set_has_keyid();
  keyid_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockTokenSecretProto.keyId)
}

// optional string userId = 3;
inline bool BlockTokenSecretProto::has_userid() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void BlockTokenSecretProto::set_has_userid() {
  _has_bits_[0] |= 0x00000001u;
}
inline void BlockTokenSecretProto::clear_has_userid() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void BlockTokenSecretProto::clear_userid() {
  userid_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_userid();
}
inline const ::std::string& BlockTokenSecretProto::userid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockTokenSecretProto.userId)
  return userid_.GetNoArena();
}
inline void BlockTokenSecretProto::set_userid(const ::std::string& value) {
  set_has_userid();
  userid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockTokenSecretProto.userId)
}
#if LANG_CXX11
inline void BlockTokenSecretProto::set_userid(::std::string&& value) {
  set_has_userid();
  userid_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.BlockTokenSecretProto.userId)
}
#endif
inline void BlockTokenSecretProto::set_userid(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_userid();
  userid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.BlockTokenSecretProto.userId)
}
inline void BlockTokenSecretProto::set_userid(const char* value, size_t size) {
  set_has_userid();
  userid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.BlockTokenSecretProto.userId)
}
inline ::std::string* BlockTokenSecretProto::mutable_userid() {
  set_has_userid();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.BlockTokenSecretProto.userId)
  return userid_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* BlockTokenSecretProto::release_userid() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.BlockTokenSecretProto.userId)
  if (!has_userid()) {
    return NULL;
  }
  clear_has_userid();
  return userid_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void BlockTokenSecretProto::set_allocated_userid(::std::string* userid) {
  if (userid != NULL) {
    set_has_userid();
  } else {
    clear_has_userid();
  }
  userid_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), userid);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.BlockTokenSecretProto.userId)
}

// optional string blockPoolId = 4;
inline bool BlockTokenSecretProto::has_blockpoolid() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void BlockTokenSecretProto::set_has_blockpoolid() {
  _has_bits_[0] |= 0x00000002u;
}
inline void BlockTokenSecretProto::clear_has_blockpoolid() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void BlockTokenSecretProto::clear_blockpoolid() {
  blockpoolid_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_blockpoolid();
}
inline const ::std::string& BlockTokenSecretProto::blockpoolid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockTokenSecretProto.blockPoolId)
  return blockpoolid_.GetNoArena();
}
inline void BlockTokenSecretProto::set_blockpoolid(const ::std::string& value) {
  set_has_blockpoolid();
  blockpoolid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockTokenSecretProto.blockPoolId)
}
#if LANG_CXX11
inline void BlockTokenSecretProto::set_blockpoolid(::std::string&& value) {
  set_has_blockpoolid();
  blockpoolid_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.BlockTokenSecretProto.blockPoolId)
}
#endif
inline void BlockTokenSecretProto::set_blockpoolid(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_blockpoolid();
  blockpoolid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.BlockTokenSecretProto.blockPoolId)
}
inline void BlockTokenSecretProto::set_blockpoolid(const char* value, size_t size) {
  set_has_blockpoolid();
  blockpoolid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.BlockTokenSecretProto.blockPoolId)
}
inline ::std::string* BlockTokenSecretProto::mutable_blockpoolid() {
  set_has_blockpoolid();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.BlockTokenSecretProto.blockPoolId)
  return blockpoolid_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* BlockTokenSecretProto::release_blockpoolid() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.BlockTokenSecretProto.blockPoolId)
  if (!has_blockpoolid()) {
    return NULL;
  }
  clear_has_blockpoolid();
  return blockpoolid_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void BlockTokenSecretProto::set_allocated_blockpoolid(::std::string* blockpoolid) {
  if (blockpoolid != NULL) {
    set_has_blockpoolid();
  } else {
    clear_has_blockpoolid();
  }
  blockpoolid_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), blockpoolid);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.BlockTokenSecretProto.blockPoolId)
}

// optional uint64 blockId = 5;
inline bool BlockTokenSecretProto::has_blockid() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void BlockTokenSecretProto::set_has_blockid() {
  _has_bits_[0] |= 0x00000010u;
}
inline void BlockTokenSecretProto::clear_has_blockid() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void BlockTokenSecretProto::clear_blockid() {
  blockid_ = GOOGLE_ULONGLONG(0);
  clear_has_blockid();
}
inline ::google::protobuf::uint64 BlockTokenSecretProto::blockid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockTokenSecretProto.blockId)
  return blockid_;
}
inline void BlockTokenSecretProto::set_blockid(::google::protobuf::uint64 value) {
  set_has_blockid();
  blockid_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockTokenSecretProto.blockId)
}

// repeated .hadoop.hdfs.AccessModeProto modes = 6;
inline int BlockTokenSecretProto::modes_size() const {
  return modes_.size();
}
inline void BlockTokenSecretProto::clear_modes() {
  modes_.Clear();
}
inline ::hadoop::hdfs::AccessModeProto BlockTokenSecretProto::modes(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockTokenSecretProto.modes)
  return static_cast< ::hadoop::hdfs::AccessModeProto >(modes_.Get(index));
}
inline void BlockTokenSecretProto::set_modes(int index, ::hadoop::hdfs::AccessModeProto value) {
  assert(::hadoop::hdfs::AccessModeProto_IsValid(value));
  modes_.Set(index, value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockTokenSecretProto.modes)
}
inline void BlockTokenSecretProto::add_modes(::hadoop::hdfs::AccessModeProto value) {
  assert(::hadoop::hdfs::AccessModeProto_IsValid(value));
  modes_.Add(value);
  // @@protoc_insertion_point(field_add:hadoop.hdfs.BlockTokenSecretProto.modes)
}
inline const ::google::protobuf::RepeatedField<int>&
BlockTokenSecretProto::modes() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.BlockTokenSecretProto.modes)
  return modes_;
}
inline ::google::protobuf::RepeatedField<int>*
BlockTokenSecretProto::mutable_modes() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.BlockTokenSecretProto.modes)
  return &modes_;
}

// repeated .hadoop.hdfs.StorageTypeProto storageTypes = 7;
inline int BlockTokenSecretProto::storagetypes_size() const {
  return storagetypes_.size();
}
inline void BlockTokenSecretProto::clear_storagetypes() {
  storagetypes_.Clear();
}
inline ::hadoop::hdfs::StorageTypeProto BlockTokenSecretProto::storagetypes(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockTokenSecretProto.storageTypes)
  return static_cast< ::hadoop::hdfs::StorageTypeProto >(storagetypes_.Get(index));
}
inline void BlockTokenSecretProto::set_storagetypes(int index, ::hadoop::hdfs::StorageTypeProto value) {
  assert(::hadoop::hdfs::StorageTypeProto_IsValid(value));
  storagetypes_.Set(index, value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockTokenSecretProto.storageTypes)
}
inline void BlockTokenSecretProto::add_storagetypes(::hadoop::hdfs::StorageTypeProto value) {
  assert(::hadoop::hdfs::StorageTypeProto_IsValid(value));
  storagetypes_.Add(value);
  // @@protoc_insertion_point(field_add:hadoop.hdfs.BlockTokenSecretProto.storageTypes)
}
inline const ::google::protobuf::RepeatedField<int>&
BlockTokenSecretProto::storagetypes() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.BlockTokenSecretProto.storageTypes)
  return storagetypes_;
}
inline ::google::protobuf::RepeatedField<int>*
BlockTokenSecretProto::mutable_storagetypes() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.BlockTokenSecretProto.storageTypes)
  return &storagetypes_;
}

// repeated string storageIds = 8;
inline int BlockTokenSecretProto::storageids_size() const {
  return storageids_.size();
}
inline void BlockTokenSecretProto::clear_storageids() {
  storageids_.Clear();
}
inline const ::std::string& BlockTokenSecretProto::storageids(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockTokenSecretProto.storageIds)
  return storageids_.Get(index);
}
inline ::std::string* BlockTokenSecretProto::mutable_storageids(int index) {
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.BlockTokenSecretProto.storageIds)
  return storageids_.Mutable(index);
}
inline void BlockTokenSecretProto::set_storageids(int index, const ::std::string& value) {
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockTokenSecretProto.storageIds)
  storageids_.Mutable(index)->assign(value);
}
#if LANG_CXX11
inline void BlockTokenSecretProto::set_storageids(int index, ::std::string&& value) {
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockTokenSecretProto.storageIds)
  storageids_.Mutable(index)->assign(std::move(value));
}
#endif
inline void BlockTokenSecretProto::set_storageids(int index, const char* value) {
  GOOGLE_DCHECK(value != NULL);
  storageids_.Mutable(index)->assign(value);
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.BlockTokenSecretProto.storageIds)
}
inline void BlockTokenSecretProto::set_storageids(int index, const char* value, size_t size) {
  storageids_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.BlockTokenSecretProto.storageIds)
}
inline ::std::string* BlockTokenSecretProto::add_storageids() {
  // @@protoc_insertion_point(field_add_mutable:hadoop.hdfs.BlockTokenSecretProto.storageIds)
  return storageids_.Add();
}
inline void BlockTokenSecretProto::add_storageids(const ::std::string& value) {
  storageids_.Add()->assign(value);
  // @@protoc_insertion_point(field_add:hadoop.hdfs.BlockTokenSecretProto.storageIds)
}
#if LANG_CXX11
inline void BlockTokenSecretProto::add_storageids(::std::string&& value) {
  storageids_.Add(std::move(value));
  // @@protoc_insertion_point(field_add:hadoop.hdfs.BlockTokenSecretProto.storageIds)
}
#endif
inline void BlockTokenSecretProto::add_storageids(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  storageids_.Add()->assign(value);
  // @@protoc_insertion_point(field_add_char:hadoop.hdfs.BlockTokenSecretProto.storageIds)
}
inline void BlockTokenSecretProto::add_storageids(const char* value, size_t size) {
  storageids_.Add()->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_add_pointer:hadoop.hdfs.BlockTokenSecretProto.storageIds)
}
inline const ::google::protobuf::RepeatedPtrField< ::std::string>&
BlockTokenSecretProto::storageids() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.BlockTokenSecretProto.storageIds)
  return storageids_;
}
inline ::google::protobuf::RepeatedPtrField< ::std::string>*
BlockTokenSecretProto::mutable_storageids() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.BlockTokenSecretProto.storageIds)
  return &storageids_;
}

// optional bytes handshakeSecret = 9;
inline bool BlockTokenSecretProto::has_handshakesecret() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void BlockTokenSecretProto::set_has_handshakesecret() {
  _has_bits_[0] |= 0x00000004u;
}
inline void BlockTokenSecretProto::clear_has_handshakesecret() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void BlockTokenSecretProto::clear_handshakesecret() {
  handshakesecret_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_handshakesecret();
}
inline const ::std::string& BlockTokenSecretProto::handshakesecret() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockTokenSecretProto.handshakeSecret)
  return handshakesecret_.GetNoArena();
}
inline void BlockTokenSecretProto::set_handshakesecret(const ::std::string& value) {
  set_has_handshakesecret();
  handshakesecret_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockTokenSecretProto.handshakeSecret)
}
#if LANG_CXX11
inline void BlockTokenSecretProto::set_handshakesecret(::std::string&& value) {
  set_has_handshakesecret();
  handshakesecret_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.BlockTokenSecretProto.handshakeSecret)
}
#endif
inline void BlockTokenSecretProto::set_handshakesecret(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_handshakesecret();
  handshakesecret_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.BlockTokenSecretProto.handshakeSecret)
}
inline void BlockTokenSecretProto::set_handshakesecret(const void* value, size_t size) {
  set_has_handshakesecret();
  handshakesecret_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.BlockTokenSecretProto.handshakeSecret)
}
inline ::std::string* BlockTokenSecretProto::mutable_handshakesecret() {
  set_has_handshakesecret();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.BlockTokenSecretProto.handshakeSecret)
  return handshakesecret_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* BlockTokenSecretProto::release_handshakesecret() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.BlockTokenSecretProto.handshakeSecret)
  if (!has_handshakesecret()) {
    return NULL;
  }
  clear_has_handshakesecret();
  return handshakesecret_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void BlockTokenSecretProto::set_allocated_handshakesecret(::std::string* handshakesecret) {
  if (handshakesecret != NULL) {
    set_has_handshakesecret();
  } else {
    clear_has_handshakesecret();
  }
  handshakesecret_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), handshakesecret);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.BlockTokenSecretProto.handshakeSecret)
}

#ifdef __GNUC__
  #pragma GCC diagnostic pop
#endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

}  // namespace hdfs
}  // namespace hadoop

namespace google {
namespace protobuf {

template <> struct is_proto_enum< ::hadoop::hdfs::DatanodeInfoProto_AdminState> : ::std::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::hdfs::DatanodeInfoProto_AdminState>() {
  return ::hadoop::hdfs::DatanodeInfoProto_AdminState_descriptor();
}
template <> struct is_proto_enum< ::hadoop::hdfs::DatanodeStorageProto_StorageState> : ::std::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::hdfs::DatanodeStorageProto_StorageState>() {
  return ::hadoop::hdfs::DatanodeStorageProto_StorageState_descriptor();
}
template <> struct is_proto_enum< ::hadoop::hdfs::HdfsFileStatusProto_FileType> : ::std::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::hdfs::HdfsFileStatusProto_FileType>() {
  return ::hadoop::hdfs::HdfsFileStatusProto_FileType_descriptor();
}
template <> struct is_proto_enum< ::hadoop::hdfs::HdfsFileStatusProto_Flags> : ::std::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::hdfs::HdfsFileStatusProto_Flags>() {
  return ::hadoop::hdfs::HdfsFileStatusProto_Flags_descriptor();
}
template <> struct is_proto_enum< ::hadoop::hdfs::StorageTypeProto> : ::std::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::hdfs::StorageTypeProto>() {
  return ::hadoop::hdfs::StorageTypeProto_descriptor();
}
template <> struct is_proto_enum< ::hadoop::hdfs::BlockTypeProto> : ::std::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::hdfs::BlockTypeProto>() {
  return ::hadoop::hdfs::BlockTypeProto_descriptor();
}
template <> struct is_proto_enum< ::hadoop::hdfs::CipherSuiteProto> : ::std::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::hdfs::CipherSuiteProto>() {
  return ::hadoop::hdfs::CipherSuiteProto_descriptor();
}
template <> struct is_proto_enum< ::hadoop::hdfs::CryptoProtocolVersionProto> : ::std::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::hdfs::CryptoProtocolVersionProto>() {
  return ::hadoop::hdfs::CryptoProtocolVersionProto_descriptor();
}
template <> struct is_proto_enum< ::hadoop::hdfs::ErasureCodingPolicyState> : ::std::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::hdfs::ErasureCodingPolicyState>() {
  return ::hadoop::hdfs::ErasureCodingPolicyState_descriptor();
}
template <> struct is_proto_enum< ::hadoop::hdfs::ChecksumTypeProto> : ::std::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::hdfs::ChecksumTypeProto>() {
  return ::hadoop::hdfs::ChecksumTypeProto_descriptor();
}
template <> struct is_proto_enum< ::hadoop::hdfs::BlockChecksumTypeProto> : ::std::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::hdfs::BlockChecksumTypeProto>() {
  return ::hadoop::hdfs::BlockChecksumTypeProto_descriptor();
}
template <> struct is_proto_enum< ::hadoop::hdfs::AccessModeProto> : ::std::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::hdfs::AccessModeProto>() {
  return ::hadoop::hdfs::AccessModeProto_descriptor();
}

}  // namespace protobuf
}  // namespace google

// @@protoc_insertion_point(global_scope)

#endif  // PROTOBUF_INCLUDED_hdfs_2eproto
