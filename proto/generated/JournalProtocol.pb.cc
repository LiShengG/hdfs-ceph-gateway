// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: JournalProtocol.proto

#include "JournalProtocol.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/port.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// This is a temporary google only hack
#ifdef GOOGLE_PROTOBUF_ENFORCE_UNIQUENESS
#include "third_party/protobuf/version.h"
#endif
// @@protoc_insertion_point(includes)

namespace protobuf_JournalProtocol_2eproto {
extern PROTOBUF_INTERNAL_EXPORT_protobuf_JournalProtocol_2eproto ::google::protobuf::internal::SCCInfo<0> scc_info_JournalInfoProto;
}  // namespace protobuf_JournalProtocol_2eproto
namespace hadoop {
namespace hdfs {
class JournalInfoProtoDefaultTypeInternal {
 public:
  ::google::protobuf::internal::ExplicitlyConstructed<JournalInfoProto>
      _instance;
} _JournalInfoProto_default_instance_;
class JournalRequestProtoDefaultTypeInternal {
 public:
  ::google::protobuf::internal::ExplicitlyConstructed<JournalRequestProto>
      _instance;
} _JournalRequestProto_default_instance_;
class JournalResponseProtoDefaultTypeInternal {
 public:
  ::google::protobuf::internal::ExplicitlyConstructed<JournalResponseProto>
      _instance;
} _JournalResponseProto_default_instance_;
class StartLogSegmentRequestProtoDefaultTypeInternal {
 public:
  ::google::protobuf::internal::ExplicitlyConstructed<StartLogSegmentRequestProto>
      _instance;
} _StartLogSegmentRequestProto_default_instance_;
class StartLogSegmentResponseProtoDefaultTypeInternal {
 public:
  ::google::protobuf::internal::ExplicitlyConstructed<StartLogSegmentResponseProto>
      _instance;
} _StartLogSegmentResponseProto_default_instance_;
class FenceRequestProtoDefaultTypeInternal {
 public:
  ::google::protobuf::internal::ExplicitlyConstructed<FenceRequestProto>
      _instance;
} _FenceRequestProto_default_instance_;
class FenceResponseProtoDefaultTypeInternal {
 public:
  ::google::protobuf::internal::ExplicitlyConstructed<FenceResponseProto>
      _instance;
} _FenceResponseProto_default_instance_;
}  // namespace hdfs
}  // namespace hadoop
namespace protobuf_JournalProtocol_2eproto {
static void InitDefaultsJournalInfoProto() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::hadoop::hdfs::_JournalInfoProto_default_instance_;
    new (ptr) ::hadoop::hdfs::JournalInfoProto();
    ::google::protobuf::internal::OnShutdownDestroyMessage(ptr);
  }
  ::hadoop::hdfs::JournalInfoProto::InitAsDefaultInstance();
}

::google::protobuf::internal::SCCInfo<0> scc_info_JournalInfoProto =
    {{ATOMIC_VAR_INIT(::google::protobuf::internal::SCCInfoBase::kUninitialized), 0, InitDefaultsJournalInfoProto}, {}};

static void InitDefaultsJournalRequestProto() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::hadoop::hdfs::_JournalRequestProto_default_instance_;
    new (ptr) ::hadoop::hdfs::JournalRequestProto();
    ::google::protobuf::internal::OnShutdownDestroyMessage(ptr);
  }
  ::hadoop::hdfs::JournalRequestProto::InitAsDefaultInstance();
}

::google::protobuf::internal::SCCInfo<1> scc_info_JournalRequestProto =
    {{ATOMIC_VAR_INIT(::google::protobuf::internal::SCCInfoBase::kUninitialized), 1, InitDefaultsJournalRequestProto}, {
      &protobuf_JournalProtocol_2eproto::scc_info_JournalInfoProto.base,}};

static void InitDefaultsJournalResponseProto() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::hadoop::hdfs::_JournalResponseProto_default_instance_;
    new (ptr) ::hadoop::hdfs::JournalResponseProto();
    ::google::protobuf::internal::OnShutdownDestroyMessage(ptr);
  }
  ::hadoop::hdfs::JournalResponseProto::InitAsDefaultInstance();
}

::google::protobuf::internal::SCCInfo<0> scc_info_JournalResponseProto =
    {{ATOMIC_VAR_INIT(::google::protobuf::internal::SCCInfoBase::kUninitialized), 0, InitDefaultsJournalResponseProto}, {}};

static void InitDefaultsStartLogSegmentRequestProto() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::hadoop::hdfs::_StartLogSegmentRequestProto_default_instance_;
    new (ptr) ::hadoop::hdfs::StartLogSegmentRequestProto();
    ::google::protobuf::internal::OnShutdownDestroyMessage(ptr);
  }
  ::hadoop::hdfs::StartLogSegmentRequestProto::InitAsDefaultInstance();
}

::google::protobuf::internal::SCCInfo<1> scc_info_StartLogSegmentRequestProto =
    {{ATOMIC_VAR_INIT(::google::protobuf::internal::SCCInfoBase::kUninitialized), 1, InitDefaultsStartLogSegmentRequestProto}, {
      &protobuf_JournalProtocol_2eproto::scc_info_JournalInfoProto.base,}};

static void InitDefaultsStartLogSegmentResponseProto() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::hadoop::hdfs::_StartLogSegmentResponseProto_default_instance_;
    new (ptr) ::hadoop::hdfs::StartLogSegmentResponseProto();
    ::google::protobuf::internal::OnShutdownDestroyMessage(ptr);
  }
  ::hadoop::hdfs::StartLogSegmentResponseProto::InitAsDefaultInstance();
}

::google::protobuf::internal::SCCInfo<0> scc_info_StartLogSegmentResponseProto =
    {{ATOMIC_VAR_INIT(::google::protobuf::internal::SCCInfoBase::kUninitialized), 0, InitDefaultsStartLogSegmentResponseProto}, {}};

static void InitDefaultsFenceRequestProto() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::hadoop::hdfs::_FenceRequestProto_default_instance_;
    new (ptr) ::hadoop::hdfs::FenceRequestProto();
    ::google::protobuf::internal::OnShutdownDestroyMessage(ptr);
  }
  ::hadoop::hdfs::FenceRequestProto::InitAsDefaultInstance();
}

::google::protobuf::internal::SCCInfo<1> scc_info_FenceRequestProto =
    {{ATOMIC_VAR_INIT(::google::protobuf::internal::SCCInfoBase::kUninitialized), 1, InitDefaultsFenceRequestProto}, {
      &protobuf_JournalProtocol_2eproto::scc_info_JournalInfoProto.base,}};

static void InitDefaultsFenceResponseProto() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::hadoop::hdfs::_FenceResponseProto_default_instance_;
    new (ptr) ::hadoop::hdfs::FenceResponseProto();
    ::google::protobuf::internal::OnShutdownDestroyMessage(ptr);
  }
  ::hadoop::hdfs::FenceResponseProto::InitAsDefaultInstance();
}

::google::protobuf::internal::SCCInfo<0> scc_info_FenceResponseProto =
    {{ATOMIC_VAR_INIT(::google::protobuf::internal::SCCInfoBase::kUninitialized), 0, InitDefaultsFenceResponseProto}, {}};

void InitDefaults() {
  ::google::protobuf::internal::InitSCC(&scc_info_JournalInfoProto.base);
  ::google::protobuf::internal::InitSCC(&scc_info_JournalRequestProto.base);
  ::google::protobuf::internal::InitSCC(&scc_info_JournalResponseProto.base);
  ::google::protobuf::internal::InitSCC(&scc_info_StartLogSegmentRequestProto.base);
  ::google::protobuf::internal::InitSCC(&scc_info_StartLogSegmentResponseProto.base);
  ::google::protobuf::internal::InitSCC(&scc_info_FenceRequestProto.base);
  ::google::protobuf::internal::InitSCC(&scc_info_FenceResponseProto.base);
}

::google::protobuf::Metadata file_level_metadata[7];

const ::google::protobuf::uint32 TableStruct::offsets[] GOOGLE_PROTOBUF_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::JournalInfoProto, _has_bits_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::JournalInfoProto, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::JournalInfoProto, clusterid_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::JournalInfoProto, layoutversion_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::JournalInfoProto, namespaceid_),
  0,
  1,
  2,
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::JournalRequestProto, _has_bits_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::JournalRequestProto, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::JournalRequestProto, journalinfo_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::JournalRequestProto, firsttxnid_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::JournalRequestProto, numtxns_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::JournalRequestProto, records_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::JournalRequestProto, epoch_),
  1,
  2,
  4,
  0,
  3,
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::JournalResponseProto, _has_bits_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::JournalResponseProto, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::StartLogSegmentRequestProto, _has_bits_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::StartLogSegmentRequestProto, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::StartLogSegmentRequestProto, journalinfo_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::StartLogSegmentRequestProto, txid_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::StartLogSegmentRequestProto, epoch_),
  0,
  1,
  2,
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::StartLogSegmentResponseProto, _has_bits_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::StartLogSegmentResponseProto, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::FenceRequestProto, _has_bits_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::FenceRequestProto, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::FenceRequestProto, journalinfo_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::FenceRequestProto, epoch_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::FenceRequestProto, fencerinfo_),
  1,
  2,
  0,
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::FenceResponseProto, _has_bits_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::FenceResponseProto, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::FenceResponseProto, previousepoch_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::FenceResponseProto, lasttransactionid_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::FenceResponseProto, insync_),
  0,
  1,
  2,
};
static const ::google::protobuf::internal::MigrationSchema schemas[] GOOGLE_PROTOBUF_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
  { 0, 8, sizeof(::hadoop::hdfs::JournalInfoProto)},
  { 11, 21, sizeof(::hadoop::hdfs::JournalRequestProto)},
  { 26, 31, sizeof(::hadoop::hdfs::JournalResponseProto)},
  { 31, 39, sizeof(::hadoop::hdfs::StartLogSegmentRequestProto)},
  { 42, 47, sizeof(::hadoop::hdfs::StartLogSegmentResponseProto)},
  { 47, 55, sizeof(::hadoop::hdfs::FenceRequestProto)},
  { 58, 66, sizeof(::hadoop::hdfs::FenceResponseProto)},
};

static ::google::protobuf::Message const * const file_default_instances[] = {
  reinterpret_cast<const ::google::protobuf::Message*>(&::hadoop::hdfs::_JournalInfoProto_default_instance_),
  reinterpret_cast<const ::google::protobuf::Message*>(&::hadoop::hdfs::_JournalRequestProto_default_instance_),
  reinterpret_cast<const ::google::protobuf::Message*>(&::hadoop::hdfs::_JournalResponseProto_default_instance_),
  reinterpret_cast<const ::google::protobuf::Message*>(&::hadoop::hdfs::_StartLogSegmentRequestProto_default_instance_),
  reinterpret_cast<const ::google::protobuf::Message*>(&::hadoop::hdfs::_StartLogSegmentResponseProto_default_instance_),
  reinterpret_cast<const ::google::protobuf::Message*>(&::hadoop::hdfs::_FenceRequestProto_default_instance_),
  reinterpret_cast<const ::google::protobuf::Message*>(&::hadoop::hdfs::_FenceResponseProto_default_instance_),
};

void protobuf_AssignDescriptors() {
  AddDescriptors();
  AssignDescriptors(
      "JournalProtocol.proto", schemas, file_default_instances, TableStruct::offsets,
      file_level_metadata, NULL, NULL);
}

void protobuf_AssignDescriptorsOnce() {
  static ::google::protobuf::internal::once_flag once;
  ::google::protobuf::internal::call_once(once, protobuf_AssignDescriptors);
}

void protobuf_RegisterTypes(const ::std::string&) GOOGLE_PROTOBUF_ATTRIBUTE_COLD;
void protobuf_RegisterTypes(const ::std::string&) {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::internal::RegisterAllTypes(file_level_metadata, 7);
}

void AddDescriptorsImpl() {
  InitDefaults();
  static const char descriptor[] GOOGLE_PROTOBUF_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
      "\n\025JournalProtocol.proto\022\013hadoop.hdfs\032\nhd"
      "fs.proto\032\020HdfsServer.proto\"Q\n\020JournalInf"
      "oProto\022\021\n\tclusterID\030\001 \002(\t\022\025\n\rlayoutVersi"
      "on\030\002 \001(\r\022\023\n\013namespaceID\030\003 \001(\r\"\216\001\n\023Journa"
      "lRequestProto\0222\n\013journalInfo\030\001 \002(\0132\035.had"
      "oop.hdfs.JournalInfoProto\022\022\n\nfirstTxnId\030"
      "\002 \002(\004\022\017\n\007numTxns\030\003 \002(\r\022\017\n\007records\030\004 \002(\014\022"
      "\r\n\005epoch\030\005 \002(\004\"\026\n\024JournalResponseProto\"n"
      "\n\033StartLogSegmentRequestProto\0222\n\013journal"
      "Info\030\001 \002(\0132\035.hadoop.hdfs.JournalInfoProt"
      "o\022\014\n\004txid\030\002 \002(\004\022\r\n\005epoch\030\003 \002(\004\"\036\n\034StartL"
      "ogSegmentResponseProto\"j\n\021FenceRequestPr"
      "oto\0222\n\013journalInfo\030\001 \002(\0132\035.hadoop.hdfs.J"
      "ournalInfoProto\022\r\n\005epoch\030\002 \002(\004\022\022\n\nfencer"
      "Info\030\003 \001(\t\"V\n\022FenceResponseProto\022\025\n\rprev"
      "iousEpoch\030\001 \001(\004\022\031\n\021lastTransactionId\030\002 \001"
      "(\004\022\016\n\006inSync\030\003 \001(\0102\232\002\n\026JournalProtocolSe"
      "rvice\022N\n\007journal\022 .hadoop.hdfs.JournalRe"
      "questProto\032!.hadoop.hdfs.JournalResponse"
      "Proto\022f\n\017startLogSegment\022(.hadoop.hdfs.S"
      "tartLogSegmentRequestProto\032).hadoop.hdfs"
      ".StartLogSegmentResponseProto\022H\n\005fence\022\036"
      ".hadoop.hdfs.FenceRequestProto\032\037.hadoop."
      "hdfs.FenceResponseProtoBD\n%org.apache.ha"
      "doop.hdfs.protocol.protoB\025JournalProtoco"
      "lProtos\210\001\001\240\001\001"
  };
  ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
      descriptor, 1013);
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
    "JournalProtocol.proto", &protobuf_RegisterTypes);
  ::protobuf_hdfs_2eproto::AddDescriptors();
  ::protobuf_HdfsServer_2eproto::AddDescriptors();
}

void AddDescriptors() {
  static ::google::protobuf::internal::once_flag once;
  ::google::protobuf::internal::call_once(once, AddDescriptorsImpl);
}
// Force AddDescriptors() to be called at dynamic initialization time.
struct StaticDescriptorInitializer {
  StaticDescriptorInitializer() {
    AddDescriptors();
  }
} static_descriptor_initializer;
}  // namespace protobuf_JournalProtocol_2eproto
namespace hadoop {
namespace hdfs {

// ===================================================================

void JournalInfoProto::InitAsDefaultInstance() {
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int JournalInfoProto::kClusterIDFieldNumber;
const int JournalInfoProto::kLayoutVersionFieldNumber;
const int JournalInfoProto::kNamespaceIDFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

JournalInfoProto::JournalInfoProto()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  ::google::protobuf::internal::InitSCC(
      &protobuf_JournalProtocol_2eproto::scc_info_JournalInfoProto.base);
  SharedCtor();
  // @@protoc_insertion_point(constructor:hadoop.hdfs.JournalInfoProto)
}
JournalInfoProto::JournalInfoProto(const JournalInfoProto& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      _has_bits_(from._has_bits_) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  clusterid_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (from.has_clusterid()) {
    clusterid_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.clusterid_);
  }
  ::memcpy(&layoutversion_, &from.layoutversion_,
    static_cast<size_t>(reinterpret_cast<char*>(&namespaceid_) -
    reinterpret_cast<char*>(&layoutversion_)) + sizeof(namespaceid_));
  // @@protoc_insertion_point(copy_constructor:hadoop.hdfs.JournalInfoProto)
}

void JournalInfoProto::SharedCtor() {
  clusterid_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  ::memset(&layoutversion_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&namespaceid_) -
      reinterpret_cast<char*>(&layoutversion_)) + sizeof(namespaceid_));
}

JournalInfoProto::~JournalInfoProto() {
  // @@protoc_insertion_point(destructor:hadoop.hdfs.JournalInfoProto)
  SharedDtor();
}

void JournalInfoProto::SharedDtor() {
  clusterid_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}

void JournalInfoProto::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const ::google::protobuf::Descriptor* JournalInfoProto::descriptor() {
  ::protobuf_JournalProtocol_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_JournalProtocol_2eproto::file_level_metadata[kIndexInFileMessages].descriptor;
}

const JournalInfoProto& JournalInfoProto::default_instance() {
  ::google::protobuf::internal::InitSCC(&protobuf_JournalProtocol_2eproto::scc_info_JournalInfoProto.base);
  return *internal_default_instance();
}


void JournalInfoProto::Clear() {
// @@protoc_insertion_point(message_clear_start:hadoop.hdfs.JournalInfoProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    clusterid_.ClearNonDefaultToEmptyNoArena();
  }
  if (cached_has_bits & 6u) {
    ::memset(&layoutversion_, 0, static_cast<size_t>(
        reinterpret_cast<char*>(&namespaceid_) -
        reinterpret_cast<char*>(&layoutversion_)) + sizeof(namespaceid_));
  }
  _has_bits_.Clear();
  _internal_metadata_.Clear();
}

bool JournalInfoProto::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:hadoop.hdfs.JournalInfoProto)
  for (;;) {
    ::std::pair<::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // required string clusterID = 1;
      case 1: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(10u /* 10 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_clusterid()));
          ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
            this->clusterid().data(), static_cast<int>(this->clusterid().length()),
            ::google::protobuf::internal::WireFormat::PARSE,
            "hadoop.hdfs.JournalInfoProto.clusterID");
        } else {
          goto handle_unusual;
        }
        break;
      }

      // optional uint32 layoutVersion = 2;
      case 2: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(16u /* 16 & 0xFF */)) {
          set_has_layoutversion();
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::uint32, ::google::protobuf::internal::WireFormatLite::TYPE_UINT32>(
                 input, &layoutversion_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // optional uint32 namespaceID = 3;
      case 3: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(24u /* 24 & 0xFF */)) {
          set_has_namespaceid();
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::uint32, ::google::protobuf::internal::WireFormatLite::TYPE_UINT32>(
                 input, &namespaceid_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:hadoop.hdfs.JournalInfoProto)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:hadoop.hdfs.JournalInfoProto)
  return false;
#undef DO_
}

void JournalInfoProto::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:hadoop.hdfs.JournalInfoProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  // required string clusterID = 1;
  if (cached_has_bits & 0x00000001u) {
    ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
      this->clusterid().data(), static_cast<int>(this->clusterid().length()),
      ::google::protobuf::internal::WireFormat::SERIALIZE,
      "hadoop.hdfs.JournalInfoProto.clusterID");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      1, this->clusterid(), output);
  }

  // optional uint32 layoutVersion = 2;
  if (cached_has_bits & 0x00000002u) {
    ::google::protobuf::internal::WireFormatLite::WriteUInt32(2, this->layoutversion(), output);
  }

  // optional uint32 namespaceID = 3;
  if (cached_has_bits & 0x00000004u) {
    ::google::protobuf::internal::WireFormatLite::WriteUInt32(3, this->namespaceid(), output);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        _internal_metadata_.unknown_fields(), output);
  }
  // @@protoc_insertion_point(serialize_end:hadoop.hdfs.JournalInfoProto)
}

::google::protobuf::uint8* JournalInfoProto::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:hadoop.hdfs.JournalInfoProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  // required string clusterID = 1;
  if (cached_has_bits & 0x00000001u) {
    ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
      this->clusterid().data(), static_cast<int>(this->clusterid().length()),
      ::google::protobuf::internal::WireFormat::SERIALIZE,
      "hadoop.hdfs.JournalInfoProto.clusterID");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        1, this->clusterid(), target);
  }

  // optional uint32 layoutVersion = 2;
  if (cached_has_bits & 0x00000002u) {
    target = ::google::protobuf::internal::WireFormatLite::WriteUInt32ToArray(2, this->layoutversion(), target);
  }

  // optional uint32 namespaceID = 3;
  if (cached_has_bits & 0x00000004u) {
    target = ::google::protobuf::internal::WireFormatLite::WriteUInt32ToArray(3, this->namespaceid(), target);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields(), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:hadoop.hdfs.JournalInfoProto)
  return target;
}

size_t JournalInfoProto::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:hadoop.hdfs.JournalInfoProto)
  size_t total_size = 0;

  if (_internal_metadata_.have_unknown_fields()) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        _internal_metadata_.unknown_fields());
  }
  // required string clusterID = 1;
  if (has_clusterid()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->clusterid());
  }
  if (_has_bits_[0 / 32] & 6u) {
    // optional uint32 layoutVersion = 2;
    if (has_layoutversion()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::UInt32Size(
          this->layoutversion());
    }

    // optional uint32 namespaceID = 3;
    if (has_namespaceid()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::UInt32Size(
          this->namespaceid());
    }

  }
  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void JournalInfoProto::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:hadoop.hdfs.JournalInfoProto)
  GOOGLE_DCHECK_NE(&from, this);
  const JournalInfoProto* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const JournalInfoProto>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:hadoop.hdfs.JournalInfoProto)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:hadoop.hdfs.JournalInfoProto)
    MergeFrom(*source);
  }
}

void JournalInfoProto::MergeFrom(const JournalInfoProto& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:hadoop.hdfs.JournalInfoProto)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._has_bits_[0];
  if (cached_has_bits & 7u) {
    if (cached_has_bits & 0x00000001u) {
      set_has_clusterid();
      clusterid_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.clusterid_);
    }
    if (cached_has_bits & 0x00000002u) {
      layoutversion_ = from.layoutversion_;
    }
    if (cached_has_bits & 0x00000004u) {
      namespaceid_ = from.namespaceid_;
    }
    _has_bits_[0] |= cached_has_bits;
  }
}

void JournalInfoProto::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:hadoop.hdfs.JournalInfoProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void JournalInfoProto::CopyFrom(const JournalInfoProto& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:hadoop.hdfs.JournalInfoProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool JournalInfoProto::IsInitialized() const {
  if ((_has_bits_[0] & 0x00000001) != 0x00000001) return false;
  return true;
}

void JournalInfoProto::Swap(JournalInfoProto* other) {
  if (other == this) return;
  InternalSwap(other);
}
void JournalInfoProto::InternalSwap(JournalInfoProto* other) {
  using std::swap;
  clusterid_.Swap(&other->clusterid_, &::google::protobuf::internal::GetEmptyStringAlreadyInited(),
    GetArenaNoVirtual());
  swap(layoutversion_, other->layoutversion_);
  swap(namespaceid_, other->namespaceid_);
  swap(_has_bits_[0], other->_has_bits_[0]);
  _internal_metadata_.Swap(&other->_internal_metadata_);
}

::google::protobuf::Metadata JournalInfoProto::GetMetadata() const {
  protobuf_JournalProtocol_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_JournalProtocol_2eproto::file_level_metadata[kIndexInFileMessages];
}


// ===================================================================

void JournalRequestProto::InitAsDefaultInstance() {
  ::hadoop::hdfs::_JournalRequestProto_default_instance_._instance.get_mutable()->journalinfo_ = const_cast< ::hadoop::hdfs::JournalInfoProto*>(
      ::hadoop::hdfs::JournalInfoProto::internal_default_instance());
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int JournalRequestProto::kJournalInfoFieldNumber;
const int JournalRequestProto::kFirstTxnIdFieldNumber;
const int JournalRequestProto::kNumTxnsFieldNumber;
const int JournalRequestProto::kRecordsFieldNumber;
const int JournalRequestProto::kEpochFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

JournalRequestProto::JournalRequestProto()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  ::google::protobuf::internal::InitSCC(
      &protobuf_JournalProtocol_2eproto::scc_info_JournalRequestProto.base);
  SharedCtor();
  // @@protoc_insertion_point(constructor:hadoop.hdfs.JournalRequestProto)
}
JournalRequestProto::JournalRequestProto(const JournalRequestProto& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      _has_bits_(from._has_bits_) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  records_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (from.has_records()) {
    records_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.records_);
  }
  if (from.has_journalinfo()) {
    journalinfo_ = new ::hadoop::hdfs::JournalInfoProto(*from.journalinfo_);
  } else {
    journalinfo_ = NULL;
  }
  ::memcpy(&firsttxnid_, &from.firsttxnid_,
    static_cast<size_t>(reinterpret_cast<char*>(&numtxns_) -
    reinterpret_cast<char*>(&firsttxnid_)) + sizeof(numtxns_));
  // @@protoc_insertion_point(copy_constructor:hadoop.hdfs.JournalRequestProto)
}

void JournalRequestProto::SharedCtor() {
  records_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  ::memset(&journalinfo_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&numtxns_) -
      reinterpret_cast<char*>(&journalinfo_)) + sizeof(numtxns_));
}

JournalRequestProto::~JournalRequestProto() {
  // @@protoc_insertion_point(destructor:hadoop.hdfs.JournalRequestProto)
  SharedDtor();
}

void JournalRequestProto::SharedDtor() {
  records_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (this != internal_default_instance()) delete journalinfo_;
}

void JournalRequestProto::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const ::google::protobuf::Descriptor* JournalRequestProto::descriptor() {
  ::protobuf_JournalProtocol_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_JournalProtocol_2eproto::file_level_metadata[kIndexInFileMessages].descriptor;
}

const JournalRequestProto& JournalRequestProto::default_instance() {
  ::google::protobuf::internal::InitSCC(&protobuf_JournalProtocol_2eproto::scc_info_JournalRequestProto.base);
  return *internal_default_instance();
}


void JournalRequestProto::Clear() {
// @@protoc_insertion_point(message_clear_start:hadoop.hdfs.JournalRequestProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  if (cached_has_bits & 3u) {
    if (cached_has_bits & 0x00000001u) {
      records_.ClearNonDefaultToEmptyNoArena();
    }
    if (cached_has_bits & 0x00000002u) {
      GOOGLE_DCHECK(journalinfo_ != NULL);
      journalinfo_->Clear();
    }
  }
  if (cached_has_bits & 28u) {
    ::memset(&firsttxnid_, 0, static_cast<size_t>(
        reinterpret_cast<char*>(&numtxns_) -
        reinterpret_cast<char*>(&firsttxnid_)) + sizeof(numtxns_));
  }
  _has_bits_.Clear();
  _internal_metadata_.Clear();
}

bool JournalRequestProto::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:hadoop.hdfs.JournalRequestProto)
  for (;;) {
    ::std::pair<::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // required .hadoop.hdfs.JournalInfoProto journalInfo = 1;
      case 1: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(10u /* 10 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_journalinfo()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // required uint64 firstTxnId = 2;
      case 2: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(16u /* 16 & 0xFF */)) {
          set_has_firsttxnid();
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::uint64, ::google::protobuf::internal::WireFormatLite::TYPE_UINT64>(
                 input, &firsttxnid_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // required uint32 numTxns = 3;
      case 3: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(24u /* 24 & 0xFF */)) {
          set_has_numtxns();
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::uint32, ::google::protobuf::internal::WireFormatLite::TYPE_UINT32>(
                 input, &numtxns_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // required bytes records = 4;
      case 4: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(34u /* 34 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadBytes(
                input, this->mutable_records()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // required uint64 epoch = 5;
      case 5: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(40u /* 40 & 0xFF */)) {
          set_has_epoch();
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::uint64, ::google::protobuf::internal::WireFormatLite::TYPE_UINT64>(
                 input, &epoch_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:hadoop.hdfs.JournalRequestProto)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:hadoop.hdfs.JournalRequestProto)
  return false;
#undef DO_
}

void JournalRequestProto::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:hadoop.hdfs.JournalRequestProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  // required .hadoop.hdfs.JournalInfoProto journalInfo = 1;
  if (cached_has_bits & 0x00000002u) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->_internal_journalinfo(), output);
  }

  // required uint64 firstTxnId = 2;
  if (cached_has_bits & 0x00000004u) {
    ::google::protobuf::internal::WireFormatLite::WriteUInt64(2, this->firsttxnid(), output);
  }

  // required uint32 numTxns = 3;
  if (cached_has_bits & 0x00000010u) {
    ::google::protobuf::internal::WireFormatLite::WriteUInt32(3, this->numtxns(), output);
  }

  // required bytes records = 4;
  if (cached_has_bits & 0x00000001u) {
    ::google::protobuf::internal::WireFormatLite::WriteBytesMaybeAliased(
      4, this->records(), output);
  }

  // required uint64 epoch = 5;
  if (cached_has_bits & 0x00000008u) {
    ::google::protobuf::internal::WireFormatLite::WriteUInt64(5, this->epoch(), output);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        _internal_metadata_.unknown_fields(), output);
  }
  // @@protoc_insertion_point(serialize_end:hadoop.hdfs.JournalRequestProto)
}

::google::protobuf::uint8* JournalRequestProto::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:hadoop.hdfs.JournalRequestProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  // required .hadoop.hdfs.JournalInfoProto journalInfo = 1;
  if (cached_has_bits & 0x00000002u) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        1, this->_internal_journalinfo(), deterministic, target);
  }

  // required uint64 firstTxnId = 2;
  if (cached_has_bits & 0x00000004u) {
    target = ::google::protobuf::internal::WireFormatLite::WriteUInt64ToArray(2, this->firsttxnid(), target);
  }

  // required uint32 numTxns = 3;
  if (cached_has_bits & 0x00000010u) {
    target = ::google::protobuf::internal::WireFormatLite::WriteUInt32ToArray(3, this->numtxns(), target);
  }

  // required bytes records = 4;
  if (cached_has_bits & 0x00000001u) {
    target =
      ::google::protobuf::internal::WireFormatLite::WriteBytesToArray(
        4, this->records(), target);
  }

  // required uint64 epoch = 5;
  if (cached_has_bits & 0x00000008u) {
    target = ::google::protobuf::internal::WireFormatLite::WriteUInt64ToArray(5, this->epoch(), target);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields(), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:hadoop.hdfs.JournalRequestProto)
  return target;
}

size_t JournalRequestProto::RequiredFieldsByteSizeFallback() const {
// @@protoc_insertion_point(required_fields_byte_size_fallback_start:hadoop.hdfs.JournalRequestProto)
  size_t total_size = 0;

  if (has_records()) {
    // required bytes records = 4;
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::BytesSize(
        this->records());
  }

  if (has_journalinfo()) {
    // required .hadoop.hdfs.JournalInfoProto journalInfo = 1;
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *journalinfo_);
  }

  if (has_firsttxnid()) {
    // required uint64 firstTxnId = 2;
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::UInt64Size(
        this->firsttxnid());
  }

  if (has_epoch()) {
    // required uint64 epoch = 5;
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::UInt64Size(
        this->epoch());
  }

  if (has_numtxns()) {
    // required uint32 numTxns = 3;
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::UInt32Size(
        this->numtxns());
  }

  return total_size;
}
size_t JournalRequestProto::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:hadoop.hdfs.JournalRequestProto)
  size_t total_size = 0;

  if (_internal_metadata_.have_unknown_fields()) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        _internal_metadata_.unknown_fields());
  }
  if (((_has_bits_[0] & 0x0000001f) ^ 0x0000001f) == 0) {  // All required fields are present.
    // required bytes records = 4;
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::BytesSize(
        this->records());

    // required .hadoop.hdfs.JournalInfoProto journalInfo = 1;
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *journalinfo_);

    // required uint64 firstTxnId = 2;
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::UInt64Size(
        this->firsttxnid());

    // required uint64 epoch = 5;
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::UInt64Size(
        this->epoch());

    // required uint32 numTxns = 3;
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::UInt32Size(
        this->numtxns());

  } else {
    total_size += RequiredFieldsByteSizeFallback();
  }
  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void JournalRequestProto::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:hadoop.hdfs.JournalRequestProto)
  GOOGLE_DCHECK_NE(&from, this);
  const JournalRequestProto* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const JournalRequestProto>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:hadoop.hdfs.JournalRequestProto)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:hadoop.hdfs.JournalRequestProto)
    MergeFrom(*source);
  }
}

void JournalRequestProto::MergeFrom(const JournalRequestProto& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:hadoop.hdfs.JournalRequestProto)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._has_bits_[0];
  if (cached_has_bits & 31u) {
    if (cached_has_bits & 0x00000001u) {
      set_has_records();
      records_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.records_);
    }
    if (cached_has_bits & 0x00000002u) {
      mutable_journalinfo()->::hadoop::hdfs::JournalInfoProto::MergeFrom(from.journalinfo());
    }
    if (cached_has_bits & 0x00000004u) {
      firsttxnid_ = from.firsttxnid_;
    }
    if (cached_has_bits & 0x00000008u) {
      epoch_ = from.epoch_;
    }
    if (cached_has_bits & 0x00000010u) {
      numtxns_ = from.numtxns_;
    }
    _has_bits_[0] |= cached_has_bits;
  }
}

void JournalRequestProto::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:hadoop.hdfs.JournalRequestProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void JournalRequestProto::CopyFrom(const JournalRequestProto& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:hadoop.hdfs.JournalRequestProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool JournalRequestProto::IsInitialized() const {
  if ((_has_bits_[0] & 0x0000001f) != 0x0000001f) return false;
  if (has_journalinfo()) {
    if (!this->journalinfo_->IsInitialized()) return false;
  }
  return true;
}

void JournalRequestProto::Swap(JournalRequestProto* other) {
  if (other == this) return;
  InternalSwap(other);
}
void JournalRequestProto::InternalSwap(JournalRequestProto* other) {
  using std::swap;
  records_.Swap(&other->records_, &::google::protobuf::internal::GetEmptyStringAlreadyInited(),
    GetArenaNoVirtual());
  swap(journalinfo_, other->journalinfo_);
  swap(firsttxnid_, other->firsttxnid_);
  swap(epoch_, other->epoch_);
  swap(numtxns_, other->numtxns_);
  swap(_has_bits_[0], other->_has_bits_[0]);
  _internal_metadata_.Swap(&other->_internal_metadata_);
}

::google::protobuf::Metadata JournalRequestProto::GetMetadata() const {
  protobuf_JournalProtocol_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_JournalProtocol_2eproto::file_level_metadata[kIndexInFileMessages];
}


// ===================================================================

void JournalResponseProto::InitAsDefaultInstance() {
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

JournalResponseProto::JournalResponseProto()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  ::google::protobuf::internal::InitSCC(
      &protobuf_JournalProtocol_2eproto::scc_info_JournalResponseProto.base);
  SharedCtor();
  // @@protoc_insertion_point(constructor:hadoop.hdfs.JournalResponseProto)
}
JournalResponseProto::JournalResponseProto(const JournalResponseProto& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      _has_bits_(from._has_bits_) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  // @@protoc_insertion_point(copy_constructor:hadoop.hdfs.JournalResponseProto)
}

void JournalResponseProto::SharedCtor() {
}

JournalResponseProto::~JournalResponseProto() {
  // @@protoc_insertion_point(destructor:hadoop.hdfs.JournalResponseProto)
  SharedDtor();
}

void JournalResponseProto::SharedDtor() {
}

void JournalResponseProto::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const ::google::protobuf::Descriptor* JournalResponseProto::descriptor() {
  ::protobuf_JournalProtocol_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_JournalProtocol_2eproto::file_level_metadata[kIndexInFileMessages].descriptor;
}

const JournalResponseProto& JournalResponseProto::default_instance() {
  ::google::protobuf::internal::InitSCC(&protobuf_JournalProtocol_2eproto::scc_info_JournalResponseProto.base);
  return *internal_default_instance();
}


void JournalResponseProto::Clear() {
// @@protoc_insertion_point(message_clear_start:hadoop.hdfs.JournalResponseProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _has_bits_.Clear();
  _internal_metadata_.Clear();
}

bool JournalResponseProto::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:hadoop.hdfs.JournalResponseProto)
  for (;;) {
    ::std::pair<::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
  handle_unusual:
    if (tag == 0) {
      goto success;
    }
    DO_(::google::protobuf::internal::WireFormat::SkipField(
          input, tag, _internal_metadata_.mutable_unknown_fields()));
  }
success:
  // @@protoc_insertion_point(parse_success:hadoop.hdfs.JournalResponseProto)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:hadoop.hdfs.JournalResponseProto)
  return false;
#undef DO_
}

void JournalResponseProto::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:hadoop.hdfs.JournalResponseProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  if (_internal_metadata_.have_unknown_fields()) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        _internal_metadata_.unknown_fields(), output);
  }
  // @@protoc_insertion_point(serialize_end:hadoop.hdfs.JournalResponseProto)
}

::google::protobuf::uint8* JournalResponseProto::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:hadoop.hdfs.JournalResponseProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  if (_internal_metadata_.have_unknown_fields()) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields(), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:hadoop.hdfs.JournalResponseProto)
  return target;
}

size_t JournalResponseProto::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:hadoop.hdfs.JournalResponseProto)
  size_t total_size = 0;

  if (_internal_metadata_.have_unknown_fields()) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        _internal_metadata_.unknown_fields());
  }
  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void JournalResponseProto::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:hadoop.hdfs.JournalResponseProto)
  GOOGLE_DCHECK_NE(&from, this);
  const JournalResponseProto* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const JournalResponseProto>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:hadoop.hdfs.JournalResponseProto)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:hadoop.hdfs.JournalResponseProto)
    MergeFrom(*source);
  }
}

void JournalResponseProto::MergeFrom(const JournalResponseProto& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:hadoop.hdfs.JournalResponseProto)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

}

void JournalResponseProto::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:hadoop.hdfs.JournalResponseProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void JournalResponseProto::CopyFrom(const JournalResponseProto& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:hadoop.hdfs.JournalResponseProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool JournalResponseProto::IsInitialized() const {
  return true;
}

void JournalResponseProto::Swap(JournalResponseProto* other) {
  if (other == this) return;
  InternalSwap(other);
}
void JournalResponseProto::InternalSwap(JournalResponseProto* other) {
  using std::swap;
  swap(_has_bits_[0], other->_has_bits_[0]);
  _internal_metadata_.Swap(&other->_internal_metadata_);
}

::google::protobuf::Metadata JournalResponseProto::GetMetadata() const {
  protobuf_JournalProtocol_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_JournalProtocol_2eproto::file_level_metadata[kIndexInFileMessages];
}


// ===================================================================

void StartLogSegmentRequestProto::InitAsDefaultInstance() {
  ::hadoop::hdfs::_StartLogSegmentRequestProto_default_instance_._instance.get_mutable()->journalinfo_ = const_cast< ::hadoop::hdfs::JournalInfoProto*>(
      ::hadoop::hdfs::JournalInfoProto::internal_default_instance());
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int StartLogSegmentRequestProto::kJournalInfoFieldNumber;
const int StartLogSegmentRequestProto::kTxidFieldNumber;
const int StartLogSegmentRequestProto::kEpochFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

StartLogSegmentRequestProto::StartLogSegmentRequestProto()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  ::google::protobuf::internal::InitSCC(
      &protobuf_JournalProtocol_2eproto::scc_info_StartLogSegmentRequestProto.base);
  SharedCtor();
  // @@protoc_insertion_point(constructor:hadoop.hdfs.StartLogSegmentRequestProto)
}
StartLogSegmentRequestProto::StartLogSegmentRequestProto(const StartLogSegmentRequestProto& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      _has_bits_(from._has_bits_) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_journalinfo()) {
    journalinfo_ = new ::hadoop::hdfs::JournalInfoProto(*from.journalinfo_);
  } else {
    journalinfo_ = NULL;
  }
  ::memcpy(&txid_, &from.txid_,
    static_cast<size_t>(reinterpret_cast<char*>(&epoch_) -
    reinterpret_cast<char*>(&txid_)) + sizeof(epoch_));
  // @@protoc_insertion_point(copy_constructor:hadoop.hdfs.StartLogSegmentRequestProto)
}

void StartLogSegmentRequestProto::SharedCtor() {
  ::memset(&journalinfo_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&epoch_) -
      reinterpret_cast<char*>(&journalinfo_)) + sizeof(epoch_));
}

StartLogSegmentRequestProto::~StartLogSegmentRequestProto() {
  // @@protoc_insertion_point(destructor:hadoop.hdfs.StartLogSegmentRequestProto)
  SharedDtor();
}

void StartLogSegmentRequestProto::SharedDtor() {
  if (this != internal_default_instance()) delete journalinfo_;
}

void StartLogSegmentRequestProto::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const ::google::protobuf::Descriptor* StartLogSegmentRequestProto::descriptor() {
  ::protobuf_JournalProtocol_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_JournalProtocol_2eproto::file_level_metadata[kIndexInFileMessages].descriptor;
}

const StartLogSegmentRequestProto& StartLogSegmentRequestProto::default_instance() {
  ::google::protobuf::internal::InitSCC(&protobuf_JournalProtocol_2eproto::scc_info_StartLogSegmentRequestProto.base);
  return *internal_default_instance();
}


void StartLogSegmentRequestProto::Clear() {
// @@protoc_insertion_point(message_clear_start:hadoop.hdfs.StartLogSegmentRequestProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    GOOGLE_DCHECK(journalinfo_ != NULL);
    journalinfo_->Clear();
  }
  if (cached_has_bits & 6u) {
    ::memset(&txid_, 0, static_cast<size_t>(
        reinterpret_cast<char*>(&epoch_) -
        reinterpret_cast<char*>(&txid_)) + sizeof(epoch_));
  }
  _has_bits_.Clear();
  _internal_metadata_.Clear();
}

bool StartLogSegmentRequestProto::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:hadoop.hdfs.StartLogSegmentRequestProto)
  for (;;) {
    ::std::pair<::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // required .hadoop.hdfs.JournalInfoProto journalInfo = 1;
      case 1: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(10u /* 10 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_journalinfo()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // required uint64 txid = 2;
      case 2: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(16u /* 16 & 0xFF */)) {
          set_has_txid();
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::uint64, ::google::protobuf::internal::WireFormatLite::TYPE_UINT64>(
                 input, &txid_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // required uint64 epoch = 3;
      case 3: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(24u /* 24 & 0xFF */)) {
          set_has_epoch();
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::uint64, ::google::protobuf::internal::WireFormatLite::TYPE_UINT64>(
                 input, &epoch_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:hadoop.hdfs.StartLogSegmentRequestProto)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:hadoop.hdfs.StartLogSegmentRequestProto)
  return false;
#undef DO_
}

void StartLogSegmentRequestProto::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:hadoop.hdfs.StartLogSegmentRequestProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  // required .hadoop.hdfs.JournalInfoProto journalInfo = 1;
  if (cached_has_bits & 0x00000001u) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->_internal_journalinfo(), output);
  }

  // required uint64 txid = 2;
  if (cached_has_bits & 0x00000002u) {
    ::google::protobuf::internal::WireFormatLite::WriteUInt64(2, this->txid(), output);
  }

  // required uint64 epoch = 3;
  if (cached_has_bits & 0x00000004u) {
    ::google::protobuf::internal::WireFormatLite::WriteUInt64(3, this->epoch(), output);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        _internal_metadata_.unknown_fields(), output);
  }
  // @@protoc_insertion_point(serialize_end:hadoop.hdfs.StartLogSegmentRequestProto)
}

::google::protobuf::uint8* StartLogSegmentRequestProto::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:hadoop.hdfs.StartLogSegmentRequestProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  // required .hadoop.hdfs.JournalInfoProto journalInfo = 1;
  if (cached_has_bits & 0x00000001u) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        1, this->_internal_journalinfo(), deterministic, target);
  }

  // required uint64 txid = 2;
  if (cached_has_bits & 0x00000002u) {
    target = ::google::protobuf::internal::WireFormatLite::WriteUInt64ToArray(2, this->txid(), target);
  }

  // required uint64 epoch = 3;
  if (cached_has_bits & 0x00000004u) {
    target = ::google::protobuf::internal::WireFormatLite::WriteUInt64ToArray(3, this->epoch(), target);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields(), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:hadoop.hdfs.StartLogSegmentRequestProto)
  return target;
}

size_t StartLogSegmentRequestProto::RequiredFieldsByteSizeFallback() const {
// @@protoc_insertion_point(required_fields_byte_size_fallback_start:hadoop.hdfs.StartLogSegmentRequestProto)
  size_t total_size = 0;

  if (has_journalinfo()) {
    // required .hadoop.hdfs.JournalInfoProto journalInfo = 1;
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *journalinfo_);
  }

  if (has_txid()) {
    // required uint64 txid = 2;
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::UInt64Size(
        this->txid());
  }

  if (has_epoch()) {
    // required uint64 epoch = 3;
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::UInt64Size(
        this->epoch());
  }

  return total_size;
}
size_t StartLogSegmentRequestProto::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:hadoop.hdfs.StartLogSegmentRequestProto)
  size_t total_size = 0;

  if (_internal_metadata_.have_unknown_fields()) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        _internal_metadata_.unknown_fields());
  }
  if (((_has_bits_[0] & 0x00000007) ^ 0x00000007) == 0) {  // All required fields are present.
    // required .hadoop.hdfs.JournalInfoProto journalInfo = 1;
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *journalinfo_);

    // required uint64 txid = 2;
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::UInt64Size(
        this->txid());

    // required uint64 epoch = 3;
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::UInt64Size(
        this->epoch());

  } else {
    total_size += RequiredFieldsByteSizeFallback();
  }
  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void StartLogSegmentRequestProto::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:hadoop.hdfs.StartLogSegmentRequestProto)
  GOOGLE_DCHECK_NE(&from, this);
  const StartLogSegmentRequestProto* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const StartLogSegmentRequestProto>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:hadoop.hdfs.StartLogSegmentRequestProto)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:hadoop.hdfs.StartLogSegmentRequestProto)
    MergeFrom(*source);
  }
}

void StartLogSegmentRequestProto::MergeFrom(const StartLogSegmentRequestProto& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:hadoop.hdfs.StartLogSegmentRequestProto)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._has_bits_[0];
  if (cached_has_bits & 7u) {
    if (cached_has_bits & 0x00000001u) {
      mutable_journalinfo()->::hadoop::hdfs::JournalInfoProto::MergeFrom(from.journalinfo());
    }
    if (cached_has_bits & 0x00000002u) {
      txid_ = from.txid_;
    }
    if (cached_has_bits & 0x00000004u) {
      epoch_ = from.epoch_;
    }
    _has_bits_[0] |= cached_has_bits;
  }
}

void StartLogSegmentRequestProto::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:hadoop.hdfs.StartLogSegmentRequestProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void StartLogSegmentRequestProto::CopyFrom(const StartLogSegmentRequestProto& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:hadoop.hdfs.StartLogSegmentRequestProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool StartLogSegmentRequestProto::IsInitialized() const {
  if ((_has_bits_[0] & 0x00000007) != 0x00000007) return false;
  if (has_journalinfo()) {
    if (!this->journalinfo_->IsInitialized()) return false;
  }
  return true;
}

void StartLogSegmentRequestProto::Swap(StartLogSegmentRequestProto* other) {
  if (other == this) return;
  InternalSwap(other);
}
void StartLogSegmentRequestProto::InternalSwap(StartLogSegmentRequestProto* other) {
  using std::swap;
  swap(journalinfo_, other->journalinfo_);
  swap(txid_, other->txid_);
  swap(epoch_, other->epoch_);
  swap(_has_bits_[0], other->_has_bits_[0]);
  _internal_metadata_.Swap(&other->_internal_metadata_);
}

::google::protobuf::Metadata StartLogSegmentRequestProto::GetMetadata() const {
  protobuf_JournalProtocol_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_JournalProtocol_2eproto::file_level_metadata[kIndexInFileMessages];
}


// ===================================================================

void StartLogSegmentResponseProto::InitAsDefaultInstance() {
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

StartLogSegmentResponseProto::StartLogSegmentResponseProto()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  ::google::protobuf::internal::InitSCC(
      &protobuf_JournalProtocol_2eproto::scc_info_StartLogSegmentResponseProto.base);
  SharedCtor();
  // @@protoc_insertion_point(constructor:hadoop.hdfs.StartLogSegmentResponseProto)
}
StartLogSegmentResponseProto::StartLogSegmentResponseProto(const StartLogSegmentResponseProto& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      _has_bits_(from._has_bits_) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  // @@protoc_insertion_point(copy_constructor:hadoop.hdfs.StartLogSegmentResponseProto)
}

void StartLogSegmentResponseProto::SharedCtor() {
}

StartLogSegmentResponseProto::~StartLogSegmentResponseProto() {
  // @@protoc_insertion_point(destructor:hadoop.hdfs.StartLogSegmentResponseProto)
  SharedDtor();
}

void StartLogSegmentResponseProto::SharedDtor() {
}

void StartLogSegmentResponseProto::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const ::google::protobuf::Descriptor* StartLogSegmentResponseProto::descriptor() {
  ::protobuf_JournalProtocol_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_JournalProtocol_2eproto::file_level_metadata[kIndexInFileMessages].descriptor;
}

const StartLogSegmentResponseProto& StartLogSegmentResponseProto::default_instance() {
  ::google::protobuf::internal::InitSCC(&protobuf_JournalProtocol_2eproto::scc_info_StartLogSegmentResponseProto.base);
  return *internal_default_instance();
}


void StartLogSegmentResponseProto::Clear() {
// @@protoc_insertion_point(message_clear_start:hadoop.hdfs.StartLogSegmentResponseProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _has_bits_.Clear();
  _internal_metadata_.Clear();
}

bool StartLogSegmentResponseProto::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:hadoop.hdfs.StartLogSegmentResponseProto)
  for (;;) {
    ::std::pair<::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
  handle_unusual:
    if (tag == 0) {
      goto success;
    }
    DO_(::google::protobuf::internal::WireFormat::SkipField(
          input, tag, _internal_metadata_.mutable_unknown_fields()));
  }
success:
  // @@protoc_insertion_point(parse_success:hadoop.hdfs.StartLogSegmentResponseProto)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:hadoop.hdfs.StartLogSegmentResponseProto)
  return false;
#undef DO_
}

void StartLogSegmentResponseProto::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:hadoop.hdfs.StartLogSegmentResponseProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  if (_internal_metadata_.have_unknown_fields()) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        _internal_metadata_.unknown_fields(), output);
  }
  // @@protoc_insertion_point(serialize_end:hadoop.hdfs.StartLogSegmentResponseProto)
}

::google::protobuf::uint8* StartLogSegmentResponseProto::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:hadoop.hdfs.StartLogSegmentResponseProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  if (_internal_metadata_.have_unknown_fields()) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields(), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:hadoop.hdfs.StartLogSegmentResponseProto)
  return target;
}

size_t StartLogSegmentResponseProto::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:hadoop.hdfs.StartLogSegmentResponseProto)
  size_t total_size = 0;

  if (_internal_metadata_.have_unknown_fields()) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        _internal_metadata_.unknown_fields());
  }
  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void StartLogSegmentResponseProto::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:hadoop.hdfs.StartLogSegmentResponseProto)
  GOOGLE_DCHECK_NE(&from, this);
  const StartLogSegmentResponseProto* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const StartLogSegmentResponseProto>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:hadoop.hdfs.StartLogSegmentResponseProto)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:hadoop.hdfs.StartLogSegmentResponseProto)
    MergeFrom(*source);
  }
}

void StartLogSegmentResponseProto::MergeFrom(const StartLogSegmentResponseProto& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:hadoop.hdfs.StartLogSegmentResponseProto)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

}

void StartLogSegmentResponseProto::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:hadoop.hdfs.StartLogSegmentResponseProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void StartLogSegmentResponseProto::CopyFrom(const StartLogSegmentResponseProto& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:hadoop.hdfs.StartLogSegmentResponseProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool StartLogSegmentResponseProto::IsInitialized() const {
  return true;
}

void StartLogSegmentResponseProto::Swap(StartLogSegmentResponseProto* other) {
  if (other == this) return;
  InternalSwap(other);
}
void StartLogSegmentResponseProto::InternalSwap(StartLogSegmentResponseProto* other) {
  using std::swap;
  swap(_has_bits_[0], other->_has_bits_[0]);
  _internal_metadata_.Swap(&other->_internal_metadata_);
}

::google::protobuf::Metadata StartLogSegmentResponseProto::GetMetadata() const {
  protobuf_JournalProtocol_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_JournalProtocol_2eproto::file_level_metadata[kIndexInFileMessages];
}


// ===================================================================

void FenceRequestProto::InitAsDefaultInstance() {
  ::hadoop::hdfs::_FenceRequestProto_default_instance_._instance.get_mutable()->journalinfo_ = const_cast< ::hadoop::hdfs::JournalInfoProto*>(
      ::hadoop::hdfs::JournalInfoProto::internal_default_instance());
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int FenceRequestProto::kJournalInfoFieldNumber;
const int FenceRequestProto::kEpochFieldNumber;
const int FenceRequestProto::kFencerInfoFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

FenceRequestProto::FenceRequestProto()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  ::google::protobuf::internal::InitSCC(
      &protobuf_JournalProtocol_2eproto::scc_info_FenceRequestProto.base);
  SharedCtor();
  // @@protoc_insertion_point(constructor:hadoop.hdfs.FenceRequestProto)
}
FenceRequestProto::FenceRequestProto(const FenceRequestProto& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      _has_bits_(from._has_bits_) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  fencerinfo_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (from.has_fencerinfo()) {
    fencerinfo_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.fencerinfo_);
  }
  if (from.has_journalinfo()) {
    journalinfo_ = new ::hadoop::hdfs::JournalInfoProto(*from.journalinfo_);
  } else {
    journalinfo_ = NULL;
  }
  epoch_ = from.epoch_;
  // @@protoc_insertion_point(copy_constructor:hadoop.hdfs.FenceRequestProto)
}

void FenceRequestProto::SharedCtor() {
  fencerinfo_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  ::memset(&journalinfo_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&epoch_) -
      reinterpret_cast<char*>(&journalinfo_)) + sizeof(epoch_));
}

FenceRequestProto::~FenceRequestProto() {
  // @@protoc_insertion_point(destructor:hadoop.hdfs.FenceRequestProto)
  SharedDtor();
}

void FenceRequestProto::SharedDtor() {
  fencerinfo_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (this != internal_default_instance()) delete journalinfo_;
}

void FenceRequestProto::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const ::google::protobuf::Descriptor* FenceRequestProto::descriptor() {
  ::protobuf_JournalProtocol_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_JournalProtocol_2eproto::file_level_metadata[kIndexInFileMessages].descriptor;
}

const FenceRequestProto& FenceRequestProto::default_instance() {
  ::google::protobuf::internal::InitSCC(&protobuf_JournalProtocol_2eproto::scc_info_FenceRequestProto.base);
  return *internal_default_instance();
}


void FenceRequestProto::Clear() {
// @@protoc_insertion_point(message_clear_start:hadoop.hdfs.FenceRequestProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  if (cached_has_bits & 3u) {
    if (cached_has_bits & 0x00000001u) {
      fencerinfo_.ClearNonDefaultToEmptyNoArena();
    }
    if (cached_has_bits & 0x00000002u) {
      GOOGLE_DCHECK(journalinfo_ != NULL);
      journalinfo_->Clear();
    }
  }
  epoch_ = GOOGLE_ULONGLONG(0);
  _has_bits_.Clear();
  _internal_metadata_.Clear();
}

bool FenceRequestProto::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:hadoop.hdfs.FenceRequestProto)
  for (;;) {
    ::std::pair<::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // required .hadoop.hdfs.JournalInfoProto journalInfo = 1;
      case 1: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(10u /* 10 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessage(
               input, mutable_journalinfo()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // required uint64 epoch = 2;
      case 2: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(16u /* 16 & 0xFF */)) {
          set_has_epoch();
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::uint64, ::google::protobuf::internal::WireFormatLite::TYPE_UINT64>(
                 input, &epoch_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // optional string fencerInfo = 3;
      case 3: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(26u /* 26 & 0xFF */)) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_fencerinfo()));
          ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
            this->fencerinfo().data(), static_cast<int>(this->fencerinfo().length()),
            ::google::protobuf::internal::WireFormat::PARSE,
            "hadoop.hdfs.FenceRequestProto.fencerInfo");
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:hadoop.hdfs.FenceRequestProto)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:hadoop.hdfs.FenceRequestProto)
  return false;
#undef DO_
}

void FenceRequestProto::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:hadoop.hdfs.FenceRequestProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  // required .hadoop.hdfs.JournalInfoProto journalInfo = 1;
  if (cached_has_bits & 0x00000002u) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->_internal_journalinfo(), output);
  }

  // required uint64 epoch = 2;
  if (cached_has_bits & 0x00000004u) {
    ::google::protobuf::internal::WireFormatLite::WriteUInt64(2, this->epoch(), output);
  }

  // optional string fencerInfo = 3;
  if (cached_has_bits & 0x00000001u) {
    ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
      this->fencerinfo().data(), static_cast<int>(this->fencerinfo().length()),
      ::google::protobuf::internal::WireFormat::SERIALIZE,
      "hadoop.hdfs.FenceRequestProto.fencerInfo");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      3, this->fencerinfo(), output);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        _internal_metadata_.unknown_fields(), output);
  }
  // @@protoc_insertion_point(serialize_end:hadoop.hdfs.FenceRequestProto)
}

::google::protobuf::uint8* FenceRequestProto::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:hadoop.hdfs.FenceRequestProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  // required .hadoop.hdfs.JournalInfoProto journalInfo = 1;
  if (cached_has_bits & 0x00000002u) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageToArray(
        1, this->_internal_journalinfo(), deterministic, target);
  }

  // required uint64 epoch = 2;
  if (cached_has_bits & 0x00000004u) {
    target = ::google::protobuf::internal::WireFormatLite::WriteUInt64ToArray(2, this->epoch(), target);
  }

  // optional string fencerInfo = 3;
  if (cached_has_bits & 0x00000001u) {
    ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
      this->fencerinfo().data(), static_cast<int>(this->fencerinfo().length()),
      ::google::protobuf::internal::WireFormat::SERIALIZE,
      "hadoop.hdfs.FenceRequestProto.fencerInfo");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        3, this->fencerinfo(), target);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields(), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:hadoop.hdfs.FenceRequestProto)
  return target;
}

size_t FenceRequestProto::RequiredFieldsByteSizeFallback() const {
// @@protoc_insertion_point(required_fields_byte_size_fallback_start:hadoop.hdfs.FenceRequestProto)
  size_t total_size = 0;

  if (has_journalinfo()) {
    // required .hadoop.hdfs.JournalInfoProto journalInfo = 1;
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *journalinfo_);
  }

  if (has_epoch()) {
    // required uint64 epoch = 2;
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::UInt64Size(
        this->epoch());
  }

  return total_size;
}
size_t FenceRequestProto::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:hadoop.hdfs.FenceRequestProto)
  size_t total_size = 0;

  if (_internal_metadata_.have_unknown_fields()) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        _internal_metadata_.unknown_fields());
  }
  if (((_has_bits_[0] & 0x00000006) ^ 0x00000006) == 0) {  // All required fields are present.
    // required .hadoop.hdfs.JournalInfoProto journalInfo = 1;
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSize(
        *journalinfo_);

    // required uint64 epoch = 2;
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::UInt64Size(
        this->epoch());

  } else {
    total_size += RequiredFieldsByteSizeFallback();
  }
  // optional string fencerInfo = 3;
  if (has_fencerinfo()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->fencerinfo());
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void FenceRequestProto::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:hadoop.hdfs.FenceRequestProto)
  GOOGLE_DCHECK_NE(&from, this);
  const FenceRequestProto* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const FenceRequestProto>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:hadoop.hdfs.FenceRequestProto)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:hadoop.hdfs.FenceRequestProto)
    MergeFrom(*source);
  }
}

void FenceRequestProto::MergeFrom(const FenceRequestProto& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:hadoop.hdfs.FenceRequestProto)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._has_bits_[0];
  if (cached_has_bits & 7u) {
    if (cached_has_bits & 0x00000001u) {
      set_has_fencerinfo();
      fencerinfo_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.fencerinfo_);
    }
    if (cached_has_bits & 0x00000002u) {
      mutable_journalinfo()->::hadoop::hdfs::JournalInfoProto::MergeFrom(from.journalinfo());
    }
    if (cached_has_bits & 0x00000004u) {
      epoch_ = from.epoch_;
    }
    _has_bits_[0] |= cached_has_bits;
  }
}

void FenceRequestProto::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:hadoop.hdfs.FenceRequestProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void FenceRequestProto::CopyFrom(const FenceRequestProto& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:hadoop.hdfs.FenceRequestProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool FenceRequestProto::IsInitialized() const {
  if ((_has_bits_[0] & 0x00000006) != 0x00000006) return false;
  if (has_journalinfo()) {
    if (!this->journalinfo_->IsInitialized()) return false;
  }
  return true;
}

void FenceRequestProto::Swap(FenceRequestProto* other) {
  if (other == this) return;
  InternalSwap(other);
}
void FenceRequestProto::InternalSwap(FenceRequestProto* other) {
  using std::swap;
  fencerinfo_.Swap(&other->fencerinfo_, &::google::protobuf::internal::GetEmptyStringAlreadyInited(),
    GetArenaNoVirtual());
  swap(journalinfo_, other->journalinfo_);
  swap(epoch_, other->epoch_);
  swap(_has_bits_[0], other->_has_bits_[0]);
  _internal_metadata_.Swap(&other->_internal_metadata_);
}

::google::protobuf::Metadata FenceRequestProto::GetMetadata() const {
  protobuf_JournalProtocol_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_JournalProtocol_2eproto::file_level_metadata[kIndexInFileMessages];
}


// ===================================================================

void FenceResponseProto::InitAsDefaultInstance() {
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int FenceResponseProto::kPreviousEpochFieldNumber;
const int FenceResponseProto::kLastTransactionIdFieldNumber;
const int FenceResponseProto::kInSyncFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

FenceResponseProto::FenceResponseProto()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  ::google::protobuf::internal::InitSCC(
      &protobuf_JournalProtocol_2eproto::scc_info_FenceResponseProto.base);
  SharedCtor();
  // @@protoc_insertion_point(constructor:hadoop.hdfs.FenceResponseProto)
}
FenceResponseProto::FenceResponseProto(const FenceResponseProto& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      _has_bits_(from._has_bits_) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::memcpy(&previousepoch_, &from.previousepoch_,
    static_cast<size_t>(reinterpret_cast<char*>(&insync_) -
    reinterpret_cast<char*>(&previousepoch_)) + sizeof(insync_));
  // @@protoc_insertion_point(copy_constructor:hadoop.hdfs.FenceResponseProto)
}

void FenceResponseProto::SharedCtor() {
  ::memset(&previousepoch_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&insync_) -
      reinterpret_cast<char*>(&previousepoch_)) + sizeof(insync_));
}

FenceResponseProto::~FenceResponseProto() {
  // @@protoc_insertion_point(destructor:hadoop.hdfs.FenceResponseProto)
  SharedDtor();
}

void FenceResponseProto::SharedDtor() {
}

void FenceResponseProto::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const ::google::protobuf::Descriptor* FenceResponseProto::descriptor() {
  ::protobuf_JournalProtocol_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_JournalProtocol_2eproto::file_level_metadata[kIndexInFileMessages].descriptor;
}

const FenceResponseProto& FenceResponseProto::default_instance() {
  ::google::protobuf::internal::InitSCC(&protobuf_JournalProtocol_2eproto::scc_info_FenceResponseProto.base);
  return *internal_default_instance();
}


void FenceResponseProto::Clear() {
// @@protoc_insertion_point(message_clear_start:hadoop.hdfs.FenceResponseProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  if (cached_has_bits & 7u) {
    ::memset(&previousepoch_, 0, static_cast<size_t>(
        reinterpret_cast<char*>(&insync_) -
        reinterpret_cast<char*>(&previousepoch_)) + sizeof(insync_));
  }
  _has_bits_.Clear();
  _internal_metadata_.Clear();
}

bool FenceResponseProto::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:hadoop.hdfs.FenceResponseProto)
  for (;;) {
    ::std::pair<::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional uint64 previousEpoch = 1;
      case 1: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(8u /* 8 & 0xFF */)) {
          set_has_previousepoch();
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::uint64, ::google::protobuf::internal::WireFormatLite::TYPE_UINT64>(
                 input, &previousepoch_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // optional uint64 lastTransactionId = 2;
      case 2: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(16u /* 16 & 0xFF */)) {
          set_has_lasttransactionid();
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::uint64, ::google::protobuf::internal::WireFormatLite::TYPE_UINT64>(
                 input, &lasttransactionid_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // optional bool inSync = 3;
      case 3: {
        if (static_cast< ::google::protobuf::uint8>(tag) ==
            static_cast< ::google::protobuf::uint8>(24u /* 24 & 0xFF */)) {
          set_has_insync();
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &insync_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, _internal_metadata_.mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:hadoop.hdfs.FenceResponseProto)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:hadoop.hdfs.FenceResponseProto)
  return false;
#undef DO_
}

void FenceResponseProto::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:hadoop.hdfs.FenceResponseProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  // optional uint64 previousEpoch = 1;
  if (cached_has_bits & 0x00000001u) {
    ::google::protobuf::internal::WireFormatLite::WriteUInt64(1, this->previousepoch(), output);
  }

  // optional uint64 lastTransactionId = 2;
  if (cached_has_bits & 0x00000002u) {
    ::google::protobuf::internal::WireFormatLite::WriteUInt64(2, this->lasttransactionid(), output);
  }

  // optional bool inSync = 3;
  if (cached_has_bits & 0x00000004u) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(3, this->insync(), output);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        _internal_metadata_.unknown_fields(), output);
  }
  // @@protoc_insertion_point(serialize_end:hadoop.hdfs.FenceResponseProto)
}

::google::protobuf::uint8* FenceResponseProto::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:hadoop.hdfs.FenceResponseProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  // optional uint64 previousEpoch = 1;
  if (cached_has_bits & 0x00000001u) {
    target = ::google::protobuf::internal::WireFormatLite::WriteUInt64ToArray(1, this->previousepoch(), target);
  }

  // optional uint64 lastTransactionId = 2;
  if (cached_has_bits & 0x00000002u) {
    target = ::google::protobuf::internal::WireFormatLite::WriteUInt64ToArray(2, this->lasttransactionid(), target);
  }

  // optional bool inSync = 3;
  if (cached_has_bits & 0x00000004u) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(3, this->insync(), target);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields(), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:hadoop.hdfs.FenceResponseProto)
  return target;
}

size_t FenceResponseProto::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:hadoop.hdfs.FenceResponseProto)
  size_t total_size = 0;

  if (_internal_metadata_.have_unknown_fields()) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        _internal_metadata_.unknown_fields());
  }
  if (_has_bits_[0 / 32] & 7u) {
    // optional uint64 previousEpoch = 1;
    if (has_previousepoch()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::UInt64Size(
          this->previousepoch());
    }

    // optional uint64 lastTransactionId = 2;
    if (has_lasttransactionid()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::UInt64Size(
          this->lasttransactionid());
    }

    // optional bool inSync = 3;
    if (has_insync()) {
      total_size += 1 + 1;
    }

  }
  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void FenceResponseProto::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:hadoop.hdfs.FenceResponseProto)
  GOOGLE_DCHECK_NE(&from, this);
  const FenceResponseProto* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const FenceResponseProto>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:hadoop.hdfs.FenceResponseProto)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:hadoop.hdfs.FenceResponseProto)
    MergeFrom(*source);
  }
}

void FenceResponseProto::MergeFrom(const FenceResponseProto& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:hadoop.hdfs.FenceResponseProto)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._has_bits_[0];
  if (cached_has_bits & 7u) {
    if (cached_has_bits & 0x00000001u) {
      previousepoch_ = from.previousepoch_;
    }
    if (cached_has_bits & 0x00000002u) {
      lasttransactionid_ = from.lasttransactionid_;
    }
    if (cached_has_bits & 0x00000004u) {
      insync_ = from.insync_;
    }
    _has_bits_[0] |= cached_has_bits;
  }
}

void FenceResponseProto::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:hadoop.hdfs.FenceResponseProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void FenceResponseProto::CopyFrom(const FenceResponseProto& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:hadoop.hdfs.FenceResponseProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool FenceResponseProto::IsInitialized() const {
  return true;
}

void FenceResponseProto::Swap(FenceResponseProto* other) {
  if (other == this) return;
  InternalSwap(other);
}
void FenceResponseProto::InternalSwap(FenceResponseProto* other) {
  using std::swap;
  swap(previousepoch_, other->previousepoch_);
  swap(lasttransactionid_, other->lasttransactionid_);
  swap(insync_, other->insync_);
  swap(_has_bits_[0], other->_has_bits_[0]);
  _internal_metadata_.Swap(&other->_internal_metadata_);
}

::google::protobuf::Metadata FenceResponseProto::GetMetadata() const {
  protobuf_JournalProtocol_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_JournalProtocol_2eproto::file_level_metadata[kIndexInFileMessages];
}


// @@protoc_insertion_point(namespace_scope)
}  // namespace hdfs
}  // namespace hadoop
namespace google {
namespace protobuf {
template<> GOOGLE_PROTOBUF_ATTRIBUTE_NOINLINE ::hadoop::hdfs::JournalInfoProto* Arena::CreateMaybeMessage< ::hadoop::hdfs::JournalInfoProto >(Arena* arena) {
  return Arena::CreateInternal< ::hadoop::hdfs::JournalInfoProto >(arena);
}
template<> GOOGLE_PROTOBUF_ATTRIBUTE_NOINLINE ::hadoop::hdfs::JournalRequestProto* Arena::CreateMaybeMessage< ::hadoop::hdfs::JournalRequestProto >(Arena* arena) {
  return Arena::CreateInternal< ::hadoop::hdfs::JournalRequestProto >(arena);
}
template<> GOOGLE_PROTOBUF_ATTRIBUTE_NOINLINE ::hadoop::hdfs::JournalResponseProto* Arena::CreateMaybeMessage< ::hadoop::hdfs::JournalResponseProto >(Arena* arena) {
  return Arena::CreateInternal< ::hadoop::hdfs::JournalResponseProto >(arena);
}
template<> GOOGLE_PROTOBUF_ATTRIBUTE_NOINLINE ::hadoop::hdfs::StartLogSegmentRequestProto* Arena::CreateMaybeMessage< ::hadoop::hdfs::StartLogSegmentRequestProto >(Arena* arena) {
  return Arena::CreateInternal< ::hadoop::hdfs::StartLogSegmentRequestProto >(arena);
}
template<> GOOGLE_PROTOBUF_ATTRIBUTE_NOINLINE ::hadoop::hdfs::StartLogSegmentResponseProto* Arena::CreateMaybeMessage< ::hadoop::hdfs::StartLogSegmentResponseProto >(Arena* arena) {
  return Arena::CreateInternal< ::hadoop::hdfs::StartLogSegmentResponseProto >(arena);
}
template<> GOOGLE_PROTOBUF_ATTRIBUTE_NOINLINE ::hadoop::hdfs::FenceRequestProto* Arena::CreateMaybeMessage< ::hadoop::hdfs::FenceRequestProto >(Arena* arena) {
  return Arena::CreateInternal< ::hadoop::hdfs::FenceRequestProto >(arena);
}
template<> GOOGLE_PROTOBUF_ATTRIBUTE_NOINLINE ::hadoop::hdfs::FenceResponseProto* Arena::CreateMaybeMessage< ::hadoop::hdfs::FenceResponseProto >(Arena* arena) {
  return Arena::CreateInternal< ::hadoop::hdfs::FenceResponseProto >(arena);
}
}  // namespace protobuf
}  // namespace google

// @@protoc_insertion_point(global_scope)
