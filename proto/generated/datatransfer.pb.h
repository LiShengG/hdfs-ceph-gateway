// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: datatransfer.proto

#ifndef PROTOBUF_INCLUDED_datatransfer_2eproto
#define PROTOBUF_INCLUDED_datatransfer_2eproto

#include <string>

#include <google/protobuf/stubs/common.h>

#if GOOGLE_PROTOBUF_VERSION < 3006001
#error This file was generated by a newer version of protoc which is
#error incompatible with your Protocol Buffer headers.  Please update
#error your headers.
#endif
#if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
#error This file was generated by an older version of protoc which is
#error incompatible with your Protocol Buffer headers.  Please
#error regenerate this file with a newer version of protoc.
#endif

#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/arena.h>
#include <google/protobuf/arenastring.h>
#include <google/protobuf/generated_message_table_driven.h>
#include <google/protobuf/generated_message_util.h>
#include <google/protobuf/inlined_string_field.h>
#include <google/protobuf/metadata.h>
#include <google/protobuf/message.h>
#include <google/protobuf/repeated_field.h>  // IWYU pragma: export
#include <google/protobuf/extension_set.h>  // IWYU pragma: export
#include <google/protobuf/generated_enum_reflection.h>
#include <google/protobuf/unknown_field_set.h>
#include "Security.pb.h"
#include "hdfs.pb.h"
// @@protoc_insertion_point(includes)
#define PROTOBUF_INTERNAL_EXPORT_protobuf_datatransfer_2eproto 

namespace protobuf_datatransfer_2eproto {
// Internal implementation detail -- do not use these members.
struct TableStruct {
  static const ::google::protobuf::internal::ParseTableField entries[];
  static const ::google::protobuf::internal::AuxillaryParseTableField aux[];
  static const ::google::protobuf::internal::ParseTable schema[29];
  static const ::google::protobuf::internal::FieldMetadata field_metadata[];
  static const ::google::protobuf::internal::SerializationTable serialization_table[];
  static const ::google::protobuf::uint32 offsets[];
};
void AddDescriptors();
}  // namespace protobuf_datatransfer_2eproto
namespace hadoop {
namespace hdfs {
class BaseHeaderProto;
class BaseHeaderProtoDefaultTypeInternal;
extern BaseHeaderProtoDefaultTypeInternal _BaseHeaderProto_default_instance_;
class BlockOpResponseProto;
class BlockOpResponseProtoDefaultTypeInternal;
extern BlockOpResponseProtoDefaultTypeInternal _BlockOpResponseProto_default_instance_;
class CachingStrategyProto;
class CachingStrategyProtoDefaultTypeInternal;
extern CachingStrategyProtoDefaultTypeInternal _CachingStrategyProto_default_instance_;
class ChecksumProto;
class ChecksumProtoDefaultTypeInternal;
extern ChecksumProtoDefaultTypeInternal _ChecksumProto_default_instance_;
class ClientOperationHeaderProto;
class ClientOperationHeaderProtoDefaultTypeInternal;
extern ClientOperationHeaderProtoDefaultTypeInternal _ClientOperationHeaderProto_default_instance_;
class ClientReadStatusProto;
class ClientReadStatusProtoDefaultTypeInternal;
extern ClientReadStatusProtoDefaultTypeInternal _ClientReadStatusProto_default_instance_;
class DNTransferAckProto;
class DNTransferAckProtoDefaultTypeInternal;
extern DNTransferAckProtoDefaultTypeInternal _DNTransferAckProto_default_instance_;
class DataTransferEncryptorMessageProto;
class DataTransferEncryptorMessageProtoDefaultTypeInternal;
extern DataTransferEncryptorMessageProtoDefaultTypeInternal _DataTransferEncryptorMessageProto_default_instance_;
class DataTransferTraceInfoProto;
class DataTransferTraceInfoProtoDefaultTypeInternal;
extern DataTransferTraceInfoProtoDefaultTypeInternal _DataTransferTraceInfoProto_default_instance_;
class HandshakeSecretProto;
class HandshakeSecretProtoDefaultTypeInternal;
extern HandshakeSecretProtoDefaultTypeInternal _HandshakeSecretProto_default_instance_;
class OpBlockChecksumProto;
class OpBlockChecksumProtoDefaultTypeInternal;
extern OpBlockChecksumProtoDefaultTypeInternal _OpBlockChecksumProto_default_instance_;
class OpBlockChecksumResponseProto;
class OpBlockChecksumResponseProtoDefaultTypeInternal;
extern OpBlockChecksumResponseProtoDefaultTypeInternal _OpBlockChecksumResponseProto_default_instance_;
class OpBlockGroupChecksumProto;
class OpBlockGroupChecksumProtoDefaultTypeInternal;
extern OpBlockGroupChecksumProtoDefaultTypeInternal _OpBlockGroupChecksumProto_default_instance_;
class OpCopyBlockProto;
class OpCopyBlockProtoDefaultTypeInternal;
extern OpCopyBlockProtoDefaultTypeInternal _OpCopyBlockProto_default_instance_;
class OpCustomProto;
class OpCustomProtoDefaultTypeInternal;
extern OpCustomProtoDefaultTypeInternal _OpCustomProto_default_instance_;
class OpReadBlockProto;
class OpReadBlockProtoDefaultTypeInternal;
extern OpReadBlockProtoDefaultTypeInternal _OpReadBlockProto_default_instance_;
class OpReplaceBlockProto;
class OpReplaceBlockProtoDefaultTypeInternal;
extern OpReplaceBlockProtoDefaultTypeInternal _OpReplaceBlockProto_default_instance_;
class OpRequestShortCircuitAccessProto;
class OpRequestShortCircuitAccessProtoDefaultTypeInternal;
extern OpRequestShortCircuitAccessProtoDefaultTypeInternal _OpRequestShortCircuitAccessProto_default_instance_;
class OpTransferBlockProto;
class OpTransferBlockProtoDefaultTypeInternal;
extern OpTransferBlockProtoDefaultTypeInternal _OpTransferBlockProto_default_instance_;
class OpWriteBlockProto;
class OpWriteBlockProtoDefaultTypeInternal;
extern OpWriteBlockProtoDefaultTypeInternal _OpWriteBlockProto_default_instance_;
class PacketHeaderProto;
class PacketHeaderProtoDefaultTypeInternal;
extern PacketHeaderProtoDefaultTypeInternal _PacketHeaderProto_default_instance_;
class PipelineAckProto;
class PipelineAckProtoDefaultTypeInternal;
extern PipelineAckProtoDefaultTypeInternal _PipelineAckProto_default_instance_;
class ReadOpChecksumInfoProto;
class ReadOpChecksumInfoProtoDefaultTypeInternal;
extern ReadOpChecksumInfoProtoDefaultTypeInternal _ReadOpChecksumInfoProto_default_instance_;
class ReleaseShortCircuitAccessRequestProto;
class ReleaseShortCircuitAccessRequestProtoDefaultTypeInternal;
extern ReleaseShortCircuitAccessRequestProtoDefaultTypeInternal _ReleaseShortCircuitAccessRequestProto_default_instance_;
class ReleaseShortCircuitAccessResponseProto;
class ReleaseShortCircuitAccessResponseProtoDefaultTypeInternal;
extern ReleaseShortCircuitAccessResponseProtoDefaultTypeInternal _ReleaseShortCircuitAccessResponseProto_default_instance_;
class ShortCircuitShmIdProto;
class ShortCircuitShmIdProtoDefaultTypeInternal;
extern ShortCircuitShmIdProtoDefaultTypeInternal _ShortCircuitShmIdProto_default_instance_;
class ShortCircuitShmRequestProto;
class ShortCircuitShmRequestProtoDefaultTypeInternal;
extern ShortCircuitShmRequestProtoDefaultTypeInternal _ShortCircuitShmRequestProto_default_instance_;
class ShortCircuitShmResponseProto;
class ShortCircuitShmResponseProtoDefaultTypeInternal;
extern ShortCircuitShmResponseProtoDefaultTypeInternal _ShortCircuitShmResponseProto_default_instance_;
class ShortCircuitShmSlotProto;
class ShortCircuitShmSlotProtoDefaultTypeInternal;
extern ShortCircuitShmSlotProtoDefaultTypeInternal _ShortCircuitShmSlotProto_default_instance_;
}  // namespace hdfs
}  // namespace hadoop
namespace google {
namespace protobuf {
template<> ::hadoop::hdfs::BaseHeaderProto* Arena::CreateMaybeMessage<::hadoop::hdfs::BaseHeaderProto>(Arena*);
template<> ::hadoop::hdfs::BlockOpResponseProto* Arena::CreateMaybeMessage<::hadoop::hdfs::BlockOpResponseProto>(Arena*);
template<> ::hadoop::hdfs::CachingStrategyProto* Arena::CreateMaybeMessage<::hadoop::hdfs::CachingStrategyProto>(Arena*);
template<> ::hadoop::hdfs::ChecksumProto* Arena::CreateMaybeMessage<::hadoop::hdfs::ChecksumProto>(Arena*);
template<> ::hadoop::hdfs::ClientOperationHeaderProto* Arena::CreateMaybeMessage<::hadoop::hdfs::ClientOperationHeaderProto>(Arena*);
template<> ::hadoop::hdfs::ClientReadStatusProto* Arena::CreateMaybeMessage<::hadoop::hdfs::ClientReadStatusProto>(Arena*);
template<> ::hadoop::hdfs::DNTransferAckProto* Arena::CreateMaybeMessage<::hadoop::hdfs::DNTransferAckProto>(Arena*);
template<> ::hadoop::hdfs::DataTransferEncryptorMessageProto* Arena::CreateMaybeMessage<::hadoop::hdfs::DataTransferEncryptorMessageProto>(Arena*);
template<> ::hadoop::hdfs::DataTransferTraceInfoProto* Arena::CreateMaybeMessage<::hadoop::hdfs::DataTransferTraceInfoProto>(Arena*);
template<> ::hadoop::hdfs::HandshakeSecretProto* Arena::CreateMaybeMessage<::hadoop::hdfs::HandshakeSecretProto>(Arena*);
template<> ::hadoop::hdfs::OpBlockChecksumProto* Arena::CreateMaybeMessage<::hadoop::hdfs::OpBlockChecksumProto>(Arena*);
template<> ::hadoop::hdfs::OpBlockChecksumResponseProto* Arena::CreateMaybeMessage<::hadoop::hdfs::OpBlockChecksumResponseProto>(Arena*);
template<> ::hadoop::hdfs::OpBlockGroupChecksumProto* Arena::CreateMaybeMessage<::hadoop::hdfs::OpBlockGroupChecksumProto>(Arena*);
template<> ::hadoop::hdfs::OpCopyBlockProto* Arena::CreateMaybeMessage<::hadoop::hdfs::OpCopyBlockProto>(Arena*);
template<> ::hadoop::hdfs::OpCustomProto* Arena::CreateMaybeMessage<::hadoop::hdfs::OpCustomProto>(Arena*);
template<> ::hadoop::hdfs::OpReadBlockProto* Arena::CreateMaybeMessage<::hadoop::hdfs::OpReadBlockProto>(Arena*);
template<> ::hadoop::hdfs::OpReplaceBlockProto* Arena::CreateMaybeMessage<::hadoop::hdfs::OpReplaceBlockProto>(Arena*);
template<> ::hadoop::hdfs::OpRequestShortCircuitAccessProto* Arena::CreateMaybeMessage<::hadoop::hdfs::OpRequestShortCircuitAccessProto>(Arena*);
template<> ::hadoop::hdfs::OpTransferBlockProto* Arena::CreateMaybeMessage<::hadoop::hdfs::OpTransferBlockProto>(Arena*);
template<> ::hadoop::hdfs::OpWriteBlockProto* Arena::CreateMaybeMessage<::hadoop::hdfs::OpWriteBlockProto>(Arena*);
template<> ::hadoop::hdfs::PacketHeaderProto* Arena::CreateMaybeMessage<::hadoop::hdfs::PacketHeaderProto>(Arena*);
template<> ::hadoop::hdfs::PipelineAckProto* Arena::CreateMaybeMessage<::hadoop::hdfs::PipelineAckProto>(Arena*);
template<> ::hadoop::hdfs::ReadOpChecksumInfoProto* Arena::CreateMaybeMessage<::hadoop::hdfs::ReadOpChecksumInfoProto>(Arena*);
template<> ::hadoop::hdfs::ReleaseShortCircuitAccessRequestProto* Arena::CreateMaybeMessage<::hadoop::hdfs::ReleaseShortCircuitAccessRequestProto>(Arena*);
template<> ::hadoop::hdfs::ReleaseShortCircuitAccessResponseProto* Arena::CreateMaybeMessage<::hadoop::hdfs::ReleaseShortCircuitAccessResponseProto>(Arena*);
template<> ::hadoop::hdfs::ShortCircuitShmIdProto* Arena::CreateMaybeMessage<::hadoop::hdfs::ShortCircuitShmIdProto>(Arena*);
template<> ::hadoop::hdfs::ShortCircuitShmRequestProto* Arena::CreateMaybeMessage<::hadoop::hdfs::ShortCircuitShmRequestProto>(Arena*);
template<> ::hadoop::hdfs::ShortCircuitShmResponseProto* Arena::CreateMaybeMessage<::hadoop::hdfs::ShortCircuitShmResponseProto>(Arena*);
template<> ::hadoop::hdfs::ShortCircuitShmSlotProto* Arena::CreateMaybeMessage<::hadoop::hdfs::ShortCircuitShmSlotProto>(Arena*);
}  // namespace protobuf
}  // namespace google
namespace hadoop {
namespace hdfs {

enum DataTransferEncryptorMessageProto_DataTransferEncryptorStatus {
  DataTransferEncryptorMessageProto_DataTransferEncryptorStatus_SUCCESS = 0,
  DataTransferEncryptorMessageProto_DataTransferEncryptorStatus_ERROR_UNKNOWN_KEY = 1,
  DataTransferEncryptorMessageProto_DataTransferEncryptorStatus_ERROR = 2
};
bool DataTransferEncryptorMessageProto_DataTransferEncryptorStatus_IsValid(int value);
const DataTransferEncryptorMessageProto_DataTransferEncryptorStatus DataTransferEncryptorMessageProto_DataTransferEncryptorStatus_DataTransferEncryptorStatus_MIN = DataTransferEncryptorMessageProto_DataTransferEncryptorStatus_SUCCESS;
const DataTransferEncryptorMessageProto_DataTransferEncryptorStatus DataTransferEncryptorMessageProto_DataTransferEncryptorStatus_DataTransferEncryptorStatus_MAX = DataTransferEncryptorMessageProto_DataTransferEncryptorStatus_ERROR;
const int DataTransferEncryptorMessageProto_DataTransferEncryptorStatus_DataTransferEncryptorStatus_ARRAYSIZE = DataTransferEncryptorMessageProto_DataTransferEncryptorStatus_DataTransferEncryptorStatus_MAX + 1;

const ::google::protobuf::EnumDescriptor* DataTransferEncryptorMessageProto_DataTransferEncryptorStatus_descriptor();
inline const ::std::string& DataTransferEncryptorMessageProto_DataTransferEncryptorStatus_Name(DataTransferEncryptorMessageProto_DataTransferEncryptorStatus value) {
  return ::google::protobuf::internal::NameOfEnum(
    DataTransferEncryptorMessageProto_DataTransferEncryptorStatus_descriptor(), value);
}
inline bool DataTransferEncryptorMessageProto_DataTransferEncryptorStatus_Parse(
    const ::std::string& name, DataTransferEncryptorMessageProto_DataTransferEncryptorStatus* value) {
  return ::google::protobuf::internal::ParseNamedEnum<DataTransferEncryptorMessageProto_DataTransferEncryptorStatus>(
    DataTransferEncryptorMessageProto_DataTransferEncryptorStatus_descriptor(), name, value);
}
enum OpWriteBlockProto_BlockConstructionStage {
  OpWriteBlockProto_BlockConstructionStage_PIPELINE_SETUP_APPEND = 0,
  OpWriteBlockProto_BlockConstructionStage_PIPELINE_SETUP_APPEND_RECOVERY = 1,
  OpWriteBlockProto_BlockConstructionStage_DATA_STREAMING = 2,
  OpWriteBlockProto_BlockConstructionStage_PIPELINE_SETUP_STREAMING_RECOVERY = 3,
  OpWriteBlockProto_BlockConstructionStage_PIPELINE_CLOSE = 4,
  OpWriteBlockProto_BlockConstructionStage_PIPELINE_CLOSE_RECOVERY = 5,
  OpWriteBlockProto_BlockConstructionStage_PIPELINE_SETUP_CREATE = 6,
  OpWriteBlockProto_BlockConstructionStage_TRANSFER_RBW = 7,
  OpWriteBlockProto_BlockConstructionStage_TRANSFER_FINALIZED = 8
};
bool OpWriteBlockProto_BlockConstructionStage_IsValid(int value);
const OpWriteBlockProto_BlockConstructionStage OpWriteBlockProto_BlockConstructionStage_BlockConstructionStage_MIN = OpWriteBlockProto_BlockConstructionStage_PIPELINE_SETUP_APPEND;
const OpWriteBlockProto_BlockConstructionStage OpWriteBlockProto_BlockConstructionStage_BlockConstructionStage_MAX = OpWriteBlockProto_BlockConstructionStage_TRANSFER_FINALIZED;
const int OpWriteBlockProto_BlockConstructionStage_BlockConstructionStage_ARRAYSIZE = OpWriteBlockProto_BlockConstructionStage_BlockConstructionStage_MAX + 1;

const ::google::protobuf::EnumDescriptor* OpWriteBlockProto_BlockConstructionStage_descriptor();
inline const ::std::string& OpWriteBlockProto_BlockConstructionStage_Name(OpWriteBlockProto_BlockConstructionStage value) {
  return ::google::protobuf::internal::NameOfEnum(
    OpWriteBlockProto_BlockConstructionStage_descriptor(), value);
}
inline bool OpWriteBlockProto_BlockConstructionStage_Parse(
    const ::std::string& name, OpWriteBlockProto_BlockConstructionStage* value) {
  return ::google::protobuf::internal::ParseNamedEnum<OpWriteBlockProto_BlockConstructionStage>(
    OpWriteBlockProto_BlockConstructionStage_descriptor(), name, value);
}
enum Status {
  SUCCESS = 0,
  ERROR = 1,
  ERROR_CHECKSUM = 2,
  ERROR_INVALID = 3,
  ERROR_EXISTS = 4,
  ERROR_ACCESS_TOKEN = 5,
  CHECKSUM_OK = 6,
  ERROR_UNSUPPORTED = 7,
  OOB_RESTART = 8,
  OOB_RESERVED1 = 9,
  OOB_RESERVED2 = 10,
  OOB_RESERVED3 = 11,
  IN_PROGRESS = 12,
  ERROR_BLOCK_PINNED = 13
};
bool Status_IsValid(int value);
const Status Status_MIN = SUCCESS;
const Status Status_MAX = ERROR_BLOCK_PINNED;
const int Status_ARRAYSIZE = Status_MAX + 1;

const ::google::protobuf::EnumDescriptor* Status_descriptor();
inline const ::std::string& Status_Name(Status value) {
  return ::google::protobuf::internal::NameOfEnum(
    Status_descriptor(), value);
}
inline bool Status_Parse(
    const ::std::string& name, Status* value) {
  return ::google::protobuf::internal::ParseNamedEnum<Status>(
    Status_descriptor(), name, value);
}
enum ShortCircuitFdResponse {
  DO_NOT_USE_RECEIPT_VERIFICATION = 0,
  USE_RECEIPT_VERIFICATION = 1
};
bool ShortCircuitFdResponse_IsValid(int value);
const ShortCircuitFdResponse ShortCircuitFdResponse_MIN = DO_NOT_USE_RECEIPT_VERIFICATION;
const ShortCircuitFdResponse ShortCircuitFdResponse_MAX = USE_RECEIPT_VERIFICATION;
const int ShortCircuitFdResponse_ARRAYSIZE = ShortCircuitFdResponse_MAX + 1;

const ::google::protobuf::EnumDescriptor* ShortCircuitFdResponse_descriptor();
inline const ::std::string& ShortCircuitFdResponse_Name(ShortCircuitFdResponse value) {
  return ::google::protobuf::internal::NameOfEnum(
    ShortCircuitFdResponse_descriptor(), value);
}
inline bool ShortCircuitFdResponse_Parse(
    const ::std::string& name, ShortCircuitFdResponse* value) {
  return ::google::protobuf::internal::ParseNamedEnum<ShortCircuitFdResponse>(
    ShortCircuitFdResponse_descriptor(), name, value);
}
// ===================================================================

class DataTransferEncryptorMessageProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.DataTransferEncryptorMessageProto) */ {
 public:
  DataTransferEncryptorMessageProto();
  virtual ~DataTransferEncryptorMessageProto();

  DataTransferEncryptorMessageProto(const DataTransferEncryptorMessageProto& from);

  inline DataTransferEncryptorMessageProto& operator=(const DataTransferEncryptorMessageProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  DataTransferEncryptorMessageProto(DataTransferEncryptorMessageProto&& from) noexcept
    : DataTransferEncryptorMessageProto() {
    *this = ::std::move(from);
  }

  inline DataTransferEncryptorMessageProto& operator=(DataTransferEncryptorMessageProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const DataTransferEncryptorMessageProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const DataTransferEncryptorMessageProto* internal_default_instance() {
    return reinterpret_cast<const DataTransferEncryptorMessageProto*>(
               &_DataTransferEncryptorMessageProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    0;

  void Swap(DataTransferEncryptorMessageProto* other);
  friend void swap(DataTransferEncryptorMessageProto& a, DataTransferEncryptorMessageProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline DataTransferEncryptorMessageProto* New() const final {
    return CreateMaybeMessage<DataTransferEncryptorMessageProto>(NULL);
  }

  DataTransferEncryptorMessageProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<DataTransferEncryptorMessageProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const DataTransferEncryptorMessageProto& from);
  void MergeFrom(const DataTransferEncryptorMessageProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(DataTransferEncryptorMessageProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  typedef DataTransferEncryptorMessageProto_DataTransferEncryptorStatus DataTransferEncryptorStatus;
  static const DataTransferEncryptorStatus SUCCESS =
    DataTransferEncryptorMessageProto_DataTransferEncryptorStatus_SUCCESS;
  static const DataTransferEncryptorStatus ERROR_UNKNOWN_KEY =
    DataTransferEncryptorMessageProto_DataTransferEncryptorStatus_ERROR_UNKNOWN_KEY;
  static const DataTransferEncryptorStatus ERROR =
    DataTransferEncryptorMessageProto_DataTransferEncryptorStatus_ERROR;
  static inline bool DataTransferEncryptorStatus_IsValid(int value) {
    return DataTransferEncryptorMessageProto_DataTransferEncryptorStatus_IsValid(value);
  }
  static const DataTransferEncryptorStatus DataTransferEncryptorStatus_MIN =
    DataTransferEncryptorMessageProto_DataTransferEncryptorStatus_DataTransferEncryptorStatus_MIN;
  static const DataTransferEncryptorStatus DataTransferEncryptorStatus_MAX =
    DataTransferEncryptorMessageProto_DataTransferEncryptorStatus_DataTransferEncryptorStatus_MAX;
  static const int DataTransferEncryptorStatus_ARRAYSIZE =
    DataTransferEncryptorMessageProto_DataTransferEncryptorStatus_DataTransferEncryptorStatus_ARRAYSIZE;
  static inline const ::google::protobuf::EnumDescriptor*
  DataTransferEncryptorStatus_descriptor() {
    return DataTransferEncryptorMessageProto_DataTransferEncryptorStatus_descriptor();
  }
  static inline const ::std::string& DataTransferEncryptorStatus_Name(DataTransferEncryptorStatus value) {
    return DataTransferEncryptorMessageProto_DataTransferEncryptorStatus_Name(value);
  }
  static inline bool DataTransferEncryptorStatus_Parse(const ::std::string& name,
      DataTransferEncryptorStatus* value) {
    return DataTransferEncryptorMessageProto_DataTransferEncryptorStatus_Parse(name, value);
  }

  // accessors -------------------------------------------------------

  // repeated .hadoop.hdfs.CipherOptionProto cipherOption = 4;
  int cipheroption_size() const;
  void clear_cipheroption();
  static const int kCipherOptionFieldNumber = 4;
  ::hadoop::hdfs::CipherOptionProto* mutable_cipheroption(int index);
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::CipherOptionProto >*
      mutable_cipheroption();
  const ::hadoop::hdfs::CipherOptionProto& cipheroption(int index) const;
  ::hadoop::hdfs::CipherOptionProto* add_cipheroption();
  const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::CipherOptionProto >&
      cipheroption() const;

  // optional bytes payload = 2;
  bool has_payload() const;
  void clear_payload();
  static const int kPayloadFieldNumber = 2;
  const ::std::string& payload() const;
  void set_payload(const ::std::string& value);
  #if LANG_CXX11
  void set_payload(::std::string&& value);
  #endif
  void set_payload(const char* value);
  void set_payload(const void* value, size_t size);
  ::std::string* mutable_payload();
  ::std::string* release_payload();
  void set_allocated_payload(::std::string* payload);

  // optional string message = 3;
  bool has_message() const;
  void clear_message();
  static const int kMessageFieldNumber = 3;
  const ::std::string& message() const;
  void set_message(const ::std::string& value);
  #if LANG_CXX11
  void set_message(::std::string&& value);
  #endif
  void set_message(const char* value);
  void set_message(const char* value, size_t size);
  ::std::string* mutable_message();
  ::std::string* release_message();
  void set_allocated_message(::std::string* message);

  // optional .hadoop.hdfs.HandshakeSecretProto handshakeSecret = 5;
  bool has_handshakesecret() const;
  void clear_handshakesecret();
  static const int kHandshakeSecretFieldNumber = 5;
  private:
  const ::hadoop::hdfs::HandshakeSecretProto& _internal_handshakesecret() const;
  public:
  const ::hadoop::hdfs::HandshakeSecretProto& handshakesecret() const;
  ::hadoop::hdfs::HandshakeSecretProto* release_handshakesecret();
  ::hadoop::hdfs::HandshakeSecretProto* mutable_handshakesecret();
  void set_allocated_handshakesecret(::hadoop::hdfs::HandshakeSecretProto* handshakesecret);

  // required .hadoop.hdfs.DataTransferEncryptorMessageProto.DataTransferEncryptorStatus status = 1;
  bool has_status() const;
  void clear_status();
  static const int kStatusFieldNumber = 1;
  ::hadoop::hdfs::DataTransferEncryptorMessageProto_DataTransferEncryptorStatus status() const;
  void set_status(::hadoop::hdfs::DataTransferEncryptorMessageProto_DataTransferEncryptorStatus value);

  // optional bool accessTokenError = 6;
  bool has_accesstokenerror() const;
  void clear_accesstokenerror();
  static const int kAccessTokenErrorFieldNumber = 6;
  bool accesstokenerror() const;
  void set_accesstokenerror(bool value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.DataTransferEncryptorMessageProto)
 private:
  void set_has_status();
  void clear_has_status();
  void set_has_payload();
  void clear_has_payload();
  void set_has_message();
  void clear_has_message();
  void set_has_handshakesecret();
  void clear_has_handshakesecret();
  void set_has_accesstokenerror();
  void clear_has_accesstokenerror();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::CipherOptionProto > cipheroption_;
  ::google::protobuf::internal::ArenaStringPtr payload_;
  ::google::protobuf::internal::ArenaStringPtr message_;
  ::hadoop::hdfs::HandshakeSecretProto* handshakesecret_;
  int status_;
  bool accesstokenerror_;
  friend struct ::protobuf_datatransfer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class HandshakeSecretProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.HandshakeSecretProto) */ {
 public:
  HandshakeSecretProto();
  virtual ~HandshakeSecretProto();

  HandshakeSecretProto(const HandshakeSecretProto& from);

  inline HandshakeSecretProto& operator=(const HandshakeSecretProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  HandshakeSecretProto(HandshakeSecretProto&& from) noexcept
    : HandshakeSecretProto() {
    *this = ::std::move(from);
  }

  inline HandshakeSecretProto& operator=(HandshakeSecretProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const HandshakeSecretProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const HandshakeSecretProto* internal_default_instance() {
    return reinterpret_cast<const HandshakeSecretProto*>(
               &_HandshakeSecretProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    1;

  void Swap(HandshakeSecretProto* other);
  friend void swap(HandshakeSecretProto& a, HandshakeSecretProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline HandshakeSecretProto* New() const final {
    return CreateMaybeMessage<HandshakeSecretProto>(NULL);
  }

  HandshakeSecretProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<HandshakeSecretProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const HandshakeSecretProto& from);
  void MergeFrom(const HandshakeSecretProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(HandshakeSecretProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required bytes secret = 1;
  bool has_secret() const;
  void clear_secret();
  static const int kSecretFieldNumber = 1;
  const ::std::string& secret() const;
  void set_secret(const ::std::string& value);
  #if LANG_CXX11
  void set_secret(::std::string&& value);
  #endif
  void set_secret(const char* value);
  void set_secret(const void* value, size_t size);
  ::std::string* mutable_secret();
  ::std::string* release_secret();
  void set_allocated_secret(::std::string* secret);

  // required string bpid = 2;
  bool has_bpid() const;
  void clear_bpid();
  static const int kBpidFieldNumber = 2;
  const ::std::string& bpid() const;
  void set_bpid(const ::std::string& value);
  #if LANG_CXX11
  void set_bpid(::std::string&& value);
  #endif
  void set_bpid(const char* value);
  void set_bpid(const char* value, size_t size);
  ::std::string* mutable_bpid();
  ::std::string* release_bpid();
  void set_allocated_bpid(::std::string* bpid);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.HandshakeSecretProto)
 private:
  void set_has_secret();
  void clear_has_secret();
  void set_has_bpid();
  void clear_has_bpid();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr secret_;
  ::google::protobuf::internal::ArenaStringPtr bpid_;
  friend struct ::protobuf_datatransfer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class BaseHeaderProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.BaseHeaderProto) */ {
 public:
  BaseHeaderProto();
  virtual ~BaseHeaderProto();

  BaseHeaderProto(const BaseHeaderProto& from);

  inline BaseHeaderProto& operator=(const BaseHeaderProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  BaseHeaderProto(BaseHeaderProto&& from) noexcept
    : BaseHeaderProto() {
    *this = ::std::move(from);
  }

  inline BaseHeaderProto& operator=(BaseHeaderProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const BaseHeaderProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const BaseHeaderProto* internal_default_instance() {
    return reinterpret_cast<const BaseHeaderProto*>(
               &_BaseHeaderProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    2;

  void Swap(BaseHeaderProto* other);
  friend void swap(BaseHeaderProto& a, BaseHeaderProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline BaseHeaderProto* New() const final {
    return CreateMaybeMessage<BaseHeaderProto>(NULL);
  }

  BaseHeaderProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<BaseHeaderProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const BaseHeaderProto& from);
  void MergeFrom(const BaseHeaderProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(BaseHeaderProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required .hadoop.hdfs.ExtendedBlockProto block = 1;
  bool has_block() const;
  void clear_block();
  static const int kBlockFieldNumber = 1;
  private:
  const ::hadoop::hdfs::ExtendedBlockProto& _internal_block() const;
  public:
  const ::hadoop::hdfs::ExtendedBlockProto& block() const;
  ::hadoop::hdfs::ExtendedBlockProto* release_block();
  ::hadoop::hdfs::ExtendedBlockProto* mutable_block();
  void set_allocated_block(::hadoop::hdfs::ExtendedBlockProto* block);

  // optional .hadoop.common.TokenProto token = 2;
  bool has_token() const;
  void clear_token();
  static const int kTokenFieldNumber = 2;
  private:
  const ::hadoop::common::TokenProto& _internal_token() const;
  public:
  const ::hadoop::common::TokenProto& token() const;
  ::hadoop::common::TokenProto* release_token();
  ::hadoop::common::TokenProto* mutable_token();
  void set_allocated_token(::hadoop::common::TokenProto* token);

  // optional .hadoop.hdfs.DataTransferTraceInfoProto traceInfo = 3;
  bool has_traceinfo() const;
  void clear_traceinfo();
  static const int kTraceInfoFieldNumber = 3;
  private:
  const ::hadoop::hdfs::DataTransferTraceInfoProto& _internal_traceinfo() const;
  public:
  const ::hadoop::hdfs::DataTransferTraceInfoProto& traceinfo() const;
  ::hadoop::hdfs::DataTransferTraceInfoProto* release_traceinfo();
  ::hadoop::hdfs::DataTransferTraceInfoProto* mutable_traceinfo();
  void set_allocated_traceinfo(::hadoop::hdfs::DataTransferTraceInfoProto* traceinfo);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.BaseHeaderProto)
 private:
  void set_has_block();
  void clear_has_block();
  void set_has_token();
  void clear_has_token();
  void set_has_traceinfo();
  void clear_has_traceinfo();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::hadoop::hdfs::ExtendedBlockProto* block_;
  ::hadoop::common::TokenProto* token_;
  ::hadoop::hdfs::DataTransferTraceInfoProto* traceinfo_;
  friend struct ::protobuf_datatransfer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class DataTransferTraceInfoProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.DataTransferTraceInfoProto) */ {
 public:
  DataTransferTraceInfoProto();
  virtual ~DataTransferTraceInfoProto();

  DataTransferTraceInfoProto(const DataTransferTraceInfoProto& from);

  inline DataTransferTraceInfoProto& operator=(const DataTransferTraceInfoProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  DataTransferTraceInfoProto(DataTransferTraceInfoProto&& from) noexcept
    : DataTransferTraceInfoProto() {
    *this = ::std::move(from);
  }

  inline DataTransferTraceInfoProto& operator=(DataTransferTraceInfoProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const DataTransferTraceInfoProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const DataTransferTraceInfoProto* internal_default_instance() {
    return reinterpret_cast<const DataTransferTraceInfoProto*>(
               &_DataTransferTraceInfoProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    3;

  void Swap(DataTransferTraceInfoProto* other);
  friend void swap(DataTransferTraceInfoProto& a, DataTransferTraceInfoProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline DataTransferTraceInfoProto* New() const final {
    return CreateMaybeMessage<DataTransferTraceInfoProto>(NULL);
  }

  DataTransferTraceInfoProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<DataTransferTraceInfoProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const DataTransferTraceInfoProto& from);
  void MergeFrom(const DataTransferTraceInfoProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(DataTransferTraceInfoProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional bytes spanContext = 3;
  bool has_spancontext() const;
  void clear_spancontext();
  static const int kSpanContextFieldNumber = 3;
  const ::std::string& spancontext() const;
  void set_spancontext(const ::std::string& value);
  #if LANG_CXX11
  void set_spancontext(::std::string&& value);
  #endif
  void set_spancontext(const char* value);
  void set_spancontext(const void* value, size_t size);
  ::std::string* mutable_spancontext();
  ::std::string* release_spancontext();
  void set_allocated_spancontext(::std::string* spancontext);

  // optional uint64 traceId = 1;
  bool has_traceid() const;
  void clear_traceid();
  static const int kTraceIdFieldNumber = 1;
  ::google::protobuf::uint64 traceid() const;
  void set_traceid(::google::protobuf::uint64 value);

  // optional uint64 parentId = 2;
  bool has_parentid() const;
  void clear_parentid();
  static const int kParentIdFieldNumber = 2;
  ::google::protobuf::uint64 parentid() const;
  void set_parentid(::google::protobuf::uint64 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.DataTransferTraceInfoProto)
 private:
  void set_has_traceid();
  void clear_has_traceid();
  void set_has_parentid();
  void clear_has_parentid();
  void set_has_spancontext();
  void clear_has_spancontext();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr spancontext_;
  ::google::protobuf::uint64 traceid_;
  ::google::protobuf::uint64 parentid_;
  friend struct ::protobuf_datatransfer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class ClientOperationHeaderProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.ClientOperationHeaderProto) */ {
 public:
  ClientOperationHeaderProto();
  virtual ~ClientOperationHeaderProto();

  ClientOperationHeaderProto(const ClientOperationHeaderProto& from);

  inline ClientOperationHeaderProto& operator=(const ClientOperationHeaderProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  ClientOperationHeaderProto(ClientOperationHeaderProto&& from) noexcept
    : ClientOperationHeaderProto() {
    *this = ::std::move(from);
  }

  inline ClientOperationHeaderProto& operator=(ClientOperationHeaderProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ClientOperationHeaderProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const ClientOperationHeaderProto* internal_default_instance() {
    return reinterpret_cast<const ClientOperationHeaderProto*>(
               &_ClientOperationHeaderProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    4;

  void Swap(ClientOperationHeaderProto* other);
  friend void swap(ClientOperationHeaderProto& a, ClientOperationHeaderProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline ClientOperationHeaderProto* New() const final {
    return CreateMaybeMessage<ClientOperationHeaderProto>(NULL);
  }

  ClientOperationHeaderProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<ClientOperationHeaderProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const ClientOperationHeaderProto& from);
  void MergeFrom(const ClientOperationHeaderProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(ClientOperationHeaderProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required string clientName = 2;
  bool has_clientname() const;
  void clear_clientname();
  static const int kClientNameFieldNumber = 2;
  const ::std::string& clientname() const;
  void set_clientname(const ::std::string& value);
  #if LANG_CXX11
  void set_clientname(::std::string&& value);
  #endif
  void set_clientname(const char* value);
  void set_clientname(const char* value, size_t size);
  ::std::string* mutable_clientname();
  ::std::string* release_clientname();
  void set_allocated_clientname(::std::string* clientname);

  // required .hadoop.hdfs.BaseHeaderProto baseHeader = 1;
  bool has_baseheader() const;
  void clear_baseheader();
  static const int kBaseHeaderFieldNumber = 1;
  private:
  const ::hadoop::hdfs::BaseHeaderProto& _internal_baseheader() const;
  public:
  const ::hadoop::hdfs::BaseHeaderProto& baseheader() const;
  ::hadoop::hdfs::BaseHeaderProto* release_baseheader();
  ::hadoop::hdfs::BaseHeaderProto* mutable_baseheader();
  void set_allocated_baseheader(::hadoop::hdfs::BaseHeaderProto* baseheader);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.ClientOperationHeaderProto)
 private:
  void set_has_baseheader();
  void clear_has_baseheader();
  void set_has_clientname();
  void clear_has_clientname();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr clientname_;
  ::hadoop::hdfs::BaseHeaderProto* baseheader_;
  friend struct ::protobuf_datatransfer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class CachingStrategyProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.CachingStrategyProto) */ {
 public:
  CachingStrategyProto();
  virtual ~CachingStrategyProto();

  CachingStrategyProto(const CachingStrategyProto& from);

  inline CachingStrategyProto& operator=(const CachingStrategyProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  CachingStrategyProto(CachingStrategyProto&& from) noexcept
    : CachingStrategyProto() {
    *this = ::std::move(from);
  }

  inline CachingStrategyProto& operator=(CachingStrategyProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const CachingStrategyProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const CachingStrategyProto* internal_default_instance() {
    return reinterpret_cast<const CachingStrategyProto*>(
               &_CachingStrategyProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    5;

  void Swap(CachingStrategyProto* other);
  friend void swap(CachingStrategyProto& a, CachingStrategyProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline CachingStrategyProto* New() const final {
    return CreateMaybeMessage<CachingStrategyProto>(NULL);
  }

  CachingStrategyProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<CachingStrategyProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const CachingStrategyProto& from);
  void MergeFrom(const CachingStrategyProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(CachingStrategyProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional int64 readahead = 2;
  bool has_readahead() const;
  void clear_readahead();
  static const int kReadaheadFieldNumber = 2;
  ::google::protobuf::int64 readahead() const;
  void set_readahead(::google::protobuf::int64 value);

  // optional bool dropBehind = 1;
  bool has_dropbehind() const;
  void clear_dropbehind();
  static const int kDropBehindFieldNumber = 1;
  bool dropbehind() const;
  void set_dropbehind(bool value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.CachingStrategyProto)
 private:
  void set_has_dropbehind();
  void clear_has_dropbehind();
  void set_has_readahead();
  void clear_has_readahead();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::int64 readahead_;
  bool dropbehind_;
  friend struct ::protobuf_datatransfer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class OpReadBlockProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.OpReadBlockProto) */ {
 public:
  OpReadBlockProto();
  virtual ~OpReadBlockProto();

  OpReadBlockProto(const OpReadBlockProto& from);

  inline OpReadBlockProto& operator=(const OpReadBlockProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  OpReadBlockProto(OpReadBlockProto&& from) noexcept
    : OpReadBlockProto() {
    *this = ::std::move(from);
  }

  inline OpReadBlockProto& operator=(OpReadBlockProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const OpReadBlockProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const OpReadBlockProto* internal_default_instance() {
    return reinterpret_cast<const OpReadBlockProto*>(
               &_OpReadBlockProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    6;

  void Swap(OpReadBlockProto* other);
  friend void swap(OpReadBlockProto& a, OpReadBlockProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline OpReadBlockProto* New() const final {
    return CreateMaybeMessage<OpReadBlockProto>(NULL);
  }

  OpReadBlockProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<OpReadBlockProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const OpReadBlockProto& from);
  void MergeFrom(const OpReadBlockProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(OpReadBlockProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required .hadoop.hdfs.ClientOperationHeaderProto header = 1;
  bool has_header() const;
  void clear_header();
  static const int kHeaderFieldNumber = 1;
  private:
  const ::hadoop::hdfs::ClientOperationHeaderProto& _internal_header() const;
  public:
  const ::hadoop::hdfs::ClientOperationHeaderProto& header() const;
  ::hadoop::hdfs::ClientOperationHeaderProto* release_header();
  ::hadoop::hdfs::ClientOperationHeaderProto* mutable_header();
  void set_allocated_header(::hadoop::hdfs::ClientOperationHeaderProto* header);

  // optional .hadoop.hdfs.CachingStrategyProto cachingStrategy = 5;
  bool has_cachingstrategy() const;
  void clear_cachingstrategy();
  static const int kCachingStrategyFieldNumber = 5;
  private:
  const ::hadoop::hdfs::CachingStrategyProto& _internal_cachingstrategy() const;
  public:
  const ::hadoop::hdfs::CachingStrategyProto& cachingstrategy() const;
  ::hadoop::hdfs::CachingStrategyProto* release_cachingstrategy();
  ::hadoop::hdfs::CachingStrategyProto* mutable_cachingstrategy();
  void set_allocated_cachingstrategy(::hadoop::hdfs::CachingStrategyProto* cachingstrategy);

  // required uint64 offset = 2;
  bool has_offset() const;
  void clear_offset();
  static const int kOffsetFieldNumber = 2;
  ::google::protobuf::uint64 offset() const;
  void set_offset(::google::protobuf::uint64 value);

  // required uint64 len = 3;
  bool has_len() const;
  void clear_len();
  static const int kLenFieldNumber = 3;
  ::google::protobuf::uint64 len() const;
  void set_len(::google::protobuf::uint64 value);

  // optional bool sendChecksums = 4 [default = true];
  bool has_sendchecksums() const;
  void clear_sendchecksums();
  static const int kSendChecksumsFieldNumber = 4;
  bool sendchecksums() const;
  void set_sendchecksums(bool value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.OpReadBlockProto)
 private:
  void set_has_header();
  void clear_has_header();
  void set_has_offset();
  void clear_has_offset();
  void set_has_len();
  void clear_has_len();
  void set_has_sendchecksums();
  void clear_has_sendchecksums();
  void set_has_cachingstrategy();
  void clear_has_cachingstrategy();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::hadoop::hdfs::ClientOperationHeaderProto* header_;
  ::hadoop::hdfs::CachingStrategyProto* cachingstrategy_;
  ::google::protobuf::uint64 offset_;
  ::google::protobuf::uint64 len_;
  bool sendchecksums_;
  friend struct ::protobuf_datatransfer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class ChecksumProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.ChecksumProto) */ {
 public:
  ChecksumProto();
  virtual ~ChecksumProto();

  ChecksumProto(const ChecksumProto& from);

  inline ChecksumProto& operator=(const ChecksumProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  ChecksumProto(ChecksumProto&& from) noexcept
    : ChecksumProto() {
    *this = ::std::move(from);
  }

  inline ChecksumProto& operator=(ChecksumProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ChecksumProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const ChecksumProto* internal_default_instance() {
    return reinterpret_cast<const ChecksumProto*>(
               &_ChecksumProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    7;

  void Swap(ChecksumProto* other);
  friend void swap(ChecksumProto& a, ChecksumProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline ChecksumProto* New() const final {
    return CreateMaybeMessage<ChecksumProto>(NULL);
  }

  ChecksumProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<ChecksumProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const ChecksumProto& from);
  void MergeFrom(const ChecksumProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(ChecksumProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required .hadoop.hdfs.ChecksumTypeProto type = 1;
  bool has_type() const;
  void clear_type();
  static const int kTypeFieldNumber = 1;
  ::hadoop::hdfs::ChecksumTypeProto type() const;
  void set_type(::hadoop::hdfs::ChecksumTypeProto value);

  // required uint32 bytesPerChecksum = 2;
  bool has_bytesperchecksum() const;
  void clear_bytesperchecksum();
  static const int kBytesPerChecksumFieldNumber = 2;
  ::google::protobuf::uint32 bytesperchecksum() const;
  void set_bytesperchecksum(::google::protobuf::uint32 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.ChecksumProto)
 private:
  void set_has_type();
  void clear_has_type();
  void set_has_bytesperchecksum();
  void clear_has_bytesperchecksum();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  int type_;
  ::google::protobuf::uint32 bytesperchecksum_;
  friend struct ::protobuf_datatransfer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class OpWriteBlockProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.OpWriteBlockProto) */ {
 public:
  OpWriteBlockProto();
  virtual ~OpWriteBlockProto();

  OpWriteBlockProto(const OpWriteBlockProto& from);

  inline OpWriteBlockProto& operator=(const OpWriteBlockProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  OpWriteBlockProto(OpWriteBlockProto&& from) noexcept
    : OpWriteBlockProto() {
    *this = ::std::move(from);
  }

  inline OpWriteBlockProto& operator=(OpWriteBlockProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const OpWriteBlockProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const OpWriteBlockProto* internal_default_instance() {
    return reinterpret_cast<const OpWriteBlockProto*>(
               &_OpWriteBlockProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    8;

  void Swap(OpWriteBlockProto* other);
  friend void swap(OpWriteBlockProto& a, OpWriteBlockProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline OpWriteBlockProto* New() const final {
    return CreateMaybeMessage<OpWriteBlockProto>(NULL);
  }

  OpWriteBlockProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<OpWriteBlockProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const OpWriteBlockProto& from);
  void MergeFrom(const OpWriteBlockProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(OpWriteBlockProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  typedef OpWriteBlockProto_BlockConstructionStage BlockConstructionStage;
  static const BlockConstructionStage PIPELINE_SETUP_APPEND =
    OpWriteBlockProto_BlockConstructionStage_PIPELINE_SETUP_APPEND;
  static const BlockConstructionStage PIPELINE_SETUP_APPEND_RECOVERY =
    OpWriteBlockProto_BlockConstructionStage_PIPELINE_SETUP_APPEND_RECOVERY;
  static const BlockConstructionStage DATA_STREAMING =
    OpWriteBlockProto_BlockConstructionStage_DATA_STREAMING;
  static const BlockConstructionStage PIPELINE_SETUP_STREAMING_RECOVERY =
    OpWriteBlockProto_BlockConstructionStage_PIPELINE_SETUP_STREAMING_RECOVERY;
  static const BlockConstructionStage PIPELINE_CLOSE =
    OpWriteBlockProto_BlockConstructionStage_PIPELINE_CLOSE;
  static const BlockConstructionStage PIPELINE_CLOSE_RECOVERY =
    OpWriteBlockProto_BlockConstructionStage_PIPELINE_CLOSE_RECOVERY;
  static const BlockConstructionStage PIPELINE_SETUP_CREATE =
    OpWriteBlockProto_BlockConstructionStage_PIPELINE_SETUP_CREATE;
  static const BlockConstructionStage TRANSFER_RBW =
    OpWriteBlockProto_BlockConstructionStage_TRANSFER_RBW;
  static const BlockConstructionStage TRANSFER_FINALIZED =
    OpWriteBlockProto_BlockConstructionStage_TRANSFER_FINALIZED;
  static inline bool BlockConstructionStage_IsValid(int value) {
    return OpWriteBlockProto_BlockConstructionStage_IsValid(value);
  }
  static const BlockConstructionStage BlockConstructionStage_MIN =
    OpWriteBlockProto_BlockConstructionStage_BlockConstructionStage_MIN;
  static const BlockConstructionStage BlockConstructionStage_MAX =
    OpWriteBlockProto_BlockConstructionStage_BlockConstructionStage_MAX;
  static const int BlockConstructionStage_ARRAYSIZE =
    OpWriteBlockProto_BlockConstructionStage_BlockConstructionStage_ARRAYSIZE;
  static inline const ::google::protobuf::EnumDescriptor*
  BlockConstructionStage_descriptor() {
    return OpWriteBlockProto_BlockConstructionStage_descriptor();
  }
  static inline const ::std::string& BlockConstructionStage_Name(BlockConstructionStage value) {
    return OpWriteBlockProto_BlockConstructionStage_Name(value);
  }
  static inline bool BlockConstructionStage_Parse(const ::std::string& name,
      BlockConstructionStage* value) {
    return OpWriteBlockProto_BlockConstructionStage_Parse(name, value);
  }

  // accessors -------------------------------------------------------

  // repeated .hadoop.hdfs.DatanodeInfoProto targets = 2;
  int targets_size() const;
  void clear_targets();
  static const int kTargetsFieldNumber = 2;
  ::hadoop::hdfs::DatanodeInfoProto* mutable_targets(int index);
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::DatanodeInfoProto >*
      mutable_targets();
  const ::hadoop::hdfs::DatanodeInfoProto& targets(int index) const;
  ::hadoop::hdfs::DatanodeInfoProto* add_targets();
  const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::DatanodeInfoProto >&
      targets() const;

  // repeated .hadoop.hdfs.StorageTypeProto targetStorageTypes = 12;
  int targetstoragetypes_size() const;
  void clear_targetstoragetypes();
  static const int kTargetStorageTypesFieldNumber = 12;
  ::hadoop::hdfs::StorageTypeProto targetstoragetypes(int index) const;
  void set_targetstoragetypes(int index, ::hadoop::hdfs::StorageTypeProto value);
  void add_targetstoragetypes(::hadoop::hdfs::StorageTypeProto value);
  const ::google::protobuf::RepeatedField<int>& targetstoragetypes() const;
  ::google::protobuf::RepeatedField<int>* mutable_targetstoragetypes();

  // repeated bool targetPinnings = 15;
  int targetpinnings_size() const;
  void clear_targetpinnings();
  static const int kTargetPinningsFieldNumber = 15;
  bool targetpinnings(int index) const;
  void set_targetpinnings(int index, bool value);
  void add_targetpinnings(bool value);
  const ::google::protobuf::RepeatedField< bool >&
      targetpinnings() const;
  ::google::protobuf::RepeatedField< bool >*
      mutable_targetpinnings();

  // repeated string targetStorageIds = 17;
  int targetstorageids_size() const;
  void clear_targetstorageids();
  static const int kTargetStorageIdsFieldNumber = 17;
  const ::std::string& targetstorageids(int index) const;
  ::std::string* mutable_targetstorageids(int index);
  void set_targetstorageids(int index, const ::std::string& value);
  #if LANG_CXX11
  void set_targetstorageids(int index, ::std::string&& value);
  #endif
  void set_targetstorageids(int index, const char* value);
  void set_targetstorageids(int index, const char* value, size_t size);
  ::std::string* add_targetstorageids();
  void add_targetstorageids(const ::std::string& value);
  #if LANG_CXX11
  void add_targetstorageids(::std::string&& value);
  #endif
  void add_targetstorageids(const char* value);
  void add_targetstorageids(const char* value, size_t size);
  const ::google::protobuf::RepeatedPtrField< ::std::string>& targetstorageids() const;
  ::google::protobuf::RepeatedPtrField< ::std::string>* mutable_targetstorageids();

  // optional string storageId = 16;
  bool has_storageid() const;
  void clear_storageid();
  static const int kStorageIdFieldNumber = 16;
  const ::std::string& storageid() const;
  void set_storageid(const ::std::string& value);
  #if LANG_CXX11
  void set_storageid(::std::string&& value);
  #endif
  void set_storageid(const char* value);
  void set_storageid(const char* value, size_t size);
  ::std::string* mutable_storageid();
  ::std::string* release_storageid();
  void set_allocated_storageid(::std::string* storageid);

  // required .hadoop.hdfs.ClientOperationHeaderProto header = 1;
  bool has_header() const;
  void clear_header();
  static const int kHeaderFieldNumber = 1;
  private:
  const ::hadoop::hdfs::ClientOperationHeaderProto& _internal_header() const;
  public:
  const ::hadoop::hdfs::ClientOperationHeaderProto& header() const;
  ::hadoop::hdfs::ClientOperationHeaderProto* release_header();
  ::hadoop::hdfs::ClientOperationHeaderProto* mutable_header();
  void set_allocated_header(::hadoop::hdfs::ClientOperationHeaderProto* header);

  // optional .hadoop.hdfs.DatanodeInfoProto source = 3;
  bool has_source() const;
  void clear_source();
  static const int kSourceFieldNumber = 3;
  private:
  const ::hadoop::hdfs::DatanodeInfoProto& _internal_source() const;
  public:
  const ::hadoop::hdfs::DatanodeInfoProto& source() const;
  ::hadoop::hdfs::DatanodeInfoProto* release_source();
  ::hadoop::hdfs::DatanodeInfoProto* mutable_source();
  void set_allocated_source(::hadoop::hdfs::DatanodeInfoProto* source);

  // required .hadoop.hdfs.ChecksumProto requestedChecksum = 9;
  bool has_requestedchecksum() const;
  void clear_requestedchecksum();
  static const int kRequestedChecksumFieldNumber = 9;
  private:
  const ::hadoop::hdfs::ChecksumProto& _internal_requestedchecksum() const;
  public:
  const ::hadoop::hdfs::ChecksumProto& requestedchecksum() const;
  ::hadoop::hdfs::ChecksumProto* release_requestedchecksum();
  ::hadoop::hdfs::ChecksumProto* mutable_requestedchecksum();
  void set_allocated_requestedchecksum(::hadoop::hdfs::ChecksumProto* requestedchecksum);

  // optional .hadoop.hdfs.CachingStrategyProto cachingStrategy = 10;
  bool has_cachingstrategy() const;
  void clear_cachingstrategy();
  static const int kCachingStrategyFieldNumber = 10;
  private:
  const ::hadoop::hdfs::CachingStrategyProto& _internal_cachingstrategy() const;
  public:
  const ::hadoop::hdfs::CachingStrategyProto& cachingstrategy() const;
  ::hadoop::hdfs::CachingStrategyProto* release_cachingstrategy();
  ::hadoop::hdfs::CachingStrategyProto* mutable_cachingstrategy();
  void set_allocated_cachingstrategy(::hadoop::hdfs::CachingStrategyProto* cachingstrategy);

  // required .hadoop.hdfs.OpWriteBlockProto.BlockConstructionStage stage = 4;
  bool has_stage() const;
  void clear_stage();
  static const int kStageFieldNumber = 4;
  ::hadoop::hdfs::OpWriteBlockProto_BlockConstructionStage stage() const;
  void set_stage(::hadoop::hdfs::OpWriteBlockProto_BlockConstructionStage value);

  // required uint32 pipelineSize = 5;
  bool has_pipelinesize() const;
  void clear_pipelinesize();
  static const int kPipelineSizeFieldNumber = 5;
  ::google::protobuf::uint32 pipelinesize() const;
  void set_pipelinesize(::google::protobuf::uint32 value);

  // required uint64 minBytesRcvd = 6;
  bool has_minbytesrcvd() const;
  void clear_minbytesrcvd();
  static const int kMinBytesRcvdFieldNumber = 6;
  ::google::protobuf::uint64 minbytesrcvd() const;
  void set_minbytesrcvd(::google::protobuf::uint64 value);

  // required uint64 maxBytesRcvd = 7;
  bool has_maxbytesrcvd() const;
  void clear_maxbytesrcvd();
  static const int kMaxBytesRcvdFieldNumber = 7;
  ::google::protobuf::uint64 maxbytesrcvd() const;
  void set_maxbytesrcvd(::google::protobuf::uint64 value);

  // required uint64 latestGenerationStamp = 8;
  bool has_latestgenerationstamp() const;
  void clear_latestgenerationstamp();
  static const int kLatestGenerationStampFieldNumber = 8;
  ::google::protobuf::uint64 latestgenerationstamp() const;
  void set_latestgenerationstamp(::google::protobuf::uint64 value);

  // optional bool allowLazyPersist = 13 [default = false];
  bool has_allowlazypersist() const;
  void clear_allowlazypersist();
  static const int kAllowLazyPersistFieldNumber = 13;
  bool allowlazypersist() const;
  void set_allowlazypersist(bool value);

  // optional bool pinning = 14 [default = false];
  bool has_pinning() const;
  void clear_pinning();
  static const int kPinningFieldNumber = 14;
  bool pinning() const;
  void set_pinning(bool value);

  // optional .hadoop.hdfs.StorageTypeProto storageType = 11 [default = DISK];
  bool has_storagetype() const;
  void clear_storagetype();
  static const int kStorageTypeFieldNumber = 11;
  ::hadoop::hdfs::StorageTypeProto storagetype() const;
  void set_storagetype(::hadoop::hdfs::StorageTypeProto value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.OpWriteBlockProto)
 private:
  void set_has_header();
  void clear_has_header();
  void set_has_source();
  void clear_has_source();
  void set_has_stage();
  void clear_has_stage();
  void set_has_pipelinesize();
  void clear_has_pipelinesize();
  void set_has_minbytesrcvd();
  void clear_has_minbytesrcvd();
  void set_has_maxbytesrcvd();
  void clear_has_maxbytesrcvd();
  void set_has_latestgenerationstamp();
  void clear_has_latestgenerationstamp();
  void set_has_requestedchecksum();
  void clear_has_requestedchecksum();
  void set_has_cachingstrategy();
  void clear_has_cachingstrategy();
  void set_has_storagetype();
  void clear_has_storagetype();
  void set_has_allowlazypersist();
  void clear_has_allowlazypersist();
  void set_has_pinning();
  void clear_has_pinning();
  void set_has_storageid();
  void clear_has_storageid();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::DatanodeInfoProto > targets_;
  ::google::protobuf::RepeatedField<int> targetstoragetypes_;
  ::google::protobuf::RepeatedField< bool > targetpinnings_;
  ::google::protobuf::RepeatedPtrField< ::std::string> targetstorageids_;
  ::google::protobuf::internal::ArenaStringPtr storageid_;
  ::hadoop::hdfs::ClientOperationHeaderProto* header_;
  ::hadoop::hdfs::DatanodeInfoProto* source_;
  ::hadoop::hdfs::ChecksumProto* requestedchecksum_;
  ::hadoop::hdfs::CachingStrategyProto* cachingstrategy_;
  int stage_;
  ::google::protobuf::uint32 pipelinesize_;
  ::google::protobuf::uint64 minbytesrcvd_;
  ::google::protobuf::uint64 maxbytesrcvd_;
  ::google::protobuf::uint64 latestgenerationstamp_;
  bool allowlazypersist_;
  bool pinning_;
  int storagetype_;
  friend struct ::protobuf_datatransfer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class OpTransferBlockProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.OpTransferBlockProto) */ {
 public:
  OpTransferBlockProto();
  virtual ~OpTransferBlockProto();

  OpTransferBlockProto(const OpTransferBlockProto& from);

  inline OpTransferBlockProto& operator=(const OpTransferBlockProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  OpTransferBlockProto(OpTransferBlockProto&& from) noexcept
    : OpTransferBlockProto() {
    *this = ::std::move(from);
  }

  inline OpTransferBlockProto& operator=(OpTransferBlockProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const OpTransferBlockProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const OpTransferBlockProto* internal_default_instance() {
    return reinterpret_cast<const OpTransferBlockProto*>(
               &_OpTransferBlockProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    9;

  void Swap(OpTransferBlockProto* other);
  friend void swap(OpTransferBlockProto& a, OpTransferBlockProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline OpTransferBlockProto* New() const final {
    return CreateMaybeMessage<OpTransferBlockProto>(NULL);
  }

  OpTransferBlockProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<OpTransferBlockProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const OpTransferBlockProto& from);
  void MergeFrom(const OpTransferBlockProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(OpTransferBlockProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.hdfs.DatanodeInfoProto targets = 2;
  int targets_size() const;
  void clear_targets();
  static const int kTargetsFieldNumber = 2;
  ::hadoop::hdfs::DatanodeInfoProto* mutable_targets(int index);
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::DatanodeInfoProto >*
      mutable_targets();
  const ::hadoop::hdfs::DatanodeInfoProto& targets(int index) const;
  ::hadoop::hdfs::DatanodeInfoProto* add_targets();
  const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::DatanodeInfoProto >&
      targets() const;

  // repeated .hadoop.hdfs.StorageTypeProto targetStorageTypes = 3;
  int targetstoragetypes_size() const;
  void clear_targetstoragetypes();
  static const int kTargetStorageTypesFieldNumber = 3;
  ::hadoop::hdfs::StorageTypeProto targetstoragetypes(int index) const;
  void set_targetstoragetypes(int index, ::hadoop::hdfs::StorageTypeProto value);
  void add_targetstoragetypes(::hadoop::hdfs::StorageTypeProto value);
  const ::google::protobuf::RepeatedField<int>& targetstoragetypes() const;
  ::google::protobuf::RepeatedField<int>* mutable_targetstoragetypes();

  // repeated string targetStorageIds = 4;
  int targetstorageids_size() const;
  void clear_targetstorageids();
  static const int kTargetStorageIdsFieldNumber = 4;
  const ::std::string& targetstorageids(int index) const;
  ::std::string* mutable_targetstorageids(int index);
  void set_targetstorageids(int index, const ::std::string& value);
  #if LANG_CXX11
  void set_targetstorageids(int index, ::std::string&& value);
  #endif
  void set_targetstorageids(int index, const char* value);
  void set_targetstorageids(int index, const char* value, size_t size);
  ::std::string* add_targetstorageids();
  void add_targetstorageids(const ::std::string& value);
  #if LANG_CXX11
  void add_targetstorageids(::std::string&& value);
  #endif
  void add_targetstorageids(const char* value);
  void add_targetstorageids(const char* value, size_t size);
  const ::google::protobuf::RepeatedPtrField< ::std::string>& targetstorageids() const;
  ::google::protobuf::RepeatedPtrField< ::std::string>* mutable_targetstorageids();

  // required .hadoop.hdfs.ClientOperationHeaderProto header = 1;
  bool has_header() const;
  void clear_header();
  static const int kHeaderFieldNumber = 1;
  private:
  const ::hadoop::hdfs::ClientOperationHeaderProto& _internal_header() const;
  public:
  const ::hadoop::hdfs::ClientOperationHeaderProto& header() const;
  ::hadoop::hdfs::ClientOperationHeaderProto* release_header();
  ::hadoop::hdfs::ClientOperationHeaderProto* mutable_header();
  void set_allocated_header(::hadoop::hdfs::ClientOperationHeaderProto* header);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.OpTransferBlockProto)
 private:
  void set_has_header();
  void clear_has_header();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::DatanodeInfoProto > targets_;
  ::google::protobuf::RepeatedField<int> targetstoragetypes_;
  ::google::protobuf::RepeatedPtrField< ::std::string> targetstorageids_;
  ::hadoop::hdfs::ClientOperationHeaderProto* header_;
  friend struct ::protobuf_datatransfer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class OpReplaceBlockProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.OpReplaceBlockProto) */ {
 public:
  OpReplaceBlockProto();
  virtual ~OpReplaceBlockProto();

  OpReplaceBlockProto(const OpReplaceBlockProto& from);

  inline OpReplaceBlockProto& operator=(const OpReplaceBlockProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  OpReplaceBlockProto(OpReplaceBlockProto&& from) noexcept
    : OpReplaceBlockProto() {
    *this = ::std::move(from);
  }

  inline OpReplaceBlockProto& operator=(OpReplaceBlockProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const OpReplaceBlockProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const OpReplaceBlockProto* internal_default_instance() {
    return reinterpret_cast<const OpReplaceBlockProto*>(
               &_OpReplaceBlockProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    10;

  void Swap(OpReplaceBlockProto* other);
  friend void swap(OpReplaceBlockProto& a, OpReplaceBlockProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline OpReplaceBlockProto* New() const final {
    return CreateMaybeMessage<OpReplaceBlockProto>(NULL);
  }

  OpReplaceBlockProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<OpReplaceBlockProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const OpReplaceBlockProto& from);
  void MergeFrom(const OpReplaceBlockProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(OpReplaceBlockProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required string delHint = 2;
  bool has_delhint() const;
  void clear_delhint();
  static const int kDelHintFieldNumber = 2;
  const ::std::string& delhint() const;
  void set_delhint(const ::std::string& value);
  #if LANG_CXX11
  void set_delhint(::std::string&& value);
  #endif
  void set_delhint(const char* value);
  void set_delhint(const char* value, size_t size);
  ::std::string* mutable_delhint();
  ::std::string* release_delhint();
  void set_allocated_delhint(::std::string* delhint);

  // optional string storageId = 5;
  bool has_storageid() const;
  void clear_storageid();
  static const int kStorageIdFieldNumber = 5;
  const ::std::string& storageid() const;
  void set_storageid(const ::std::string& value);
  #if LANG_CXX11
  void set_storageid(::std::string&& value);
  #endif
  void set_storageid(const char* value);
  void set_storageid(const char* value, size_t size);
  ::std::string* mutable_storageid();
  ::std::string* release_storageid();
  void set_allocated_storageid(::std::string* storageid);

  // required .hadoop.hdfs.BaseHeaderProto header = 1;
  bool has_header() const;
  void clear_header();
  static const int kHeaderFieldNumber = 1;
  private:
  const ::hadoop::hdfs::BaseHeaderProto& _internal_header() const;
  public:
  const ::hadoop::hdfs::BaseHeaderProto& header() const;
  ::hadoop::hdfs::BaseHeaderProto* release_header();
  ::hadoop::hdfs::BaseHeaderProto* mutable_header();
  void set_allocated_header(::hadoop::hdfs::BaseHeaderProto* header);

  // required .hadoop.hdfs.DatanodeInfoProto source = 3;
  bool has_source() const;
  void clear_source();
  static const int kSourceFieldNumber = 3;
  private:
  const ::hadoop::hdfs::DatanodeInfoProto& _internal_source() const;
  public:
  const ::hadoop::hdfs::DatanodeInfoProto& source() const;
  ::hadoop::hdfs::DatanodeInfoProto* release_source();
  ::hadoop::hdfs::DatanodeInfoProto* mutable_source();
  void set_allocated_source(::hadoop::hdfs::DatanodeInfoProto* source);

  // optional .hadoop.hdfs.StorageTypeProto storageType = 4 [default = DISK];
  bool has_storagetype() const;
  void clear_storagetype();
  static const int kStorageTypeFieldNumber = 4;
  ::hadoop::hdfs::StorageTypeProto storagetype() const;
  void set_storagetype(::hadoop::hdfs::StorageTypeProto value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.OpReplaceBlockProto)
 private:
  void set_has_header();
  void clear_has_header();
  void set_has_delhint();
  void clear_has_delhint();
  void set_has_source();
  void clear_has_source();
  void set_has_storagetype();
  void clear_has_storagetype();
  void set_has_storageid();
  void clear_has_storageid();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr delhint_;
  ::google::protobuf::internal::ArenaStringPtr storageid_;
  ::hadoop::hdfs::BaseHeaderProto* header_;
  ::hadoop::hdfs::DatanodeInfoProto* source_;
  int storagetype_;
  friend struct ::protobuf_datatransfer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class OpCopyBlockProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.OpCopyBlockProto) */ {
 public:
  OpCopyBlockProto();
  virtual ~OpCopyBlockProto();

  OpCopyBlockProto(const OpCopyBlockProto& from);

  inline OpCopyBlockProto& operator=(const OpCopyBlockProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  OpCopyBlockProto(OpCopyBlockProto&& from) noexcept
    : OpCopyBlockProto() {
    *this = ::std::move(from);
  }

  inline OpCopyBlockProto& operator=(OpCopyBlockProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const OpCopyBlockProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const OpCopyBlockProto* internal_default_instance() {
    return reinterpret_cast<const OpCopyBlockProto*>(
               &_OpCopyBlockProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    11;

  void Swap(OpCopyBlockProto* other);
  friend void swap(OpCopyBlockProto& a, OpCopyBlockProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline OpCopyBlockProto* New() const final {
    return CreateMaybeMessage<OpCopyBlockProto>(NULL);
  }

  OpCopyBlockProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<OpCopyBlockProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const OpCopyBlockProto& from);
  void MergeFrom(const OpCopyBlockProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(OpCopyBlockProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required .hadoop.hdfs.BaseHeaderProto header = 1;
  bool has_header() const;
  void clear_header();
  static const int kHeaderFieldNumber = 1;
  private:
  const ::hadoop::hdfs::BaseHeaderProto& _internal_header() const;
  public:
  const ::hadoop::hdfs::BaseHeaderProto& header() const;
  ::hadoop::hdfs::BaseHeaderProto* release_header();
  ::hadoop::hdfs::BaseHeaderProto* mutable_header();
  void set_allocated_header(::hadoop::hdfs::BaseHeaderProto* header);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.OpCopyBlockProto)
 private:
  void set_has_header();
  void clear_has_header();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::hadoop::hdfs::BaseHeaderProto* header_;
  friend struct ::protobuf_datatransfer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class OpBlockChecksumProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.OpBlockChecksumProto) */ {
 public:
  OpBlockChecksumProto();
  virtual ~OpBlockChecksumProto();

  OpBlockChecksumProto(const OpBlockChecksumProto& from);

  inline OpBlockChecksumProto& operator=(const OpBlockChecksumProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  OpBlockChecksumProto(OpBlockChecksumProto&& from) noexcept
    : OpBlockChecksumProto() {
    *this = ::std::move(from);
  }

  inline OpBlockChecksumProto& operator=(OpBlockChecksumProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const OpBlockChecksumProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const OpBlockChecksumProto* internal_default_instance() {
    return reinterpret_cast<const OpBlockChecksumProto*>(
               &_OpBlockChecksumProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    12;

  void Swap(OpBlockChecksumProto* other);
  friend void swap(OpBlockChecksumProto& a, OpBlockChecksumProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline OpBlockChecksumProto* New() const final {
    return CreateMaybeMessage<OpBlockChecksumProto>(NULL);
  }

  OpBlockChecksumProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<OpBlockChecksumProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const OpBlockChecksumProto& from);
  void MergeFrom(const OpBlockChecksumProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(OpBlockChecksumProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required .hadoop.hdfs.BaseHeaderProto header = 1;
  bool has_header() const;
  void clear_header();
  static const int kHeaderFieldNumber = 1;
  private:
  const ::hadoop::hdfs::BaseHeaderProto& _internal_header() const;
  public:
  const ::hadoop::hdfs::BaseHeaderProto& header() const;
  ::hadoop::hdfs::BaseHeaderProto* release_header();
  ::hadoop::hdfs::BaseHeaderProto* mutable_header();
  void set_allocated_header(::hadoop::hdfs::BaseHeaderProto* header);

  // optional .hadoop.hdfs.BlockChecksumOptionsProto blockChecksumOptions = 2;
  bool has_blockchecksumoptions() const;
  void clear_blockchecksumoptions();
  static const int kBlockChecksumOptionsFieldNumber = 2;
  private:
  const ::hadoop::hdfs::BlockChecksumOptionsProto& _internal_blockchecksumoptions() const;
  public:
  const ::hadoop::hdfs::BlockChecksumOptionsProto& blockchecksumoptions() const;
  ::hadoop::hdfs::BlockChecksumOptionsProto* release_blockchecksumoptions();
  ::hadoop::hdfs::BlockChecksumOptionsProto* mutable_blockchecksumoptions();
  void set_allocated_blockchecksumoptions(::hadoop::hdfs::BlockChecksumOptionsProto* blockchecksumoptions);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.OpBlockChecksumProto)
 private:
  void set_has_header();
  void clear_has_header();
  void set_has_blockchecksumoptions();
  void clear_has_blockchecksumoptions();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::hadoop::hdfs::BaseHeaderProto* header_;
  ::hadoop::hdfs::BlockChecksumOptionsProto* blockchecksumoptions_;
  friend struct ::protobuf_datatransfer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class OpBlockGroupChecksumProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.OpBlockGroupChecksumProto) */ {
 public:
  OpBlockGroupChecksumProto();
  virtual ~OpBlockGroupChecksumProto();

  OpBlockGroupChecksumProto(const OpBlockGroupChecksumProto& from);

  inline OpBlockGroupChecksumProto& operator=(const OpBlockGroupChecksumProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  OpBlockGroupChecksumProto(OpBlockGroupChecksumProto&& from) noexcept
    : OpBlockGroupChecksumProto() {
    *this = ::std::move(from);
  }

  inline OpBlockGroupChecksumProto& operator=(OpBlockGroupChecksumProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const OpBlockGroupChecksumProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const OpBlockGroupChecksumProto* internal_default_instance() {
    return reinterpret_cast<const OpBlockGroupChecksumProto*>(
               &_OpBlockGroupChecksumProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    13;

  void Swap(OpBlockGroupChecksumProto* other);
  friend void swap(OpBlockGroupChecksumProto& a, OpBlockGroupChecksumProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline OpBlockGroupChecksumProto* New() const final {
    return CreateMaybeMessage<OpBlockGroupChecksumProto>(NULL);
  }

  OpBlockGroupChecksumProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<OpBlockGroupChecksumProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const OpBlockGroupChecksumProto& from);
  void MergeFrom(const OpBlockGroupChecksumProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(OpBlockGroupChecksumProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.common.TokenProto blockTokens = 3;
  int blocktokens_size() const;
  void clear_blocktokens();
  static const int kBlockTokensFieldNumber = 3;
  ::hadoop::common::TokenProto* mutable_blocktokens(int index);
  ::google::protobuf::RepeatedPtrField< ::hadoop::common::TokenProto >*
      mutable_blocktokens();
  const ::hadoop::common::TokenProto& blocktokens(int index) const;
  ::hadoop::common::TokenProto* add_blocktokens();
  const ::google::protobuf::RepeatedPtrField< ::hadoop::common::TokenProto >&
      blocktokens() const;

  // repeated uint32 blockIndices = 5;
  int blockindices_size() const;
  void clear_blockindices();
  static const int kBlockIndicesFieldNumber = 5;
  ::google::protobuf::uint32 blockindices(int index) const;
  void set_blockindices(int index, ::google::protobuf::uint32 value);
  void add_blockindices(::google::protobuf::uint32 value);
  const ::google::protobuf::RepeatedField< ::google::protobuf::uint32 >&
      blockindices() const;
  ::google::protobuf::RepeatedField< ::google::protobuf::uint32 >*
      mutable_blockindices();

  // required .hadoop.hdfs.BaseHeaderProto header = 1;
  bool has_header() const;
  void clear_header();
  static const int kHeaderFieldNumber = 1;
  private:
  const ::hadoop::hdfs::BaseHeaderProto& _internal_header() const;
  public:
  const ::hadoop::hdfs::BaseHeaderProto& header() const;
  ::hadoop::hdfs::BaseHeaderProto* release_header();
  ::hadoop::hdfs::BaseHeaderProto* mutable_header();
  void set_allocated_header(::hadoop::hdfs::BaseHeaderProto* header);

  // required .hadoop.hdfs.DatanodeInfosProto datanodes = 2;
  bool has_datanodes() const;
  void clear_datanodes();
  static const int kDatanodesFieldNumber = 2;
  private:
  const ::hadoop::hdfs::DatanodeInfosProto& _internal_datanodes() const;
  public:
  const ::hadoop::hdfs::DatanodeInfosProto& datanodes() const;
  ::hadoop::hdfs::DatanodeInfosProto* release_datanodes();
  ::hadoop::hdfs::DatanodeInfosProto* mutable_datanodes();
  void set_allocated_datanodes(::hadoop::hdfs::DatanodeInfosProto* datanodes);

  // required .hadoop.hdfs.ErasureCodingPolicyProto ecPolicy = 4;
  bool has_ecpolicy() const;
  void clear_ecpolicy();
  static const int kEcPolicyFieldNumber = 4;
  private:
  const ::hadoop::hdfs::ErasureCodingPolicyProto& _internal_ecpolicy() const;
  public:
  const ::hadoop::hdfs::ErasureCodingPolicyProto& ecpolicy() const;
  ::hadoop::hdfs::ErasureCodingPolicyProto* release_ecpolicy();
  ::hadoop::hdfs::ErasureCodingPolicyProto* mutable_ecpolicy();
  void set_allocated_ecpolicy(::hadoop::hdfs::ErasureCodingPolicyProto* ecpolicy);

  // optional .hadoop.hdfs.BlockChecksumOptionsProto blockChecksumOptions = 7;
  bool has_blockchecksumoptions() const;
  void clear_blockchecksumoptions();
  static const int kBlockChecksumOptionsFieldNumber = 7;
  private:
  const ::hadoop::hdfs::BlockChecksumOptionsProto& _internal_blockchecksumoptions() const;
  public:
  const ::hadoop::hdfs::BlockChecksumOptionsProto& blockchecksumoptions() const;
  ::hadoop::hdfs::BlockChecksumOptionsProto* release_blockchecksumoptions();
  ::hadoop::hdfs::BlockChecksumOptionsProto* mutable_blockchecksumoptions();
  void set_allocated_blockchecksumoptions(::hadoop::hdfs::BlockChecksumOptionsProto* blockchecksumoptions);

  // required uint64 requestedNumBytes = 6;
  bool has_requestednumbytes() const;
  void clear_requestednumbytes();
  static const int kRequestedNumBytesFieldNumber = 6;
  ::google::protobuf::uint64 requestednumbytes() const;
  void set_requestednumbytes(::google::protobuf::uint64 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.OpBlockGroupChecksumProto)
 private:
  void set_has_header();
  void clear_has_header();
  void set_has_datanodes();
  void clear_has_datanodes();
  void set_has_ecpolicy();
  void clear_has_ecpolicy();
  void set_has_requestednumbytes();
  void clear_has_requestednumbytes();
  void set_has_blockchecksumoptions();
  void clear_has_blockchecksumoptions();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::common::TokenProto > blocktokens_;
  ::google::protobuf::RepeatedField< ::google::protobuf::uint32 > blockindices_;
  ::hadoop::hdfs::BaseHeaderProto* header_;
  ::hadoop::hdfs::DatanodeInfosProto* datanodes_;
  ::hadoop::hdfs::ErasureCodingPolicyProto* ecpolicy_;
  ::hadoop::hdfs::BlockChecksumOptionsProto* blockchecksumoptions_;
  ::google::protobuf::uint64 requestednumbytes_;
  friend struct ::protobuf_datatransfer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class ShortCircuitShmIdProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.ShortCircuitShmIdProto) */ {
 public:
  ShortCircuitShmIdProto();
  virtual ~ShortCircuitShmIdProto();

  ShortCircuitShmIdProto(const ShortCircuitShmIdProto& from);

  inline ShortCircuitShmIdProto& operator=(const ShortCircuitShmIdProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  ShortCircuitShmIdProto(ShortCircuitShmIdProto&& from) noexcept
    : ShortCircuitShmIdProto() {
    *this = ::std::move(from);
  }

  inline ShortCircuitShmIdProto& operator=(ShortCircuitShmIdProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ShortCircuitShmIdProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const ShortCircuitShmIdProto* internal_default_instance() {
    return reinterpret_cast<const ShortCircuitShmIdProto*>(
               &_ShortCircuitShmIdProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    14;

  void Swap(ShortCircuitShmIdProto* other);
  friend void swap(ShortCircuitShmIdProto& a, ShortCircuitShmIdProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline ShortCircuitShmIdProto* New() const final {
    return CreateMaybeMessage<ShortCircuitShmIdProto>(NULL);
  }

  ShortCircuitShmIdProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<ShortCircuitShmIdProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const ShortCircuitShmIdProto& from);
  void MergeFrom(const ShortCircuitShmIdProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(ShortCircuitShmIdProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required int64 hi = 1;
  bool has_hi() const;
  void clear_hi();
  static const int kHiFieldNumber = 1;
  ::google::protobuf::int64 hi() const;
  void set_hi(::google::protobuf::int64 value);

  // required int64 lo = 2;
  bool has_lo() const;
  void clear_lo();
  static const int kLoFieldNumber = 2;
  ::google::protobuf::int64 lo() const;
  void set_lo(::google::protobuf::int64 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.ShortCircuitShmIdProto)
 private:
  void set_has_hi();
  void clear_has_hi();
  void set_has_lo();
  void clear_has_lo();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::int64 hi_;
  ::google::protobuf::int64 lo_;
  friend struct ::protobuf_datatransfer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class ShortCircuitShmSlotProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.ShortCircuitShmSlotProto) */ {
 public:
  ShortCircuitShmSlotProto();
  virtual ~ShortCircuitShmSlotProto();

  ShortCircuitShmSlotProto(const ShortCircuitShmSlotProto& from);

  inline ShortCircuitShmSlotProto& operator=(const ShortCircuitShmSlotProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  ShortCircuitShmSlotProto(ShortCircuitShmSlotProto&& from) noexcept
    : ShortCircuitShmSlotProto() {
    *this = ::std::move(from);
  }

  inline ShortCircuitShmSlotProto& operator=(ShortCircuitShmSlotProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ShortCircuitShmSlotProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const ShortCircuitShmSlotProto* internal_default_instance() {
    return reinterpret_cast<const ShortCircuitShmSlotProto*>(
               &_ShortCircuitShmSlotProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    15;

  void Swap(ShortCircuitShmSlotProto* other);
  friend void swap(ShortCircuitShmSlotProto& a, ShortCircuitShmSlotProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline ShortCircuitShmSlotProto* New() const final {
    return CreateMaybeMessage<ShortCircuitShmSlotProto>(NULL);
  }

  ShortCircuitShmSlotProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<ShortCircuitShmSlotProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const ShortCircuitShmSlotProto& from);
  void MergeFrom(const ShortCircuitShmSlotProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(ShortCircuitShmSlotProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required .hadoop.hdfs.ShortCircuitShmIdProto shmId = 1;
  bool has_shmid() const;
  void clear_shmid();
  static const int kShmIdFieldNumber = 1;
  private:
  const ::hadoop::hdfs::ShortCircuitShmIdProto& _internal_shmid() const;
  public:
  const ::hadoop::hdfs::ShortCircuitShmIdProto& shmid() const;
  ::hadoop::hdfs::ShortCircuitShmIdProto* release_shmid();
  ::hadoop::hdfs::ShortCircuitShmIdProto* mutable_shmid();
  void set_allocated_shmid(::hadoop::hdfs::ShortCircuitShmIdProto* shmid);

  // required int32 slotIdx = 2;
  bool has_slotidx() const;
  void clear_slotidx();
  static const int kSlotIdxFieldNumber = 2;
  ::google::protobuf::int32 slotidx() const;
  void set_slotidx(::google::protobuf::int32 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.ShortCircuitShmSlotProto)
 private:
  void set_has_shmid();
  void clear_has_shmid();
  void set_has_slotidx();
  void clear_has_slotidx();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::hadoop::hdfs::ShortCircuitShmIdProto* shmid_;
  ::google::protobuf::int32 slotidx_;
  friend struct ::protobuf_datatransfer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class OpRequestShortCircuitAccessProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.OpRequestShortCircuitAccessProto) */ {
 public:
  OpRequestShortCircuitAccessProto();
  virtual ~OpRequestShortCircuitAccessProto();

  OpRequestShortCircuitAccessProto(const OpRequestShortCircuitAccessProto& from);

  inline OpRequestShortCircuitAccessProto& operator=(const OpRequestShortCircuitAccessProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  OpRequestShortCircuitAccessProto(OpRequestShortCircuitAccessProto&& from) noexcept
    : OpRequestShortCircuitAccessProto() {
    *this = ::std::move(from);
  }

  inline OpRequestShortCircuitAccessProto& operator=(OpRequestShortCircuitAccessProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const OpRequestShortCircuitAccessProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const OpRequestShortCircuitAccessProto* internal_default_instance() {
    return reinterpret_cast<const OpRequestShortCircuitAccessProto*>(
               &_OpRequestShortCircuitAccessProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    16;

  void Swap(OpRequestShortCircuitAccessProto* other);
  friend void swap(OpRequestShortCircuitAccessProto& a, OpRequestShortCircuitAccessProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline OpRequestShortCircuitAccessProto* New() const final {
    return CreateMaybeMessage<OpRequestShortCircuitAccessProto>(NULL);
  }

  OpRequestShortCircuitAccessProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<OpRequestShortCircuitAccessProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const OpRequestShortCircuitAccessProto& from);
  void MergeFrom(const OpRequestShortCircuitAccessProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(OpRequestShortCircuitAccessProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required .hadoop.hdfs.BaseHeaderProto header = 1;
  bool has_header() const;
  void clear_header();
  static const int kHeaderFieldNumber = 1;
  private:
  const ::hadoop::hdfs::BaseHeaderProto& _internal_header() const;
  public:
  const ::hadoop::hdfs::BaseHeaderProto& header() const;
  ::hadoop::hdfs::BaseHeaderProto* release_header();
  ::hadoop::hdfs::BaseHeaderProto* mutable_header();
  void set_allocated_header(::hadoop::hdfs::BaseHeaderProto* header);

  // optional .hadoop.hdfs.ShortCircuitShmSlotProto slotId = 3;
  bool has_slotid() const;
  void clear_slotid();
  static const int kSlotIdFieldNumber = 3;
  private:
  const ::hadoop::hdfs::ShortCircuitShmSlotProto& _internal_slotid() const;
  public:
  const ::hadoop::hdfs::ShortCircuitShmSlotProto& slotid() const;
  ::hadoop::hdfs::ShortCircuitShmSlotProto* release_slotid();
  ::hadoop::hdfs::ShortCircuitShmSlotProto* mutable_slotid();
  void set_allocated_slotid(::hadoop::hdfs::ShortCircuitShmSlotProto* slotid);

  // required uint32 maxVersion = 2;
  bool has_maxversion() const;
  void clear_maxversion();
  static const int kMaxVersionFieldNumber = 2;
  ::google::protobuf::uint32 maxversion() const;
  void set_maxversion(::google::protobuf::uint32 value);

  // optional bool supportsReceiptVerification = 4 [default = false];
  bool has_supportsreceiptverification() const;
  void clear_supportsreceiptverification();
  static const int kSupportsReceiptVerificationFieldNumber = 4;
  bool supportsreceiptverification() const;
  void set_supportsreceiptverification(bool value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.OpRequestShortCircuitAccessProto)
 private:
  void set_has_header();
  void clear_has_header();
  void set_has_maxversion();
  void clear_has_maxversion();
  void set_has_slotid();
  void clear_has_slotid();
  void set_has_supportsreceiptverification();
  void clear_has_supportsreceiptverification();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::hadoop::hdfs::BaseHeaderProto* header_;
  ::hadoop::hdfs::ShortCircuitShmSlotProto* slotid_;
  ::google::protobuf::uint32 maxversion_;
  bool supportsreceiptverification_;
  friend struct ::protobuf_datatransfer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class ReleaseShortCircuitAccessRequestProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.ReleaseShortCircuitAccessRequestProto) */ {
 public:
  ReleaseShortCircuitAccessRequestProto();
  virtual ~ReleaseShortCircuitAccessRequestProto();

  ReleaseShortCircuitAccessRequestProto(const ReleaseShortCircuitAccessRequestProto& from);

  inline ReleaseShortCircuitAccessRequestProto& operator=(const ReleaseShortCircuitAccessRequestProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  ReleaseShortCircuitAccessRequestProto(ReleaseShortCircuitAccessRequestProto&& from) noexcept
    : ReleaseShortCircuitAccessRequestProto() {
    *this = ::std::move(from);
  }

  inline ReleaseShortCircuitAccessRequestProto& operator=(ReleaseShortCircuitAccessRequestProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ReleaseShortCircuitAccessRequestProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const ReleaseShortCircuitAccessRequestProto* internal_default_instance() {
    return reinterpret_cast<const ReleaseShortCircuitAccessRequestProto*>(
               &_ReleaseShortCircuitAccessRequestProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    17;

  void Swap(ReleaseShortCircuitAccessRequestProto* other);
  friend void swap(ReleaseShortCircuitAccessRequestProto& a, ReleaseShortCircuitAccessRequestProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline ReleaseShortCircuitAccessRequestProto* New() const final {
    return CreateMaybeMessage<ReleaseShortCircuitAccessRequestProto>(NULL);
  }

  ReleaseShortCircuitAccessRequestProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<ReleaseShortCircuitAccessRequestProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const ReleaseShortCircuitAccessRequestProto& from);
  void MergeFrom(const ReleaseShortCircuitAccessRequestProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(ReleaseShortCircuitAccessRequestProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required .hadoop.hdfs.ShortCircuitShmSlotProto slotId = 1;
  bool has_slotid() const;
  void clear_slotid();
  static const int kSlotIdFieldNumber = 1;
  private:
  const ::hadoop::hdfs::ShortCircuitShmSlotProto& _internal_slotid() const;
  public:
  const ::hadoop::hdfs::ShortCircuitShmSlotProto& slotid() const;
  ::hadoop::hdfs::ShortCircuitShmSlotProto* release_slotid();
  ::hadoop::hdfs::ShortCircuitShmSlotProto* mutable_slotid();
  void set_allocated_slotid(::hadoop::hdfs::ShortCircuitShmSlotProto* slotid);

  // optional .hadoop.hdfs.DataTransferTraceInfoProto traceInfo = 2;
  bool has_traceinfo() const;
  void clear_traceinfo();
  static const int kTraceInfoFieldNumber = 2;
  private:
  const ::hadoop::hdfs::DataTransferTraceInfoProto& _internal_traceinfo() const;
  public:
  const ::hadoop::hdfs::DataTransferTraceInfoProto& traceinfo() const;
  ::hadoop::hdfs::DataTransferTraceInfoProto* release_traceinfo();
  ::hadoop::hdfs::DataTransferTraceInfoProto* mutable_traceinfo();
  void set_allocated_traceinfo(::hadoop::hdfs::DataTransferTraceInfoProto* traceinfo);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.ReleaseShortCircuitAccessRequestProto)
 private:
  void set_has_slotid();
  void clear_has_slotid();
  void set_has_traceinfo();
  void clear_has_traceinfo();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::hadoop::hdfs::ShortCircuitShmSlotProto* slotid_;
  ::hadoop::hdfs::DataTransferTraceInfoProto* traceinfo_;
  friend struct ::protobuf_datatransfer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class ReleaseShortCircuitAccessResponseProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.ReleaseShortCircuitAccessResponseProto) */ {
 public:
  ReleaseShortCircuitAccessResponseProto();
  virtual ~ReleaseShortCircuitAccessResponseProto();

  ReleaseShortCircuitAccessResponseProto(const ReleaseShortCircuitAccessResponseProto& from);

  inline ReleaseShortCircuitAccessResponseProto& operator=(const ReleaseShortCircuitAccessResponseProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  ReleaseShortCircuitAccessResponseProto(ReleaseShortCircuitAccessResponseProto&& from) noexcept
    : ReleaseShortCircuitAccessResponseProto() {
    *this = ::std::move(from);
  }

  inline ReleaseShortCircuitAccessResponseProto& operator=(ReleaseShortCircuitAccessResponseProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ReleaseShortCircuitAccessResponseProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const ReleaseShortCircuitAccessResponseProto* internal_default_instance() {
    return reinterpret_cast<const ReleaseShortCircuitAccessResponseProto*>(
               &_ReleaseShortCircuitAccessResponseProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    18;

  void Swap(ReleaseShortCircuitAccessResponseProto* other);
  friend void swap(ReleaseShortCircuitAccessResponseProto& a, ReleaseShortCircuitAccessResponseProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline ReleaseShortCircuitAccessResponseProto* New() const final {
    return CreateMaybeMessage<ReleaseShortCircuitAccessResponseProto>(NULL);
  }

  ReleaseShortCircuitAccessResponseProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<ReleaseShortCircuitAccessResponseProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const ReleaseShortCircuitAccessResponseProto& from);
  void MergeFrom(const ReleaseShortCircuitAccessResponseProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(ReleaseShortCircuitAccessResponseProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string error = 2;
  bool has_error() const;
  void clear_error();
  static const int kErrorFieldNumber = 2;
  const ::std::string& error() const;
  void set_error(const ::std::string& value);
  #if LANG_CXX11
  void set_error(::std::string&& value);
  #endif
  void set_error(const char* value);
  void set_error(const char* value, size_t size);
  ::std::string* mutable_error();
  ::std::string* release_error();
  void set_allocated_error(::std::string* error);

  // required .hadoop.hdfs.Status status = 1;
  bool has_status() const;
  void clear_status();
  static const int kStatusFieldNumber = 1;
  ::hadoop::hdfs::Status status() const;
  void set_status(::hadoop::hdfs::Status value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.ReleaseShortCircuitAccessResponseProto)
 private:
  void set_has_status();
  void clear_has_status();
  void set_has_error();
  void clear_has_error();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr error_;
  int status_;
  friend struct ::protobuf_datatransfer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class ShortCircuitShmRequestProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.ShortCircuitShmRequestProto) */ {
 public:
  ShortCircuitShmRequestProto();
  virtual ~ShortCircuitShmRequestProto();

  ShortCircuitShmRequestProto(const ShortCircuitShmRequestProto& from);

  inline ShortCircuitShmRequestProto& operator=(const ShortCircuitShmRequestProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  ShortCircuitShmRequestProto(ShortCircuitShmRequestProto&& from) noexcept
    : ShortCircuitShmRequestProto() {
    *this = ::std::move(from);
  }

  inline ShortCircuitShmRequestProto& operator=(ShortCircuitShmRequestProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ShortCircuitShmRequestProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const ShortCircuitShmRequestProto* internal_default_instance() {
    return reinterpret_cast<const ShortCircuitShmRequestProto*>(
               &_ShortCircuitShmRequestProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    19;

  void Swap(ShortCircuitShmRequestProto* other);
  friend void swap(ShortCircuitShmRequestProto& a, ShortCircuitShmRequestProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline ShortCircuitShmRequestProto* New() const final {
    return CreateMaybeMessage<ShortCircuitShmRequestProto>(NULL);
  }

  ShortCircuitShmRequestProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<ShortCircuitShmRequestProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const ShortCircuitShmRequestProto& from);
  void MergeFrom(const ShortCircuitShmRequestProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(ShortCircuitShmRequestProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required string clientName = 1;
  bool has_clientname() const;
  void clear_clientname();
  static const int kClientNameFieldNumber = 1;
  const ::std::string& clientname() const;
  void set_clientname(const ::std::string& value);
  #if LANG_CXX11
  void set_clientname(::std::string&& value);
  #endif
  void set_clientname(const char* value);
  void set_clientname(const char* value, size_t size);
  ::std::string* mutable_clientname();
  ::std::string* release_clientname();
  void set_allocated_clientname(::std::string* clientname);

  // optional .hadoop.hdfs.DataTransferTraceInfoProto traceInfo = 2;
  bool has_traceinfo() const;
  void clear_traceinfo();
  static const int kTraceInfoFieldNumber = 2;
  private:
  const ::hadoop::hdfs::DataTransferTraceInfoProto& _internal_traceinfo() const;
  public:
  const ::hadoop::hdfs::DataTransferTraceInfoProto& traceinfo() const;
  ::hadoop::hdfs::DataTransferTraceInfoProto* release_traceinfo();
  ::hadoop::hdfs::DataTransferTraceInfoProto* mutable_traceinfo();
  void set_allocated_traceinfo(::hadoop::hdfs::DataTransferTraceInfoProto* traceinfo);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.ShortCircuitShmRequestProto)
 private:
  void set_has_clientname();
  void clear_has_clientname();
  void set_has_traceinfo();
  void clear_has_traceinfo();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr clientname_;
  ::hadoop::hdfs::DataTransferTraceInfoProto* traceinfo_;
  friend struct ::protobuf_datatransfer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class ShortCircuitShmResponseProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.ShortCircuitShmResponseProto) */ {
 public:
  ShortCircuitShmResponseProto();
  virtual ~ShortCircuitShmResponseProto();

  ShortCircuitShmResponseProto(const ShortCircuitShmResponseProto& from);

  inline ShortCircuitShmResponseProto& operator=(const ShortCircuitShmResponseProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  ShortCircuitShmResponseProto(ShortCircuitShmResponseProto&& from) noexcept
    : ShortCircuitShmResponseProto() {
    *this = ::std::move(from);
  }

  inline ShortCircuitShmResponseProto& operator=(ShortCircuitShmResponseProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ShortCircuitShmResponseProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const ShortCircuitShmResponseProto* internal_default_instance() {
    return reinterpret_cast<const ShortCircuitShmResponseProto*>(
               &_ShortCircuitShmResponseProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    20;

  void Swap(ShortCircuitShmResponseProto* other);
  friend void swap(ShortCircuitShmResponseProto& a, ShortCircuitShmResponseProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline ShortCircuitShmResponseProto* New() const final {
    return CreateMaybeMessage<ShortCircuitShmResponseProto>(NULL);
  }

  ShortCircuitShmResponseProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<ShortCircuitShmResponseProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const ShortCircuitShmResponseProto& from);
  void MergeFrom(const ShortCircuitShmResponseProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(ShortCircuitShmResponseProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string error = 2;
  bool has_error() const;
  void clear_error();
  static const int kErrorFieldNumber = 2;
  const ::std::string& error() const;
  void set_error(const ::std::string& value);
  #if LANG_CXX11
  void set_error(::std::string&& value);
  #endif
  void set_error(const char* value);
  void set_error(const char* value, size_t size);
  ::std::string* mutable_error();
  ::std::string* release_error();
  void set_allocated_error(::std::string* error);

  // optional .hadoop.hdfs.ShortCircuitShmIdProto id = 3;
  bool has_id() const;
  void clear_id();
  static const int kIdFieldNumber = 3;
  private:
  const ::hadoop::hdfs::ShortCircuitShmIdProto& _internal_id() const;
  public:
  const ::hadoop::hdfs::ShortCircuitShmIdProto& id() const;
  ::hadoop::hdfs::ShortCircuitShmIdProto* release_id();
  ::hadoop::hdfs::ShortCircuitShmIdProto* mutable_id();
  void set_allocated_id(::hadoop::hdfs::ShortCircuitShmIdProto* id);

  // required .hadoop.hdfs.Status status = 1;
  bool has_status() const;
  void clear_status();
  static const int kStatusFieldNumber = 1;
  ::hadoop::hdfs::Status status() const;
  void set_status(::hadoop::hdfs::Status value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.ShortCircuitShmResponseProto)
 private:
  void set_has_status();
  void clear_has_status();
  void set_has_error();
  void clear_has_error();
  void set_has_id();
  void clear_has_id();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr error_;
  ::hadoop::hdfs::ShortCircuitShmIdProto* id_;
  int status_;
  friend struct ::protobuf_datatransfer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class PacketHeaderProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.PacketHeaderProto) */ {
 public:
  PacketHeaderProto();
  virtual ~PacketHeaderProto();

  PacketHeaderProto(const PacketHeaderProto& from);

  inline PacketHeaderProto& operator=(const PacketHeaderProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  PacketHeaderProto(PacketHeaderProto&& from) noexcept
    : PacketHeaderProto() {
    *this = ::std::move(from);
  }

  inline PacketHeaderProto& operator=(PacketHeaderProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const PacketHeaderProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const PacketHeaderProto* internal_default_instance() {
    return reinterpret_cast<const PacketHeaderProto*>(
               &_PacketHeaderProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    21;

  void Swap(PacketHeaderProto* other);
  friend void swap(PacketHeaderProto& a, PacketHeaderProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline PacketHeaderProto* New() const final {
    return CreateMaybeMessage<PacketHeaderProto>(NULL);
  }

  PacketHeaderProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<PacketHeaderProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const PacketHeaderProto& from);
  void MergeFrom(const PacketHeaderProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(PacketHeaderProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required sfixed64 offsetInBlock = 1;
  bool has_offsetinblock() const;
  void clear_offsetinblock();
  static const int kOffsetInBlockFieldNumber = 1;
  ::google::protobuf::int64 offsetinblock() const;
  void set_offsetinblock(::google::protobuf::int64 value);

  // required sfixed64 seqno = 2;
  bool has_seqno() const;
  void clear_seqno();
  static const int kSeqnoFieldNumber = 2;
  ::google::protobuf::int64 seqno() const;
  void set_seqno(::google::protobuf::int64 value);

  // required sfixed32 dataLen = 4;
  bool has_datalen() const;
  void clear_datalen();
  static const int kDataLenFieldNumber = 4;
  ::google::protobuf::int32 datalen() const;
  void set_datalen(::google::protobuf::int32 value);

  // required bool lastPacketInBlock = 3;
  bool has_lastpacketinblock() const;
  void clear_lastpacketinblock();
  static const int kLastPacketInBlockFieldNumber = 3;
  bool lastpacketinblock() const;
  void set_lastpacketinblock(bool value);

  // optional bool syncBlock = 5 [default = false];
  bool has_syncblock() const;
  void clear_syncblock();
  static const int kSyncBlockFieldNumber = 5;
  bool syncblock() const;
  void set_syncblock(bool value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.PacketHeaderProto)
 private:
  void set_has_offsetinblock();
  void clear_has_offsetinblock();
  void set_has_seqno();
  void clear_has_seqno();
  void set_has_lastpacketinblock();
  void clear_has_lastpacketinblock();
  void set_has_datalen();
  void clear_has_datalen();
  void set_has_syncblock();
  void clear_has_syncblock();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::int64 offsetinblock_;
  ::google::protobuf::int64 seqno_;
  ::google::protobuf::int32 datalen_;
  bool lastpacketinblock_;
  bool syncblock_;
  friend struct ::protobuf_datatransfer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class PipelineAckProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.PipelineAckProto) */ {
 public:
  PipelineAckProto();
  virtual ~PipelineAckProto();

  PipelineAckProto(const PipelineAckProto& from);

  inline PipelineAckProto& operator=(const PipelineAckProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  PipelineAckProto(PipelineAckProto&& from) noexcept
    : PipelineAckProto() {
    *this = ::std::move(from);
  }

  inline PipelineAckProto& operator=(PipelineAckProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const PipelineAckProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const PipelineAckProto* internal_default_instance() {
    return reinterpret_cast<const PipelineAckProto*>(
               &_PipelineAckProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    22;

  void Swap(PipelineAckProto* other);
  friend void swap(PipelineAckProto& a, PipelineAckProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline PipelineAckProto* New() const final {
    return CreateMaybeMessage<PipelineAckProto>(NULL);
  }

  PipelineAckProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<PipelineAckProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const PipelineAckProto& from);
  void MergeFrom(const PipelineAckProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(PipelineAckProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.hdfs.Status reply = 2;
  int reply_size() const;
  void clear_reply();
  static const int kReplyFieldNumber = 2;
  ::hadoop::hdfs::Status reply(int index) const;
  void set_reply(int index, ::hadoop::hdfs::Status value);
  void add_reply(::hadoop::hdfs::Status value);
  const ::google::protobuf::RepeatedField<int>& reply() const;
  ::google::protobuf::RepeatedField<int>* mutable_reply();

  // repeated uint32 flag = 4 [packed = true];
  int flag_size() const;
  void clear_flag();
  static const int kFlagFieldNumber = 4;
  ::google::protobuf::uint32 flag(int index) const;
  void set_flag(int index, ::google::protobuf::uint32 value);
  void add_flag(::google::protobuf::uint32 value);
  const ::google::protobuf::RepeatedField< ::google::protobuf::uint32 >&
      flag() const;
  ::google::protobuf::RepeatedField< ::google::protobuf::uint32 >*
      mutable_flag();

  // required sint64 seqno = 1;
  bool has_seqno() const;
  void clear_seqno();
  static const int kSeqnoFieldNumber = 1;
  ::google::protobuf::int64 seqno() const;
  void set_seqno(::google::protobuf::int64 value);

  // optional uint64 downstreamAckTimeNanos = 3 [default = 0];
  bool has_downstreamacktimenanos() const;
  void clear_downstreamacktimenanos();
  static const int kDownstreamAckTimeNanosFieldNumber = 3;
  ::google::protobuf::uint64 downstreamacktimenanos() const;
  void set_downstreamacktimenanos(::google::protobuf::uint64 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.PipelineAckProto)
 private:
  void set_has_seqno();
  void clear_has_seqno();
  void set_has_downstreamacktimenanos();
  void clear_has_downstreamacktimenanos();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::RepeatedField<int> reply_;
  ::google::protobuf::RepeatedField< ::google::protobuf::uint32 > flag_;
  mutable int _flag_cached_byte_size_;
  ::google::protobuf::int64 seqno_;
  ::google::protobuf::uint64 downstreamacktimenanos_;
  friend struct ::protobuf_datatransfer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class ReadOpChecksumInfoProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.ReadOpChecksumInfoProto) */ {
 public:
  ReadOpChecksumInfoProto();
  virtual ~ReadOpChecksumInfoProto();

  ReadOpChecksumInfoProto(const ReadOpChecksumInfoProto& from);

  inline ReadOpChecksumInfoProto& operator=(const ReadOpChecksumInfoProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  ReadOpChecksumInfoProto(ReadOpChecksumInfoProto&& from) noexcept
    : ReadOpChecksumInfoProto() {
    *this = ::std::move(from);
  }

  inline ReadOpChecksumInfoProto& operator=(ReadOpChecksumInfoProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ReadOpChecksumInfoProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const ReadOpChecksumInfoProto* internal_default_instance() {
    return reinterpret_cast<const ReadOpChecksumInfoProto*>(
               &_ReadOpChecksumInfoProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    23;

  void Swap(ReadOpChecksumInfoProto* other);
  friend void swap(ReadOpChecksumInfoProto& a, ReadOpChecksumInfoProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline ReadOpChecksumInfoProto* New() const final {
    return CreateMaybeMessage<ReadOpChecksumInfoProto>(NULL);
  }

  ReadOpChecksumInfoProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<ReadOpChecksumInfoProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const ReadOpChecksumInfoProto& from);
  void MergeFrom(const ReadOpChecksumInfoProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(ReadOpChecksumInfoProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required .hadoop.hdfs.ChecksumProto checksum = 1;
  bool has_checksum() const;
  void clear_checksum();
  static const int kChecksumFieldNumber = 1;
  private:
  const ::hadoop::hdfs::ChecksumProto& _internal_checksum() const;
  public:
  const ::hadoop::hdfs::ChecksumProto& checksum() const;
  ::hadoop::hdfs::ChecksumProto* release_checksum();
  ::hadoop::hdfs::ChecksumProto* mutable_checksum();
  void set_allocated_checksum(::hadoop::hdfs::ChecksumProto* checksum);

  // required uint64 chunkOffset = 2;
  bool has_chunkoffset() const;
  void clear_chunkoffset();
  static const int kChunkOffsetFieldNumber = 2;
  ::google::protobuf::uint64 chunkoffset() const;
  void set_chunkoffset(::google::protobuf::uint64 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.ReadOpChecksumInfoProto)
 private:
  void set_has_checksum();
  void clear_has_checksum();
  void set_has_chunkoffset();
  void clear_has_chunkoffset();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::hadoop::hdfs::ChecksumProto* checksum_;
  ::google::protobuf::uint64 chunkoffset_;
  friend struct ::protobuf_datatransfer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class BlockOpResponseProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.BlockOpResponseProto) */ {
 public:
  BlockOpResponseProto();
  virtual ~BlockOpResponseProto();

  BlockOpResponseProto(const BlockOpResponseProto& from);

  inline BlockOpResponseProto& operator=(const BlockOpResponseProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  BlockOpResponseProto(BlockOpResponseProto&& from) noexcept
    : BlockOpResponseProto() {
    *this = ::std::move(from);
  }

  inline BlockOpResponseProto& operator=(BlockOpResponseProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const BlockOpResponseProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const BlockOpResponseProto* internal_default_instance() {
    return reinterpret_cast<const BlockOpResponseProto*>(
               &_BlockOpResponseProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    24;

  void Swap(BlockOpResponseProto* other);
  friend void swap(BlockOpResponseProto& a, BlockOpResponseProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline BlockOpResponseProto* New() const final {
    return CreateMaybeMessage<BlockOpResponseProto>(NULL);
  }

  BlockOpResponseProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<BlockOpResponseProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const BlockOpResponseProto& from);
  void MergeFrom(const BlockOpResponseProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(BlockOpResponseProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string firstBadLink = 2;
  bool has_firstbadlink() const;
  void clear_firstbadlink();
  static const int kFirstBadLinkFieldNumber = 2;
  const ::std::string& firstbadlink() const;
  void set_firstbadlink(const ::std::string& value);
  #if LANG_CXX11
  void set_firstbadlink(::std::string&& value);
  #endif
  void set_firstbadlink(const char* value);
  void set_firstbadlink(const char* value, size_t size);
  ::std::string* mutable_firstbadlink();
  ::std::string* release_firstbadlink();
  void set_allocated_firstbadlink(::std::string* firstbadlink);

  // optional string message = 5;
  bool has_message() const;
  void clear_message();
  static const int kMessageFieldNumber = 5;
  const ::std::string& message() const;
  void set_message(const ::std::string& value);
  #if LANG_CXX11
  void set_message(::std::string&& value);
  #endif
  void set_message(const char* value);
  void set_message(const char* value, size_t size);
  ::std::string* mutable_message();
  ::std::string* release_message();
  void set_allocated_message(::std::string* message);

  // optional .hadoop.hdfs.OpBlockChecksumResponseProto checksumResponse = 3;
  bool has_checksumresponse() const;
  void clear_checksumresponse();
  static const int kChecksumResponseFieldNumber = 3;
  private:
  const ::hadoop::hdfs::OpBlockChecksumResponseProto& _internal_checksumresponse() const;
  public:
  const ::hadoop::hdfs::OpBlockChecksumResponseProto& checksumresponse() const;
  ::hadoop::hdfs::OpBlockChecksumResponseProto* release_checksumresponse();
  ::hadoop::hdfs::OpBlockChecksumResponseProto* mutable_checksumresponse();
  void set_allocated_checksumresponse(::hadoop::hdfs::OpBlockChecksumResponseProto* checksumresponse);

  // optional .hadoop.hdfs.ReadOpChecksumInfoProto readOpChecksumInfo = 4;
  bool has_readopchecksuminfo() const;
  void clear_readopchecksuminfo();
  static const int kReadOpChecksumInfoFieldNumber = 4;
  private:
  const ::hadoop::hdfs::ReadOpChecksumInfoProto& _internal_readopchecksuminfo() const;
  public:
  const ::hadoop::hdfs::ReadOpChecksumInfoProto& readopchecksuminfo() const;
  ::hadoop::hdfs::ReadOpChecksumInfoProto* release_readopchecksuminfo();
  ::hadoop::hdfs::ReadOpChecksumInfoProto* mutable_readopchecksuminfo();
  void set_allocated_readopchecksuminfo(::hadoop::hdfs::ReadOpChecksumInfoProto* readopchecksuminfo);

  // required .hadoop.hdfs.Status status = 1;
  bool has_status() const;
  void clear_status();
  static const int kStatusFieldNumber = 1;
  ::hadoop::hdfs::Status status() const;
  void set_status(::hadoop::hdfs::Status value);

  // optional uint32 shortCircuitAccessVersion = 6;
  bool has_shortcircuitaccessversion() const;
  void clear_shortcircuitaccessversion();
  static const int kShortCircuitAccessVersionFieldNumber = 6;
  ::google::protobuf::uint32 shortcircuitaccessversion() const;
  void set_shortcircuitaccessversion(::google::protobuf::uint32 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.BlockOpResponseProto)
 private:
  void set_has_status();
  void clear_has_status();
  void set_has_firstbadlink();
  void clear_has_firstbadlink();
  void set_has_checksumresponse();
  void clear_has_checksumresponse();
  void set_has_readopchecksuminfo();
  void clear_has_readopchecksuminfo();
  void set_has_message();
  void clear_has_message();
  void set_has_shortcircuitaccessversion();
  void clear_has_shortcircuitaccessversion();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr firstbadlink_;
  ::google::protobuf::internal::ArenaStringPtr message_;
  ::hadoop::hdfs::OpBlockChecksumResponseProto* checksumresponse_;
  ::hadoop::hdfs::ReadOpChecksumInfoProto* readopchecksuminfo_;
  int status_;
  ::google::protobuf::uint32 shortcircuitaccessversion_;
  friend struct ::protobuf_datatransfer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class ClientReadStatusProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.ClientReadStatusProto) */ {
 public:
  ClientReadStatusProto();
  virtual ~ClientReadStatusProto();

  ClientReadStatusProto(const ClientReadStatusProto& from);

  inline ClientReadStatusProto& operator=(const ClientReadStatusProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  ClientReadStatusProto(ClientReadStatusProto&& from) noexcept
    : ClientReadStatusProto() {
    *this = ::std::move(from);
  }

  inline ClientReadStatusProto& operator=(ClientReadStatusProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ClientReadStatusProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const ClientReadStatusProto* internal_default_instance() {
    return reinterpret_cast<const ClientReadStatusProto*>(
               &_ClientReadStatusProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    25;

  void Swap(ClientReadStatusProto* other);
  friend void swap(ClientReadStatusProto& a, ClientReadStatusProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline ClientReadStatusProto* New() const final {
    return CreateMaybeMessage<ClientReadStatusProto>(NULL);
  }

  ClientReadStatusProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<ClientReadStatusProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const ClientReadStatusProto& from);
  void MergeFrom(const ClientReadStatusProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(ClientReadStatusProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required .hadoop.hdfs.Status status = 1;
  bool has_status() const;
  void clear_status();
  static const int kStatusFieldNumber = 1;
  ::hadoop::hdfs::Status status() const;
  void set_status(::hadoop::hdfs::Status value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.ClientReadStatusProto)
 private:
  void set_has_status();
  void clear_has_status();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  int status_;
  friend struct ::protobuf_datatransfer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class DNTransferAckProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.DNTransferAckProto) */ {
 public:
  DNTransferAckProto();
  virtual ~DNTransferAckProto();

  DNTransferAckProto(const DNTransferAckProto& from);

  inline DNTransferAckProto& operator=(const DNTransferAckProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  DNTransferAckProto(DNTransferAckProto&& from) noexcept
    : DNTransferAckProto() {
    *this = ::std::move(from);
  }

  inline DNTransferAckProto& operator=(DNTransferAckProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const DNTransferAckProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const DNTransferAckProto* internal_default_instance() {
    return reinterpret_cast<const DNTransferAckProto*>(
               &_DNTransferAckProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    26;

  void Swap(DNTransferAckProto* other);
  friend void swap(DNTransferAckProto& a, DNTransferAckProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline DNTransferAckProto* New() const final {
    return CreateMaybeMessage<DNTransferAckProto>(NULL);
  }

  DNTransferAckProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<DNTransferAckProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const DNTransferAckProto& from);
  void MergeFrom(const DNTransferAckProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(DNTransferAckProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required .hadoop.hdfs.Status status = 1;
  bool has_status() const;
  void clear_status();
  static const int kStatusFieldNumber = 1;
  ::hadoop::hdfs::Status status() const;
  void set_status(::hadoop::hdfs::Status value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.DNTransferAckProto)
 private:
  void set_has_status();
  void clear_has_status();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  int status_;
  friend struct ::protobuf_datatransfer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class OpBlockChecksumResponseProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.OpBlockChecksumResponseProto) */ {
 public:
  OpBlockChecksumResponseProto();
  virtual ~OpBlockChecksumResponseProto();

  OpBlockChecksumResponseProto(const OpBlockChecksumResponseProto& from);

  inline OpBlockChecksumResponseProto& operator=(const OpBlockChecksumResponseProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  OpBlockChecksumResponseProto(OpBlockChecksumResponseProto&& from) noexcept
    : OpBlockChecksumResponseProto() {
    *this = ::std::move(from);
  }

  inline OpBlockChecksumResponseProto& operator=(OpBlockChecksumResponseProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const OpBlockChecksumResponseProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const OpBlockChecksumResponseProto* internal_default_instance() {
    return reinterpret_cast<const OpBlockChecksumResponseProto*>(
               &_OpBlockChecksumResponseProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    27;

  void Swap(OpBlockChecksumResponseProto* other);
  friend void swap(OpBlockChecksumResponseProto& a, OpBlockChecksumResponseProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline OpBlockChecksumResponseProto* New() const final {
    return CreateMaybeMessage<OpBlockChecksumResponseProto>(NULL);
  }

  OpBlockChecksumResponseProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<OpBlockChecksumResponseProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const OpBlockChecksumResponseProto& from);
  void MergeFrom(const OpBlockChecksumResponseProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(OpBlockChecksumResponseProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required bytes blockChecksum = 3;
  bool has_blockchecksum() const;
  void clear_blockchecksum();
  static const int kBlockChecksumFieldNumber = 3;
  const ::std::string& blockchecksum() const;
  void set_blockchecksum(const ::std::string& value);
  #if LANG_CXX11
  void set_blockchecksum(::std::string&& value);
  #endif
  void set_blockchecksum(const char* value);
  void set_blockchecksum(const void* value, size_t size);
  ::std::string* mutable_blockchecksum();
  ::std::string* release_blockchecksum();
  void set_allocated_blockchecksum(::std::string* blockchecksum);

  // optional .hadoop.hdfs.BlockChecksumOptionsProto blockChecksumOptions = 5;
  bool has_blockchecksumoptions() const;
  void clear_blockchecksumoptions();
  static const int kBlockChecksumOptionsFieldNumber = 5;
  private:
  const ::hadoop::hdfs::BlockChecksumOptionsProto& _internal_blockchecksumoptions() const;
  public:
  const ::hadoop::hdfs::BlockChecksumOptionsProto& blockchecksumoptions() const;
  ::hadoop::hdfs::BlockChecksumOptionsProto* release_blockchecksumoptions();
  ::hadoop::hdfs::BlockChecksumOptionsProto* mutable_blockchecksumoptions();
  void set_allocated_blockchecksumoptions(::hadoop::hdfs::BlockChecksumOptionsProto* blockchecksumoptions);

  // required uint64 crcPerBlock = 2;
  bool has_crcperblock() const;
  void clear_crcperblock();
  static const int kCrcPerBlockFieldNumber = 2;
  ::google::protobuf::uint64 crcperblock() const;
  void set_crcperblock(::google::protobuf::uint64 value);

  // required uint32 bytesPerCrc = 1;
  bool has_bytespercrc() const;
  void clear_bytespercrc();
  static const int kBytesPerCrcFieldNumber = 1;
  ::google::protobuf::uint32 bytespercrc() const;
  void set_bytespercrc(::google::protobuf::uint32 value);

  // optional .hadoop.hdfs.ChecksumTypeProto crcType = 4;
  bool has_crctype() const;
  void clear_crctype();
  static const int kCrcTypeFieldNumber = 4;
  ::hadoop::hdfs::ChecksumTypeProto crctype() const;
  void set_crctype(::hadoop::hdfs::ChecksumTypeProto value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.OpBlockChecksumResponseProto)
 private:
  void set_has_bytespercrc();
  void clear_has_bytespercrc();
  void set_has_crcperblock();
  void clear_has_crcperblock();
  void set_has_blockchecksum();
  void clear_has_blockchecksum();
  void set_has_crctype();
  void clear_has_crctype();
  void set_has_blockchecksumoptions();
  void clear_has_blockchecksumoptions();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr blockchecksum_;
  ::hadoop::hdfs::BlockChecksumOptionsProto* blockchecksumoptions_;
  ::google::protobuf::uint64 crcperblock_;
  ::google::protobuf::uint32 bytespercrc_;
  int crctype_;
  friend struct ::protobuf_datatransfer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class OpCustomProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.OpCustomProto) */ {
 public:
  OpCustomProto();
  virtual ~OpCustomProto();

  OpCustomProto(const OpCustomProto& from);

  inline OpCustomProto& operator=(const OpCustomProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  OpCustomProto(OpCustomProto&& from) noexcept
    : OpCustomProto() {
    *this = ::std::move(from);
  }

  inline OpCustomProto& operator=(OpCustomProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const OpCustomProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const OpCustomProto* internal_default_instance() {
    return reinterpret_cast<const OpCustomProto*>(
               &_OpCustomProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    28;

  void Swap(OpCustomProto* other);
  friend void swap(OpCustomProto& a, OpCustomProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline OpCustomProto* New() const final {
    return CreateMaybeMessage<OpCustomProto>(NULL);
  }

  OpCustomProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<OpCustomProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const OpCustomProto& from);
  void MergeFrom(const OpCustomProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(OpCustomProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required string customId = 1;
  bool has_customid() const;
  void clear_customid();
  static const int kCustomIdFieldNumber = 1;
  const ::std::string& customid() const;
  void set_customid(const ::std::string& value);
  #if LANG_CXX11
  void set_customid(::std::string&& value);
  #endif
  void set_customid(const char* value);
  void set_customid(const char* value, size_t size);
  ::std::string* mutable_customid();
  ::std::string* release_customid();
  void set_allocated_customid(::std::string* customid);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.OpCustomProto)
 private:
  void set_has_customid();
  void clear_has_customid();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr customid_;
  friend struct ::protobuf_datatransfer_2eproto::TableStruct;
};
// ===================================================================


// ===================================================================

#ifdef __GNUC__
  #pragma GCC diagnostic push
  #pragma GCC diagnostic ignored "-Wstrict-aliasing"
#endif  // __GNUC__
// DataTransferEncryptorMessageProto

// required .hadoop.hdfs.DataTransferEncryptorMessageProto.DataTransferEncryptorStatus status = 1;
inline bool DataTransferEncryptorMessageProto::has_status() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void DataTransferEncryptorMessageProto::set_has_status() {
  _has_bits_[0] |= 0x00000008u;
}
inline void DataTransferEncryptorMessageProto::clear_has_status() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void DataTransferEncryptorMessageProto::clear_status() {
  status_ = 0;
  clear_has_status();
}
inline ::hadoop::hdfs::DataTransferEncryptorMessageProto_DataTransferEncryptorStatus DataTransferEncryptorMessageProto::status() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DataTransferEncryptorMessageProto.status)
  return static_cast< ::hadoop::hdfs::DataTransferEncryptorMessageProto_DataTransferEncryptorStatus >(status_);
}
inline void DataTransferEncryptorMessageProto::set_status(::hadoop::hdfs::DataTransferEncryptorMessageProto_DataTransferEncryptorStatus value) {
  assert(::hadoop::hdfs::DataTransferEncryptorMessageProto_DataTransferEncryptorStatus_IsValid(value));
  set_has_status();
  status_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DataTransferEncryptorMessageProto.status)
}

// optional bytes payload = 2;
inline bool DataTransferEncryptorMessageProto::has_payload() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void DataTransferEncryptorMessageProto::set_has_payload() {
  _has_bits_[0] |= 0x00000001u;
}
inline void DataTransferEncryptorMessageProto::clear_has_payload() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void DataTransferEncryptorMessageProto::clear_payload() {
  payload_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_payload();
}
inline const ::std::string& DataTransferEncryptorMessageProto::payload() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DataTransferEncryptorMessageProto.payload)
  return payload_.GetNoArena();
}
inline void DataTransferEncryptorMessageProto::set_payload(const ::std::string& value) {
  set_has_payload();
  payload_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DataTransferEncryptorMessageProto.payload)
}
#if LANG_CXX11
inline void DataTransferEncryptorMessageProto::set_payload(::std::string&& value) {
  set_has_payload();
  payload_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.DataTransferEncryptorMessageProto.payload)
}
#endif
inline void DataTransferEncryptorMessageProto::set_payload(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_payload();
  payload_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.DataTransferEncryptorMessageProto.payload)
}
inline void DataTransferEncryptorMessageProto::set_payload(const void* value, size_t size) {
  set_has_payload();
  payload_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.DataTransferEncryptorMessageProto.payload)
}
inline ::std::string* DataTransferEncryptorMessageProto::mutable_payload() {
  set_has_payload();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.DataTransferEncryptorMessageProto.payload)
  return payload_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* DataTransferEncryptorMessageProto::release_payload() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.DataTransferEncryptorMessageProto.payload)
  if (!has_payload()) {
    return NULL;
  }
  clear_has_payload();
  return payload_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void DataTransferEncryptorMessageProto::set_allocated_payload(::std::string* payload) {
  if (payload != NULL) {
    set_has_payload();
  } else {
    clear_has_payload();
  }
  payload_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), payload);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.DataTransferEncryptorMessageProto.payload)
}

// optional string message = 3;
inline bool DataTransferEncryptorMessageProto::has_message() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void DataTransferEncryptorMessageProto::set_has_message() {
  _has_bits_[0] |= 0x00000002u;
}
inline void DataTransferEncryptorMessageProto::clear_has_message() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void DataTransferEncryptorMessageProto::clear_message() {
  message_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_message();
}
inline const ::std::string& DataTransferEncryptorMessageProto::message() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DataTransferEncryptorMessageProto.message)
  return message_.GetNoArena();
}
inline void DataTransferEncryptorMessageProto::set_message(const ::std::string& value) {
  set_has_message();
  message_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DataTransferEncryptorMessageProto.message)
}
#if LANG_CXX11
inline void DataTransferEncryptorMessageProto::set_message(::std::string&& value) {
  set_has_message();
  message_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.DataTransferEncryptorMessageProto.message)
}
#endif
inline void DataTransferEncryptorMessageProto::set_message(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_message();
  message_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.DataTransferEncryptorMessageProto.message)
}
inline void DataTransferEncryptorMessageProto::set_message(const char* value, size_t size) {
  set_has_message();
  message_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.DataTransferEncryptorMessageProto.message)
}
inline ::std::string* DataTransferEncryptorMessageProto::mutable_message() {
  set_has_message();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.DataTransferEncryptorMessageProto.message)
  return message_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* DataTransferEncryptorMessageProto::release_message() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.DataTransferEncryptorMessageProto.message)
  if (!has_message()) {
    return NULL;
  }
  clear_has_message();
  return message_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void DataTransferEncryptorMessageProto::set_allocated_message(::std::string* message) {
  if (message != NULL) {
    set_has_message();
  } else {
    clear_has_message();
  }
  message_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), message);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.DataTransferEncryptorMessageProto.message)
}

// repeated .hadoop.hdfs.CipherOptionProto cipherOption = 4;
inline int DataTransferEncryptorMessageProto::cipheroption_size() const {
  return cipheroption_.size();
}
inline ::hadoop::hdfs::CipherOptionProto* DataTransferEncryptorMessageProto::mutable_cipheroption(int index) {
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.DataTransferEncryptorMessageProto.cipherOption)
  return cipheroption_.Mutable(index);
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::CipherOptionProto >*
DataTransferEncryptorMessageProto::mutable_cipheroption() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.DataTransferEncryptorMessageProto.cipherOption)
  return &cipheroption_;
}
inline const ::hadoop::hdfs::CipherOptionProto& DataTransferEncryptorMessageProto::cipheroption(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DataTransferEncryptorMessageProto.cipherOption)
  return cipheroption_.Get(index);
}
inline ::hadoop::hdfs::CipherOptionProto* DataTransferEncryptorMessageProto::add_cipheroption() {
  // @@protoc_insertion_point(field_add:hadoop.hdfs.DataTransferEncryptorMessageProto.cipherOption)
  return cipheroption_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::CipherOptionProto >&
DataTransferEncryptorMessageProto::cipheroption() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.DataTransferEncryptorMessageProto.cipherOption)
  return cipheroption_;
}

// optional .hadoop.hdfs.HandshakeSecretProto handshakeSecret = 5;
inline bool DataTransferEncryptorMessageProto::has_handshakesecret() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void DataTransferEncryptorMessageProto::set_has_handshakesecret() {
  _has_bits_[0] |= 0x00000004u;
}
inline void DataTransferEncryptorMessageProto::clear_has_handshakesecret() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void DataTransferEncryptorMessageProto::clear_handshakesecret() {
  if (handshakesecret_ != NULL) handshakesecret_->Clear();
  clear_has_handshakesecret();
}
inline const ::hadoop::hdfs::HandshakeSecretProto& DataTransferEncryptorMessageProto::_internal_handshakesecret() const {
  return *handshakesecret_;
}
inline const ::hadoop::hdfs::HandshakeSecretProto& DataTransferEncryptorMessageProto::handshakesecret() const {
  const ::hadoop::hdfs::HandshakeSecretProto* p = handshakesecret_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DataTransferEncryptorMessageProto.handshakeSecret)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::HandshakeSecretProto*>(
      &::hadoop::hdfs::_HandshakeSecretProto_default_instance_);
}
inline ::hadoop::hdfs::HandshakeSecretProto* DataTransferEncryptorMessageProto::release_handshakesecret() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.DataTransferEncryptorMessageProto.handshakeSecret)
  clear_has_handshakesecret();
  ::hadoop::hdfs::HandshakeSecretProto* temp = handshakesecret_;
  handshakesecret_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::HandshakeSecretProto* DataTransferEncryptorMessageProto::mutable_handshakesecret() {
  set_has_handshakesecret();
  if (handshakesecret_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::HandshakeSecretProto>(GetArenaNoVirtual());
    handshakesecret_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.DataTransferEncryptorMessageProto.handshakeSecret)
  return handshakesecret_;
}
inline void DataTransferEncryptorMessageProto::set_allocated_handshakesecret(::hadoop::hdfs::HandshakeSecretProto* handshakesecret) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete handshakesecret_;
  }
  if (handshakesecret) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      handshakesecret = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, handshakesecret, submessage_arena);
    }
    set_has_handshakesecret();
  } else {
    clear_has_handshakesecret();
  }
  handshakesecret_ = handshakesecret;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.DataTransferEncryptorMessageProto.handshakeSecret)
}

// optional bool accessTokenError = 6;
inline bool DataTransferEncryptorMessageProto::has_accesstokenerror() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void DataTransferEncryptorMessageProto::set_has_accesstokenerror() {
  _has_bits_[0] |= 0x00000010u;
}
inline void DataTransferEncryptorMessageProto::clear_has_accesstokenerror() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void DataTransferEncryptorMessageProto::clear_accesstokenerror() {
  accesstokenerror_ = false;
  clear_has_accesstokenerror();
}
inline bool DataTransferEncryptorMessageProto::accesstokenerror() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DataTransferEncryptorMessageProto.accessTokenError)
  return accesstokenerror_;
}
inline void DataTransferEncryptorMessageProto::set_accesstokenerror(bool value) {
  set_has_accesstokenerror();
  accesstokenerror_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DataTransferEncryptorMessageProto.accessTokenError)
}

// -------------------------------------------------------------------

// HandshakeSecretProto

// required bytes secret = 1;
inline bool HandshakeSecretProto::has_secret() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void HandshakeSecretProto::set_has_secret() {
  _has_bits_[0] |= 0x00000001u;
}
inline void HandshakeSecretProto::clear_has_secret() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void HandshakeSecretProto::clear_secret() {
  secret_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_secret();
}
inline const ::std::string& HandshakeSecretProto::secret() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.HandshakeSecretProto.secret)
  return secret_.GetNoArena();
}
inline void HandshakeSecretProto::set_secret(const ::std::string& value) {
  set_has_secret();
  secret_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.HandshakeSecretProto.secret)
}
#if LANG_CXX11
inline void HandshakeSecretProto::set_secret(::std::string&& value) {
  set_has_secret();
  secret_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.HandshakeSecretProto.secret)
}
#endif
inline void HandshakeSecretProto::set_secret(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_secret();
  secret_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.HandshakeSecretProto.secret)
}
inline void HandshakeSecretProto::set_secret(const void* value, size_t size) {
  set_has_secret();
  secret_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.HandshakeSecretProto.secret)
}
inline ::std::string* HandshakeSecretProto::mutable_secret() {
  set_has_secret();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.HandshakeSecretProto.secret)
  return secret_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* HandshakeSecretProto::release_secret() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.HandshakeSecretProto.secret)
  if (!has_secret()) {
    return NULL;
  }
  clear_has_secret();
  return secret_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void HandshakeSecretProto::set_allocated_secret(::std::string* secret) {
  if (secret != NULL) {
    set_has_secret();
  } else {
    clear_has_secret();
  }
  secret_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), secret);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.HandshakeSecretProto.secret)
}

// required string bpid = 2;
inline bool HandshakeSecretProto::has_bpid() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void HandshakeSecretProto::set_has_bpid() {
  _has_bits_[0] |= 0x00000002u;
}
inline void HandshakeSecretProto::clear_has_bpid() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void HandshakeSecretProto::clear_bpid() {
  bpid_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_bpid();
}
inline const ::std::string& HandshakeSecretProto::bpid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.HandshakeSecretProto.bpid)
  return bpid_.GetNoArena();
}
inline void HandshakeSecretProto::set_bpid(const ::std::string& value) {
  set_has_bpid();
  bpid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.HandshakeSecretProto.bpid)
}
#if LANG_CXX11
inline void HandshakeSecretProto::set_bpid(::std::string&& value) {
  set_has_bpid();
  bpid_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.HandshakeSecretProto.bpid)
}
#endif
inline void HandshakeSecretProto::set_bpid(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_bpid();
  bpid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.HandshakeSecretProto.bpid)
}
inline void HandshakeSecretProto::set_bpid(const char* value, size_t size) {
  set_has_bpid();
  bpid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.HandshakeSecretProto.bpid)
}
inline ::std::string* HandshakeSecretProto::mutable_bpid() {
  set_has_bpid();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.HandshakeSecretProto.bpid)
  return bpid_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* HandshakeSecretProto::release_bpid() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.HandshakeSecretProto.bpid)
  if (!has_bpid()) {
    return NULL;
  }
  clear_has_bpid();
  return bpid_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void HandshakeSecretProto::set_allocated_bpid(::std::string* bpid) {
  if (bpid != NULL) {
    set_has_bpid();
  } else {
    clear_has_bpid();
  }
  bpid_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), bpid);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.HandshakeSecretProto.bpid)
}

// -------------------------------------------------------------------

// BaseHeaderProto

// required .hadoop.hdfs.ExtendedBlockProto block = 1;
inline bool BaseHeaderProto::has_block() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void BaseHeaderProto::set_has_block() {
  _has_bits_[0] |= 0x00000001u;
}
inline void BaseHeaderProto::clear_has_block() {
  _has_bits_[0] &= ~0x00000001u;
}
inline const ::hadoop::hdfs::ExtendedBlockProto& BaseHeaderProto::_internal_block() const {
  return *block_;
}
inline const ::hadoop::hdfs::ExtendedBlockProto& BaseHeaderProto::block() const {
  const ::hadoop::hdfs::ExtendedBlockProto* p = block_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BaseHeaderProto.block)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::ExtendedBlockProto*>(
      &::hadoop::hdfs::_ExtendedBlockProto_default_instance_);
}
inline ::hadoop::hdfs::ExtendedBlockProto* BaseHeaderProto::release_block() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.BaseHeaderProto.block)
  clear_has_block();
  ::hadoop::hdfs::ExtendedBlockProto* temp = block_;
  block_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::ExtendedBlockProto* BaseHeaderProto::mutable_block() {
  set_has_block();
  if (block_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::ExtendedBlockProto>(GetArenaNoVirtual());
    block_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.BaseHeaderProto.block)
  return block_;
}
inline void BaseHeaderProto::set_allocated_block(::hadoop::hdfs::ExtendedBlockProto* block) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete reinterpret_cast< ::google::protobuf::MessageLite*>(block_);
  }
  if (block) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      block = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, block, submessage_arena);
    }
    set_has_block();
  } else {
    clear_has_block();
  }
  block_ = block;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.BaseHeaderProto.block)
}

// optional .hadoop.common.TokenProto token = 2;
inline bool BaseHeaderProto::has_token() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void BaseHeaderProto::set_has_token() {
  _has_bits_[0] |= 0x00000002u;
}
inline void BaseHeaderProto::clear_has_token() {
  _has_bits_[0] &= ~0x00000002u;
}
inline const ::hadoop::common::TokenProto& BaseHeaderProto::_internal_token() const {
  return *token_;
}
inline const ::hadoop::common::TokenProto& BaseHeaderProto::token() const {
  const ::hadoop::common::TokenProto* p = token_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BaseHeaderProto.token)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::common::TokenProto*>(
      &::hadoop::common::_TokenProto_default_instance_);
}
inline ::hadoop::common::TokenProto* BaseHeaderProto::release_token() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.BaseHeaderProto.token)
  clear_has_token();
  ::hadoop::common::TokenProto* temp = token_;
  token_ = NULL;
  return temp;
}
inline ::hadoop::common::TokenProto* BaseHeaderProto::mutable_token() {
  set_has_token();
  if (token_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::common::TokenProto>(GetArenaNoVirtual());
    token_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.BaseHeaderProto.token)
  return token_;
}
inline void BaseHeaderProto::set_allocated_token(::hadoop::common::TokenProto* token) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete reinterpret_cast< ::google::protobuf::MessageLite*>(token_);
  }
  if (token) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      token = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, token, submessage_arena);
    }
    set_has_token();
  } else {
    clear_has_token();
  }
  token_ = token;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.BaseHeaderProto.token)
}

// optional .hadoop.hdfs.DataTransferTraceInfoProto traceInfo = 3;
inline bool BaseHeaderProto::has_traceinfo() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void BaseHeaderProto::set_has_traceinfo() {
  _has_bits_[0] |= 0x00000004u;
}
inline void BaseHeaderProto::clear_has_traceinfo() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void BaseHeaderProto::clear_traceinfo() {
  if (traceinfo_ != NULL) traceinfo_->Clear();
  clear_has_traceinfo();
}
inline const ::hadoop::hdfs::DataTransferTraceInfoProto& BaseHeaderProto::_internal_traceinfo() const {
  return *traceinfo_;
}
inline const ::hadoop::hdfs::DataTransferTraceInfoProto& BaseHeaderProto::traceinfo() const {
  const ::hadoop::hdfs::DataTransferTraceInfoProto* p = traceinfo_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BaseHeaderProto.traceInfo)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::DataTransferTraceInfoProto*>(
      &::hadoop::hdfs::_DataTransferTraceInfoProto_default_instance_);
}
inline ::hadoop::hdfs::DataTransferTraceInfoProto* BaseHeaderProto::release_traceinfo() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.BaseHeaderProto.traceInfo)
  clear_has_traceinfo();
  ::hadoop::hdfs::DataTransferTraceInfoProto* temp = traceinfo_;
  traceinfo_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::DataTransferTraceInfoProto* BaseHeaderProto::mutable_traceinfo() {
  set_has_traceinfo();
  if (traceinfo_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::DataTransferTraceInfoProto>(GetArenaNoVirtual());
    traceinfo_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.BaseHeaderProto.traceInfo)
  return traceinfo_;
}
inline void BaseHeaderProto::set_allocated_traceinfo(::hadoop::hdfs::DataTransferTraceInfoProto* traceinfo) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete traceinfo_;
  }
  if (traceinfo) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      traceinfo = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, traceinfo, submessage_arena);
    }
    set_has_traceinfo();
  } else {
    clear_has_traceinfo();
  }
  traceinfo_ = traceinfo;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.BaseHeaderProto.traceInfo)
}

// -------------------------------------------------------------------

// DataTransferTraceInfoProto

// optional uint64 traceId = 1;
inline bool DataTransferTraceInfoProto::has_traceid() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void DataTransferTraceInfoProto::set_has_traceid() {
  _has_bits_[0] |= 0x00000002u;
}
inline void DataTransferTraceInfoProto::clear_has_traceid() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void DataTransferTraceInfoProto::clear_traceid() {
  traceid_ = GOOGLE_ULONGLONG(0);
  clear_has_traceid();
}
inline ::google::protobuf::uint64 DataTransferTraceInfoProto::traceid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DataTransferTraceInfoProto.traceId)
  return traceid_;
}
inline void DataTransferTraceInfoProto::set_traceid(::google::protobuf::uint64 value) {
  set_has_traceid();
  traceid_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DataTransferTraceInfoProto.traceId)
}

// optional uint64 parentId = 2;
inline bool DataTransferTraceInfoProto::has_parentid() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void DataTransferTraceInfoProto::set_has_parentid() {
  _has_bits_[0] |= 0x00000004u;
}
inline void DataTransferTraceInfoProto::clear_has_parentid() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void DataTransferTraceInfoProto::clear_parentid() {
  parentid_ = GOOGLE_ULONGLONG(0);
  clear_has_parentid();
}
inline ::google::protobuf::uint64 DataTransferTraceInfoProto::parentid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DataTransferTraceInfoProto.parentId)
  return parentid_;
}
inline void DataTransferTraceInfoProto::set_parentid(::google::protobuf::uint64 value) {
  set_has_parentid();
  parentid_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DataTransferTraceInfoProto.parentId)
}

// optional bytes spanContext = 3;
inline bool DataTransferTraceInfoProto::has_spancontext() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void DataTransferTraceInfoProto::set_has_spancontext() {
  _has_bits_[0] |= 0x00000001u;
}
inline void DataTransferTraceInfoProto::clear_has_spancontext() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void DataTransferTraceInfoProto::clear_spancontext() {
  spancontext_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_spancontext();
}
inline const ::std::string& DataTransferTraceInfoProto::spancontext() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DataTransferTraceInfoProto.spanContext)
  return spancontext_.GetNoArena();
}
inline void DataTransferTraceInfoProto::set_spancontext(const ::std::string& value) {
  set_has_spancontext();
  spancontext_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DataTransferTraceInfoProto.spanContext)
}
#if LANG_CXX11
inline void DataTransferTraceInfoProto::set_spancontext(::std::string&& value) {
  set_has_spancontext();
  spancontext_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.DataTransferTraceInfoProto.spanContext)
}
#endif
inline void DataTransferTraceInfoProto::set_spancontext(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_spancontext();
  spancontext_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.DataTransferTraceInfoProto.spanContext)
}
inline void DataTransferTraceInfoProto::set_spancontext(const void* value, size_t size) {
  set_has_spancontext();
  spancontext_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.DataTransferTraceInfoProto.spanContext)
}
inline ::std::string* DataTransferTraceInfoProto::mutable_spancontext() {
  set_has_spancontext();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.DataTransferTraceInfoProto.spanContext)
  return spancontext_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* DataTransferTraceInfoProto::release_spancontext() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.DataTransferTraceInfoProto.spanContext)
  if (!has_spancontext()) {
    return NULL;
  }
  clear_has_spancontext();
  return spancontext_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void DataTransferTraceInfoProto::set_allocated_spancontext(::std::string* spancontext) {
  if (spancontext != NULL) {
    set_has_spancontext();
  } else {
    clear_has_spancontext();
  }
  spancontext_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), spancontext);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.DataTransferTraceInfoProto.spanContext)
}

// -------------------------------------------------------------------

// ClientOperationHeaderProto

// required .hadoop.hdfs.BaseHeaderProto baseHeader = 1;
inline bool ClientOperationHeaderProto::has_baseheader() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ClientOperationHeaderProto::set_has_baseheader() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ClientOperationHeaderProto::clear_has_baseheader() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ClientOperationHeaderProto::clear_baseheader() {
  if (baseheader_ != NULL) baseheader_->Clear();
  clear_has_baseheader();
}
inline const ::hadoop::hdfs::BaseHeaderProto& ClientOperationHeaderProto::_internal_baseheader() const {
  return *baseheader_;
}
inline const ::hadoop::hdfs::BaseHeaderProto& ClientOperationHeaderProto::baseheader() const {
  const ::hadoop::hdfs::BaseHeaderProto* p = baseheader_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ClientOperationHeaderProto.baseHeader)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::BaseHeaderProto*>(
      &::hadoop::hdfs::_BaseHeaderProto_default_instance_);
}
inline ::hadoop::hdfs::BaseHeaderProto* ClientOperationHeaderProto::release_baseheader() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.ClientOperationHeaderProto.baseHeader)
  clear_has_baseheader();
  ::hadoop::hdfs::BaseHeaderProto* temp = baseheader_;
  baseheader_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::BaseHeaderProto* ClientOperationHeaderProto::mutable_baseheader() {
  set_has_baseheader();
  if (baseheader_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::BaseHeaderProto>(GetArenaNoVirtual());
    baseheader_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.ClientOperationHeaderProto.baseHeader)
  return baseheader_;
}
inline void ClientOperationHeaderProto::set_allocated_baseheader(::hadoop::hdfs::BaseHeaderProto* baseheader) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete baseheader_;
  }
  if (baseheader) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      baseheader = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, baseheader, submessage_arena);
    }
    set_has_baseheader();
  } else {
    clear_has_baseheader();
  }
  baseheader_ = baseheader;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.ClientOperationHeaderProto.baseHeader)
}

// required string clientName = 2;
inline bool ClientOperationHeaderProto::has_clientname() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ClientOperationHeaderProto::set_has_clientname() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ClientOperationHeaderProto::clear_has_clientname() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ClientOperationHeaderProto::clear_clientname() {
  clientname_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_clientname();
}
inline const ::std::string& ClientOperationHeaderProto::clientname() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ClientOperationHeaderProto.clientName)
  return clientname_.GetNoArena();
}
inline void ClientOperationHeaderProto::set_clientname(const ::std::string& value) {
  set_has_clientname();
  clientname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ClientOperationHeaderProto.clientName)
}
#if LANG_CXX11
inline void ClientOperationHeaderProto::set_clientname(::std::string&& value) {
  set_has_clientname();
  clientname_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.ClientOperationHeaderProto.clientName)
}
#endif
inline void ClientOperationHeaderProto::set_clientname(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_clientname();
  clientname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.ClientOperationHeaderProto.clientName)
}
inline void ClientOperationHeaderProto::set_clientname(const char* value, size_t size) {
  set_has_clientname();
  clientname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.ClientOperationHeaderProto.clientName)
}
inline ::std::string* ClientOperationHeaderProto::mutable_clientname() {
  set_has_clientname();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.ClientOperationHeaderProto.clientName)
  return clientname_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* ClientOperationHeaderProto::release_clientname() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.ClientOperationHeaderProto.clientName)
  if (!has_clientname()) {
    return NULL;
  }
  clear_has_clientname();
  return clientname_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void ClientOperationHeaderProto::set_allocated_clientname(::std::string* clientname) {
  if (clientname != NULL) {
    set_has_clientname();
  } else {
    clear_has_clientname();
  }
  clientname_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), clientname);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.ClientOperationHeaderProto.clientName)
}

// -------------------------------------------------------------------

// CachingStrategyProto

// optional bool dropBehind = 1;
inline bool CachingStrategyProto::has_dropbehind() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void CachingStrategyProto::set_has_dropbehind() {
  _has_bits_[0] |= 0x00000002u;
}
inline void CachingStrategyProto::clear_has_dropbehind() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void CachingStrategyProto::clear_dropbehind() {
  dropbehind_ = false;
  clear_has_dropbehind();
}
inline bool CachingStrategyProto::dropbehind() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.CachingStrategyProto.dropBehind)
  return dropbehind_;
}
inline void CachingStrategyProto::set_dropbehind(bool value) {
  set_has_dropbehind();
  dropbehind_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.CachingStrategyProto.dropBehind)
}

// optional int64 readahead = 2;
inline bool CachingStrategyProto::has_readahead() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void CachingStrategyProto::set_has_readahead() {
  _has_bits_[0] |= 0x00000001u;
}
inline void CachingStrategyProto::clear_has_readahead() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void CachingStrategyProto::clear_readahead() {
  readahead_ = GOOGLE_LONGLONG(0);
  clear_has_readahead();
}
inline ::google::protobuf::int64 CachingStrategyProto::readahead() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.CachingStrategyProto.readahead)
  return readahead_;
}
inline void CachingStrategyProto::set_readahead(::google::protobuf::int64 value) {
  set_has_readahead();
  readahead_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.CachingStrategyProto.readahead)
}

// -------------------------------------------------------------------

// OpReadBlockProto

// required .hadoop.hdfs.ClientOperationHeaderProto header = 1;
inline bool OpReadBlockProto::has_header() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void OpReadBlockProto::set_has_header() {
  _has_bits_[0] |= 0x00000001u;
}
inline void OpReadBlockProto::clear_has_header() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void OpReadBlockProto::clear_header() {
  if (header_ != NULL) header_->Clear();
  clear_has_header();
}
inline const ::hadoop::hdfs::ClientOperationHeaderProto& OpReadBlockProto::_internal_header() const {
  return *header_;
}
inline const ::hadoop::hdfs::ClientOperationHeaderProto& OpReadBlockProto::header() const {
  const ::hadoop::hdfs::ClientOperationHeaderProto* p = header_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpReadBlockProto.header)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::ClientOperationHeaderProto*>(
      &::hadoop::hdfs::_ClientOperationHeaderProto_default_instance_);
}
inline ::hadoop::hdfs::ClientOperationHeaderProto* OpReadBlockProto::release_header() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.OpReadBlockProto.header)
  clear_has_header();
  ::hadoop::hdfs::ClientOperationHeaderProto* temp = header_;
  header_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::ClientOperationHeaderProto* OpReadBlockProto::mutable_header() {
  set_has_header();
  if (header_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::ClientOperationHeaderProto>(GetArenaNoVirtual());
    header_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.OpReadBlockProto.header)
  return header_;
}
inline void OpReadBlockProto::set_allocated_header(::hadoop::hdfs::ClientOperationHeaderProto* header) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete header_;
  }
  if (header) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      header = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, header, submessage_arena);
    }
    set_has_header();
  } else {
    clear_has_header();
  }
  header_ = header;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.OpReadBlockProto.header)
}

// required uint64 offset = 2;
inline bool OpReadBlockProto::has_offset() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void OpReadBlockProto::set_has_offset() {
  _has_bits_[0] |= 0x00000004u;
}
inline void OpReadBlockProto::clear_has_offset() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void OpReadBlockProto::clear_offset() {
  offset_ = GOOGLE_ULONGLONG(0);
  clear_has_offset();
}
inline ::google::protobuf::uint64 OpReadBlockProto::offset() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpReadBlockProto.offset)
  return offset_;
}
inline void OpReadBlockProto::set_offset(::google::protobuf::uint64 value) {
  set_has_offset();
  offset_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpReadBlockProto.offset)
}

// required uint64 len = 3;
inline bool OpReadBlockProto::has_len() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void OpReadBlockProto::set_has_len() {
  _has_bits_[0] |= 0x00000008u;
}
inline void OpReadBlockProto::clear_has_len() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void OpReadBlockProto::clear_len() {
  len_ = GOOGLE_ULONGLONG(0);
  clear_has_len();
}
inline ::google::protobuf::uint64 OpReadBlockProto::len() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpReadBlockProto.len)
  return len_;
}
inline void OpReadBlockProto::set_len(::google::protobuf::uint64 value) {
  set_has_len();
  len_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpReadBlockProto.len)
}

// optional bool sendChecksums = 4 [default = true];
inline bool OpReadBlockProto::has_sendchecksums() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void OpReadBlockProto::set_has_sendchecksums() {
  _has_bits_[0] |= 0x00000010u;
}
inline void OpReadBlockProto::clear_has_sendchecksums() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void OpReadBlockProto::clear_sendchecksums() {
  sendchecksums_ = true;
  clear_has_sendchecksums();
}
inline bool OpReadBlockProto::sendchecksums() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpReadBlockProto.sendChecksums)
  return sendchecksums_;
}
inline void OpReadBlockProto::set_sendchecksums(bool value) {
  set_has_sendchecksums();
  sendchecksums_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpReadBlockProto.sendChecksums)
}

// optional .hadoop.hdfs.CachingStrategyProto cachingStrategy = 5;
inline bool OpReadBlockProto::has_cachingstrategy() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void OpReadBlockProto::set_has_cachingstrategy() {
  _has_bits_[0] |= 0x00000002u;
}
inline void OpReadBlockProto::clear_has_cachingstrategy() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void OpReadBlockProto::clear_cachingstrategy() {
  if (cachingstrategy_ != NULL) cachingstrategy_->Clear();
  clear_has_cachingstrategy();
}
inline const ::hadoop::hdfs::CachingStrategyProto& OpReadBlockProto::_internal_cachingstrategy() const {
  return *cachingstrategy_;
}
inline const ::hadoop::hdfs::CachingStrategyProto& OpReadBlockProto::cachingstrategy() const {
  const ::hadoop::hdfs::CachingStrategyProto* p = cachingstrategy_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpReadBlockProto.cachingStrategy)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::CachingStrategyProto*>(
      &::hadoop::hdfs::_CachingStrategyProto_default_instance_);
}
inline ::hadoop::hdfs::CachingStrategyProto* OpReadBlockProto::release_cachingstrategy() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.OpReadBlockProto.cachingStrategy)
  clear_has_cachingstrategy();
  ::hadoop::hdfs::CachingStrategyProto* temp = cachingstrategy_;
  cachingstrategy_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::CachingStrategyProto* OpReadBlockProto::mutable_cachingstrategy() {
  set_has_cachingstrategy();
  if (cachingstrategy_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::CachingStrategyProto>(GetArenaNoVirtual());
    cachingstrategy_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.OpReadBlockProto.cachingStrategy)
  return cachingstrategy_;
}
inline void OpReadBlockProto::set_allocated_cachingstrategy(::hadoop::hdfs::CachingStrategyProto* cachingstrategy) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete cachingstrategy_;
  }
  if (cachingstrategy) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      cachingstrategy = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, cachingstrategy, submessage_arena);
    }
    set_has_cachingstrategy();
  } else {
    clear_has_cachingstrategy();
  }
  cachingstrategy_ = cachingstrategy;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.OpReadBlockProto.cachingStrategy)
}

// -------------------------------------------------------------------

// ChecksumProto

// required .hadoop.hdfs.ChecksumTypeProto type = 1;
inline bool ChecksumProto::has_type() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ChecksumProto::set_has_type() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ChecksumProto::clear_has_type() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ChecksumProto::clear_type() {
  type_ = 0;
  clear_has_type();
}
inline ::hadoop::hdfs::ChecksumTypeProto ChecksumProto::type() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ChecksumProto.type)
  return static_cast< ::hadoop::hdfs::ChecksumTypeProto >(type_);
}
inline void ChecksumProto::set_type(::hadoop::hdfs::ChecksumTypeProto value) {
  assert(::hadoop::hdfs::ChecksumTypeProto_IsValid(value));
  set_has_type();
  type_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ChecksumProto.type)
}

// required uint32 bytesPerChecksum = 2;
inline bool ChecksumProto::has_bytesperchecksum() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ChecksumProto::set_has_bytesperchecksum() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ChecksumProto::clear_has_bytesperchecksum() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ChecksumProto::clear_bytesperchecksum() {
  bytesperchecksum_ = 0u;
  clear_has_bytesperchecksum();
}
inline ::google::protobuf::uint32 ChecksumProto::bytesperchecksum() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ChecksumProto.bytesPerChecksum)
  return bytesperchecksum_;
}
inline void ChecksumProto::set_bytesperchecksum(::google::protobuf::uint32 value) {
  set_has_bytesperchecksum();
  bytesperchecksum_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ChecksumProto.bytesPerChecksum)
}

// -------------------------------------------------------------------

// OpWriteBlockProto

// required .hadoop.hdfs.ClientOperationHeaderProto header = 1;
inline bool OpWriteBlockProto::has_header() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void OpWriteBlockProto::set_has_header() {
  _has_bits_[0] |= 0x00000002u;
}
inline void OpWriteBlockProto::clear_has_header() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void OpWriteBlockProto::clear_header() {
  if (header_ != NULL) header_->Clear();
  clear_has_header();
}
inline const ::hadoop::hdfs::ClientOperationHeaderProto& OpWriteBlockProto::_internal_header() const {
  return *header_;
}
inline const ::hadoop::hdfs::ClientOperationHeaderProto& OpWriteBlockProto::header() const {
  const ::hadoop::hdfs::ClientOperationHeaderProto* p = header_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpWriteBlockProto.header)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::ClientOperationHeaderProto*>(
      &::hadoop::hdfs::_ClientOperationHeaderProto_default_instance_);
}
inline ::hadoop::hdfs::ClientOperationHeaderProto* OpWriteBlockProto::release_header() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.OpWriteBlockProto.header)
  clear_has_header();
  ::hadoop::hdfs::ClientOperationHeaderProto* temp = header_;
  header_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::ClientOperationHeaderProto* OpWriteBlockProto::mutable_header() {
  set_has_header();
  if (header_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::ClientOperationHeaderProto>(GetArenaNoVirtual());
    header_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.OpWriteBlockProto.header)
  return header_;
}
inline void OpWriteBlockProto::set_allocated_header(::hadoop::hdfs::ClientOperationHeaderProto* header) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete header_;
  }
  if (header) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      header = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, header, submessage_arena);
    }
    set_has_header();
  } else {
    clear_has_header();
  }
  header_ = header;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.OpWriteBlockProto.header)
}

// repeated .hadoop.hdfs.DatanodeInfoProto targets = 2;
inline int OpWriteBlockProto::targets_size() const {
  return targets_.size();
}
inline ::hadoop::hdfs::DatanodeInfoProto* OpWriteBlockProto::mutable_targets(int index) {
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.OpWriteBlockProto.targets)
  return targets_.Mutable(index);
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::DatanodeInfoProto >*
OpWriteBlockProto::mutable_targets() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.OpWriteBlockProto.targets)
  return &targets_;
}
inline const ::hadoop::hdfs::DatanodeInfoProto& OpWriteBlockProto::targets(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpWriteBlockProto.targets)
  return targets_.Get(index);
}
inline ::hadoop::hdfs::DatanodeInfoProto* OpWriteBlockProto::add_targets() {
  // @@protoc_insertion_point(field_add:hadoop.hdfs.OpWriteBlockProto.targets)
  return targets_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::DatanodeInfoProto >&
OpWriteBlockProto::targets() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.OpWriteBlockProto.targets)
  return targets_;
}

// optional .hadoop.hdfs.DatanodeInfoProto source = 3;
inline bool OpWriteBlockProto::has_source() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void OpWriteBlockProto::set_has_source() {
  _has_bits_[0] |= 0x00000004u;
}
inline void OpWriteBlockProto::clear_has_source() {
  _has_bits_[0] &= ~0x00000004u;
}
inline const ::hadoop::hdfs::DatanodeInfoProto& OpWriteBlockProto::_internal_source() const {
  return *source_;
}
inline const ::hadoop::hdfs::DatanodeInfoProto& OpWriteBlockProto::source() const {
  const ::hadoop::hdfs::DatanodeInfoProto* p = source_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpWriteBlockProto.source)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::DatanodeInfoProto*>(
      &::hadoop::hdfs::_DatanodeInfoProto_default_instance_);
}
inline ::hadoop::hdfs::DatanodeInfoProto* OpWriteBlockProto::release_source() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.OpWriteBlockProto.source)
  clear_has_source();
  ::hadoop::hdfs::DatanodeInfoProto* temp = source_;
  source_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::DatanodeInfoProto* OpWriteBlockProto::mutable_source() {
  set_has_source();
  if (source_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::DatanodeInfoProto>(GetArenaNoVirtual());
    source_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.OpWriteBlockProto.source)
  return source_;
}
inline void OpWriteBlockProto::set_allocated_source(::hadoop::hdfs::DatanodeInfoProto* source) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete reinterpret_cast< ::google::protobuf::MessageLite*>(source_);
  }
  if (source) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      source = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, source, submessage_arena);
    }
    set_has_source();
  } else {
    clear_has_source();
  }
  source_ = source;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.OpWriteBlockProto.source)
}

// required .hadoop.hdfs.OpWriteBlockProto.BlockConstructionStage stage = 4;
inline bool OpWriteBlockProto::has_stage() const {
  return (_has_bits_[0] & 0x00000020u) != 0;
}
inline void OpWriteBlockProto::set_has_stage() {
  _has_bits_[0] |= 0x00000020u;
}
inline void OpWriteBlockProto::clear_has_stage() {
  _has_bits_[0] &= ~0x00000020u;
}
inline void OpWriteBlockProto::clear_stage() {
  stage_ = 0;
  clear_has_stage();
}
inline ::hadoop::hdfs::OpWriteBlockProto_BlockConstructionStage OpWriteBlockProto::stage() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpWriteBlockProto.stage)
  return static_cast< ::hadoop::hdfs::OpWriteBlockProto_BlockConstructionStage >(stage_);
}
inline void OpWriteBlockProto::set_stage(::hadoop::hdfs::OpWriteBlockProto_BlockConstructionStage value) {
  assert(::hadoop::hdfs::OpWriteBlockProto_BlockConstructionStage_IsValid(value));
  set_has_stage();
  stage_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpWriteBlockProto.stage)
}

// required uint32 pipelineSize = 5;
inline bool OpWriteBlockProto::has_pipelinesize() const {
  return (_has_bits_[0] & 0x00000040u) != 0;
}
inline void OpWriteBlockProto::set_has_pipelinesize() {
  _has_bits_[0] |= 0x00000040u;
}
inline void OpWriteBlockProto::clear_has_pipelinesize() {
  _has_bits_[0] &= ~0x00000040u;
}
inline void OpWriteBlockProto::clear_pipelinesize() {
  pipelinesize_ = 0u;
  clear_has_pipelinesize();
}
inline ::google::protobuf::uint32 OpWriteBlockProto::pipelinesize() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpWriteBlockProto.pipelineSize)
  return pipelinesize_;
}
inline void OpWriteBlockProto::set_pipelinesize(::google::protobuf::uint32 value) {
  set_has_pipelinesize();
  pipelinesize_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpWriteBlockProto.pipelineSize)
}

// required uint64 minBytesRcvd = 6;
inline bool OpWriteBlockProto::has_minbytesrcvd() const {
  return (_has_bits_[0] & 0x00000080u) != 0;
}
inline void OpWriteBlockProto::set_has_minbytesrcvd() {
  _has_bits_[0] |= 0x00000080u;
}
inline void OpWriteBlockProto::clear_has_minbytesrcvd() {
  _has_bits_[0] &= ~0x00000080u;
}
inline void OpWriteBlockProto::clear_minbytesrcvd() {
  minbytesrcvd_ = GOOGLE_ULONGLONG(0);
  clear_has_minbytesrcvd();
}
inline ::google::protobuf::uint64 OpWriteBlockProto::minbytesrcvd() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpWriteBlockProto.minBytesRcvd)
  return minbytesrcvd_;
}
inline void OpWriteBlockProto::set_minbytesrcvd(::google::protobuf::uint64 value) {
  set_has_minbytesrcvd();
  minbytesrcvd_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpWriteBlockProto.minBytesRcvd)
}

// required uint64 maxBytesRcvd = 7;
inline bool OpWriteBlockProto::has_maxbytesrcvd() const {
  return (_has_bits_[0] & 0x00000100u) != 0;
}
inline void OpWriteBlockProto::set_has_maxbytesrcvd() {
  _has_bits_[0] |= 0x00000100u;
}
inline void OpWriteBlockProto::clear_has_maxbytesrcvd() {
  _has_bits_[0] &= ~0x00000100u;
}
inline void OpWriteBlockProto::clear_maxbytesrcvd() {
  maxbytesrcvd_ = GOOGLE_ULONGLONG(0);
  clear_has_maxbytesrcvd();
}
inline ::google::protobuf::uint64 OpWriteBlockProto::maxbytesrcvd() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpWriteBlockProto.maxBytesRcvd)
  return maxbytesrcvd_;
}
inline void OpWriteBlockProto::set_maxbytesrcvd(::google::protobuf::uint64 value) {
  set_has_maxbytesrcvd();
  maxbytesrcvd_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpWriteBlockProto.maxBytesRcvd)
}

// required uint64 latestGenerationStamp = 8;
inline bool OpWriteBlockProto::has_latestgenerationstamp() const {
  return (_has_bits_[0] & 0x00000200u) != 0;
}
inline void OpWriteBlockProto::set_has_latestgenerationstamp() {
  _has_bits_[0] |= 0x00000200u;
}
inline void OpWriteBlockProto::clear_has_latestgenerationstamp() {
  _has_bits_[0] &= ~0x00000200u;
}
inline void OpWriteBlockProto::clear_latestgenerationstamp() {
  latestgenerationstamp_ = GOOGLE_ULONGLONG(0);
  clear_has_latestgenerationstamp();
}
inline ::google::protobuf::uint64 OpWriteBlockProto::latestgenerationstamp() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpWriteBlockProto.latestGenerationStamp)
  return latestgenerationstamp_;
}
inline void OpWriteBlockProto::set_latestgenerationstamp(::google::protobuf::uint64 value) {
  set_has_latestgenerationstamp();
  latestgenerationstamp_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpWriteBlockProto.latestGenerationStamp)
}

// required .hadoop.hdfs.ChecksumProto requestedChecksum = 9;
inline bool OpWriteBlockProto::has_requestedchecksum() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void OpWriteBlockProto::set_has_requestedchecksum() {
  _has_bits_[0] |= 0x00000008u;
}
inline void OpWriteBlockProto::clear_has_requestedchecksum() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void OpWriteBlockProto::clear_requestedchecksum() {
  if (requestedchecksum_ != NULL) requestedchecksum_->Clear();
  clear_has_requestedchecksum();
}
inline const ::hadoop::hdfs::ChecksumProto& OpWriteBlockProto::_internal_requestedchecksum() const {
  return *requestedchecksum_;
}
inline const ::hadoop::hdfs::ChecksumProto& OpWriteBlockProto::requestedchecksum() const {
  const ::hadoop::hdfs::ChecksumProto* p = requestedchecksum_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpWriteBlockProto.requestedChecksum)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::ChecksumProto*>(
      &::hadoop::hdfs::_ChecksumProto_default_instance_);
}
inline ::hadoop::hdfs::ChecksumProto* OpWriteBlockProto::release_requestedchecksum() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.OpWriteBlockProto.requestedChecksum)
  clear_has_requestedchecksum();
  ::hadoop::hdfs::ChecksumProto* temp = requestedchecksum_;
  requestedchecksum_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::ChecksumProto* OpWriteBlockProto::mutable_requestedchecksum() {
  set_has_requestedchecksum();
  if (requestedchecksum_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::ChecksumProto>(GetArenaNoVirtual());
    requestedchecksum_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.OpWriteBlockProto.requestedChecksum)
  return requestedchecksum_;
}
inline void OpWriteBlockProto::set_allocated_requestedchecksum(::hadoop::hdfs::ChecksumProto* requestedchecksum) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete requestedchecksum_;
  }
  if (requestedchecksum) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      requestedchecksum = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, requestedchecksum, submessage_arena);
    }
    set_has_requestedchecksum();
  } else {
    clear_has_requestedchecksum();
  }
  requestedchecksum_ = requestedchecksum;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.OpWriteBlockProto.requestedChecksum)
}

// optional .hadoop.hdfs.CachingStrategyProto cachingStrategy = 10;
inline bool OpWriteBlockProto::has_cachingstrategy() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void OpWriteBlockProto::set_has_cachingstrategy() {
  _has_bits_[0] |= 0x00000010u;
}
inline void OpWriteBlockProto::clear_has_cachingstrategy() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void OpWriteBlockProto::clear_cachingstrategy() {
  if (cachingstrategy_ != NULL) cachingstrategy_->Clear();
  clear_has_cachingstrategy();
}
inline const ::hadoop::hdfs::CachingStrategyProto& OpWriteBlockProto::_internal_cachingstrategy() const {
  return *cachingstrategy_;
}
inline const ::hadoop::hdfs::CachingStrategyProto& OpWriteBlockProto::cachingstrategy() const {
  const ::hadoop::hdfs::CachingStrategyProto* p = cachingstrategy_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpWriteBlockProto.cachingStrategy)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::CachingStrategyProto*>(
      &::hadoop::hdfs::_CachingStrategyProto_default_instance_);
}
inline ::hadoop::hdfs::CachingStrategyProto* OpWriteBlockProto::release_cachingstrategy() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.OpWriteBlockProto.cachingStrategy)
  clear_has_cachingstrategy();
  ::hadoop::hdfs::CachingStrategyProto* temp = cachingstrategy_;
  cachingstrategy_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::CachingStrategyProto* OpWriteBlockProto::mutable_cachingstrategy() {
  set_has_cachingstrategy();
  if (cachingstrategy_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::CachingStrategyProto>(GetArenaNoVirtual());
    cachingstrategy_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.OpWriteBlockProto.cachingStrategy)
  return cachingstrategy_;
}
inline void OpWriteBlockProto::set_allocated_cachingstrategy(::hadoop::hdfs::CachingStrategyProto* cachingstrategy) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete cachingstrategy_;
  }
  if (cachingstrategy) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      cachingstrategy = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, cachingstrategy, submessage_arena);
    }
    set_has_cachingstrategy();
  } else {
    clear_has_cachingstrategy();
  }
  cachingstrategy_ = cachingstrategy;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.OpWriteBlockProto.cachingStrategy)
}

// optional .hadoop.hdfs.StorageTypeProto storageType = 11 [default = DISK];
inline bool OpWriteBlockProto::has_storagetype() const {
  return (_has_bits_[0] & 0x00001000u) != 0;
}
inline void OpWriteBlockProto::set_has_storagetype() {
  _has_bits_[0] |= 0x00001000u;
}
inline void OpWriteBlockProto::clear_has_storagetype() {
  _has_bits_[0] &= ~0x00001000u;
}
inline void OpWriteBlockProto::clear_storagetype() {
  storagetype_ = 1;
  clear_has_storagetype();
}
inline ::hadoop::hdfs::StorageTypeProto OpWriteBlockProto::storagetype() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpWriteBlockProto.storageType)
  return static_cast< ::hadoop::hdfs::StorageTypeProto >(storagetype_);
}
inline void OpWriteBlockProto::set_storagetype(::hadoop::hdfs::StorageTypeProto value) {
  assert(::hadoop::hdfs::StorageTypeProto_IsValid(value));
  set_has_storagetype();
  storagetype_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpWriteBlockProto.storageType)
}

// repeated .hadoop.hdfs.StorageTypeProto targetStorageTypes = 12;
inline int OpWriteBlockProto::targetstoragetypes_size() const {
  return targetstoragetypes_.size();
}
inline void OpWriteBlockProto::clear_targetstoragetypes() {
  targetstoragetypes_.Clear();
}
inline ::hadoop::hdfs::StorageTypeProto OpWriteBlockProto::targetstoragetypes(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpWriteBlockProto.targetStorageTypes)
  return static_cast< ::hadoop::hdfs::StorageTypeProto >(targetstoragetypes_.Get(index));
}
inline void OpWriteBlockProto::set_targetstoragetypes(int index, ::hadoop::hdfs::StorageTypeProto value) {
  assert(::hadoop::hdfs::StorageTypeProto_IsValid(value));
  targetstoragetypes_.Set(index, value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpWriteBlockProto.targetStorageTypes)
}
inline void OpWriteBlockProto::add_targetstoragetypes(::hadoop::hdfs::StorageTypeProto value) {
  assert(::hadoop::hdfs::StorageTypeProto_IsValid(value));
  targetstoragetypes_.Add(value);
  // @@protoc_insertion_point(field_add:hadoop.hdfs.OpWriteBlockProto.targetStorageTypes)
}
inline const ::google::protobuf::RepeatedField<int>&
OpWriteBlockProto::targetstoragetypes() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.OpWriteBlockProto.targetStorageTypes)
  return targetstoragetypes_;
}
inline ::google::protobuf::RepeatedField<int>*
OpWriteBlockProto::mutable_targetstoragetypes() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.OpWriteBlockProto.targetStorageTypes)
  return &targetstoragetypes_;
}

// optional bool allowLazyPersist = 13 [default = false];
inline bool OpWriteBlockProto::has_allowlazypersist() const {
  return (_has_bits_[0] & 0x00000400u) != 0;
}
inline void OpWriteBlockProto::set_has_allowlazypersist() {
  _has_bits_[0] |= 0x00000400u;
}
inline void OpWriteBlockProto::clear_has_allowlazypersist() {
  _has_bits_[0] &= ~0x00000400u;
}
inline void OpWriteBlockProto::clear_allowlazypersist() {
  allowlazypersist_ = false;
  clear_has_allowlazypersist();
}
inline bool OpWriteBlockProto::allowlazypersist() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpWriteBlockProto.allowLazyPersist)
  return allowlazypersist_;
}
inline void OpWriteBlockProto::set_allowlazypersist(bool value) {
  set_has_allowlazypersist();
  allowlazypersist_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpWriteBlockProto.allowLazyPersist)
}

// optional bool pinning = 14 [default = false];
inline bool OpWriteBlockProto::has_pinning() const {
  return (_has_bits_[0] & 0x00000800u) != 0;
}
inline void OpWriteBlockProto::set_has_pinning() {
  _has_bits_[0] |= 0x00000800u;
}
inline void OpWriteBlockProto::clear_has_pinning() {
  _has_bits_[0] &= ~0x00000800u;
}
inline void OpWriteBlockProto::clear_pinning() {
  pinning_ = false;
  clear_has_pinning();
}
inline bool OpWriteBlockProto::pinning() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpWriteBlockProto.pinning)
  return pinning_;
}
inline void OpWriteBlockProto::set_pinning(bool value) {
  set_has_pinning();
  pinning_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpWriteBlockProto.pinning)
}

// repeated bool targetPinnings = 15;
inline int OpWriteBlockProto::targetpinnings_size() const {
  return targetpinnings_.size();
}
inline void OpWriteBlockProto::clear_targetpinnings() {
  targetpinnings_.Clear();
}
inline bool OpWriteBlockProto::targetpinnings(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpWriteBlockProto.targetPinnings)
  return targetpinnings_.Get(index);
}
inline void OpWriteBlockProto::set_targetpinnings(int index, bool value) {
  targetpinnings_.Set(index, value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpWriteBlockProto.targetPinnings)
}
inline void OpWriteBlockProto::add_targetpinnings(bool value) {
  targetpinnings_.Add(value);
  // @@protoc_insertion_point(field_add:hadoop.hdfs.OpWriteBlockProto.targetPinnings)
}
inline const ::google::protobuf::RepeatedField< bool >&
OpWriteBlockProto::targetpinnings() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.OpWriteBlockProto.targetPinnings)
  return targetpinnings_;
}
inline ::google::protobuf::RepeatedField< bool >*
OpWriteBlockProto::mutable_targetpinnings() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.OpWriteBlockProto.targetPinnings)
  return &targetpinnings_;
}

// optional string storageId = 16;
inline bool OpWriteBlockProto::has_storageid() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void OpWriteBlockProto::set_has_storageid() {
  _has_bits_[0] |= 0x00000001u;
}
inline void OpWriteBlockProto::clear_has_storageid() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void OpWriteBlockProto::clear_storageid() {
  storageid_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_storageid();
}
inline const ::std::string& OpWriteBlockProto::storageid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpWriteBlockProto.storageId)
  return storageid_.GetNoArena();
}
inline void OpWriteBlockProto::set_storageid(const ::std::string& value) {
  set_has_storageid();
  storageid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpWriteBlockProto.storageId)
}
#if LANG_CXX11
inline void OpWriteBlockProto::set_storageid(::std::string&& value) {
  set_has_storageid();
  storageid_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.OpWriteBlockProto.storageId)
}
#endif
inline void OpWriteBlockProto::set_storageid(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_storageid();
  storageid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.OpWriteBlockProto.storageId)
}
inline void OpWriteBlockProto::set_storageid(const char* value, size_t size) {
  set_has_storageid();
  storageid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.OpWriteBlockProto.storageId)
}
inline ::std::string* OpWriteBlockProto::mutable_storageid() {
  set_has_storageid();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.OpWriteBlockProto.storageId)
  return storageid_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* OpWriteBlockProto::release_storageid() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.OpWriteBlockProto.storageId)
  if (!has_storageid()) {
    return NULL;
  }
  clear_has_storageid();
  return storageid_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void OpWriteBlockProto::set_allocated_storageid(::std::string* storageid) {
  if (storageid != NULL) {
    set_has_storageid();
  } else {
    clear_has_storageid();
  }
  storageid_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), storageid);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.OpWriteBlockProto.storageId)
}

// repeated string targetStorageIds = 17;
inline int OpWriteBlockProto::targetstorageids_size() const {
  return targetstorageids_.size();
}
inline void OpWriteBlockProto::clear_targetstorageids() {
  targetstorageids_.Clear();
}
inline const ::std::string& OpWriteBlockProto::targetstorageids(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpWriteBlockProto.targetStorageIds)
  return targetstorageids_.Get(index);
}
inline ::std::string* OpWriteBlockProto::mutable_targetstorageids(int index) {
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.OpWriteBlockProto.targetStorageIds)
  return targetstorageids_.Mutable(index);
}
inline void OpWriteBlockProto::set_targetstorageids(int index, const ::std::string& value) {
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpWriteBlockProto.targetStorageIds)
  targetstorageids_.Mutable(index)->assign(value);
}
#if LANG_CXX11
inline void OpWriteBlockProto::set_targetstorageids(int index, ::std::string&& value) {
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpWriteBlockProto.targetStorageIds)
  targetstorageids_.Mutable(index)->assign(std::move(value));
}
#endif
inline void OpWriteBlockProto::set_targetstorageids(int index, const char* value) {
  GOOGLE_DCHECK(value != NULL);
  targetstorageids_.Mutable(index)->assign(value);
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.OpWriteBlockProto.targetStorageIds)
}
inline void OpWriteBlockProto::set_targetstorageids(int index, const char* value, size_t size) {
  targetstorageids_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.OpWriteBlockProto.targetStorageIds)
}
inline ::std::string* OpWriteBlockProto::add_targetstorageids() {
  // @@protoc_insertion_point(field_add_mutable:hadoop.hdfs.OpWriteBlockProto.targetStorageIds)
  return targetstorageids_.Add();
}
inline void OpWriteBlockProto::add_targetstorageids(const ::std::string& value) {
  targetstorageids_.Add()->assign(value);
  // @@protoc_insertion_point(field_add:hadoop.hdfs.OpWriteBlockProto.targetStorageIds)
}
#if LANG_CXX11
inline void OpWriteBlockProto::add_targetstorageids(::std::string&& value) {
  targetstorageids_.Add(std::move(value));
  // @@protoc_insertion_point(field_add:hadoop.hdfs.OpWriteBlockProto.targetStorageIds)
}
#endif
inline void OpWriteBlockProto::add_targetstorageids(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  targetstorageids_.Add()->assign(value);
  // @@protoc_insertion_point(field_add_char:hadoop.hdfs.OpWriteBlockProto.targetStorageIds)
}
inline void OpWriteBlockProto::add_targetstorageids(const char* value, size_t size) {
  targetstorageids_.Add()->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_add_pointer:hadoop.hdfs.OpWriteBlockProto.targetStorageIds)
}
inline const ::google::protobuf::RepeatedPtrField< ::std::string>&
OpWriteBlockProto::targetstorageids() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.OpWriteBlockProto.targetStorageIds)
  return targetstorageids_;
}
inline ::google::protobuf::RepeatedPtrField< ::std::string>*
OpWriteBlockProto::mutable_targetstorageids() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.OpWriteBlockProto.targetStorageIds)
  return &targetstorageids_;
}

// -------------------------------------------------------------------

// OpTransferBlockProto

// required .hadoop.hdfs.ClientOperationHeaderProto header = 1;
inline bool OpTransferBlockProto::has_header() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void OpTransferBlockProto::set_has_header() {
  _has_bits_[0] |= 0x00000001u;
}
inline void OpTransferBlockProto::clear_has_header() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void OpTransferBlockProto::clear_header() {
  if (header_ != NULL) header_->Clear();
  clear_has_header();
}
inline const ::hadoop::hdfs::ClientOperationHeaderProto& OpTransferBlockProto::_internal_header() const {
  return *header_;
}
inline const ::hadoop::hdfs::ClientOperationHeaderProto& OpTransferBlockProto::header() const {
  const ::hadoop::hdfs::ClientOperationHeaderProto* p = header_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpTransferBlockProto.header)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::ClientOperationHeaderProto*>(
      &::hadoop::hdfs::_ClientOperationHeaderProto_default_instance_);
}
inline ::hadoop::hdfs::ClientOperationHeaderProto* OpTransferBlockProto::release_header() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.OpTransferBlockProto.header)
  clear_has_header();
  ::hadoop::hdfs::ClientOperationHeaderProto* temp = header_;
  header_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::ClientOperationHeaderProto* OpTransferBlockProto::mutable_header() {
  set_has_header();
  if (header_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::ClientOperationHeaderProto>(GetArenaNoVirtual());
    header_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.OpTransferBlockProto.header)
  return header_;
}
inline void OpTransferBlockProto::set_allocated_header(::hadoop::hdfs::ClientOperationHeaderProto* header) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete header_;
  }
  if (header) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      header = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, header, submessage_arena);
    }
    set_has_header();
  } else {
    clear_has_header();
  }
  header_ = header;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.OpTransferBlockProto.header)
}

// repeated .hadoop.hdfs.DatanodeInfoProto targets = 2;
inline int OpTransferBlockProto::targets_size() const {
  return targets_.size();
}
inline ::hadoop::hdfs::DatanodeInfoProto* OpTransferBlockProto::mutable_targets(int index) {
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.OpTransferBlockProto.targets)
  return targets_.Mutable(index);
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::DatanodeInfoProto >*
OpTransferBlockProto::mutable_targets() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.OpTransferBlockProto.targets)
  return &targets_;
}
inline const ::hadoop::hdfs::DatanodeInfoProto& OpTransferBlockProto::targets(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpTransferBlockProto.targets)
  return targets_.Get(index);
}
inline ::hadoop::hdfs::DatanodeInfoProto* OpTransferBlockProto::add_targets() {
  // @@protoc_insertion_point(field_add:hadoop.hdfs.OpTransferBlockProto.targets)
  return targets_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::DatanodeInfoProto >&
OpTransferBlockProto::targets() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.OpTransferBlockProto.targets)
  return targets_;
}

// repeated .hadoop.hdfs.StorageTypeProto targetStorageTypes = 3;
inline int OpTransferBlockProto::targetstoragetypes_size() const {
  return targetstoragetypes_.size();
}
inline void OpTransferBlockProto::clear_targetstoragetypes() {
  targetstoragetypes_.Clear();
}
inline ::hadoop::hdfs::StorageTypeProto OpTransferBlockProto::targetstoragetypes(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpTransferBlockProto.targetStorageTypes)
  return static_cast< ::hadoop::hdfs::StorageTypeProto >(targetstoragetypes_.Get(index));
}
inline void OpTransferBlockProto::set_targetstoragetypes(int index, ::hadoop::hdfs::StorageTypeProto value) {
  assert(::hadoop::hdfs::StorageTypeProto_IsValid(value));
  targetstoragetypes_.Set(index, value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpTransferBlockProto.targetStorageTypes)
}
inline void OpTransferBlockProto::add_targetstoragetypes(::hadoop::hdfs::StorageTypeProto value) {
  assert(::hadoop::hdfs::StorageTypeProto_IsValid(value));
  targetstoragetypes_.Add(value);
  // @@protoc_insertion_point(field_add:hadoop.hdfs.OpTransferBlockProto.targetStorageTypes)
}
inline const ::google::protobuf::RepeatedField<int>&
OpTransferBlockProto::targetstoragetypes() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.OpTransferBlockProto.targetStorageTypes)
  return targetstoragetypes_;
}
inline ::google::protobuf::RepeatedField<int>*
OpTransferBlockProto::mutable_targetstoragetypes() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.OpTransferBlockProto.targetStorageTypes)
  return &targetstoragetypes_;
}

// repeated string targetStorageIds = 4;
inline int OpTransferBlockProto::targetstorageids_size() const {
  return targetstorageids_.size();
}
inline void OpTransferBlockProto::clear_targetstorageids() {
  targetstorageids_.Clear();
}
inline const ::std::string& OpTransferBlockProto::targetstorageids(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpTransferBlockProto.targetStorageIds)
  return targetstorageids_.Get(index);
}
inline ::std::string* OpTransferBlockProto::mutable_targetstorageids(int index) {
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.OpTransferBlockProto.targetStorageIds)
  return targetstorageids_.Mutable(index);
}
inline void OpTransferBlockProto::set_targetstorageids(int index, const ::std::string& value) {
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpTransferBlockProto.targetStorageIds)
  targetstorageids_.Mutable(index)->assign(value);
}
#if LANG_CXX11
inline void OpTransferBlockProto::set_targetstorageids(int index, ::std::string&& value) {
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpTransferBlockProto.targetStorageIds)
  targetstorageids_.Mutable(index)->assign(std::move(value));
}
#endif
inline void OpTransferBlockProto::set_targetstorageids(int index, const char* value) {
  GOOGLE_DCHECK(value != NULL);
  targetstorageids_.Mutable(index)->assign(value);
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.OpTransferBlockProto.targetStorageIds)
}
inline void OpTransferBlockProto::set_targetstorageids(int index, const char* value, size_t size) {
  targetstorageids_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.OpTransferBlockProto.targetStorageIds)
}
inline ::std::string* OpTransferBlockProto::add_targetstorageids() {
  // @@protoc_insertion_point(field_add_mutable:hadoop.hdfs.OpTransferBlockProto.targetStorageIds)
  return targetstorageids_.Add();
}
inline void OpTransferBlockProto::add_targetstorageids(const ::std::string& value) {
  targetstorageids_.Add()->assign(value);
  // @@protoc_insertion_point(field_add:hadoop.hdfs.OpTransferBlockProto.targetStorageIds)
}
#if LANG_CXX11
inline void OpTransferBlockProto::add_targetstorageids(::std::string&& value) {
  targetstorageids_.Add(std::move(value));
  // @@protoc_insertion_point(field_add:hadoop.hdfs.OpTransferBlockProto.targetStorageIds)
}
#endif
inline void OpTransferBlockProto::add_targetstorageids(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  targetstorageids_.Add()->assign(value);
  // @@protoc_insertion_point(field_add_char:hadoop.hdfs.OpTransferBlockProto.targetStorageIds)
}
inline void OpTransferBlockProto::add_targetstorageids(const char* value, size_t size) {
  targetstorageids_.Add()->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_add_pointer:hadoop.hdfs.OpTransferBlockProto.targetStorageIds)
}
inline const ::google::protobuf::RepeatedPtrField< ::std::string>&
OpTransferBlockProto::targetstorageids() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.OpTransferBlockProto.targetStorageIds)
  return targetstorageids_;
}
inline ::google::protobuf::RepeatedPtrField< ::std::string>*
OpTransferBlockProto::mutable_targetstorageids() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.OpTransferBlockProto.targetStorageIds)
  return &targetstorageids_;
}

// -------------------------------------------------------------------

// OpReplaceBlockProto

// required .hadoop.hdfs.BaseHeaderProto header = 1;
inline bool OpReplaceBlockProto::has_header() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void OpReplaceBlockProto::set_has_header() {
  _has_bits_[0] |= 0x00000004u;
}
inline void OpReplaceBlockProto::clear_has_header() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void OpReplaceBlockProto::clear_header() {
  if (header_ != NULL) header_->Clear();
  clear_has_header();
}
inline const ::hadoop::hdfs::BaseHeaderProto& OpReplaceBlockProto::_internal_header() const {
  return *header_;
}
inline const ::hadoop::hdfs::BaseHeaderProto& OpReplaceBlockProto::header() const {
  const ::hadoop::hdfs::BaseHeaderProto* p = header_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpReplaceBlockProto.header)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::BaseHeaderProto*>(
      &::hadoop::hdfs::_BaseHeaderProto_default_instance_);
}
inline ::hadoop::hdfs::BaseHeaderProto* OpReplaceBlockProto::release_header() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.OpReplaceBlockProto.header)
  clear_has_header();
  ::hadoop::hdfs::BaseHeaderProto* temp = header_;
  header_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::BaseHeaderProto* OpReplaceBlockProto::mutable_header() {
  set_has_header();
  if (header_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::BaseHeaderProto>(GetArenaNoVirtual());
    header_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.OpReplaceBlockProto.header)
  return header_;
}
inline void OpReplaceBlockProto::set_allocated_header(::hadoop::hdfs::BaseHeaderProto* header) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete header_;
  }
  if (header) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      header = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, header, submessage_arena);
    }
    set_has_header();
  } else {
    clear_has_header();
  }
  header_ = header;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.OpReplaceBlockProto.header)
}

// required string delHint = 2;
inline bool OpReplaceBlockProto::has_delhint() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void OpReplaceBlockProto::set_has_delhint() {
  _has_bits_[0] |= 0x00000001u;
}
inline void OpReplaceBlockProto::clear_has_delhint() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void OpReplaceBlockProto::clear_delhint() {
  delhint_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_delhint();
}
inline const ::std::string& OpReplaceBlockProto::delhint() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpReplaceBlockProto.delHint)
  return delhint_.GetNoArena();
}
inline void OpReplaceBlockProto::set_delhint(const ::std::string& value) {
  set_has_delhint();
  delhint_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpReplaceBlockProto.delHint)
}
#if LANG_CXX11
inline void OpReplaceBlockProto::set_delhint(::std::string&& value) {
  set_has_delhint();
  delhint_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.OpReplaceBlockProto.delHint)
}
#endif
inline void OpReplaceBlockProto::set_delhint(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_delhint();
  delhint_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.OpReplaceBlockProto.delHint)
}
inline void OpReplaceBlockProto::set_delhint(const char* value, size_t size) {
  set_has_delhint();
  delhint_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.OpReplaceBlockProto.delHint)
}
inline ::std::string* OpReplaceBlockProto::mutable_delhint() {
  set_has_delhint();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.OpReplaceBlockProto.delHint)
  return delhint_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* OpReplaceBlockProto::release_delhint() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.OpReplaceBlockProto.delHint)
  if (!has_delhint()) {
    return NULL;
  }
  clear_has_delhint();
  return delhint_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void OpReplaceBlockProto::set_allocated_delhint(::std::string* delhint) {
  if (delhint != NULL) {
    set_has_delhint();
  } else {
    clear_has_delhint();
  }
  delhint_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), delhint);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.OpReplaceBlockProto.delHint)
}

// required .hadoop.hdfs.DatanodeInfoProto source = 3;
inline bool OpReplaceBlockProto::has_source() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void OpReplaceBlockProto::set_has_source() {
  _has_bits_[0] |= 0x00000008u;
}
inline void OpReplaceBlockProto::clear_has_source() {
  _has_bits_[0] &= ~0x00000008u;
}
inline const ::hadoop::hdfs::DatanodeInfoProto& OpReplaceBlockProto::_internal_source() const {
  return *source_;
}
inline const ::hadoop::hdfs::DatanodeInfoProto& OpReplaceBlockProto::source() const {
  const ::hadoop::hdfs::DatanodeInfoProto* p = source_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpReplaceBlockProto.source)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::DatanodeInfoProto*>(
      &::hadoop::hdfs::_DatanodeInfoProto_default_instance_);
}
inline ::hadoop::hdfs::DatanodeInfoProto* OpReplaceBlockProto::release_source() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.OpReplaceBlockProto.source)
  clear_has_source();
  ::hadoop::hdfs::DatanodeInfoProto* temp = source_;
  source_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::DatanodeInfoProto* OpReplaceBlockProto::mutable_source() {
  set_has_source();
  if (source_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::DatanodeInfoProto>(GetArenaNoVirtual());
    source_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.OpReplaceBlockProto.source)
  return source_;
}
inline void OpReplaceBlockProto::set_allocated_source(::hadoop::hdfs::DatanodeInfoProto* source) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete reinterpret_cast< ::google::protobuf::MessageLite*>(source_);
  }
  if (source) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      source = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, source, submessage_arena);
    }
    set_has_source();
  } else {
    clear_has_source();
  }
  source_ = source;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.OpReplaceBlockProto.source)
}

// optional .hadoop.hdfs.StorageTypeProto storageType = 4 [default = DISK];
inline bool OpReplaceBlockProto::has_storagetype() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void OpReplaceBlockProto::set_has_storagetype() {
  _has_bits_[0] |= 0x00000010u;
}
inline void OpReplaceBlockProto::clear_has_storagetype() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void OpReplaceBlockProto::clear_storagetype() {
  storagetype_ = 1;
  clear_has_storagetype();
}
inline ::hadoop::hdfs::StorageTypeProto OpReplaceBlockProto::storagetype() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpReplaceBlockProto.storageType)
  return static_cast< ::hadoop::hdfs::StorageTypeProto >(storagetype_);
}
inline void OpReplaceBlockProto::set_storagetype(::hadoop::hdfs::StorageTypeProto value) {
  assert(::hadoop::hdfs::StorageTypeProto_IsValid(value));
  set_has_storagetype();
  storagetype_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpReplaceBlockProto.storageType)
}

// optional string storageId = 5;
inline bool OpReplaceBlockProto::has_storageid() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void OpReplaceBlockProto::set_has_storageid() {
  _has_bits_[0] |= 0x00000002u;
}
inline void OpReplaceBlockProto::clear_has_storageid() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void OpReplaceBlockProto::clear_storageid() {
  storageid_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_storageid();
}
inline const ::std::string& OpReplaceBlockProto::storageid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpReplaceBlockProto.storageId)
  return storageid_.GetNoArena();
}
inline void OpReplaceBlockProto::set_storageid(const ::std::string& value) {
  set_has_storageid();
  storageid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpReplaceBlockProto.storageId)
}
#if LANG_CXX11
inline void OpReplaceBlockProto::set_storageid(::std::string&& value) {
  set_has_storageid();
  storageid_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.OpReplaceBlockProto.storageId)
}
#endif
inline void OpReplaceBlockProto::set_storageid(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_storageid();
  storageid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.OpReplaceBlockProto.storageId)
}
inline void OpReplaceBlockProto::set_storageid(const char* value, size_t size) {
  set_has_storageid();
  storageid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.OpReplaceBlockProto.storageId)
}
inline ::std::string* OpReplaceBlockProto::mutable_storageid() {
  set_has_storageid();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.OpReplaceBlockProto.storageId)
  return storageid_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* OpReplaceBlockProto::release_storageid() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.OpReplaceBlockProto.storageId)
  if (!has_storageid()) {
    return NULL;
  }
  clear_has_storageid();
  return storageid_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void OpReplaceBlockProto::set_allocated_storageid(::std::string* storageid) {
  if (storageid != NULL) {
    set_has_storageid();
  } else {
    clear_has_storageid();
  }
  storageid_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), storageid);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.OpReplaceBlockProto.storageId)
}

// -------------------------------------------------------------------

// OpCopyBlockProto

// required .hadoop.hdfs.BaseHeaderProto header = 1;
inline bool OpCopyBlockProto::has_header() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void OpCopyBlockProto::set_has_header() {
  _has_bits_[0] |= 0x00000001u;
}
inline void OpCopyBlockProto::clear_has_header() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void OpCopyBlockProto::clear_header() {
  if (header_ != NULL) header_->Clear();
  clear_has_header();
}
inline const ::hadoop::hdfs::BaseHeaderProto& OpCopyBlockProto::_internal_header() const {
  return *header_;
}
inline const ::hadoop::hdfs::BaseHeaderProto& OpCopyBlockProto::header() const {
  const ::hadoop::hdfs::BaseHeaderProto* p = header_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpCopyBlockProto.header)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::BaseHeaderProto*>(
      &::hadoop::hdfs::_BaseHeaderProto_default_instance_);
}
inline ::hadoop::hdfs::BaseHeaderProto* OpCopyBlockProto::release_header() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.OpCopyBlockProto.header)
  clear_has_header();
  ::hadoop::hdfs::BaseHeaderProto* temp = header_;
  header_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::BaseHeaderProto* OpCopyBlockProto::mutable_header() {
  set_has_header();
  if (header_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::BaseHeaderProto>(GetArenaNoVirtual());
    header_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.OpCopyBlockProto.header)
  return header_;
}
inline void OpCopyBlockProto::set_allocated_header(::hadoop::hdfs::BaseHeaderProto* header) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete header_;
  }
  if (header) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      header = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, header, submessage_arena);
    }
    set_has_header();
  } else {
    clear_has_header();
  }
  header_ = header;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.OpCopyBlockProto.header)
}

// -------------------------------------------------------------------

// OpBlockChecksumProto

// required .hadoop.hdfs.BaseHeaderProto header = 1;
inline bool OpBlockChecksumProto::has_header() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void OpBlockChecksumProto::set_has_header() {
  _has_bits_[0] |= 0x00000001u;
}
inline void OpBlockChecksumProto::clear_has_header() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void OpBlockChecksumProto::clear_header() {
  if (header_ != NULL) header_->Clear();
  clear_has_header();
}
inline const ::hadoop::hdfs::BaseHeaderProto& OpBlockChecksumProto::_internal_header() const {
  return *header_;
}
inline const ::hadoop::hdfs::BaseHeaderProto& OpBlockChecksumProto::header() const {
  const ::hadoop::hdfs::BaseHeaderProto* p = header_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpBlockChecksumProto.header)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::BaseHeaderProto*>(
      &::hadoop::hdfs::_BaseHeaderProto_default_instance_);
}
inline ::hadoop::hdfs::BaseHeaderProto* OpBlockChecksumProto::release_header() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.OpBlockChecksumProto.header)
  clear_has_header();
  ::hadoop::hdfs::BaseHeaderProto* temp = header_;
  header_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::BaseHeaderProto* OpBlockChecksumProto::mutable_header() {
  set_has_header();
  if (header_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::BaseHeaderProto>(GetArenaNoVirtual());
    header_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.OpBlockChecksumProto.header)
  return header_;
}
inline void OpBlockChecksumProto::set_allocated_header(::hadoop::hdfs::BaseHeaderProto* header) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete header_;
  }
  if (header) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      header = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, header, submessage_arena);
    }
    set_has_header();
  } else {
    clear_has_header();
  }
  header_ = header;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.OpBlockChecksumProto.header)
}

// optional .hadoop.hdfs.BlockChecksumOptionsProto blockChecksumOptions = 2;
inline bool OpBlockChecksumProto::has_blockchecksumoptions() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void OpBlockChecksumProto::set_has_blockchecksumoptions() {
  _has_bits_[0] |= 0x00000002u;
}
inline void OpBlockChecksumProto::clear_has_blockchecksumoptions() {
  _has_bits_[0] &= ~0x00000002u;
}
inline const ::hadoop::hdfs::BlockChecksumOptionsProto& OpBlockChecksumProto::_internal_blockchecksumoptions() const {
  return *blockchecksumoptions_;
}
inline const ::hadoop::hdfs::BlockChecksumOptionsProto& OpBlockChecksumProto::blockchecksumoptions() const {
  const ::hadoop::hdfs::BlockChecksumOptionsProto* p = blockchecksumoptions_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpBlockChecksumProto.blockChecksumOptions)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::BlockChecksumOptionsProto*>(
      &::hadoop::hdfs::_BlockChecksumOptionsProto_default_instance_);
}
inline ::hadoop::hdfs::BlockChecksumOptionsProto* OpBlockChecksumProto::release_blockchecksumoptions() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.OpBlockChecksumProto.blockChecksumOptions)
  clear_has_blockchecksumoptions();
  ::hadoop::hdfs::BlockChecksumOptionsProto* temp = blockchecksumoptions_;
  blockchecksumoptions_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::BlockChecksumOptionsProto* OpBlockChecksumProto::mutable_blockchecksumoptions() {
  set_has_blockchecksumoptions();
  if (blockchecksumoptions_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::BlockChecksumOptionsProto>(GetArenaNoVirtual());
    blockchecksumoptions_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.OpBlockChecksumProto.blockChecksumOptions)
  return blockchecksumoptions_;
}
inline void OpBlockChecksumProto::set_allocated_blockchecksumoptions(::hadoop::hdfs::BlockChecksumOptionsProto* blockchecksumoptions) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete reinterpret_cast< ::google::protobuf::MessageLite*>(blockchecksumoptions_);
  }
  if (blockchecksumoptions) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      blockchecksumoptions = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, blockchecksumoptions, submessage_arena);
    }
    set_has_blockchecksumoptions();
  } else {
    clear_has_blockchecksumoptions();
  }
  blockchecksumoptions_ = blockchecksumoptions;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.OpBlockChecksumProto.blockChecksumOptions)
}

// -------------------------------------------------------------------

// OpBlockGroupChecksumProto

// required .hadoop.hdfs.BaseHeaderProto header = 1;
inline bool OpBlockGroupChecksumProto::has_header() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void OpBlockGroupChecksumProto::set_has_header() {
  _has_bits_[0] |= 0x00000001u;
}
inline void OpBlockGroupChecksumProto::clear_has_header() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void OpBlockGroupChecksumProto::clear_header() {
  if (header_ != NULL) header_->Clear();
  clear_has_header();
}
inline const ::hadoop::hdfs::BaseHeaderProto& OpBlockGroupChecksumProto::_internal_header() const {
  return *header_;
}
inline const ::hadoop::hdfs::BaseHeaderProto& OpBlockGroupChecksumProto::header() const {
  const ::hadoop::hdfs::BaseHeaderProto* p = header_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpBlockGroupChecksumProto.header)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::BaseHeaderProto*>(
      &::hadoop::hdfs::_BaseHeaderProto_default_instance_);
}
inline ::hadoop::hdfs::BaseHeaderProto* OpBlockGroupChecksumProto::release_header() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.OpBlockGroupChecksumProto.header)
  clear_has_header();
  ::hadoop::hdfs::BaseHeaderProto* temp = header_;
  header_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::BaseHeaderProto* OpBlockGroupChecksumProto::mutable_header() {
  set_has_header();
  if (header_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::BaseHeaderProto>(GetArenaNoVirtual());
    header_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.OpBlockGroupChecksumProto.header)
  return header_;
}
inline void OpBlockGroupChecksumProto::set_allocated_header(::hadoop::hdfs::BaseHeaderProto* header) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete header_;
  }
  if (header) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      header = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, header, submessage_arena);
    }
    set_has_header();
  } else {
    clear_has_header();
  }
  header_ = header;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.OpBlockGroupChecksumProto.header)
}

// required .hadoop.hdfs.DatanodeInfosProto datanodes = 2;
inline bool OpBlockGroupChecksumProto::has_datanodes() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void OpBlockGroupChecksumProto::set_has_datanodes() {
  _has_bits_[0] |= 0x00000002u;
}
inline void OpBlockGroupChecksumProto::clear_has_datanodes() {
  _has_bits_[0] &= ~0x00000002u;
}
inline const ::hadoop::hdfs::DatanodeInfosProto& OpBlockGroupChecksumProto::_internal_datanodes() const {
  return *datanodes_;
}
inline const ::hadoop::hdfs::DatanodeInfosProto& OpBlockGroupChecksumProto::datanodes() const {
  const ::hadoop::hdfs::DatanodeInfosProto* p = datanodes_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpBlockGroupChecksumProto.datanodes)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::DatanodeInfosProto*>(
      &::hadoop::hdfs::_DatanodeInfosProto_default_instance_);
}
inline ::hadoop::hdfs::DatanodeInfosProto* OpBlockGroupChecksumProto::release_datanodes() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.OpBlockGroupChecksumProto.datanodes)
  clear_has_datanodes();
  ::hadoop::hdfs::DatanodeInfosProto* temp = datanodes_;
  datanodes_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::DatanodeInfosProto* OpBlockGroupChecksumProto::mutable_datanodes() {
  set_has_datanodes();
  if (datanodes_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::DatanodeInfosProto>(GetArenaNoVirtual());
    datanodes_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.OpBlockGroupChecksumProto.datanodes)
  return datanodes_;
}
inline void OpBlockGroupChecksumProto::set_allocated_datanodes(::hadoop::hdfs::DatanodeInfosProto* datanodes) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete reinterpret_cast< ::google::protobuf::MessageLite*>(datanodes_);
  }
  if (datanodes) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      datanodes = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, datanodes, submessage_arena);
    }
    set_has_datanodes();
  } else {
    clear_has_datanodes();
  }
  datanodes_ = datanodes;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.OpBlockGroupChecksumProto.datanodes)
}

// repeated .hadoop.common.TokenProto blockTokens = 3;
inline int OpBlockGroupChecksumProto::blocktokens_size() const {
  return blocktokens_.size();
}
inline ::hadoop::common::TokenProto* OpBlockGroupChecksumProto::mutable_blocktokens(int index) {
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.OpBlockGroupChecksumProto.blockTokens)
  return blocktokens_.Mutable(index);
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::common::TokenProto >*
OpBlockGroupChecksumProto::mutable_blocktokens() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.OpBlockGroupChecksumProto.blockTokens)
  return &blocktokens_;
}
inline const ::hadoop::common::TokenProto& OpBlockGroupChecksumProto::blocktokens(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpBlockGroupChecksumProto.blockTokens)
  return blocktokens_.Get(index);
}
inline ::hadoop::common::TokenProto* OpBlockGroupChecksumProto::add_blocktokens() {
  // @@protoc_insertion_point(field_add:hadoop.hdfs.OpBlockGroupChecksumProto.blockTokens)
  return blocktokens_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::common::TokenProto >&
OpBlockGroupChecksumProto::blocktokens() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.OpBlockGroupChecksumProto.blockTokens)
  return blocktokens_;
}

// required .hadoop.hdfs.ErasureCodingPolicyProto ecPolicy = 4;
inline bool OpBlockGroupChecksumProto::has_ecpolicy() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void OpBlockGroupChecksumProto::set_has_ecpolicy() {
  _has_bits_[0] |= 0x00000004u;
}
inline void OpBlockGroupChecksumProto::clear_has_ecpolicy() {
  _has_bits_[0] &= ~0x00000004u;
}
inline const ::hadoop::hdfs::ErasureCodingPolicyProto& OpBlockGroupChecksumProto::_internal_ecpolicy() const {
  return *ecpolicy_;
}
inline const ::hadoop::hdfs::ErasureCodingPolicyProto& OpBlockGroupChecksumProto::ecpolicy() const {
  const ::hadoop::hdfs::ErasureCodingPolicyProto* p = ecpolicy_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpBlockGroupChecksumProto.ecPolicy)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::ErasureCodingPolicyProto*>(
      &::hadoop::hdfs::_ErasureCodingPolicyProto_default_instance_);
}
inline ::hadoop::hdfs::ErasureCodingPolicyProto* OpBlockGroupChecksumProto::release_ecpolicy() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.OpBlockGroupChecksumProto.ecPolicy)
  clear_has_ecpolicy();
  ::hadoop::hdfs::ErasureCodingPolicyProto* temp = ecpolicy_;
  ecpolicy_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::ErasureCodingPolicyProto* OpBlockGroupChecksumProto::mutable_ecpolicy() {
  set_has_ecpolicy();
  if (ecpolicy_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::ErasureCodingPolicyProto>(GetArenaNoVirtual());
    ecpolicy_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.OpBlockGroupChecksumProto.ecPolicy)
  return ecpolicy_;
}
inline void OpBlockGroupChecksumProto::set_allocated_ecpolicy(::hadoop::hdfs::ErasureCodingPolicyProto* ecpolicy) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete reinterpret_cast< ::google::protobuf::MessageLite*>(ecpolicy_);
  }
  if (ecpolicy) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      ecpolicy = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, ecpolicy, submessage_arena);
    }
    set_has_ecpolicy();
  } else {
    clear_has_ecpolicy();
  }
  ecpolicy_ = ecpolicy;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.OpBlockGroupChecksumProto.ecPolicy)
}

// repeated uint32 blockIndices = 5;
inline int OpBlockGroupChecksumProto::blockindices_size() const {
  return blockindices_.size();
}
inline void OpBlockGroupChecksumProto::clear_blockindices() {
  blockindices_.Clear();
}
inline ::google::protobuf::uint32 OpBlockGroupChecksumProto::blockindices(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpBlockGroupChecksumProto.blockIndices)
  return blockindices_.Get(index);
}
inline void OpBlockGroupChecksumProto::set_blockindices(int index, ::google::protobuf::uint32 value) {
  blockindices_.Set(index, value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpBlockGroupChecksumProto.blockIndices)
}
inline void OpBlockGroupChecksumProto::add_blockindices(::google::protobuf::uint32 value) {
  blockindices_.Add(value);
  // @@protoc_insertion_point(field_add:hadoop.hdfs.OpBlockGroupChecksumProto.blockIndices)
}
inline const ::google::protobuf::RepeatedField< ::google::protobuf::uint32 >&
OpBlockGroupChecksumProto::blockindices() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.OpBlockGroupChecksumProto.blockIndices)
  return blockindices_;
}
inline ::google::protobuf::RepeatedField< ::google::protobuf::uint32 >*
OpBlockGroupChecksumProto::mutable_blockindices() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.OpBlockGroupChecksumProto.blockIndices)
  return &blockindices_;
}

// required uint64 requestedNumBytes = 6;
inline bool OpBlockGroupChecksumProto::has_requestednumbytes() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void OpBlockGroupChecksumProto::set_has_requestednumbytes() {
  _has_bits_[0] |= 0x00000010u;
}
inline void OpBlockGroupChecksumProto::clear_has_requestednumbytes() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void OpBlockGroupChecksumProto::clear_requestednumbytes() {
  requestednumbytes_ = GOOGLE_ULONGLONG(0);
  clear_has_requestednumbytes();
}
inline ::google::protobuf::uint64 OpBlockGroupChecksumProto::requestednumbytes() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpBlockGroupChecksumProto.requestedNumBytes)
  return requestednumbytes_;
}
inline void OpBlockGroupChecksumProto::set_requestednumbytes(::google::protobuf::uint64 value) {
  set_has_requestednumbytes();
  requestednumbytes_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpBlockGroupChecksumProto.requestedNumBytes)
}

// optional .hadoop.hdfs.BlockChecksumOptionsProto blockChecksumOptions = 7;
inline bool OpBlockGroupChecksumProto::has_blockchecksumoptions() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void OpBlockGroupChecksumProto::set_has_blockchecksumoptions() {
  _has_bits_[0] |= 0x00000008u;
}
inline void OpBlockGroupChecksumProto::clear_has_blockchecksumoptions() {
  _has_bits_[0] &= ~0x00000008u;
}
inline const ::hadoop::hdfs::BlockChecksumOptionsProto& OpBlockGroupChecksumProto::_internal_blockchecksumoptions() const {
  return *blockchecksumoptions_;
}
inline const ::hadoop::hdfs::BlockChecksumOptionsProto& OpBlockGroupChecksumProto::blockchecksumoptions() const {
  const ::hadoop::hdfs::BlockChecksumOptionsProto* p = blockchecksumoptions_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpBlockGroupChecksumProto.blockChecksumOptions)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::BlockChecksumOptionsProto*>(
      &::hadoop::hdfs::_BlockChecksumOptionsProto_default_instance_);
}
inline ::hadoop::hdfs::BlockChecksumOptionsProto* OpBlockGroupChecksumProto::release_blockchecksumoptions() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.OpBlockGroupChecksumProto.blockChecksumOptions)
  clear_has_blockchecksumoptions();
  ::hadoop::hdfs::BlockChecksumOptionsProto* temp = blockchecksumoptions_;
  blockchecksumoptions_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::BlockChecksumOptionsProto* OpBlockGroupChecksumProto::mutable_blockchecksumoptions() {
  set_has_blockchecksumoptions();
  if (blockchecksumoptions_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::BlockChecksumOptionsProto>(GetArenaNoVirtual());
    blockchecksumoptions_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.OpBlockGroupChecksumProto.blockChecksumOptions)
  return blockchecksumoptions_;
}
inline void OpBlockGroupChecksumProto::set_allocated_blockchecksumoptions(::hadoop::hdfs::BlockChecksumOptionsProto* blockchecksumoptions) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete reinterpret_cast< ::google::protobuf::MessageLite*>(blockchecksumoptions_);
  }
  if (blockchecksumoptions) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      blockchecksumoptions = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, blockchecksumoptions, submessage_arena);
    }
    set_has_blockchecksumoptions();
  } else {
    clear_has_blockchecksumoptions();
  }
  blockchecksumoptions_ = blockchecksumoptions;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.OpBlockGroupChecksumProto.blockChecksumOptions)
}

// -------------------------------------------------------------------

// ShortCircuitShmIdProto

// required int64 hi = 1;
inline bool ShortCircuitShmIdProto::has_hi() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ShortCircuitShmIdProto::set_has_hi() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ShortCircuitShmIdProto::clear_has_hi() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ShortCircuitShmIdProto::clear_hi() {
  hi_ = GOOGLE_LONGLONG(0);
  clear_has_hi();
}
inline ::google::protobuf::int64 ShortCircuitShmIdProto::hi() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ShortCircuitShmIdProto.hi)
  return hi_;
}
inline void ShortCircuitShmIdProto::set_hi(::google::protobuf::int64 value) {
  set_has_hi();
  hi_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ShortCircuitShmIdProto.hi)
}

// required int64 lo = 2;
inline bool ShortCircuitShmIdProto::has_lo() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ShortCircuitShmIdProto::set_has_lo() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ShortCircuitShmIdProto::clear_has_lo() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ShortCircuitShmIdProto::clear_lo() {
  lo_ = GOOGLE_LONGLONG(0);
  clear_has_lo();
}
inline ::google::protobuf::int64 ShortCircuitShmIdProto::lo() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ShortCircuitShmIdProto.lo)
  return lo_;
}
inline void ShortCircuitShmIdProto::set_lo(::google::protobuf::int64 value) {
  set_has_lo();
  lo_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ShortCircuitShmIdProto.lo)
}

// -------------------------------------------------------------------

// ShortCircuitShmSlotProto

// required .hadoop.hdfs.ShortCircuitShmIdProto shmId = 1;
inline bool ShortCircuitShmSlotProto::has_shmid() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ShortCircuitShmSlotProto::set_has_shmid() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ShortCircuitShmSlotProto::clear_has_shmid() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ShortCircuitShmSlotProto::clear_shmid() {
  if (shmid_ != NULL) shmid_->Clear();
  clear_has_shmid();
}
inline const ::hadoop::hdfs::ShortCircuitShmIdProto& ShortCircuitShmSlotProto::_internal_shmid() const {
  return *shmid_;
}
inline const ::hadoop::hdfs::ShortCircuitShmIdProto& ShortCircuitShmSlotProto::shmid() const {
  const ::hadoop::hdfs::ShortCircuitShmIdProto* p = shmid_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ShortCircuitShmSlotProto.shmId)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::ShortCircuitShmIdProto*>(
      &::hadoop::hdfs::_ShortCircuitShmIdProto_default_instance_);
}
inline ::hadoop::hdfs::ShortCircuitShmIdProto* ShortCircuitShmSlotProto::release_shmid() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.ShortCircuitShmSlotProto.shmId)
  clear_has_shmid();
  ::hadoop::hdfs::ShortCircuitShmIdProto* temp = shmid_;
  shmid_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::ShortCircuitShmIdProto* ShortCircuitShmSlotProto::mutable_shmid() {
  set_has_shmid();
  if (shmid_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::ShortCircuitShmIdProto>(GetArenaNoVirtual());
    shmid_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.ShortCircuitShmSlotProto.shmId)
  return shmid_;
}
inline void ShortCircuitShmSlotProto::set_allocated_shmid(::hadoop::hdfs::ShortCircuitShmIdProto* shmid) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete shmid_;
  }
  if (shmid) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      shmid = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, shmid, submessage_arena);
    }
    set_has_shmid();
  } else {
    clear_has_shmid();
  }
  shmid_ = shmid;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.ShortCircuitShmSlotProto.shmId)
}

// required int32 slotIdx = 2;
inline bool ShortCircuitShmSlotProto::has_slotidx() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ShortCircuitShmSlotProto::set_has_slotidx() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ShortCircuitShmSlotProto::clear_has_slotidx() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ShortCircuitShmSlotProto::clear_slotidx() {
  slotidx_ = 0;
  clear_has_slotidx();
}
inline ::google::protobuf::int32 ShortCircuitShmSlotProto::slotidx() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ShortCircuitShmSlotProto.slotIdx)
  return slotidx_;
}
inline void ShortCircuitShmSlotProto::set_slotidx(::google::protobuf::int32 value) {
  set_has_slotidx();
  slotidx_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ShortCircuitShmSlotProto.slotIdx)
}

// -------------------------------------------------------------------

// OpRequestShortCircuitAccessProto

// required .hadoop.hdfs.BaseHeaderProto header = 1;
inline bool OpRequestShortCircuitAccessProto::has_header() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void OpRequestShortCircuitAccessProto::set_has_header() {
  _has_bits_[0] |= 0x00000001u;
}
inline void OpRequestShortCircuitAccessProto::clear_has_header() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void OpRequestShortCircuitAccessProto::clear_header() {
  if (header_ != NULL) header_->Clear();
  clear_has_header();
}
inline const ::hadoop::hdfs::BaseHeaderProto& OpRequestShortCircuitAccessProto::_internal_header() const {
  return *header_;
}
inline const ::hadoop::hdfs::BaseHeaderProto& OpRequestShortCircuitAccessProto::header() const {
  const ::hadoop::hdfs::BaseHeaderProto* p = header_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpRequestShortCircuitAccessProto.header)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::BaseHeaderProto*>(
      &::hadoop::hdfs::_BaseHeaderProto_default_instance_);
}
inline ::hadoop::hdfs::BaseHeaderProto* OpRequestShortCircuitAccessProto::release_header() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.OpRequestShortCircuitAccessProto.header)
  clear_has_header();
  ::hadoop::hdfs::BaseHeaderProto* temp = header_;
  header_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::BaseHeaderProto* OpRequestShortCircuitAccessProto::mutable_header() {
  set_has_header();
  if (header_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::BaseHeaderProto>(GetArenaNoVirtual());
    header_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.OpRequestShortCircuitAccessProto.header)
  return header_;
}
inline void OpRequestShortCircuitAccessProto::set_allocated_header(::hadoop::hdfs::BaseHeaderProto* header) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete header_;
  }
  if (header) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      header = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, header, submessage_arena);
    }
    set_has_header();
  } else {
    clear_has_header();
  }
  header_ = header;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.OpRequestShortCircuitAccessProto.header)
}

// required uint32 maxVersion = 2;
inline bool OpRequestShortCircuitAccessProto::has_maxversion() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void OpRequestShortCircuitAccessProto::set_has_maxversion() {
  _has_bits_[0] |= 0x00000004u;
}
inline void OpRequestShortCircuitAccessProto::clear_has_maxversion() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void OpRequestShortCircuitAccessProto::clear_maxversion() {
  maxversion_ = 0u;
  clear_has_maxversion();
}
inline ::google::protobuf::uint32 OpRequestShortCircuitAccessProto::maxversion() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpRequestShortCircuitAccessProto.maxVersion)
  return maxversion_;
}
inline void OpRequestShortCircuitAccessProto::set_maxversion(::google::protobuf::uint32 value) {
  set_has_maxversion();
  maxversion_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpRequestShortCircuitAccessProto.maxVersion)
}

// optional .hadoop.hdfs.ShortCircuitShmSlotProto slotId = 3;
inline bool OpRequestShortCircuitAccessProto::has_slotid() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void OpRequestShortCircuitAccessProto::set_has_slotid() {
  _has_bits_[0] |= 0x00000002u;
}
inline void OpRequestShortCircuitAccessProto::clear_has_slotid() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void OpRequestShortCircuitAccessProto::clear_slotid() {
  if (slotid_ != NULL) slotid_->Clear();
  clear_has_slotid();
}
inline const ::hadoop::hdfs::ShortCircuitShmSlotProto& OpRequestShortCircuitAccessProto::_internal_slotid() const {
  return *slotid_;
}
inline const ::hadoop::hdfs::ShortCircuitShmSlotProto& OpRequestShortCircuitAccessProto::slotid() const {
  const ::hadoop::hdfs::ShortCircuitShmSlotProto* p = slotid_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpRequestShortCircuitAccessProto.slotId)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::ShortCircuitShmSlotProto*>(
      &::hadoop::hdfs::_ShortCircuitShmSlotProto_default_instance_);
}
inline ::hadoop::hdfs::ShortCircuitShmSlotProto* OpRequestShortCircuitAccessProto::release_slotid() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.OpRequestShortCircuitAccessProto.slotId)
  clear_has_slotid();
  ::hadoop::hdfs::ShortCircuitShmSlotProto* temp = slotid_;
  slotid_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::ShortCircuitShmSlotProto* OpRequestShortCircuitAccessProto::mutable_slotid() {
  set_has_slotid();
  if (slotid_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::ShortCircuitShmSlotProto>(GetArenaNoVirtual());
    slotid_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.OpRequestShortCircuitAccessProto.slotId)
  return slotid_;
}
inline void OpRequestShortCircuitAccessProto::set_allocated_slotid(::hadoop::hdfs::ShortCircuitShmSlotProto* slotid) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete slotid_;
  }
  if (slotid) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      slotid = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, slotid, submessage_arena);
    }
    set_has_slotid();
  } else {
    clear_has_slotid();
  }
  slotid_ = slotid;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.OpRequestShortCircuitAccessProto.slotId)
}

// optional bool supportsReceiptVerification = 4 [default = false];
inline bool OpRequestShortCircuitAccessProto::has_supportsreceiptverification() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void OpRequestShortCircuitAccessProto::set_has_supportsreceiptverification() {
  _has_bits_[0] |= 0x00000008u;
}
inline void OpRequestShortCircuitAccessProto::clear_has_supportsreceiptverification() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void OpRequestShortCircuitAccessProto::clear_supportsreceiptverification() {
  supportsreceiptverification_ = false;
  clear_has_supportsreceiptverification();
}
inline bool OpRequestShortCircuitAccessProto::supportsreceiptverification() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpRequestShortCircuitAccessProto.supportsReceiptVerification)
  return supportsreceiptverification_;
}
inline void OpRequestShortCircuitAccessProto::set_supportsreceiptverification(bool value) {
  set_has_supportsreceiptverification();
  supportsreceiptverification_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpRequestShortCircuitAccessProto.supportsReceiptVerification)
}

// -------------------------------------------------------------------

// ReleaseShortCircuitAccessRequestProto

// required .hadoop.hdfs.ShortCircuitShmSlotProto slotId = 1;
inline bool ReleaseShortCircuitAccessRequestProto::has_slotid() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ReleaseShortCircuitAccessRequestProto::set_has_slotid() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ReleaseShortCircuitAccessRequestProto::clear_has_slotid() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ReleaseShortCircuitAccessRequestProto::clear_slotid() {
  if (slotid_ != NULL) slotid_->Clear();
  clear_has_slotid();
}
inline const ::hadoop::hdfs::ShortCircuitShmSlotProto& ReleaseShortCircuitAccessRequestProto::_internal_slotid() const {
  return *slotid_;
}
inline const ::hadoop::hdfs::ShortCircuitShmSlotProto& ReleaseShortCircuitAccessRequestProto::slotid() const {
  const ::hadoop::hdfs::ShortCircuitShmSlotProto* p = slotid_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ReleaseShortCircuitAccessRequestProto.slotId)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::ShortCircuitShmSlotProto*>(
      &::hadoop::hdfs::_ShortCircuitShmSlotProto_default_instance_);
}
inline ::hadoop::hdfs::ShortCircuitShmSlotProto* ReleaseShortCircuitAccessRequestProto::release_slotid() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.ReleaseShortCircuitAccessRequestProto.slotId)
  clear_has_slotid();
  ::hadoop::hdfs::ShortCircuitShmSlotProto* temp = slotid_;
  slotid_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::ShortCircuitShmSlotProto* ReleaseShortCircuitAccessRequestProto::mutable_slotid() {
  set_has_slotid();
  if (slotid_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::ShortCircuitShmSlotProto>(GetArenaNoVirtual());
    slotid_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.ReleaseShortCircuitAccessRequestProto.slotId)
  return slotid_;
}
inline void ReleaseShortCircuitAccessRequestProto::set_allocated_slotid(::hadoop::hdfs::ShortCircuitShmSlotProto* slotid) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete slotid_;
  }
  if (slotid) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      slotid = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, slotid, submessage_arena);
    }
    set_has_slotid();
  } else {
    clear_has_slotid();
  }
  slotid_ = slotid;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.ReleaseShortCircuitAccessRequestProto.slotId)
}

// optional .hadoop.hdfs.DataTransferTraceInfoProto traceInfo = 2;
inline bool ReleaseShortCircuitAccessRequestProto::has_traceinfo() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ReleaseShortCircuitAccessRequestProto::set_has_traceinfo() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ReleaseShortCircuitAccessRequestProto::clear_has_traceinfo() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ReleaseShortCircuitAccessRequestProto::clear_traceinfo() {
  if (traceinfo_ != NULL) traceinfo_->Clear();
  clear_has_traceinfo();
}
inline const ::hadoop::hdfs::DataTransferTraceInfoProto& ReleaseShortCircuitAccessRequestProto::_internal_traceinfo() const {
  return *traceinfo_;
}
inline const ::hadoop::hdfs::DataTransferTraceInfoProto& ReleaseShortCircuitAccessRequestProto::traceinfo() const {
  const ::hadoop::hdfs::DataTransferTraceInfoProto* p = traceinfo_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ReleaseShortCircuitAccessRequestProto.traceInfo)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::DataTransferTraceInfoProto*>(
      &::hadoop::hdfs::_DataTransferTraceInfoProto_default_instance_);
}
inline ::hadoop::hdfs::DataTransferTraceInfoProto* ReleaseShortCircuitAccessRequestProto::release_traceinfo() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.ReleaseShortCircuitAccessRequestProto.traceInfo)
  clear_has_traceinfo();
  ::hadoop::hdfs::DataTransferTraceInfoProto* temp = traceinfo_;
  traceinfo_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::DataTransferTraceInfoProto* ReleaseShortCircuitAccessRequestProto::mutable_traceinfo() {
  set_has_traceinfo();
  if (traceinfo_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::DataTransferTraceInfoProto>(GetArenaNoVirtual());
    traceinfo_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.ReleaseShortCircuitAccessRequestProto.traceInfo)
  return traceinfo_;
}
inline void ReleaseShortCircuitAccessRequestProto::set_allocated_traceinfo(::hadoop::hdfs::DataTransferTraceInfoProto* traceinfo) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete traceinfo_;
  }
  if (traceinfo) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      traceinfo = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, traceinfo, submessage_arena);
    }
    set_has_traceinfo();
  } else {
    clear_has_traceinfo();
  }
  traceinfo_ = traceinfo;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.ReleaseShortCircuitAccessRequestProto.traceInfo)
}

// -------------------------------------------------------------------

// ReleaseShortCircuitAccessResponseProto

// required .hadoop.hdfs.Status status = 1;
inline bool ReleaseShortCircuitAccessResponseProto::has_status() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ReleaseShortCircuitAccessResponseProto::set_has_status() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ReleaseShortCircuitAccessResponseProto::clear_has_status() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ReleaseShortCircuitAccessResponseProto::clear_status() {
  status_ = 0;
  clear_has_status();
}
inline ::hadoop::hdfs::Status ReleaseShortCircuitAccessResponseProto::status() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ReleaseShortCircuitAccessResponseProto.status)
  return static_cast< ::hadoop::hdfs::Status >(status_);
}
inline void ReleaseShortCircuitAccessResponseProto::set_status(::hadoop::hdfs::Status value) {
  assert(::hadoop::hdfs::Status_IsValid(value));
  set_has_status();
  status_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ReleaseShortCircuitAccessResponseProto.status)
}

// optional string error = 2;
inline bool ReleaseShortCircuitAccessResponseProto::has_error() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ReleaseShortCircuitAccessResponseProto::set_has_error() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ReleaseShortCircuitAccessResponseProto::clear_has_error() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ReleaseShortCircuitAccessResponseProto::clear_error() {
  error_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_error();
}
inline const ::std::string& ReleaseShortCircuitAccessResponseProto::error() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ReleaseShortCircuitAccessResponseProto.error)
  return error_.GetNoArena();
}
inline void ReleaseShortCircuitAccessResponseProto::set_error(const ::std::string& value) {
  set_has_error();
  error_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ReleaseShortCircuitAccessResponseProto.error)
}
#if LANG_CXX11
inline void ReleaseShortCircuitAccessResponseProto::set_error(::std::string&& value) {
  set_has_error();
  error_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.ReleaseShortCircuitAccessResponseProto.error)
}
#endif
inline void ReleaseShortCircuitAccessResponseProto::set_error(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_error();
  error_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.ReleaseShortCircuitAccessResponseProto.error)
}
inline void ReleaseShortCircuitAccessResponseProto::set_error(const char* value, size_t size) {
  set_has_error();
  error_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.ReleaseShortCircuitAccessResponseProto.error)
}
inline ::std::string* ReleaseShortCircuitAccessResponseProto::mutable_error() {
  set_has_error();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.ReleaseShortCircuitAccessResponseProto.error)
  return error_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* ReleaseShortCircuitAccessResponseProto::release_error() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.ReleaseShortCircuitAccessResponseProto.error)
  if (!has_error()) {
    return NULL;
  }
  clear_has_error();
  return error_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void ReleaseShortCircuitAccessResponseProto::set_allocated_error(::std::string* error) {
  if (error != NULL) {
    set_has_error();
  } else {
    clear_has_error();
  }
  error_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), error);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.ReleaseShortCircuitAccessResponseProto.error)
}

// -------------------------------------------------------------------

// ShortCircuitShmRequestProto

// required string clientName = 1;
inline bool ShortCircuitShmRequestProto::has_clientname() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ShortCircuitShmRequestProto::set_has_clientname() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ShortCircuitShmRequestProto::clear_has_clientname() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ShortCircuitShmRequestProto::clear_clientname() {
  clientname_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_clientname();
}
inline const ::std::string& ShortCircuitShmRequestProto::clientname() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ShortCircuitShmRequestProto.clientName)
  return clientname_.GetNoArena();
}
inline void ShortCircuitShmRequestProto::set_clientname(const ::std::string& value) {
  set_has_clientname();
  clientname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ShortCircuitShmRequestProto.clientName)
}
#if LANG_CXX11
inline void ShortCircuitShmRequestProto::set_clientname(::std::string&& value) {
  set_has_clientname();
  clientname_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.ShortCircuitShmRequestProto.clientName)
}
#endif
inline void ShortCircuitShmRequestProto::set_clientname(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_clientname();
  clientname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.ShortCircuitShmRequestProto.clientName)
}
inline void ShortCircuitShmRequestProto::set_clientname(const char* value, size_t size) {
  set_has_clientname();
  clientname_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.ShortCircuitShmRequestProto.clientName)
}
inline ::std::string* ShortCircuitShmRequestProto::mutable_clientname() {
  set_has_clientname();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.ShortCircuitShmRequestProto.clientName)
  return clientname_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* ShortCircuitShmRequestProto::release_clientname() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.ShortCircuitShmRequestProto.clientName)
  if (!has_clientname()) {
    return NULL;
  }
  clear_has_clientname();
  return clientname_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void ShortCircuitShmRequestProto::set_allocated_clientname(::std::string* clientname) {
  if (clientname != NULL) {
    set_has_clientname();
  } else {
    clear_has_clientname();
  }
  clientname_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), clientname);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.ShortCircuitShmRequestProto.clientName)
}

// optional .hadoop.hdfs.DataTransferTraceInfoProto traceInfo = 2;
inline bool ShortCircuitShmRequestProto::has_traceinfo() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ShortCircuitShmRequestProto::set_has_traceinfo() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ShortCircuitShmRequestProto::clear_has_traceinfo() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ShortCircuitShmRequestProto::clear_traceinfo() {
  if (traceinfo_ != NULL) traceinfo_->Clear();
  clear_has_traceinfo();
}
inline const ::hadoop::hdfs::DataTransferTraceInfoProto& ShortCircuitShmRequestProto::_internal_traceinfo() const {
  return *traceinfo_;
}
inline const ::hadoop::hdfs::DataTransferTraceInfoProto& ShortCircuitShmRequestProto::traceinfo() const {
  const ::hadoop::hdfs::DataTransferTraceInfoProto* p = traceinfo_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ShortCircuitShmRequestProto.traceInfo)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::DataTransferTraceInfoProto*>(
      &::hadoop::hdfs::_DataTransferTraceInfoProto_default_instance_);
}
inline ::hadoop::hdfs::DataTransferTraceInfoProto* ShortCircuitShmRequestProto::release_traceinfo() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.ShortCircuitShmRequestProto.traceInfo)
  clear_has_traceinfo();
  ::hadoop::hdfs::DataTransferTraceInfoProto* temp = traceinfo_;
  traceinfo_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::DataTransferTraceInfoProto* ShortCircuitShmRequestProto::mutable_traceinfo() {
  set_has_traceinfo();
  if (traceinfo_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::DataTransferTraceInfoProto>(GetArenaNoVirtual());
    traceinfo_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.ShortCircuitShmRequestProto.traceInfo)
  return traceinfo_;
}
inline void ShortCircuitShmRequestProto::set_allocated_traceinfo(::hadoop::hdfs::DataTransferTraceInfoProto* traceinfo) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete traceinfo_;
  }
  if (traceinfo) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      traceinfo = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, traceinfo, submessage_arena);
    }
    set_has_traceinfo();
  } else {
    clear_has_traceinfo();
  }
  traceinfo_ = traceinfo;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.ShortCircuitShmRequestProto.traceInfo)
}

// -------------------------------------------------------------------

// ShortCircuitShmResponseProto

// required .hadoop.hdfs.Status status = 1;
inline bool ShortCircuitShmResponseProto::has_status() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void ShortCircuitShmResponseProto::set_has_status() {
  _has_bits_[0] |= 0x00000004u;
}
inline void ShortCircuitShmResponseProto::clear_has_status() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void ShortCircuitShmResponseProto::clear_status() {
  status_ = 0;
  clear_has_status();
}
inline ::hadoop::hdfs::Status ShortCircuitShmResponseProto::status() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ShortCircuitShmResponseProto.status)
  return static_cast< ::hadoop::hdfs::Status >(status_);
}
inline void ShortCircuitShmResponseProto::set_status(::hadoop::hdfs::Status value) {
  assert(::hadoop::hdfs::Status_IsValid(value));
  set_has_status();
  status_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ShortCircuitShmResponseProto.status)
}

// optional string error = 2;
inline bool ShortCircuitShmResponseProto::has_error() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ShortCircuitShmResponseProto::set_has_error() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ShortCircuitShmResponseProto::clear_has_error() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ShortCircuitShmResponseProto::clear_error() {
  error_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_error();
}
inline const ::std::string& ShortCircuitShmResponseProto::error() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ShortCircuitShmResponseProto.error)
  return error_.GetNoArena();
}
inline void ShortCircuitShmResponseProto::set_error(const ::std::string& value) {
  set_has_error();
  error_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ShortCircuitShmResponseProto.error)
}
#if LANG_CXX11
inline void ShortCircuitShmResponseProto::set_error(::std::string&& value) {
  set_has_error();
  error_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.ShortCircuitShmResponseProto.error)
}
#endif
inline void ShortCircuitShmResponseProto::set_error(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_error();
  error_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.ShortCircuitShmResponseProto.error)
}
inline void ShortCircuitShmResponseProto::set_error(const char* value, size_t size) {
  set_has_error();
  error_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.ShortCircuitShmResponseProto.error)
}
inline ::std::string* ShortCircuitShmResponseProto::mutable_error() {
  set_has_error();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.ShortCircuitShmResponseProto.error)
  return error_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* ShortCircuitShmResponseProto::release_error() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.ShortCircuitShmResponseProto.error)
  if (!has_error()) {
    return NULL;
  }
  clear_has_error();
  return error_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void ShortCircuitShmResponseProto::set_allocated_error(::std::string* error) {
  if (error != NULL) {
    set_has_error();
  } else {
    clear_has_error();
  }
  error_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), error);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.ShortCircuitShmResponseProto.error)
}

// optional .hadoop.hdfs.ShortCircuitShmIdProto id = 3;
inline bool ShortCircuitShmResponseProto::has_id() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ShortCircuitShmResponseProto::set_has_id() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ShortCircuitShmResponseProto::clear_has_id() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ShortCircuitShmResponseProto::clear_id() {
  if (id_ != NULL) id_->Clear();
  clear_has_id();
}
inline const ::hadoop::hdfs::ShortCircuitShmIdProto& ShortCircuitShmResponseProto::_internal_id() const {
  return *id_;
}
inline const ::hadoop::hdfs::ShortCircuitShmIdProto& ShortCircuitShmResponseProto::id() const {
  const ::hadoop::hdfs::ShortCircuitShmIdProto* p = id_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ShortCircuitShmResponseProto.id)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::ShortCircuitShmIdProto*>(
      &::hadoop::hdfs::_ShortCircuitShmIdProto_default_instance_);
}
inline ::hadoop::hdfs::ShortCircuitShmIdProto* ShortCircuitShmResponseProto::release_id() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.ShortCircuitShmResponseProto.id)
  clear_has_id();
  ::hadoop::hdfs::ShortCircuitShmIdProto* temp = id_;
  id_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::ShortCircuitShmIdProto* ShortCircuitShmResponseProto::mutable_id() {
  set_has_id();
  if (id_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::ShortCircuitShmIdProto>(GetArenaNoVirtual());
    id_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.ShortCircuitShmResponseProto.id)
  return id_;
}
inline void ShortCircuitShmResponseProto::set_allocated_id(::hadoop::hdfs::ShortCircuitShmIdProto* id) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete id_;
  }
  if (id) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      id = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, id, submessage_arena);
    }
    set_has_id();
  } else {
    clear_has_id();
  }
  id_ = id;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.ShortCircuitShmResponseProto.id)
}

// -------------------------------------------------------------------

// PacketHeaderProto

// required sfixed64 offsetInBlock = 1;
inline bool PacketHeaderProto::has_offsetinblock() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void PacketHeaderProto::set_has_offsetinblock() {
  _has_bits_[0] |= 0x00000001u;
}
inline void PacketHeaderProto::clear_has_offsetinblock() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void PacketHeaderProto::clear_offsetinblock() {
  offsetinblock_ = GOOGLE_LONGLONG(0);
  clear_has_offsetinblock();
}
inline ::google::protobuf::int64 PacketHeaderProto::offsetinblock() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.PacketHeaderProto.offsetInBlock)
  return offsetinblock_;
}
inline void PacketHeaderProto::set_offsetinblock(::google::protobuf::int64 value) {
  set_has_offsetinblock();
  offsetinblock_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.PacketHeaderProto.offsetInBlock)
}

// required sfixed64 seqno = 2;
inline bool PacketHeaderProto::has_seqno() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void PacketHeaderProto::set_has_seqno() {
  _has_bits_[0] |= 0x00000002u;
}
inline void PacketHeaderProto::clear_has_seqno() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void PacketHeaderProto::clear_seqno() {
  seqno_ = GOOGLE_LONGLONG(0);
  clear_has_seqno();
}
inline ::google::protobuf::int64 PacketHeaderProto::seqno() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.PacketHeaderProto.seqno)
  return seqno_;
}
inline void PacketHeaderProto::set_seqno(::google::protobuf::int64 value) {
  set_has_seqno();
  seqno_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.PacketHeaderProto.seqno)
}

// required bool lastPacketInBlock = 3;
inline bool PacketHeaderProto::has_lastpacketinblock() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void PacketHeaderProto::set_has_lastpacketinblock() {
  _has_bits_[0] |= 0x00000008u;
}
inline void PacketHeaderProto::clear_has_lastpacketinblock() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void PacketHeaderProto::clear_lastpacketinblock() {
  lastpacketinblock_ = false;
  clear_has_lastpacketinblock();
}
inline bool PacketHeaderProto::lastpacketinblock() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.PacketHeaderProto.lastPacketInBlock)
  return lastpacketinblock_;
}
inline void PacketHeaderProto::set_lastpacketinblock(bool value) {
  set_has_lastpacketinblock();
  lastpacketinblock_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.PacketHeaderProto.lastPacketInBlock)
}

// required sfixed32 dataLen = 4;
inline bool PacketHeaderProto::has_datalen() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void PacketHeaderProto::set_has_datalen() {
  _has_bits_[0] |= 0x00000004u;
}
inline void PacketHeaderProto::clear_has_datalen() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void PacketHeaderProto::clear_datalen() {
  datalen_ = 0;
  clear_has_datalen();
}
inline ::google::protobuf::int32 PacketHeaderProto::datalen() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.PacketHeaderProto.dataLen)
  return datalen_;
}
inline void PacketHeaderProto::set_datalen(::google::protobuf::int32 value) {
  set_has_datalen();
  datalen_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.PacketHeaderProto.dataLen)
}

// optional bool syncBlock = 5 [default = false];
inline bool PacketHeaderProto::has_syncblock() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void PacketHeaderProto::set_has_syncblock() {
  _has_bits_[0] |= 0x00000010u;
}
inline void PacketHeaderProto::clear_has_syncblock() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void PacketHeaderProto::clear_syncblock() {
  syncblock_ = false;
  clear_has_syncblock();
}
inline bool PacketHeaderProto::syncblock() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.PacketHeaderProto.syncBlock)
  return syncblock_;
}
inline void PacketHeaderProto::set_syncblock(bool value) {
  set_has_syncblock();
  syncblock_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.PacketHeaderProto.syncBlock)
}

// -------------------------------------------------------------------

// PipelineAckProto

// required sint64 seqno = 1;
inline bool PipelineAckProto::has_seqno() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void PipelineAckProto::set_has_seqno() {
  _has_bits_[0] |= 0x00000001u;
}
inline void PipelineAckProto::clear_has_seqno() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void PipelineAckProto::clear_seqno() {
  seqno_ = GOOGLE_LONGLONG(0);
  clear_has_seqno();
}
inline ::google::protobuf::int64 PipelineAckProto::seqno() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.PipelineAckProto.seqno)
  return seqno_;
}
inline void PipelineAckProto::set_seqno(::google::protobuf::int64 value) {
  set_has_seqno();
  seqno_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.PipelineAckProto.seqno)
}

// repeated .hadoop.hdfs.Status reply = 2;
inline int PipelineAckProto::reply_size() const {
  return reply_.size();
}
inline void PipelineAckProto::clear_reply() {
  reply_.Clear();
}
inline ::hadoop::hdfs::Status PipelineAckProto::reply(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.PipelineAckProto.reply)
  return static_cast< ::hadoop::hdfs::Status >(reply_.Get(index));
}
inline void PipelineAckProto::set_reply(int index, ::hadoop::hdfs::Status value) {
  assert(::hadoop::hdfs::Status_IsValid(value));
  reply_.Set(index, value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.PipelineAckProto.reply)
}
inline void PipelineAckProto::add_reply(::hadoop::hdfs::Status value) {
  assert(::hadoop::hdfs::Status_IsValid(value));
  reply_.Add(value);
  // @@protoc_insertion_point(field_add:hadoop.hdfs.PipelineAckProto.reply)
}
inline const ::google::protobuf::RepeatedField<int>&
PipelineAckProto::reply() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.PipelineAckProto.reply)
  return reply_;
}
inline ::google::protobuf::RepeatedField<int>*
PipelineAckProto::mutable_reply() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.PipelineAckProto.reply)
  return &reply_;
}

// optional uint64 downstreamAckTimeNanos = 3 [default = 0];
inline bool PipelineAckProto::has_downstreamacktimenanos() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void PipelineAckProto::set_has_downstreamacktimenanos() {
  _has_bits_[0] |= 0x00000002u;
}
inline void PipelineAckProto::clear_has_downstreamacktimenanos() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void PipelineAckProto::clear_downstreamacktimenanos() {
  downstreamacktimenanos_ = GOOGLE_ULONGLONG(0);
  clear_has_downstreamacktimenanos();
}
inline ::google::protobuf::uint64 PipelineAckProto::downstreamacktimenanos() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.PipelineAckProto.downstreamAckTimeNanos)
  return downstreamacktimenanos_;
}
inline void PipelineAckProto::set_downstreamacktimenanos(::google::protobuf::uint64 value) {
  set_has_downstreamacktimenanos();
  downstreamacktimenanos_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.PipelineAckProto.downstreamAckTimeNanos)
}

// repeated uint32 flag = 4 [packed = true];
inline int PipelineAckProto::flag_size() const {
  return flag_.size();
}
inline void PipelineAckProto::clear_flag() {
  flag_.Clear();
}
inline ::google::protobuf::uint32 PipelineAckProto::flag(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.PipelineAckProto.flag)
  return flag_.Get(index);
}
inline void PipelineAckProto::set_flag(int index, ::google::protobuf::uint32 value) {
  flag_.Set(index, value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.PipelineAckProto.flag)
}
inline void PipelineAckProto::add_flag(::google::protobuf::uint32 value) {
  flag_.Add(value);
  // @@protoc_insertion_point(field_add:hadoop.hdfs.PipelineAckProto.flag)
}
inline const ::google::protobuf::RepeatedField< ::google::protobuf::uint32 >&
PipelineAckProto::flag() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.PipelineAckProto.flag)
  return flag_;
}
inline ::google::protobuf::RepeatedField< ::google::protobuf::uint32 >*
PipelineAckProto::mutable_flag() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.PipelineAckProto.flag)
  return &flag_;
}

// -------------------------------------------------------------------

// ReadOpChecksumInfoProto

// required .hadoop.hdfs.ChecksumProto checksum = 1;
inline bool ReadOpChecksumInfoProto::has_checksum() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ReadOpChecksumInfoProto::set_has_checksum() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ReadOpChecksumInfoProto::clear_has_checksum() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ReadOpChecksumInfoProto::clear_checksum() {
  if (checksum_ != NULL) checksum_->Clear();
  clear_has_checksum();
}
inline const ::hadoop::hdfs::ChecksumProto& ReadOpChecksumInfoProto::_internal_checksum() const {
  return *checksum_;
}
inline const ::hadoop::hdfs::ChecksumProto& ReadOpChecksumInfoProto::checksum() const {
  const ::hadoop::hdfs::ChecksumProto* p = checksum_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ReadOpChecksumInfoProto.checksum)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::ChecksumProto*>(
      &::hadoop::hdfs::_ChecksumProto_default_instance_);
}
inline ::hadoop::hdfs::ChecksumProto* ReadOpChecksumInfoProto::release_checksum() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.ReadOpChecksumInfoProto.checksum)
  clear_has_checksum();
  ::hadoop::hdfs::ChecksumProto* temp = checksum_;
  checksum_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::ChecksumProto* ReadOpChecksumInfoProto::mutable_checksum() {
  set_has_checksum();
  if (checksum_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::ChecksumProto>(GetArenaNoVirtual());
    checksum_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.ReadOpChecksumInfoProto.checksum)
  return checksum_;
}
inline void ReadOpChecksumInfoProto::set_allocated_checksum(::hadoop::hdfs::ChecksumProto* checksum) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete checksum_;
  }
  if (checksum) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      checksum = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, checksum, submessage_arena);
    }
    set_has_checksum();
  } else {
    clear_has_checksum();
  }
  checksum_ = checksum;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.ReadOpChecksumInfoProto.checksum)
}

// required uint64 chunkOffset = 2;
inline bool ReadOpChecksumInfoProto::has_chunkoffset() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ReadOpChecksumInfoProto::set_has_chunkoffset() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ReadOpChecksumInfoProto::clear_has_chunkoffset() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ReadOpChecksumInfoProto::clear_chunkoffset() {
  chunkoffset_ = GOOGLE_ULONGLONG(0);
  clear_has_chunkoffset();
}
inline ::google::protobuf::uint64 ReadOpChecksumInfoProto::chunkoffset() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ReadOpChecksumInfoProto.chunkOffset)
  return chunkoffset_;
}
inline void ReadOpChecksumInfoProto::set_chunkoffset(::google::protobuf::uint64 value) {
  set_has_chunkoffset();
  chunkoffset_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ReadOpChecksumInfoProto.chunkOffset)
}

// -------------------------------------------------------------------

// BlockOpResponseProto

// required .hadoop.hdfs.Status status = 1;
inline bool BlockOpResponseProto::has_status() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void BlockOpResponseProto::set_has_status() {
  _has_bits_[0] |= 0x00000010u;
}
inline void BlockOpResponseProto::clear_has_status() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void BlockOpResponseProto::clear_status() {
  status_ = 0;
  clear_has_status();
}
inline ::hadoop::hdfs::Status BlockOpResponseProto::status() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockOpResponseProto.status)
  return static_cast< ::hadoop::hdfs::Status >(status_);
}
inline void BlockOpResponseProto::set_status(::hadoop::hdfs::Status value) {
  assert(::hadoop::hdfs::Status_IsValid(value));
  set_has_status();
  status_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockOpResponseProto.status)
}

// optional string firstBadLink = 2;
inline bool BlockOpResponseProto::has_firstbadlink() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void BlockOpResponseProto::set_has_firstbadlink() {
  _has_bits_[0] |= 0x00000001u;
}
inline void BlockOpResponseProto::clear_has_firstbadlink() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void BlockOpResponseProto::clear_firstbadlink() {
  firstbadlink_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_firstbadlink();
}
inline const ::std::string& BlockOpResponseProto::firstbadlink() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockOpResponseProto.firstBadLink)
  return firstbadlink_.GetNoArena();
}
inline void BlockOpResponseProto::set_firstbadlink(const ::std::string& value) {
  set_has_firstbadlink();
  firstbadlink_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockOpResponseProto.firstBadLink)
}
#if LANG_CXX11
inline void BlockOpResponseProto::set_firstbadlink(::std::string&& value) {
  set_has_firstbadlink();
  firstbadlink_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.BlockOpResponseProto.firstBadLink)
}
#endif
inline void BlockOpResponseProto::set_firstbadlink(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_firstbadlink();
  firstbadlink_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.BlockOpResponseProto.firstBadLink)
}
inline void BlockOpResponseProto::set_firstbadlink(const char* value, size_t size) {
  set_has_firstbadlink();
  firstbadlink_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.BlockOpResponseProto.firstBadLink)
}
inline ::std::string* BlockOpResponseProto::mutable_firstbadlink() {
  set_has_firstbadlink();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.BlockOpResponseProto.firstBadLink)
  return firstbadlink_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* BlockOpResponseProto::release_firstbadlink() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.BlockOpResponseProto.firstBadLink)
  if (!has_firstbadlink()) {
    return NULL;
  }
  clear_has_firstbadlink();
  return firstbadlink_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void BlockOpResponseProto::set_allocated_firstbadlink(::std::string* firstbadlink) {
  if (firstbadlink != NULL) {
    set_has_firstbadlink();
  } else {
    clear_has_firstbadlink();
  }
  firstbadlink_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), firstbadlink);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.BlockOpResponseProto.firstBadLink)
}

// optional .hadoop.hdfs.OpBlockChecksumResponseProto checksumResponse = 3;
inline bool BlockOpResponseProto::has_checksumresponse() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void BlockOpResponseProto::set_has_checksumresponse() {
  _has_bits_[0] |= 0x00000004u;
}
inline void BlockOpResponseProto::clear_has_checksumresponse() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void BlockOpResponseProto::clear_checksumresponse() {
  if (checksumresponse_ != NULL) checksumresponse_->Clear();
  clear_has_checksumresponse();
}
inline const ::hadoop::hdfs::OpBlockChecksumResponseProto& BlockOpResponseProto::_internal_checksumresponse() const {
  return *checksumresponse_;
}
inline const ::hadoop::hdfs::OpBlockChecksumResponseProto& BlockOpResponseProto::checksumresponse() const {
  const ::hadoop::hdfs::OpBlockChecksumResponseProto* p = checksumresponse_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockOpResponseProto.checksumResponse)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::OpBlockChecksumResponseProto*>(
      &::hadoop::hdfs::_OpBlockChecksumResponseProto_default_instance_);
}
inline ::hadoop::hdfs::OpBlockChecksumResponseProto* BlockOpResponseProto::release_checksumresponse() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.BlockOpResponseProto.checksumResponse)
  clear_has_checksumresponse();
  ::hadoop::hdfs::OpBlockChecksumResponseProto* temp = checksumresponse_;
  checksumresponse_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::OpBlockChecksumResponseProto* BlockOpResponseProto::mutable_checksumresponse() {
  set_has_checksumresponse();
  if (checksumresponse_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::OpBlockChecksumResponseProto>(GetArenaNoVirtual());
    checksumresponse_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.BlockOpResponseProto.checksumResponse)
  return checksumresponse_;
}
inline void BlockOpResponseProto::set_allocated_checksumresponse(::hadoop::hdfs::OpBlockChecksumResponseProto* checksumresponse) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete checksumresponse_;
  }
  if (checksumresponse) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      checksumresponse = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, checksumresponse, submessage_arena);
    }
    set_has_checksumresponse();
  } else {
    clear_has_checksumresponse();
  }
  checksumresponse_ = checksumresponse;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.BlockOpResponseProto.checksumResponse)
}

// optional .hadoop.hdfs.ReadOpChecksumInfoProto readOpChecksumInfo = 4;
inline bool BlockOpResponseProto::has_readopchecksuminfo() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void BlockOpResponseProto::set_has_readopchecksuminfo() {
  _has_bits_[0] |= 0x00000008u;
}
inline void BlockOpResponseProto::clear_has_readopchecksuminfo() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void BlockOpResponseProto::clear_readopchecksuminfo() {
  if (readopchecksuminfo_ != NULL) readopchecksuminfo_->Clear();
  clear_has_readopchecksuminfo();
}
inline const ::hadoop::hdfs::ReadOpChecksumInfoProto& BlockOpResponseProto::_internal_readopchecksuminfo() const {
  return *readopchecksuminfo_;
}
inline const ::hadoop::hdfs::ReadOpChecksumInfoProto& BlockOpResponseProto::readopchecksuminfo() const {
  const ::hadoop::hdfs::ReadOpChecksumInfoProto* p = readopchecksuminfo_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockOpResponseProto.readOpChecksumInfo)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::ReadOpChecksumInfoProto*>(
      &::hadoop::hdfs::_ReadOpChecksumInfoProto_default_instance_);
}
inline ::hadoop::hdfs::ReadOpChecksumInfoProto* BlockOpResponseProto::release_readopchecksuminfo() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.BlockOpResponseProto.readOpChecksumInfo)
  clear_has_readopchecksuminfo();
  ::hadoop::hdfs::ReadOpChecksumInfoProto* temp = readopchecksuminfo_;
  readopchecksuminfo_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::ReadOpChecksumInfoProto* BlockOpResponseProto::mutable_readopchecksuminfo() {
  set_has_readopchecksuminfo();
  if (readopchecksuminfo_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::ReadOpChecksumInfoProto>(GetArenaNoVirtual());
    readopchecksuminfo_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.BlockOpResponseProto.readOpChecksumInfo)
  return readopchecksuminfo_;
}
inline void BlockOpResponseProto::set_allocated_readopchecksuminfo(::hadoop::hdfs::ReadOpChecksumInfoProto* readopchecksuminfo) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete readopchecksuminfo_;
  }
  if (readopchecksuminfo) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      readopchecksuminfo = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, readopchecksuminfo, submessage_arena);
    }
    set_has_readopchecksuminfo();
  } else {
    clear_has_readopchecksuminfo();
  }
  readopchecksuminfo_ = readopchecksuminfo;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.BlockOpResponseProto.readOpChecksumInfo)
}

// optional string message = 5;
inline bool BlockOpResponseProto::has_message() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void BlockOpResponseProto::set_has_message() {
  _has_bits_[0] |= 0x00000002u;
}
inline void BlockOpResponseProto::clear_has_message() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void BlockOpResponseProto::clear_message() {
  message_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_message();
}
inline const ::std::string& BlockOpResponseProto::message() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockOpResponseProto.message)
  return message_.GetNoArena();
}
inline void BlockOpResponseProto::set_message(const ::std::string& value) {
  set_has_message();
  message_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockOpResponseProto.message)
}
#if LANG_CXX11
inline void BlockOpResponseProto::set_message(::std::string&& value) {
  set_has_message();
  message_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.BlockOpResponseProto.message)
}
#endif
inline void BlockOpResponseProto::set_message(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_message();
  message_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.BlockOpResponseProto.message)
}
inline void BlockOpResponseProto::set_message(const char* value, size_t size) {
  set_has_message();
  message_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.BlockOpResponseProto.message)
}
inline ::std::string* BlockOpResponseProto::mutable_message() {
  set_has_message();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.BlockOpResponseProto.message)
  return message_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* BlockOpResponseProto::release_message() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.BlockOpResponseProto.message)
  if (!has_message()) {
    return NULL;
  }
  clear_has_message();
  return message_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void BlockOpResponseProto::set_allocated_message(::std::string* message) {
  if (message != NULL) {
    set_has_message();
  } else {
    clear_has_message();
  }
  message_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), message);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.BlockOpResponseProto.message)
}

// optional uint32 shortCircuitAccessVersion = 6;
inline bool BlockOpResponseProto::has_shortcircuitaccessversion() const {
  return (_has_bits_[0] & 0x00000020u) != 0;
}
inline void BlockOpResponseProto::set_has_shortcircuitaccessversion() {
  _has_bits_[0] |= 0x00000020u;
}
inline void BlockOpResponseProto::clear_has_shortcircuitaccessversion() {
  _has_bits_[0] &= ~0x00000020u;
}
inline void BlockOpResponseProto::clear_shortcircuitaccessversion() {
  shortcircuitaccessversion_ = 0u;
  clear_has_shortcircuitaccessversion();
}
inline ::google::protobuf::uint32 BlockOpResponseProto::shortcircuitaccessversion() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockOpResponseProto.shortCircuitAccessVersion)
  return shortcircuitaccessversion_;
}
inline void BlockOpResponseProto::set_shortcircuitaccessversion(::google::protobuf::uint32 value) {
  set_has_shortcircuitaccessversion();
  shortcircuitaccessversion_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockOpResponseProto.shortCircuitAccessVersion)
}

// -------------------------------------------------------------------

// ClientReadStatusProto

// required .hadoop.hdfs.Status status = 1;
inline bool ClientReadStatusProto::has_status() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ClientReadStatusProto::set_has_status() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ClientReadStatusProto::clear_has_status() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ClientReadStatusProto::clear_status() {
  status_ = 0;
  clear_has_status();
}
inline ::hadoop::hdfs::Status ClientReadStatusProto::status() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ClientReadStatusProto.status)
  return static_cast< ::hadoop::hdfs::Status >(status_);
}
inline void ClientReadStatusProto::set_status(::hadoop::hdfs::Status value) {
  assert(::hadoop::hdfs::Status_IsValid(value));
  set_has_status();
  status_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ClientReadStatusProto.status)
}

// -------------------------------------------------------------------

// DNTransferAckProto

// required .hadoop.hdfs.Status status = 1;
inline bool DNTransferAckProto::has_status() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void DNTransferAckProto::set_has_status() {
  _has_bits_[0] |= 0x00000001u;
}
inline void DNTransferAckProto::clear_has_status() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void DNTransferAckProto::clear_status() {
  status_ = 0;
  clear_has_status();
}
inline ::hadoop::hdfs::Status DNTransferAckProto::status() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.DNTransferAckProto.status)
  return static_cast< ::hadoop::hdfs::Status >(status_);
}
inline void DNTransferAckProto::set_status(::hadoop::hdfs::Status value) {
  assert(::hadoop::hdfs::Status_IsValid(value));
  set_has_status();
  status_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.DNTransferAckProto.status)
}

// -------------------------------------------------------------------

// OpBlockChecksumResponseProto

// required uint32 bytesPerCrc = 1;
inline bool OpBlockChecksumResponseProto::has_bytespercrc() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void OpBlockChecksumResponseProto::set_has_bytespercrc() {
  _has_bits_[0] |= 0x00000008u;
}
inline void OpBlockChecksumResponseProto::clear_has_bytespercrc() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void OpBlockChecksumResponseProto::clear_bytespercrc() {
  bytespercrc_ = 0u;
  clear_has_bytespercrc();
}
inline ::google::protobuf::uint32 OpBlockChecksumResponseProto::bytespercrc() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpBlockChecksumResponseProto.bytesPerCrc)
  return bytespercrc_;
}
inline void OpBlockChecksumResponseProto::set_bytespercrc(::google::protobuf::uint32 value) {
  set_has_bytespercrc();
  bytespercrc_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpBlockChecksumResponseProto.bytesPerCrc)
}

// required uint64 crcPerBlock = 2;
inline bool OpBlockChecksumResponseProto::has_crcperblock() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void OpBlockChecksumResponseProto::set_has_crcperblock() {
  _has_bits_[0] |= 0x00000004u;
}
inline void OpBlockChecksumResponseProto::clear_has_crcperblock() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void OpBlockChecksumResponseProto::clear_crcperblock() {
  crcperblock_ = GOOGLE_ULONGLONG(0);
  clear_has_crcperblock();
}
inline ::google::protobuf::uint64 OpBlockChecksumResponseProto::crcperblock() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpBlockChecksumResponseProto.crcPerBlock)
  return crcperblock_;
}
inline void OpBlockChecksumResponseProto::set_crcperblock(::google::protobuf::uint64 value) {
  set_has_crcperblock();
  crcperblock_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpBlockChecksumResponseProto.crcPerBlock)
}

// required bytes blockChecksum = 3;
inline bool OpBlockChecksumResponseProto::has_blockchecksum() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void OpBlockChecksumResponseProto::set_has_blockchecksum() {
  _has_bits_[0] |= 0x00000001u;
}
inline void OpBlockChecksumResponseProto::clear_has_blockchecksum() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void OpBlockChecksumResponseProto::clear_blockchecksum() {
  blockchecksum_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_blockchecksum();
}
inline const ::std::string& OpBlockChecksumResponseProto::blockchecksum() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpBlockChecksumResponseProto.blockChecksum)
  return blockchecksum_.GetNoArena();
}
inline void OpBlockChecksumResponseProto::set_blockchecksum(const ::std::string& value) {
  set_has_blockchecksum();
  blockchecksum_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpBlockChecksumResponseProto.blockChecksum)
}
#if LANG_CXX11
inline void OpBlockChecksumResponseProto::set_blockchecksum(::std::string&& value) {
  set_has_blockchecksum();
  blockchecksum_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.OpBlockChecksumResponseProto.blockChecksum)
}
#endif
inline void OpBlockChecksumResponseProto::set_blockchecksum(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_blockchecksum();
  blockchecksum_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.OpBlockChecksumResponseProto.blockChecksum)
}
inline void OpBlockChecksumResponseProto::set_blockchecksum(const void* value, size_t size) {
  set_has_blockchecksum();
  blockchecksum_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.OpBlockChecksumResponseProto.blockChecksum)
}
inline ::std::string* OpBlockChecksumResponseProto::mutable_blockchecksum() {
  set_has_blockchecksum();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.OpBlockChecksumResponseProto.blockChecksum)
  return blockchecksum_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* OpBlockChecksumResponseProto::release_blockchecksum() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.OpBlockChecksumResponseProto.blockChecksum)
  if (!has_blockchecksum()) {
    return NULL;
  }
  clear_has_blockchecksum();
  return blockchecksum_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void OpBlockChecksumResponseProto::set_allocated_blockchecksum(::std::string* blockchecksum) {
  if (blockchecksum != NULL) {
    set_has_blockchecksum();
  } else {
    clear_has_blockchecksum();
  }
  blockchecksum_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), blockchecksum);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.OpBlockChecksumResponseProto.blockChecksum)
}

// optional .hadoop.hdfs.ChecksumTypeProto crcType = 4;
inline bool OpBlockChecksumResponseProto::has_crctype() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void OpBlockChecksumResponseProto::set_has_crctype() {
  _has_bits_[0] |= 0x00000010u;
}
inline void OpBlockChecksumResponseProto::clear_has_crctype() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void OpBlockChecksumResponseProto::clear_crctype() {
  crctype_ = 0;
  clear_has_crctype();
}
inline ::hadoop::hdfs::ChecksumTypeProto OpBlockChecksumResponseProto::crctype() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpBlockChecksumResponseProto.crcType)
  return static_cast< ::hadoop::hdfs::ChecksumTypeProto >(crctype_);
}
inline void OpBlockChecksumResponseProto::set_crctype(::hadoop::hdfs::ChecksumTypeProto value) {
  assert(::hadoop::hdfs::ChecksumTypeProto_IsValid(value));
  set_has_crctype();
  crctype_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpBlockChecksumResponseProto.crcType)
}

// optional .hadoop.hdfs.BlockChecksumOptionsProto blockChecksumOptions = 5;
inline bool OpBlockChecksumResponseProto::has_blockchecksumoptions() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void OpBlockChecksumResponseProto::set_has_blockchecksumoptions() {
  _has_bits_[0] |= 0x00000002u;
}
inline void OpBlockChecksumResponseProto::clear_has_blockchecksumoptions() {
  _has_bits_[0] &= ~0x00000002u;
}
inline const ::hadoop::hdfs::BlockChecksumOptionsProto& OpBlockChecksumResponseProto::_internal_blockchecksumoptions() const {
  return *blockchecksumoptions_;
}
inline const ::hadoop::hdfs::BlockChecksumOptionsProto& OpBlockChecksumResponseProto::blockchecksumoptions() const {
  const ::hadoop::hdfs::BlockChecksumOptionsProto* p = blockchecksumoptions_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpBlockChecksumResponseProto.blockChecksumOptions)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::BlockChecksumOptionsProto*>(
      &::hadoop::hdfs::_BlockChecksumOptionsProto_default_instance_);
}
inline ::hadoop::hdfs::BlockChecksumOptionsProto* OpBlockChecksumResponseProto::release_blockchecksumoptions() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.OpBlockChecksumResponseProto.blockChecksumOptions)
  clear_has_blockchecksumoptions();
  ::hadoop::hdfs::BlockChecksumOptionsProto* temp = blockchecksumoptions_;
  blockchecksumoptions_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::BlockChecksumOptionsProto* OpBlockChecksumResponseProto::mutable_blockchecksumoptions() {
  set_has_blockchecksumoptions();
  if (blockchecksumoptions_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::BlockChecksumOptionsProto>(GetArenaNoVirtual());
    blockchecksumoptions_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.OpBlockChecksumResponseProto.blockChecksumOptions)
  return blockchecksumoptions_;
}
inline void OpBlockChecksumResponseProto::set_allocated_blockchecksumoptions(::hadoop::hdfs::BlockChecksumOptionsProto* blockchecksumoptions) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete reinterpret_cast< ::google::protobuf::MessageLite*>(blockchecksumoptions_);
  }
  if (blockchecksumoptions) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      blockchecksumoptions = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, blockchecksumoptions, submessage_arena);
    }
    set_has_blockchecksumoptions();
  } else {
    clear_has_blockchecksumoptions();
  }
  blockchecksumoptions_ = blockchecksumoptions;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.OpBlockChecksumResponseProto.blockChecksumOptions)
}

// -------------------------------------------------------------------

// OpCustomProto

// required string customId = 1;
inline bool OpCustomProto::has_customid() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void OpCustomProto::set_has_customid() {
  _has_bits_[0] |= 0x00000001u;
}
inline void OpCustomProto::clear_has_customid() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void OpCustomProto::clear_customid() {
  customid_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_customid();
}
inline const ::std::string& OpCustomProto::customid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.OpCustomProto.customId)
  return customid_.GetNoArena();
}
inline void OpCustomProto::set_customid(const ::std::string& value) {
  set_has_customid();
  customid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.OpCustomProto.customId)
}
#if LANG_CXX11
inline void OpCustomProto::set_customid(::std::string&& value) {
  set_has_customid();
  customid_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.OpCustomProto.customId)
}
#endif
inline void OpCustomProto::set_customid(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_customid();
  customid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.OpCustomProto.customId)
}
inline void OpCustomProto::set_customid(const char* value, size_t size) {
  set_has_customid();
  customid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.OpCustomProto.customId)
}
inline ::std::string* OpCustomProto::mutable_customid() {
  set_has_customid();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.OpCustomProto.customId)
  return customid_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* OpCustomProto::release_customid() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.OpCustomProto.customId)
  if (!has_customid()) {
    return NULL;
  }
  clear_has_customid();
  return customid_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void OpCustomProto::set_allocated_customid(::std::string* customid) {
  if (customid != NULL) {
    set_has_customid();
  } else {
    clear_has_customid();
  }
  customid_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), customid);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.OpCustomProto.customId)
}

#ifdef __GNUC__
  #pragma GCC diagnostic pop
#endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

}  // namespace hdfs
}  // namespace hadoop

namespace google {
namespace protobuf {

template <> struct is_proto_enum< ::hadoop::hdfs::DataTransferEncryptorMessageProto_DataTransferEncryptorStatus> : ::std::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::hdfs::DataTransferEncryptorMessageProto_DataTransferEncryptorStatus>() {
  return ::hadoop::hdfs::DataTransferEncryptorMessageProto_DataTransferEncryptorStatus_descriptor();
}
template <> struct is_proto_enum< ::hadoop::hdfs::OpWriteBlockProto_BlockConstructionStage> : ::std::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::hdfs::OpWriteBlockProto_BlockConstructionStage>() {
  return ::hadoop::hdfs::OpWriteBlockProto_BlockConstructionStage_descriptor();
}
template <> struct is_proto_enum< ::hadoop::hdfs::Status> : ::std::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::hdfs::Status>() {
  return ::hadoop::hdfs::Status_descriptor();
}
template <> struct is_proto_enum< ::hadoop::hdfs::ShortCircuitFdResponse> : ::std::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::hdfs::ShortCircuitFdResponse>() {
  return ::hadoop::hdfs::ShortCircuitFdResponse_descriptor();
}

}  // namespace protobuf
}  // namespace google

// @@protoc_insertion_point(global_scope)

#endif  // PROTOBUF_INCLUDED_datatransfer_2eproto
