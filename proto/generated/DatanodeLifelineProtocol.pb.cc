// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: DatanodeLifelineProtocol.proto

#include "DatanodeLifelineProtocol.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/port.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// This is a temporary google only hack
#ifdef GOOGLE_PROTOBUF_ENFORCE_UNIQUENESS
#include "third_party/protobuf/version.h"
#endif
// @@protoc_insertion_point(includes)

namespace hadoop {
namespace hdfs {
namespace datanodelifeline {
class LifelineResponseProtoDefaultTypeInternal {
 public:
  ::google::protobuf::internal::ExplicitlyConstructed<LifelineResponseProto>
      _instance;
} _LifelineResponseProto_default_instance_;
}  // namespace datanodelifeline
}  // namespace hdfs
}  // namespace hadoop
namespace protobuf_DatanodeLifelineProtocol_2eproto {
static void InitDefaultsLifelineResponseProto() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  {
    void* ptr = &::hadoop::hdfs::datanodelifeline::_LifelineResponseProto_default_instance_;
    new (ptr) ::hadoop::hdfs::datanodelifeline::LifelineResponseProto();
    ::google::protobuf::internal::OnShutdownDestroyMessage(ptr);
  }
  ::hadoop::hdfs::datanodelifeline::LifelineResponseProto::InitAsDefaultInstance();
}

::google::protobuf::internal::SCCInfo<0> scc_info_LifelineResponseProto =
    {{ATOMIC_VAR_INIT(::google::protobuf::internal::SCCInfoBase::kUninitialized), 0, InitDefaultsLifelineResponseProto}, {}};

void InitDefaults() {
  ::google::protobuf::internal::InitSCC(&scc_info_LifelineResponseProto.base);
}

::google::protobuf::Metadata file_level_metadata[1];

const ::google::protobuf::uint32 TableStruct::offsets[] GOOGLE_PROTOBUF_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::datanodelifeline::LifelineResponseProto, _has_bits_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(::hadoop::hdfs::datanodelifeline::LifelineResponseProto, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
};
static const ::google::protobuf::internal::MigrationSchema schemas[] GOOGLE_PROTOBUF_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
  { 0, 5, sizeof(::hadoop::hdfs::datanodelifeline::LifelineResponseProto)},
};

static ::google::protobuf::Message const * const file_default_instances[] = {
  reinterpret_cast<const ::google::protobuf::Message*>(&::hadoop::hdfs::datanodelifeline::_LifelineResponseProto_default_instance_),
};

void protobuf_AssignDescriptors() {
  AddDescriptors();
  AssignDescriptors(
      "DatanodeLifelineProtocol.proto", schemas, file_default_instances, TableStruct::offsets,
      file_level_metadata, NULL, NULL);
}

void protobuf_AssignDescriptorsOnce() {
  static ::google::protobuf::internal::once_flag once;
  ::google::protobuf::internal::call_once(once, protobuf_AssignDescriptors);
}

void protobuf_RegisterTypes(const ::std::string&) GOOGLE_PROTOBUF_ATTRIBUTE_COLD;
void protobuf_RegisterTypes(const ::std::string&) {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::internal::RegisterAllTypes(file_level_metadata, 1);
}

void AddDescriptorsImpl() {
  InitDefaults();
  static const char descriptor[] GOOGLE_PROTOBUF_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
      "\n\036DatanodeLifelineProtocol.proto\022\034hadoop"
      ".hdfs.datanodelifeline\032\026DatanodeProtocol"
      ".proto\"\027\n\025LifelineResponseProto2\223\001\n\037Data"
      "nodeLifelineProtocolService\022p\n\014sendLifel"
      "ine\022+.hadoop.hdfs.datanode.HeartbeatRequ"
      "estProto\0323.hadoop.hdfs.datanodelifeline."
      "LifelineResponseProtoBM\n%org.apache.hado"
      "op.hdfs.protocol.protoB\036DatanodeLifeline"
      "ProtocolProtos\210\001\001\240\001\001"
  };
  ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
      descriptor, 340);
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
    "DatanodeLifelineProtocol.proto", &protobuf_RegisterTypes);
  ::protobuf_DatanodeProtocol_2eproto::AddDescriptors();
}

void AddDescriptors() {
  static ::google::protobuf::internal::once_flag once;
  ::google::protobuf::internal::call_once(once, AddDescriptorsImpl);
}
// Force AddDescriptors() to be called at dynamic initialization time.
struct StaticDescriptorInitializer {
  StaticDescriptorInitializer() {
    AddDescriptors();
  }
} static_descriptor_initializer;
}  // namespace protobuf_DatanodeLifelineProtocol_2eproto
namespace hadoop {
namespace hdfs {
namespace datanodelifeline {

// ===================================================================

void LifelineResponseProto::InitAsDefaultInstance() {
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

LifelineResponseProto::LifelineResponseProto()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  ::google::protobuf::internal::InitSCC(
      &protobuf_DatanodeLifelineProtocol_2eproto::scc_info_LifelineResponseProto.base);
  SharedCtor();
  // @@protoc_insertion_point(constructor:hadoop.hdfs.datanodelifeline.LifelineResponseProto)
}
LifelineResponseProto::LifelineResponseProto(const LifelineResponseProto& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      _has_bits_(from._has_bits_) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  // @@protoc_insertion_point(copy_constructor:hadoop.hdfs.datanodelifeline.LifelineResponseProto)
}

void LifelineResponseProto::SharedCtor() {
}

LifelineResponseProto::~LifelineResponseProto() {
  // @@protoc_insertion_point(destructor:hadoop.hdfs.datanodelifeline.LifelineResponseProto)
  SharedDtor();
}

void LifelineResponseProto::SharedDtor() {
}

void LifelineResponseProto::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}
const ::google::protobuf::Descriptor* LifelineResponseProto::descriptor() {
  ::protobuf_DatanodeLifelineProtocol_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_DatanodeLifelineProtocol_2eproto::file_level_metadata[kIndexInFileMessages].descriptor;
}

const LifelineResponseProto& LifelineResponseProto::default_instance() {
  ::google::protobuf::internal::InitSCC(&protobuf_DatanodeLifelineProtocol_2eproto::scc_info_LifelineResponseProto.base);
  return *internal_default_instance();
}


void LifelineResponseProto::Clear() {
// @@protoc_insertion_point(message_clear_start:hadoop.hdfs.datanodelifeline.LifelineResponseProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _has_bits_.Clear();
  _internal_metadata_.Clear();
}

bool LifelineResponseProto::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:hadoop.hdfs.datanodelifeline.LifelineResponseProto)
  for (;;) {
    ::std::pair<::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
  handle_unusual:
    if (tag == 0) {
      goto success;
    }
    DO_(::google::protobuf::internal::WireFormat::SkipField(
          input, tag, _internal_metadata_.mutable_unknown_fields()));
  }
success:
  // @@protoc_insertion_point(parse_success:hadoop.hdfs.datanodelifeline.LifelineResponseProto)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:hadoop.hdfs.datanodelifeline.LifelineResponseProto)
  return false;
#undef DO_
}

void LifelineResponseProto::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:hadoop.hdfs.datanodelifeline.LifelineResponseProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  if (_internal_metadata_.have_unknown_fields()) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        _internal_metadata_.unknown_fields(), output);
  }
  // @@protoc_insertion_point(serialize_end:hadoop.hdfs.datanodelifeline.LifelineResponseProto)
}

::google::protobuf::uint8* LifelineResponseProto::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:hadoop.hdfs.datanodelifeline.LifelineResponseProto)
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

  if (_internal_metadata_.have_unknown_fields()) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields(), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:hadoop.hdfs.datanodelifeline.LifelineResponseProto)
  return target;
}

size_t LifelineResponseProto::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:hadoop.hdfs.datanodelifeline.LifelineResponseProto)
  size_t total_size = 0;

  if (_internal_metadata_.have_unknown_fields()) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        _internal_metadata_.unknown_fields());
  }
  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void LifelineResponseProto::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:hadoop.hdfs.datanodelifeline.LifelineResponseProto)
  GOOGLE_DCHECK_NE(&from, this);
  const LifelineResponseProto* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const LifelineResponseProto>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:hadoop.hdfs.datanodelifeline.LifelineResponseProto)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:hadoop.hdfs.datanodelifeline.LifelineResponseProto)
    MergeFrom(*source);
  }
}

void LifelineResponseProto::MergeFrom(const LifelineResponseProto& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:hadoop.hdfs.datanodelifeline.LifelineResponseProto)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  ::google::protobuf::uint32 cached_has_bits = 0;
  (void) cached_has_bits;

}

void LifelineResponseProto::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:hadoop.hdfs.datanodelifeline.LifelineResponseProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void LifelineResponseProto::CopyFrom(const LifelineResponseProto& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:hadoop.hdfs.datanodelifeline.LifelineResponseProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool LifelineResponseProto::IsInitialized() const {
  return true;
}

void LifelineResponseProto::Swap(LifelineResponseProto* other) {
  if (other == this) return;
  InternalSwap(other);
}
void LifelineResponseProto::InternalSwap(LifelineResponseProto* other) {
  using std::swap;
  swap(_has_bits_[0], other->_has_bits_[0]);
  _internal_metadata_.Swap(&other->_internal_metadata_);
}

::google::protobuf::Metadata LifelineResponseProto::GetMetadata() const {
  protobuf_DatanodeLifelineProtocol_2eproto::protobuf_AssignDescriptorsOnce();
  return ::protobuf_DatanodeLifelineProtocol_2eproto::file_level_metadata[kIndexInFileMessages];
}


// @@protoc_insertion_point(namespace_scope)
}  // namespace datanodelifeline
}  // namespace hdfs
}  // namespace hadoop
namespace google {
namespace protobuf {
template<> GOOGLE_PROTOBUF_ATTRIBUTE_NOINLINE ::hadoop::hdfs::datanodelifeline::LifelineResponseProto* Arena::CreateMaybeMessage< ::hadoop::hdfs::datanodelifeline::LifelineResponseProto >(Arena* arena) {
  return Arena::CreateInternal< ::hadoop::hdfs::datanodelifeline::LifelineResponseProto >(arena);
}
}  // namespace protobuf
}  // namespace google

// @@protoc_insertion_point(global_scope)
