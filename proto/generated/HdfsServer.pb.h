// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: HdfsServer.proto

#ifndef PROTOBUF_INCLUDED_HdfsServer_2eproto
#define PROTOBUF_INCLUDED_HdfsServer_2eproto

#include <string>

#include <google/protobuf/stubs/common.h>

#if GOOGLE_PROTOBUF_VERSION < 3006001
#error This file was generated by a newer version of protoc which is
#error incompatible with your Protocol Buffer headers.  Please update
#error your headers.
#endif
#if 3006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
#error This file was generated by an older version of protoc which is
#error incompatible with your Protocol Buffer headers.  Please
#error regenerate this file with a newer version of protoc.
#endif

#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/arena.h>
#include <google/protobuf/arenastring.h>
#include <google/protobuf/generated_message_table_driven.h>
#include <google/protobuf/generated_message_util.h>
#include <google/protobuf/inlined_string_field.h>
#include <google/protobuf/metadata.h>
#include <google/protobuf/message.h>
#include <google/protobuf/repeated_field.h>  // IWYU pragma: export
#include <google/protobuf/extension_set.h>  // IWYU pragma: export
#include <google/protobuf/generated_enum_reflection.h>
#include <google/protobuf/unknown_field_set.h>
#include "hdfs.pb.h"
#include "HAServiceProtocol.pb.h"
// @@protoc_insertion_point(includes)
#define PROTOBUF_INTERNAL_EXPORT_protobuf_HdfsServer_2eproto 

namespace protobuf_HdfsServer_2eproto {
// Internal implementation detail -- do not use these members.
struct TableStruct {
  static const ::google::protobuf::internal::ParseTableField entries[];
  static const ::google::protobuf::internal::AuxillaryParseTableField aux[];
  static const ::google::protobuf::internal::ParseTable schema[16];
  static const ::google::protobuf::internal::FieldMetadata field_metadata[];
  static const ::google::protobuf::internal::SerializationTable serialization_table[];
  static const ::google::protobuf::uint32 offsets[];
};
void AddDescriptors();
}  // namespace protobuf_HdfsServer_2eproto
namespace hadoop {
namespace hdfs {
class BlockKeyProto;
class BlockKeyProtoDefaultTypeInternal;
extern BlockKeyProtoDefaultTypeInternal _BlockKeyProto_default_instance_;
class BlockWithLocationsProto;
class BlockWithLocationsProtoDefaultTypeInternal;
extern BlockWithLocationsProtoDefaultTypeInternal _BlockWithLocationsProto_default_instance_;
class BlocksWithLocationsProto;
class BlocksWithLocationsProtoDefaultTypeInternal;
extern BlocksWithLocationsProtoDefaultTypeInternal _BlocksWithLocationsProto_default_instance_;
class CheckpointCommandProto;
class CheckpointCommandProtoDefaultTypeInternal;
extern CheckpointCommandProtoDefaultTypeInternal _CheckpointCommandProto_default_instance_;
class CheckpointSignatureProto;
class CheckpointSignatureProtoDefaultTypeInternal;
extern CheckpointSignatureProtoDefaultTypeInternal _CheckpointSignatureProto_default_instance_;
class ExportedBlockKeysProto;
class ExportedBlockKeysProtoDefaultTypeInternal;
extern ExportedBlockKeysProtoDefaultTypeInternal _ExportedBlockKeysProto_default_instance_;
class NNHAStatusHeartbeatProto;
class NNHAStatusHeartbeatProtoDefaultTypeInternal;
extern NNHAStatusHeartbeatProtoDefaultTypeInternal _NNHAStatusHeartbeatProto_default_instance_;
class NamenodeCommandProto;
class NamenodeCommandProtoDefaultTypeInternal;
extern NamenodeCommandProtoDefaultTypeInternal _NamenodeCommandProto_default_instance_;
class NamenodeRegistrationProto;
class NamenodeRegistrationProtoDefaultTypeInternal;
extern NamenodeRegistrationProtoDefaultTypeInternal _NamenodeRegistrationProto_default_instance_;
class NamespaceInfoProto;
class NamespaceInfoProtoDefaultTypeInternal;
extern NamespaceInfoProtoDefaultTypeInternal _NamespaceInfoProto_default_instance_;
class RecoveringBlockProto;
class RecoveringBlockProtoDefaultTypeInternal;
extern RecoveringBlockProtoDefaultTypeInternal _RecoveringBlockProto_default_instance_;
class RemoteEditLogManifestProto;
class RemoteEditLogManifestProtoDefaultTypeInternal;
extern RemoteEditLogManifestProtoDefaultTypeInternal _RemoteEditLogManifestProto_default_instance_;
class RemoteEditLogProto;
class RemoteEditLogProtoDefaultTypeInternal;
extern RemoteEditLogProtoDefaultTypeInternal _RemoteEditLogProto_default_instance_;
class StorageInfoProto;
class StorageInfoProtoDefaultTypeInternal;
extern StorageInfoProtoDefaultTypeInternal _StorageInfoProto_default_instance_;
class VersionRequestProto;
class VersionRequestProtoDefaultTypeInternal;
extern VersionRequestProtoDefaultTypeInternal _VersionRequestProto_default_instance_;
class VersionResponseProto;
class VersionResponseProtoDefaultTypeInternal;
extern VersionResponseProtoDefaultTypeInternal _VersionResponseProto_default_instance_;
}  // namespace hdfs
}  // namespace hadoop
namespace google {
namespace protobuf {
template<> ::hadoop::hdfs::BlockKeyProto* Arena::CreateMaybeMessage<::hadoop::hdfs::BlockKeyProto>(Arena*);
template<> ::hadoop::hdfs::BlockWithLocationsProto* Arena::CreateMaybeMessage<::hadoop::hdfs::BlockWithLocationsProto>(Arena*);
template<> ::hadoop::hdfs::BlocksWithLocationsProto* Arena::CreateMaybeMessage<::hadoop::hdfs::BlocksWithLocationsProto>(Arena*);
template<> ::hadoop::hdfs::CheckpointCommandProto* Arena::CreateMaybeMessage<::hadoop::hdfs::CheckpointCommandProto>(Arena*);
template<> ::hadoop::hdfs::CheckpointSignatureProto* Arena::CreateMaybeMessage<::hadoop::hdfs::CheckpointSignatureProto>(Arena*);
template<> ::hadoop::hdfs::ExportedBlockKeysProto* Arena::CreateMaybeMessage<::hadoop::hdfs::ExportedBlockKeysProto>(Arena*);
template<> ::hadoop::hdfs::NNHAStatusHeartbeatProto* Arena::CreateMaybeMessage<::hadoop::hdfs::NNHAStatusHeartbeatProto>(Arena*);
template<> ::hadoop::hdfs::NamenodeCommandProto* Arena::CreateMaybeMessage<::hadoop::hdfs::NamenodeCommandProto>(Arena*);
template<> ::hadoop::hdfs::NamenodeRegistrationProto* Arena::CreateMaybeMessage<::hadoop::hdfs::NamenodeRegistrationProto>(Arena*);
template<> ::hadoop::hdfs::NamespaceInfoProto* Arena::CreateMaybeMessage<::hadoop::hdfs::NamespaceInfoProto>(Arena*);
template<> ::hadoop::hdfs::RecoveringBlockProto* Arena::CreateMaybeMessage<::hadoop::hdfs::RecoveringBlockProto>(Arena*);
template<> ::hadoop::hdfs::RemoteEditLogManifestProto* Arena::CreateMaybeMessage<::hadoop::hdfs::RemoteEditLogManifestProto>(Arena*);
template<> ::hadoop::hdfs::RemoteEditLogProto* Arena::CreateMaybeMessage<::hadoop::hdfs::RemoteEditLogProto>(Arena*);
template<> ::hadoop::hdfs::StorageInfoProto* Arena::CreateMaybeMessage<::hadoop::hdfs::StorageInfoProto>(Arena*);
template<> ::hadoop::hdfs::VersionRequestProto* Arena::CreateMaybeMessage<::hadoop::hdfs::VersionRequestProto>(Arena*);
template<> ::hadoop::hdfs::VersionResponseProto* Arena::CreateMaybeMessage<::hadoop::hdfs::VersionResponseProto>(Arena*);
}  // namespace protobuf
}  // namespace google
namespace hadoop {
namespace hdfs {

enum NamenodeCommandProto_Type {
  NamenodeCommandProto_Type_NamenodeCommand = 0,
  NamenodeCommandProto_Type_CheckPointCommand = 1
};
bool NamenodeCommandProto_Type_IsValid(int value);
const NamenodeCommandProto_Type NamenodeCommandProto_Type_Type_MIN = NamenodeCommandProto_Type_NamenodeCommand;
const NamenodeCommandProto_Type NamenodeCommandProto_Type_Type_MAX = NamenodeCommandProto_Type_CheckPointCommand;
const int NamenodeCommandProto_Type_Type_ARRAYSIZE = NamenodeCommandProto_Type_Type_MAX + 1;

const ::google::protobuf::EnumDescriptor* NamenodeCommandProto_Type_descriptor();
inline const ::std::string& NamenodeCommandProto_Type_Name(NamenodeCommandProto_Type value) {
  return ::google::protobuf::internal::NameOfEnum(
    NamenodeCommandProto_Type_descriptor(), value);
}
inline bool NamenodeCommandProto_Type_Parse(
    const ::std::string& name, NamenodeCommandProto_Type* value) {
  return ::google::protobuf::internal::ParseNamedEnum<NamenodeCommandProto_Type>(
    NamenodeCommandProto_Type_descriptor(), name, value);
}
enum NamenodeRegistrationProto_NamenodeRoleProto {
  NamenodeRegistrationProto_NamenodeRoleProto_NAMENODE = 1,
  NamenodeRegistrationProto_NamenodeRoleProto_BACKUP = 2,
  NamenodeRegistrationProto_NamenodeRoleProto_CHECKPOINT = 3
};
bool NamenodeRegistrationProto_NamenodeRoleProto_IsValid(int value);
const NamenodeRegistrationProto_NamenodeRoleProto NamenodeRegistrationProto_NamenodeRoleProto_NamenodeRoleProto_MIN = NamenodeRegistrationProto_NamenodeRoleProto_NAMENODE;
const NamenodeRegistrationProto_NamenodeRoleProto NamenodeRegistrationProto_NamenodeRoleProto_NamenodeRoleProto_MAX = NamenodeRegistrationProto_NamenodeRoleProto_CHECKPOINT;
const int NamenodeRegistrationProto_NamenodeRoleProto_NamenodeRoleProto_ARRAYSIZE = NamenodeRegistrationProto_NamenodeRoleProto_NamenodeRoleProto_MAX + 1;

const ::google::protobuf::EnumDescriptor* NamenodeRegistrationProto_NamenodeRoleProto_descriptor();
inline const ::std::string& NamenodeRegistrationProto_NamenodeRoleProto_Name(NamenodeRegistrationProto_NamenodeRoleProto value) {
  return ::google::protobuf::internal::NameOfEnum(
    NamenodeRegistrationProto_NamenodeRoleProto_descriptor(), value);
}
inline bool NamenodeRegistrationProto_NamenodeRoleProto_Parse(
    const ::std::string& name, NamenodeRegistrationProto_NamenodeRoleProto* value) {
  return ::google::protobuf::internal::ParseNamedEnum<NamenodeRegistrationProto_NamenodeRoleProto>(
    NamenodeRegistrationProto_NamenodeRoleProto_descriptor(), name, value);
}
enum NNHAStatusHeartbeatProto_State {
  NNHAStatusHeartbeatProto_State_ACTIVE = 0,
  NNHAStatusHeartbeatProto_State_STANDBY = 1,
  NNHAStatusHeartbeatProto_State_OBSERVER = 2
};
bool NNHAStatusHeartbeatProto_State_IsValid(int value);
const NNHAStatusHeartbeatProto_State NNHAStatusHeartbeatProto_State_State_MIN = NNHAStatusHeartbeatProto_State_ACTIVE;
const NNHAStatusHeartbeatProto_State NNHAStatusHeartbeatProto_State_State_MAX = NNHAStatusHeartbeatProto_State_OBSERVER;
const int NNHAStatusHeartbeatProto_State_State_ARRAYSIZE = NNHAStatusHeartbeatProto_State_State_MAX + 1;

const ::google::protobuf::EnumDescriptor* NNHAStatusHeartbeatProto_State_descriptor();
inline const ::std::string& NNHAStatusHeartbeatProto_State_Name(NNHAStatusHeartbeatProto_State value) {
  return ::google::protobuf::internal::NameOfEnum(
    NNHAStatusHeartbeatProto_State_descriptor(), value);
}
inline bool NNHAStatusHeartbeatProto_State_Parse(
    const ::std::string& name, NNHAStatusHeartbeatProto_State* value) {
  return ::google::protobuf::internal::ParseNamedEnum<NNHAStatusHeartbeatProto_State>(
    NNHAStatusHeartbeatProto_State_descriptor(), name, value);
}
enum ReplicaStateProto {
  FINALIZED = 0,
  RBW = 1,
  RWR = 2,
  RUR = 3,
  TEMPORARY = 4
};
bool ReplicaStateProto_IsValid(int value);
const ReplicaStateProto ReplicaStateProto_MIN = FINALIZED;
const ReplicaStateProto ReplicaStateProto_MAX = TEMPORARY;
const int ReplicaStateProto_ARRAYSIZE = ReplicaStateProto_MAX + 1;

const ::google::protobuf::EnumDescriptor* ReplicaStateProto_descriptor();
inline const ::std::string& ReplicaStateProto_Name(ReplicaStateProto value) {
  return ::google::protobuf::internal::NameOfEnum(
    ReplicaStateProto_descriptor(), value);
}
inline bool ReplicaStateProto_Parse(
    const ::std::string& name, ReplicaStateProto* value) {
  return ::google::protobuf::internal::ParseNamedEnum<ReplicaStateProto>(
    ReplicaStateProto_descriptor(), name, value);
}
// ===================================================================

class BlockKeyProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.BlockKeyProto) */ {
 public:
  BlockKeyProto();
  virtual ~BlockKeyProto();

  BlockKeyProto(const BlockKeyProto& from);

  inline BlockKeyProto& operator=(const BlockKeyProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  BlockKeyProto(BlockKeyProto&& from) noexcept
    : BlockKeyProto() {
    *this = ::std::move(from);
  }

  inline BlockKeyProto& operator=(BlockKeyProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const BlockKeyProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const BlockKeyProto* internal_default_instance() {
    return reinterpret_cast<const BlockKeyProto*>(
               &_BlockKeyProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    0;

  void Swap(BlockKeyProto* other);
  friend void swap(BlockKeyProto& a, BlockKeyProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline BlockKeyProto* New() const final {
    return CreateMaybeMessage<BlockKeyProto>(NULL);
  }

  BlockKeyProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<BlockKeyProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const BlockKeyProto& from);
  void MergeFrom(const BlockKeyProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(BlockKeyProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional bytes keyBytes = 3;
  bool has_keybytes() const;
  void clear_keybytes();
  static const int kKeyBytesFieldNumber = 3;
  const ::std::string& keybytes() const;
  void set_keybytes(const ::std::string& value);
  #if LANG_CXX11
  void set_keybytes(::std::string&& value);
  #endif
  void set_keybytes(const char* value);
  void set_keybytes(const void* value, size_t size);
  ::std::string* mutable_keybytes();
  ::std::string* release_keybytes();
  void set_allocated_keybytes(::std::string* keybytes);

  // required uint64 expiryDate = 2;
  bool has_expirydate() const;
  void clear_expirydate();
  static const int kExpiryDateFieldNumber = 2;
  ::google::protobuf::uint64 expirydate() const;
  void set_expirydate(::google::protobuf::uint64 value);

  // required uint32 keyId = 1;
  bool has_keyid() const;
  void clear_keyid();
  static const int kKeyIdFieldNumber = 1;
  ::google::protobuf::uint32 keyid() const;
  void set_keyid(::google::protobuf::uint32 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.BlockKeyProto)
 private:
  void set_has_keyid();
  void clear_has_keyid();
  void set_has_expirydate();
  void clear_has_expirydate();
  void set_has_keybytes();
  void clear_has_keybytes();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr keybytes_;
  ::google::protobuf::uint64 expirydate_;
  ::google::protobuf::uint32 keyid_;
  friend struct ::protobuf_HdfsServer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class ExportedBlockKeysProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.ExportedBlockKeysProto) */ {
 public:
  ExportedBlockKeysProto();
  virtual ~ExportedBlockKeysProto();

  ExportedBlockKeysProto(const ExportedBlockKeysProto& from);

  inline ExportedBlockKeysProto& operator=(const ExportedBlockKeysProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  ExportedBlockKeysProto(ExportedBlockKeysProto&& from) noexcept
    : ExportedBlockKeysProto() {
    *this = ::std::move(from);
  }

  inline ExportedBlockKeysProto& operator=(ExportedBlockKeysProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const ExportedBlockKeysProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const ExportedBlockKeysProto* internal_default_instance() {
    return reinterpret_cast<const ExportedBlockKeysProto*>(
               &_ExportedBlockKeysProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    1;

  void Swap(ExportedBlockKeysProto* other);
  friend void swap(ExportedBlockKeysProto& a, ExportedBlockKeysProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline ExportedBlockKeysProto* New() const final {
    return CreateMaybeMessage<ExportedBlockKeysProto>(NULL);
  }

  ExportedBlockKeysProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<ExportedBlockKeysProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const ExportedBlockKeysProto& from);
  void MergeFrom(const ExportedBlockKeysProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(ExportedBlockKeysProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.hdfs.BlockKeyProto allKeys = 5;
  int allkeys_size() const;
  void clear_allkeys();
  static const int kAllKeysFieldNumber = 5;
  ::hadoop::hdfs::BlockKeyProto* mutable_allkeys(int index);
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::BlockKeyProto >*
      mutable_allkeys();
  const ::hadoop::hdfs::BlockKeyProto& allkeys(int index) const;
  ::hadoop::hdfs::BlockKeyProto* add_allkeys();
  const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::BlockKeyProto >&
      allkeys() const;

  // required .hadoop.hdfs.BlockKeyProto currentKey = 4;
  bool has_currentkey() const;
  void clear_currentkey();
  static const int kCurrentKeyFieldNumber = 4;
  private:
  const ::hadoop::hdfs::BlockKeyProto& _internal_currentkey() const;
  public:
  const ::hadoop::hdfs::BlockKeyProto& currentkey() const;
  ::hadoop::hdfs::BlockKeyProto* release_currentkey();
  ::hadoop::hdfs::BlockKeyProto* mutable_currentkey();
  void set_allocated_currentkey(::hadoop::hdfs::BlockKeyProto* currentkey);

  // required uint64 keyUpdateInterval = 2;
  bool has_keyupdateinterval() const;
  void clear_keyupdateinterval();
  static const int kKeyUpdateIntervalFieldNumber = 2;
  ::google::protobuf::uint64 keyupdateinterval() const;
  void set_keyupdateinterval(::google::protobuf::uint64 value);

  // required uint64 tokenLifeTime = 3;
  bool has_tokenlifetime() const;
  void clear_tokenlifetime();
  static const int kTokenLifeTimeFieldNumber = 3;
  ::google::protobuf::uint64 tokenlifetime() const;
  void set_tokenlifetime(::google::protobuf::uint64 value);

  // required bool isBlockTokenEnabled = 1;
  bool has_isblocktokenenabled() const;
  void clear_isblocktokenenabled();
  static const int kIsBlockTokenEnabledFieldNumber = 1;
  bool isblocktokenenabled() const;
  void set_isblocktokenenabled(bool value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.ExportedBlockKeysProto)
 private:
  void set_has_isblocktokenenabled();
  void clear_has_isblocktokenenabled();
  void set_has_keyupdateinterval();
  void clear_has_keyupdateinterval();
  void set_has_tokenlifetime();
  void clear_has_tokenlifetime();
  void set_has_currentkey();
  void clear_has_currentkey();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::BlockKeyProto > allkeys_;
  ::hadoop::hdfs::BlockKeyProto* currentkey_;
  ::google::protobuf::uint64 keyupdateinterval_;
  ::google::protobuf::uint64 tokenlifetime_;
  bool isblocktokenenabled_;
  friend struct ::protobuf_HdfsServer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class BlockWithLocationsProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.BlockWithLocationsProto) */ {
 public:
  BlockWithLocationsProto();
  virtual ~BlockWithLocationsProto();

  BlockWithLocationsProto(const BlockWithLocationsProto& from);

  inline BlockWithLocationsProto& operator=(const BlockWithLocationsProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  BlockWithLocationsProto(BlockWithLocationsProto&& from) noexcept
    : BlockWithLocationsProto() {
    *this = ::std::move(from);
  }

  inline BlockWithLocationsProto& operator=(BlockWithLocationsProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const BlockWithLocationsProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const BlockWithLocationsProto* internal_default_instance() {
    return reinterpret_cast<const BlockWithLocationsProto*>(
               &_BlockWithLocationsProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    2;

  void Swap(BlockWithLocationsProto* other);
  friend void swap(BlockWithLocationsProto& a, BlockWithLocationsProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline BlockWithLocationsProto* New() const final {
    return CreateMaybeMessage<BlockWithLocationsProto>(NULL);
  }

  BlockWithLocationsProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<BlockWithLocationsProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const BlockWithLocationsProto& from);
  void MergeFrom(const BlockWithLocationsProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(BlockWithLocationsProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated string datanodeUuids = 2;
  int datanodeuuids_size() const;
  void clear_datanodeuuids();
  static const int kDatanodeUuidsFieldNumber = 2;
  const ::std::string& datanodeuuids(int index) const;
  ::std::string* mutable_datanodeuuids(int index);
  void set_datanodeuuids(int index, const ::std::string& value);
  #if LANG_CXX11
  void set_datanodeuuids(int index, ::std::string&& value);
  #endif
  void set_datanodeuuids(int index, const char* value);
  void set_datanodeuuids(int index, const char* value, size_t size);
  ::std::string* add_datanodeuuids();
  void add_datanodeuuids(const ::std::string& value);
  #if LANG_CXX11
  void add_datanodeuuids(::std::string&& value);
  #endif
  void add_datanodeuuids(const char* value);
  void add_datanodeuuids(const char* value, size_t size);
  const ::google::protobuf::RepeatedPtrField< ::std::string>& datanodeuuids() const;
  ::google::protobuf::RepeatedPtrField< ::std::string>* mutable_datanodeuuids();

  // repeated string storageUuids = 3;
  int storageuuids_size() const;
  void clear_storageuuids();
  static const int kStorageUuidsFieldNumber = 3;
  const ::std::string& storageuuids(int index) const;
  ::std::string* mutable_storageuuids(int index);
  void set_storageuuids(int index, const ::std::string& value);
  #if LANG_CXX11
  void set_storageuuids(int index, ::std::string&& value);
  #endif
  void set_storageuuids(int index, const char* value);
  void set_storageuuids(int index, const char* value, size_t size);
  ::std::string* add_storageuuids();
  void add_storageuuids(const ::std::string& value);
  #if LANG_CXX11
  void add_storageuuids(::std::string&& value);
  #endif
  void add_storageuuids(const char* value);
  void add_storageuuids(const char* value, size_t size);
  const ::google::protobuf::RepeatedPtrField< ::std::string>& storageuuids() const;
  ::google::protobuf::RepeatedPtrField< ::std::string>* mutable_storageuuids();

  // repeated .hadoop.hdfs.StorageTypeProto storageTypes = 4;
  int storagetypes_size() const;
  void clear_storagetypes();
  static const int kStorageTypesFieldNumber = 4;
  ::hadoop::hdfs::StorageTypeProto storagetypes(int index) const;
  void set_storagetypes(int index, ::hadoop::hdfs::StorageTypeProto value);
  void add_storagetypes(::hadoop::hdfs::StorageTypeProto value);
  const ::google::protobuf::RepeatedField<int>& storagetypes() const;
  ::google::protobuf::RepeatedField<int>* mutable_storagetypes();

  // optional bytes indices = 5;
  bool has_indices() const;
  void clear_indices();
  static const int kIndicesFieldNumber = 5;
  const ::std::string& indices() const;
  void set_indices(const ::std::string& value);
  #if LANG_CXX11
  void set_indices(::std::string&& value);
  #endif
  void set_indices(const char* value);
  void set_indices(const void* value, size_t size);
  ::std::string* mutable_indices();
  ::std::string* release_indices();
  void set_allocated_indices(::std::string* indices);

  // required .hadoop.hdfs.BlockProto block = 1;
  bool has_block() const;
  void clear_block();
  static const int kBlockFieldNumber = 1;
  private:
  const ::hadoop::hdfs::BlockProto& _internal_block() const;
  public:
  const ::hadoop::hdfs::BlockProto& block() const;
  ::hadoop::hdfs::BlockProto* release_block();
  ::hadoop::hdfs::BlockProto* mutable_block();
  void set_allocated_block(::hadoop::hdfs::BlockProto* block);

  // optional uint32 dataBlockNum = 6;
  bool has_datablocknum() const;
  void clear_datablocknum();
  static const int kDataBlockNumFieldNumber = 6;
  ::google::protobuf::uint32 datablocknum() const;
  void set_datablocknum(::google::protobuf::uint32 value);

  // optional uint32 cellSize = 7;
  bool has_cellsize() const;
  void clear_cellsize();
  static const int kCellSizeFieldNumber = 7;
  ::google::protobuf::uint32 cellsize() const;
  void set_cellsize(::google::protobuf::uint32 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.BlockWithLocationsProto)
 private:
  void set_has_block();
  void clear_has_block();
  void set_has_indices();
  void clear_has_indices();
  void set_has_datablocknum();
  void clear_has_datablocknum();
  void set_has_cellsize();
  void clear_has_cellsize();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::RepeatedPtrField< ::std::string> datanodeuuids_;
  ::google::protobuf::RepeatedPtrField< ::std::string> storageuuids_;
  ::google::protobuf::RepeatedField<int> storagetypes_;
  ::google::protobuf::internal::ArenaStringPtr indices_;
  ::hadoop::hdfs::BlockProto* block_;
  ::google::protobuf::uint32 datablocknum_;
  ::google::protobuf::uint32 cellsize_;
  friend struct ::protobuf_HdfsServer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class BlocksWithLocationsProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.BlocksWithLocationsProto) */ {
 public:
  BlocksWithLocationsProto();
  virtual ~BlocksWithLocationsProto();

  BlocksWithLocationsProto(const BlocksWithLocationsProto& from);

  inline BlocksWithLocationsProto& operator=(const BlocksWithLocationsProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  BlocksWithLocationsProto(BlocksWithLocationsProto&& from) noexcept
    : BlocksWithLocationsProto() {
    *this = ::std::move(from);
  }

  inline BlocksWithLocationsProto& operator=(BlocksWithLocationsProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const BlocksWithLocationsProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const BlocksWithLocationsProto* internal_default_instance() {
    return reinterpret_cast<const BlocksWithLocationsProto*>(
               &_BlocksWithLocationsProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    3;

  void Swap(BlocksWithLocationsProto* other);
  friend void swap(BlocksWithLocationsProto& a, BlocksWithLocationsProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline BlocksWithLocationsProto* New() const final {
    return CreateMaybeMessage<BlocksWithLocationsProto>(NULL);
  }

  BlocksWithLocationsProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<BlocksWithLocationsProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const BlocksWithLocationsProto& from);
  void MergeFrom(const BlocksWithLocationsProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(BlocksWithLocationsProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.hdfs.BlockWithLocationsProto blocks = 1;
  int blocks_size() const;
  void clear_blocks();
  static const int kBlocksFieldNumber = 1;
  ::hadoop::hdfs::BlockWithLocationsProto* mutable_blocks(int index);
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::BlockWithLocationsProto >*
      mutable_blocks();
  const ::hadoop::hdfs::BlockWithLocationsProto& blocks(int index) const;
  ::hadoop::hdfs::BlockWithLocationsProto* add_blocks();
  const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::BlockWithLocationsProto >&
      blocks() const;

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.BlocksWithLocationsProto)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::BlockWithLocationsProto > blocks_;
  friend struct ::protobuf_HdfsServer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class RemoteEditLogProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.RemoteEditLogProto) */ {
 public:
  RemoteEditLogProto();
  virtual ~RemoteEditLogProto();

  RemoteEditLogProto(const RemoteEditLogProto& from);

  inline RemoteEditLogProto& operator=(const RemoteEditLogProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  RemoteEditLogProto(RemoteEditLogProto&& from) noexcept
    : RemoteEditLogProto() {
    *this = ::std::move(from);
  }

  inline RemoteEditLogProto& operator=(RemoteEditLogProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const RemoteEditLogProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const RemoteEditLogProto* internal_default_instance() {
    return reinterpret_cast<const RemoteEditLogProto*>(
               &_RemoteEditLogProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    4;

  void Swap(RemoteEditLogProto* other);
  friend void swap(RemoteEditLogProto& a, RemoteEditLogProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline RemoteEditLogProto* New() const final {
    return CreateMaybeMessage<RemoteEditLogProto>(NULL);
  }

  RemoteEditLogProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<RemoteEditLogProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const RemoteEditLogProto& from);
  void MergeFrom(const RemoteEditLogProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(RemoteEditLogProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required uint64 startTxId = 1;
  bool has_starttxid() const;
  void clear_starttxid();
  static const int kStartTxIdFieldNumber = 1;
  ::google::protobuf::uint64 starttxid() const;
  void set_starttxid(::google::protobuf::uint64 value);

  // required uint64 endTxId = 2;
  bool has_endtxid() const;
  void clear_endtxid();
  static const int kEndTxIdFieldNumber = 2;
  ::google::protobuf::uint64 endtxid() const;
  void set_endtxid(::google::protobuf::uint64 value);

  // optional bool isInProgress = 3 [default = false];
  bool has_isinprogress() const;
  void clear_isinprogress();
  static const int kIsInProgressFieldNumber = 3;
  bool isinprogress() const;
  void set_isinprogress(bool value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.RemoteEditLogProto)
 private:
  void set_has_starttxid();
  void clear_has_starttxid();
  void set_has_endtxid();
  void clear_has_endtxid();
  void set_has_isinprogress();
  void clear_has_isinprogress();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::uint64 starttxid_;
  ::google::protobuf::uint64 endtxid_;
  bool isinprogress_;
  friend struct ::protobuf_HdfsServer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class RemoteEditLogManifestProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.RemoteEditLogManifestProto) */ {
 public:
  RemoteEditLogManifestProto();
  virtual ~RemoteEditLogManifestProto();

  RemoteEditLogManifestProto(const RemoteEditLogManifestProto& from);

  inline RemoteEditLogManifestProto& operator=(const RemoteEditLogManifestProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  RemoteEditLogManifestProto(RemoteEditLogManifestProto&& from) noexcept
    : RemoteEditLogManifestProto() {
    *this = ::std::move(from);
  }

  inline RemoteEditLogManifestProto& operator=(RemoteEditLogManifestProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const RemoteEditLogManifestProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const RemoteEditLogManifestProto* internal_default_instance() {
    return reinterpret_cast<const RemoteEditLogManifestProto*>(
               &_RemoteEditLogManifestProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    5;

  void Swap(RemoteEditLogManifestProto* other);
  friend void swap(RemoteEditLogManifestProto& a, RemoteEditLogManifestProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline RemoteEditLogManifestProto* New() const final {
    return CreateMaybeMessage<RemoteEditLogManifestProto>(NULL);
  }

  RemoteEditLogManifestProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<RemoteEditLogManifestProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const RemoteEditLogManifestProto& from);
  void MergeFrom(const RemoteEditLogManifestProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(RemoteEditLogManifestProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // repeated .hadoop.hdfs.RemoteEditLogProto logs = 1;
  int logs_size() const;
  void clear_logs();
  static const int kLogsFieldNumber = 1;
  ::hadoop::hdfs::RemoteEditLogProto* mutable_logs(int index);
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::RemoteEditLogProto >*
      mutable_logs();
  const ::hadoop::hdfs::RemoteEditLogProto& logs(int index) const;
  ::hadoop::hdfs::RemoteEditLogProto* add_logs();
  const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::RemoteEditLogProto >&
      logs() const;

  // optional uint64 committedTxnId = 2;
  bool has_committedtxnid() const;
  void clear_committedtxnid();
  static const int kCommittedTxnIdFieldNumber = 2;
  ::google::protobuf::uint64 committedtxnid() const;
  void set_committedtxnid(::google::protobuf::uint64 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.RemoteEditLogManifestProto)
 private:
  void set_has_committedtxnid();
  void clear_has_committedtxnid();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::RemoteEditLogProto > logs_;
  ::google::protobuf::uint64 committedtxnid_;
  friend struct ::protobuf_HdfsServer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class NamespaceInfoProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.NamespaceInfoProto) */ {
 public:
  NamespaceInfoProto();
  virtual ~NamespaceInfoProto();

  NamespaceInfoProto(const NamespaceInfoProto& from);

  inline NamespaceInfoProto& operator=(const NamespaceInfoProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  NamespaceInfoProto(NamespaceInfoProto&& from) noexcept
    : NamespaceInfoProto() {
    *this = ::std::move(from);
  }

  inline NamespaceInfoProto& operator=(NamespaceInfoProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const NamespaceInfoProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const NamespaceInfoProto* internal_default_instance() {
    return reinterpret_cast<const NamespaceInfoProto*>(
               &_NamespaceInfoProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    6;

  void Swap(NamespaceInfoProto* other);
  friend void swap(NamespaceInfoProto& a, NamespaceInfoProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline NamespaceInfoProto* New() const final {
    return CreateMaybeMessage<NamespaceInfoProto>(NULL);
  }

  NamespaceInfoProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<NamespaceInfoProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const NamespaceInfoProto& from);
  void MergeFrom(const NamespaceInfoProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(NamespaceInfoProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required string buildVersion = 1;
  bool has_buildversion() const;
  void clear_buildversion();
  static const int kBuildVersionFieldNumber = 1;
  const ::std::string& buildversion() const;
  void set_buildversion(const ::std::string& value);
  #if LANG_CXX11
  void set_buildversion(::std::string&& value);
  #endif
  void set_buildversion(const char* value);
  void set_buildversion(const char* value, size_t size);
  ::std::string* mutable_buildversion();
  ::std::string* release_buildversion();
  void set_allocated_buildversion(::std::string* buildversion);

  // required string blockPoolID = 3;
  bool has_blockpoolid() const;
  void clear_blockpoolid();
  static const int kBlockPoolIDFieldNumber = 3;
  const ::std::string& blockpoolid() const;
  void set_blockpoolid(const ::std::string& value);
  #if LANG_CXX11
  void set_blockpoolid(::std::string&& value);
  #endif
  void set_blockpoolid(const char* value);
  void set_blockpoolid(const char* value, size_t size);
  ::std::string* mutable_blockpoolid();
  ::std::string* release_blockpoolid();
  void set_allocated_blockpoolid(::std::string* blockpoolid);

  // required string softwareVersion = 5;
  bool has_softwareversion() const;
  void clear_softwareversion();
  static const int kSoftwareVersionFieldNumber = 5;
  const ::std::string& softwareversion() const;
  void set_softwareversion(const ::std::string& value);
  #if LANG_CXX11
  void set_softwareversion(::std::string&& value);
  #endif
  void set_softwareversion(const char* value);
  void set_softwareversion(const char* value, size_t size);
  ::std::string* mutable_softwareversion();
  ::std::string* release_softwareversion();
  void set_allocated_softwareversion(::std::string* softwareversion);

  // required .hadoop.hdfs.StorageInfoProto storageInfo = 4;
  bool has_storageinfo() const;
  void clear_storageinfo();
  static const int kStorageInfoFieldNumber = 4;
  private:
  const ::hadoop::hdfs::StorageInfoProto& _internal_storageinfo() const;
  public:
  const ::hadoop::hdfs::StorageInfoProto& storageinfo() const;
  ::hadoop::hdfs::StorageInfoProto* release_storageinfo();
  ::hadoop::hdfs::StorageInfoProto* mutable_storageinfo();
  void set_allocated_storageinfo(::hadoop::hdfs::StorageInfoProto* storageinfo);

  // required uint32 unused = 2;
  bool has_unused() const;
  void clear_unused();
  static const int kUnusedFieldNumber = 2;
  ::google::protobuf::uint32 unused() const;
  void set_unused(::google::protobuf::uint32 value);

  // optional .hadoop.hdfs.NNHAStatusHeartbeatProto.State state = 7;
  bool has_state() const;
  void clear_state();
  static const int kStateFieldNumber = 7;
  ::hadoop::hdfs::NNHAStatusHeartbeatProto_State state() const;
  void set_state(::hadoop::hdfs::NNHAStatusHeartbeatProto_State value);

  // optional uint64 capabilities = 6 [default = 0];
  bool has_capabilities() const;
  void clear_capabilities();
  static const int kCapabilitiesFieldNumber = 6;
  ::google::protobuf::uint64 capabilities() const;
  void set_capabilities(::google::protobuf::uint64 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.NamespaceInfoProto)
 private:
  void set_has_buildversion();
  void clear_has_buildversion();
  void set_has_unused();
  void clear_has_unused();
  void set_has_blockpoolid();
  void clear_has_blockpoolid();
  void set_has_storageinfo();
  void clear_has_storageinfo();
  void set_has_softwareversion();
  void clear_has_softwareversion();
  void set_has_capabilities();
  void clear_has_capabilities();
  void set_has_state();
  void clear_has_state();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr buildversion_;
  ::google::protobuf::internal::ArenaStringPtr blockpoolid_;
  ::google::protobuf::internal::ArenaStringPtr softwareversion_;
  ::hadoop::hdfs::StorageInfoProto* storageinfo_;
  ::google::protobuf::uint32 unused_;
  int state_;
  ::google::protobuf::uint64 capabilities_;
  friend struct ::protobuf_HdfsServer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class RecoveringBlockProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.RecoveringBlockProto) */ {
 public:
  RecoveringBlockProto();
  virtual ~RecoveringBlockProto();

  RecoveringBlockProto(const RecoveringBlockProto& from);

  inline RecoveringBlockProto& operator=(const RecoveringBlockProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  RecoveringBlockProto(RecoveringBlockProto&& from) noexcept
    : RecoveringBlockProto() {
    *this = ::std::move(from);
  }

  inline RecoveringBlockProto& operator=(RecoveringBlockProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const RecoveringBlockProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const RecoveringBlockProto* internal_default_instance() {
    return reinterpret_cast<const RecoveringBlockProto*>(
               &_RecoveringBlockProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    7;

  void Swap(RecoveringBlockProto* other);
  friend void swap(RecoveringBlockProto& a, RecoveringBlockProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline RecoveringBlockProto* New() const final {
    return CreateMaybeMessage<RecoveringBlockProto>(NULL);
  }

  RecoveringBlockProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<RecoveringBlockProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const RecoveringBlockProto& from);
  void MergeFrom(const RecoveringBlockProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(RecoveringBlockProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional bytes blockIndices = 5;
  bool has_blockindices() const;
  void clear_blockindices();
  static const int kBlockIndicesFieldNumber = 5;
  const ::std::string& blockindices() const;
  void set_blockindices(const ::std::string& value);
  #if LANG_CXX11
  void set_blockindices(::std::string&& value);
  #endif
  void set_blockindices(const char* value);
  void set_blockindices(const void* value, size_t size);
  ::std::string* mutable_blockindices();
  ::std::string* release_blockindices();
  void set_allocated_blockindices(::std::string* blockindices);

  // required .hadoop.hdfs.LocatedBlockProto block = 2;
  bool has_block() const;
  void clear_block();
  static const int kBlockFieldNumber = 2;
  private:
  const ::hadoop::hdfs::LocatedBlockProto& _internal_block() const;
  public:
  const ::hadoop::hdfs::LocatedBlockProto& block() const;
  ::hadoop::hdfs::LocatedBlockProto* release_block();
  ::hadoop::hdfs::LocatedBlockProto* mutable_block();
  void set_allocated_block(::hadoop::hdfs::LocatedBlockProto* block);

  // optional .hadoop.hdfs.BlockProto truncateBlock = 3;
  bool has_truncateblock() const;
  void clear_truncateblock();
  static const int kTruncateBlockFieldNumber = 3;
  private:
  const ::hadoop::hdfs::BlockProto& _internal_truncateblock() const;
  public:
  const ::hadoop::hdfs::BlockProto& truncateblock() const;
  ::hadoop::hdfs::BlockProto* release_truncateblock();
  ::hadoop::hdfs::BlockProto* mutable_truncateblock();
  void set_allocated_truncateblock(::hadoop::hdfs::BlockProto* truncateblock);

  // optional .hadoop.hdfs.ErasureCodingPolicyProto ecPolicy = 4;
  bool has_ecpolicy() const;
  void clear_ecpolicy();
  static const int kEcPolicyFieldNumber = 4;
  private:
  const ::hadoop::hdfs::ErasureCodingPolicyProto& _internal_ecpolicy() const;
  public:
  const ::hadoop::hdfs::ErasureCodingPolicyProto& ecpolicy() const;
  ::hadoop::hdfs::ErasureCodingPolicyProto* release_ecpolicy();
  ::hadoop::hdfs::ErasureCodingPolicyProto* mutable_ecpolicy();
  void set_allocated_ecpolicy(::hadoop::hdfs::ErasureCodingPolicyProto* ecpolicy);

  // required uint64 newGenStamp = 1;
  bool has_newgenstamp() const;
  void clear_newgenstamp();
  static const int kNewGenStampFieldNumber = 1;
  ::google::protobuf::uint64 newgenstamp() const;
  void set_newgenstamp(::google::protobuf::uint64 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.RecoveringBlockProto)
 private:
  void set_has_newgenstamp();
  void clear_has_newgenstamp();
  void set_has_block();
  void clear_has_block();
  void set_has_truncateblock();
  void clear_has_truncateblock();
  void set_has_ecpolicy();
  void clear_has_ecpolicy();
  void set_has_blockindices();
  void clear_has_blockindices();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr blockindices_;
  ::hadoop::hdfs::LocatedBlockProto* block_;
  ::hadoop::hdfs::BlockProto* truncateblock_;
  ::hadoop::hdfs::ErasureCodingPolicyProto* ecpolicy_;
  ::google::protobuf::uint64 newgenstamp_;
  friend struct ::protobuf_HdfsServer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class CheckpointSignatureProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.CheckpointSignatureProto) */ {
 public:
  CheckpointSignatureProto();
  virtual ~CheckpointSignatureProto();

  CheckpointSignatureProto(const CheckpointSignatureProto& from);

  inline CheckpointSignatureProto& operator=(const CheckpointSignatureProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  CheckpointSignatureProto(CheckpointSignatureProto&& from) noexcept
    : CheckpointSignatureProto() {
    *this = ::std::move(from);
  }

  inline CheckpointSignatureProto& operator=(CheckpointSignatureProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const CheckpointSignatureProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const CheckpointSignatureProto* internal_default_instance() {
    return reinterpret_cast<const CheckpointSignatureProto*>(
               &_CheckpointSignatureProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    8;

  void Swap(CheckpointSignatureProto* other);
  friend void swap(CheckpointSignatureProto& a, CheckpointSignatureProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline CheckpointSignatureProto* New() const final {
    return CreateMaybeMessage<CheckpointSignatureProto>(NULL);
  }

  CheckpointSignatureProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<CheckpointSignatureProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const CheckpointSignatureProto& from);
  void MergeFrom(const CheckpointSignatureProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(CheckpointSignatureProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required string blockPoolId = 1;
  bool has_blockpoolid() const;
  void clear_blockpoolid();
  static const int kBlockPoolIdFieldNumber = 1;
  const ::std::string& blockpoolid() const;
  void set_blockpoolid(const ::std::string& value);
  #if LANG_CXX11
  void set_blockpoolid(::std::string&& value);
  #endif
  void set_blockpoolid(const char* value);
  void set_blockpoolid(const char* value, size_t size);
  ::std::string* mutable_blockpoolid();
  ::std::string* release_blockpoolid();
  void set_allocated_blockpoolid(::std::string* blockpoolid);

  // required .hadoop.hdfs.StorageInfoProto storageInfo = 4;
  bool has_storageinfo() const;
  void clear_storageinfo();
  static const int kStorageInfoFieldNumber = 4;
  private:
  const ::hadoop::hdfs::StorageInfoProto& _internal_storageinfo() const;
  public:
  const ::hadoop::hdfs::StorageInfoProto& storageinfo() const;
  ::hadoop::hdfs::StorageInfoProto* release_storageinfo();
  ::hadoop::hdfs::StorageInfoProto* mutable_storageinfo();
  void set_allocated_storageinfo(::hadoop::hdfs::StorageInfoProto* storageinfo);

  // required uint64 mostRecentCheckpointTxId = 2;
  bool has_mostrecentcheckpointtxid() const;
  void clear_mostrecentcheckpointtxid();
  static const int kMostRecentCheckpointTxIdFieldNumber = 2;
  ::google::protobuf::uint64 mostrecentcheckpointtxid() const;
  void set_mostrecentcheckpointtxid(::google::protobuf::uint64 value);

  // required uint64 curSegmentTxId = 3;
  bool has_cursegmenttxid() const;
  void clear_cursegmenttxid();
  static const int kCurSegmentTxIdFieldNumber = 3;
  ::google::protobuf::uint64 cursegmenttxid() const;
  void set_cursegmenttxid(::google::protobuf::uint64 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.CheckpointSignatureProto)
 private:
  void set_has_blockpoolid();
  void clear_has_blockpoolid();
  void set_has_mostrecentcheckpointtxid();
  void clear_has_mostrecentcheckpointtxid();
  void set_has_cursegmenttxid();
  void clear_has_cursegmenttxid();
  void set_has_storageinfo();
  void clear_has_storageinfo();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr blockpoolid_;
  ::hadoop::hdfs::StorageInfoProto* storageinfo_;
  ::google::protobuf::uint64 mostrecentcheckpointtxid_;
  ::google::protobuf::uint64 cursegmenttxid_;
  friend struct ::protobuf_HdfsServer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class CheckpointCommandProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.CheckpointCommandProto) */ {
 public:
  CheckpointCommandProto();
  virtual ~CheckpointCommandProto();

  CheckpointCommandProto(const CheckpointCommandProto& from);

  inline CheckpointCommandProto& operator=(const CheckpointCommandProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  CheckpointCommandProto(CheckpointCommandProto&& from) noexcept
    : CheckpointCommandProto() {
    *this = ::std::move(from);
  }

  inline CheckpointCommandProto& operator=(CheckpointCommandProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const CheckpointCommandProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const CheckpointCommandProto* internal_default_instance() {
    return reinterpret_cast<const CheckpointCommandProto*>(
               &_CheckpointCommandProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    9;

  void Swap(CheckpointCommandProto* other);
  friend void swap(CheckpointCommandProto& a, CheckpointCommandProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline CheckpointCommandProto* New() const final {
    return CreateMaybeMessage<CheckpointCommandProto>(NULL);
  }

  CheckpointCommandProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<CheckpointCommandProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const CheckpointCommandProto& from);
  void MergeFrom(const CheckpointCommandProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(CheckpointCommandProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required .hadoop.hdfs.CheckpointSignatureProto signature = 1;
  bool has_signature() const;
  void clear_signature();
  static const int kSignatureFieldNumber = 1;
  private:
  const ::hadoop::hdfs::CheckpointSignatureProto& _internal_signature() const;
  public:
  const ::hadoop::hdfs::CheckpointSignatureProto& signature() const;
  ::hadoop::hdfs::CheckpointSignatureProto* release_signature();
  ::hadoop::hdfs::CheckpointSignatureProto* mutable_signature();
  void set_allocated_signature(::hadoop::hdfs::CheckpointSignatureProto* signature);

  // required bool needToReturnImage = 2;
  bool has_needtoreturnimage() const;
  void clear_needtoreturnimage();
  static const int kNeedToReturnImageFieldNumber = 2;
  bool needtoreturnimage() const;
  void set_needtoreturnimage(bool value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.CheckpointCommandProto)
 private:
  void set_has_signature();
  void clear_has_signature();
  void set_has_needtoreturnimage();
  void clear_has_needtoreturnimage();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::hadoop::hdfs::CheckpointSignatureProto* signature_;
  bool needtoreturnimage_;
  friend struct ::protobuf_HdfsServer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class NamenodeCommandProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.NamenodeCommandProto) */ {
 public:
  NamenodeCommandProto();
  virtual ~NamenodeCommandProto();

  NamenodeCommandProto(const NamenodeCommandProto& from);

  inline NamenodeCommandProto& operator=(const NamenodeCommandProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  NamenodeCommandProto(NamenodeCommandProto&& from) noexcept
    : NamenodeCommandProto() {
    *this = ::std::move(from);
  }

  inline NamenodeCommandProto& operator=(NamenodeCommandProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const NamenodeCommandProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const NamenodeCommandProto* internal_default_instance() {
    return reinterpret_cast<const NamenodeCommandProto*>(
               &_NamenodeCommandProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    10;

  void Swap(NamenodeCommandProto* other);
  friend void swap(NamenodeCommandProto& a, NamenodeCommandProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline NamenodeCommandProto* New() const final {
    return CreateMaybeMessage<NamenodeCommandProto>(NULL);
  }

  NamenodeCommandProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<NamenodeCommandProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const NamenodeCommandProto& from);
  void MergeFrom(const NamenodeCommandProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(NamenodeCommandProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  typedef NamenodeCommandProto_Type Type;
  static const Type NamenodeCommand =
    NamenodeCommandProto_Type_NamenodeCommand;
  static const Type CheckPointCommand =
    NamenodeCommandProto_Type_CheckPointCommand;
  static inline bool Type_IsValid(int value) {
    return NamenodeCommandProto_Type_IsValid(value);
  }
  static const Type Type_MIN =
    NamenodeCommandProto_Type_Type_MIN;
  static const Type Type_MAX =
    NamenodeCommandProto_Type_Type_MAX;
  static const int Type_ARRAYSIZE =
    NamenodeCommandProto_Type_Type_ARRAYSIZE;
  static inline const ::google::protobuf::EnumDescriptor*
  Type_descriptor() {
    return NamenodeCommandProto_Type_descriptor();
  }
  static inline const ::std::string& Type_Name(Type value) {
    return NamenodeCommandProto_Type_Name(value);
  }
  static inline bool Type_Parse(const ::std::string& name,
      Type* value) {
    return NamenodeCommandProto_Type_Parse(name, value);
  }

  // accessors -------------------------------------------------------

  // optional .hadoop.hdfs.CheckpointCommandProto checkpointCmd = 3;
  bool has_checkpointcmd() const;
  void clear_checkpointcmd();
  static const int kCheckpointCmdFieldNumber = 3;
  private:
  const ::hadoop::hdfs::CheckpointCommandProto& _internal_checkpointcmd() const;
  public:
  const ::hadoop::hdfs::CheckpointCommandProto& checkpointcmd() const;
  ::hadoop::hdfs::CheckpointCommandProto* release_checkpointcmd();
  ::hadoop::hdfs::CheckpointCommandProto* mutable_checkpointcmd();
  void set_allocated_checkpointcmd(::hadoop::hdfs::CheckpointCommandProto* checkpointcmd);

  // required uint32 action = 1;
  bool has_action() const;
  void clear_action();
  static const int kActionFieldNumber = 1;
  ::google::protobuf::uint32 action() const;
  void set_action(::google::protobuf::uint32 value);

  // required .hadoop.hdfs.NamenodeCommandProto.Type type = 2;
  bool has_type() const;
  void clear_type();
  static const int kTypeFieldNumber = 2;
  ::hadoop::hdfs::NamenodeCommandProto_Type type() const;
  void set_type(::hadoop::hdfs::NamenodeCommandProto_Type value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.NamenodeCommandProto)
 private:
  void set_has_action();
  void clear_has_action();
  void set_has_type();
  void clear_has_type();
  void set_has_checkpointcmd();
  void clear_has_checkpointcmd();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::hadoop::hdfs::CheckpointCommandProto* checkpointcmd_;
  ::google::protobuf::uint32 action_;
  int type_;
  friend struct ::protobuf_HdfsServer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class VersionRequestProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.VersionRequestProto) */ {
 public:
  VersionRequestProto();
  virtual ~VersionRequestProto();

  VersionRequestProto(const VersionRequestProto& from);

  inline VersionRequestProto& operator=(const VersionRequestProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  VersionRequestProto(VersionRequestProto&& from) noexcept
    : VersionRequestProto() {
    *this = ::std::move(from);
  }

  inline VersionRequestProto& operator=(VersionRequestProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const VersionRequestProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const VersionRequestProto* internal_default_instance() {
    return reinterpret_cast<const VersionRequestProto*>(
               &_VersionRequestProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    11;

  void Swap(VersionRequestProto* other);
  friend void swap(VersionRequestProto& a, VersionRequestProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline VersionRequestProto* New() const final {
    return CreateMaybeMessage<VersionRequestProto>(NULL);
  }

  VersionRequestProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<VersionRequestProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const VersionRequestProto& from);
  void MergeFrom(const VersionRequestProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(VersionRequestProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.VersionRequestProto)
 private:

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  friend struct ::protobuf_HdfsServer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class VersionResponseProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.VersionResponseProto) */ {
 public:
  VersionResponseProto();
  virtual ~VersionResponseProto();

  VersionResponseProto(const VersionResponseProto& from);

  inline VersionResponseProto& operator=(const VersionResponseProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  VersionResponseProto(VersionResponseProto&& from) noexcept
    : VersionResponseProto() {
    *this = ::std::move(from);
  }

  inline VersionResponseProto& operator=(VersionResponseProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const VersionResponseProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const VersionResponseProto* internal_default_instance() {
    return reinterpret_cast<const VersionResponseProto*>(
               &_VersionResponseProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    12;

  void Swap(VersionResponseProto* other);
  friend void swap(VersionResponseProto& a, VersionResponseProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline VersionResponseProto* New() const final {
    return CreateMaybeMessage<VersionResponseProto>(NULL);
  }

  VersionResponseProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<VersionResponseProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const VersionResponseProto& from);
  void MergeFrom(const VersionResponseProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(VersionResponseProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required .hadoop.hdfs.NamespaceInfoProto info = 1;
  bool has_info() const;
  void clear_info();
  static const int kInfoFieldNumber = 1;
  private:
  const ::hadoop::hdfs::NamespaceInfoProto& _internal_info() const;
  public:
  const ::hadoop::hdfs::NamespaceInfoProto& info() const;
  ::hadoop::hdfs::NamespaceInfoProto* release_info();
  ::hadoop::hdfs::NamespaceInfoProto* mutable_info();
  void set_allocated_info(::hadoop::hdfs::NamespaceInfoProto* info);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.VersionResponseProto)
 private:
  void set_has_info();
  void clear_has_info();

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::hadoop::hdfs::NamespaceInfoProto* info_;
  friend struct ::protobuf_HdfsServer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class StorageInfoProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.StorageInfoProto) */ {
 public:
  StorageInfoProto();
  virtual ~StorageInfoProto();

  StorageInfoProto(const StorageInfoProto& from);

  inline StorageInfoProto& operator=(const StorageInfoProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  StorageInfoProto(StorageInfoProto&& from) noexcept
    : StorageInfoProto() {
    *this = ::std::move(from);
  }

  inline StorageInfoProto& operator=(StorageInfoProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const StorageInfoProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const StorageInfoProto* internal_default_instance() {
    return reinterpret_cast<const StorageInfoProto*>(
               &_StorageInfoProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    13;

  void Swap(StorageInfoProto* other);
  friend void swap(StorageInfoProto& a, StorageInfoProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline StorageInfoProto* New() const final {
    return CreateMaybeMessage<StorageInfoProto>(NULL);
  }

  StorageInfoProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<StorageInfoProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const StorageInfoProto& from);
  void MergeFrom(const StorageInfoProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(StorageInfoProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // required string clusterID = 3;
  bool has_clusterid() const;
  void clear_clusterid();
  static const int kClusterIDFieldNumber = 3;
  const ::std::string& clusterid() const;
  void set_clusterid(const ::std::string& value);
  #if LANG_CXX11
  void set_clusterid(::std::string&& value);
  #endif
  void set_clusterid(const char* value);
  void set_clusterid(const char* value, size_t size);
  ::std::string* mutable_clusterid();
  ::std::string* release_clusterid();
  void set_allocated_clusterid(::std::string* clusterid);

  // required uint32 layoutVersion = 1;
  bool has_layoutversion() const;
  void clear_layoutversion();
  static const int kLayoutVersionFieldNumber = 1;
  ::google::protobuf::uint32 layoutversion() const;
  void set_layoutversion(::google::protobuf::uint32 value);

  // required uint32 namespceID = 2;
  bool has_namespceid() const;
  void clear_namespceid();
  static const int kNamespceIDFieldNumber = 2;
  ::google::protobuf::uint32 namespceid() const;
  void set_namespceid(::google::protobuf::uint32 value);

  // required uint64 cTime = 4;
  bool has_ctime() const;
  void clear_ctime();
  static const int kCTimeFieldNumber = 4;
  ::google::protobuf::uint64 ctime() const;
  void set_ctime(::google::protobuf::uint64 value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.StorageInfoProto)
 private:
  void set_has_layoutversion();
  void clear_has_layoutversion();
  void set_has_namespceid();
  void clear_has_namespceid();
  void set_has_clusterid();
  void clear_has_clusterid();
  void set_has_ctime();
  void clear_has_ctime();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr clusterid_;
  ::google::protobuf::uint32 layoutversion_;
  ::google::protobuf::uint32 namespceid_;
  ::google::protobuf::uint64 ctime_;
  friend struct ::protobuf_HdfsServer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class NamenodeRegistrationProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.NamenodeRegistrationProto) */ {
 public:
  NamenodeRegistrationProto();
  virtual ~NamenodeRegistrationProto();

  NamenodeRegistrationProto(const NamenodeRegistrationProto& from);

  inline NamenodeRegistrationProto& operator=(const NamenodeRegistrationProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  NamenodeRegistrationProto(NamenodeRegistrationProto&& from) noexcept
    : NamenodeRegistrationProto() {
    *this = ::std::move(from);
  }

  inline NamenodeRegistrationProto& operator=(NamenodeRegistrationProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const NamenodeRegistrationProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const NamenodeRegistrationProto* internal_default_instance() {
    return reinterpret_cast<const NamenodeRegistrationProto*>(
               &_NamenodeRegistrationProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    14;

  void Swap(NamenodeRegistrationProto* other);
  friend void swap(NamenodeRegistrationProto& a, NamenodeRegistrationProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline NamenodeRegistrationProto* New() const final {
    return CreateMaybeMessage<NamenodeRegistrationProto>(NULL);
  }

  NamenodeRegistrationProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<NamenodeRegistrationProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const NamenodeRegistrationProto& from);
  void MergeFrom(const NamenodeRegistrationProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(NamenodeRegistrationProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  typedef NamenodeRegistrationProto_NamenodeRoleProto NamenodeRoleProto;
  static const NamenodeRoleProto NAMENODE =
    NamenodeRegistrationProto_NamenodeRoleProto_NAMENODE;
  static const NamenodeRoleProto BACKUP =
    NamenodeRegistrationProto_NamenodeRoleProto_BACKUP;
  static const NamenodeRoleProto CHECKPOINT =
    NamenodeRegistrationProto_NamenodeRoleProto_CHECKPOINT;
  static inline bool NamenodeRoleProto_IsValid(int value) {
    return NamenodeRegistrationProto_NamenodeRoleProto_IsValid(value);
  }
  static const NamenodeRoleProto NamenodeRoleProto_MIN =
    NamenodeRegistrationProto_NamenodeRoleProto_NamenodeRoleProto_MIN;
  static const NamenodeRoleProto NamenodeRoleProto_MAX =
    NamenodeRegistrationProto_NamenodeRoleProto_NamenodeRoleProto_MAX;
  static const int NamenodeRoleProto_ARRAYSIZE =
    NamenodeRegistrationProto_NamenodeRoleProto_NamenodeRoleProto_ARRAYSIZE;
  static inline const ::google::protobuf::EnumDescriptor*
  NamenodeRoleProto_descriptor() {
    return NamenodeRegistrationProto_NamenodeRoleProto_descriptor();
  }
  static inline const ::std::string& NamenodeRoleProto_Name(NamenodeRoleProto value) {
    return NamenodeRegistrationProto_NamenodeRoleProto_Name(value);
  }
  static inline bool NamenodeRoleProto_Parse(const ::std::string& name,
      NamenodeRoleProto* value) {
    return NamenodeRegistrationProto_NamenodeRoleProto_Parse(name, value);
  }

  // accessors -------------------------------------------------------

  // required string rpcAddress = 1;
  bool has_rpcaddress() const;
  void clear_rpcaddress();
  static const int kRpcAddressFieldNumber = 1;
  const ::std::string& rpcaddress() const;
  void set_rpcaddress(const ::std::string& value);
  #if LANG_CXX11
  void set_rpcaddress(::std::string&& value);
  #endif
  void set_rpcaddress(const char* value);
  void set_rpcaddress(const char* value, size_t size);
  ::std::string* mutable_rpcaddress();
  ::std::string* release_rpcaddress();
  void set_allocated_rpcaddress(::std::string* rpcaddress);

  // required string httpAddress = 2;
  bool has_httpaddress() const;
  void clear_httpaddress();
  static const int kHttpAddressFieldNumber = 2;
  const ::std::string& httpaddress() const;
  void set_httpaddress(const ::std::string& value);
  #if LANG_CXX11
  void set_httpaddress(::std::string&& value);
  #endif
  void set_httpaddress(const char* value);
  void set_httpaddress(const char* value, size_t size);
  ::std::string* mutable_httpaddress();
  ::std::string* release_httpaddress();
  void set_allocated_httpaddress(::std::string* httpaddress);

  // required .hadoop.hdfs.StorageInfoProto storageInfo = 3;
  bool has_storageinfo() const;
  void clear_storageinfo();
  static const int kStorageInfoFieldNumber = 3;
  private:
  const ::hadoop::hdfs::StorageInfoProto& _internal_storageinfo() const;
  public:
  const ::hadoop::hdfs::StorageInfoProto& storageinfo() const;
  ::hadoop::hdfs::StorageInfoProto* release_storageinfo();
  ::hadoop::hdfs::StorageInfoProto* mutable_storageinfo();
  void set_allocated_storageinfo(::hadoop::hdfs::StorageInfoProto* storageinfo);

  // optional .hadoop.hdfs.NamenodeRegistrationProto.NamenodeRoleProto role = 4 [default = NAMENODE];
  bool has_role() const;
  void clear_role();
  static const int kRoleFieldNumber = 4;
  ::hadoop::hdfs::NamenodeRegistrationProto_NamenodeRoleProto role() const;
  void set_role(::hadoop::hdfs::NamenodeRegistrationProto_NamenodeRoleProto value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.NamenodeRegistrationProto)
 private:
  void set_has_rpcaddress();
  void clear_has_rpcaddress();
  void set_has_httpaddress();
  void clear_has_httpaddress();
  void set_has_storageinfo();
  void clear_has_storageinfo();
  void set_has_role();
  void clear_has_role();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::internal::ArenaStringPtr rpcaddress_;
  ::google::protobuf::internal::ArenaStringPtr httpaddress_;
  ::hadoop::hdfs::StorageInfoProto* storageinfo_;
  int role_;
  friend struct ::protobuf_HdfsServer_2eproto::TableStruct;
};
// -------------------------------------------------------------------

class NNHAStatusHeartbeatProto : public ::google::protobuf::Message /* @@protoc_insertion_point(class_definition:hadoop.hdfs.NNHAStatusHeartbeatProto) */ {
 public:
  NNHAStatusHeartbeatProto();
  virtual ~NNHAStatusHeartbeatProto();

  NNHAStatusHeartbeatProto(const NNHAStatusHeartbeatProto& from);

  inline NNHAStatusHeartbeatProto& operator=(const NNHAStatusHeartbeatProto& from) {
    CopyFrom(from);
    return *this;
  }
  #if LANG_CXX11
  NNHAStatusHeartbeatProto(NNHAStatusHeartbeatProto&& from) noexcept
    : NNHAStatusHeartbeatProto() {
    *this = ::std::move(from);
  }

  inline NNHAStatusHeartbeatProto& operator=(NNHAStatusHeartbeatProto&& from) noexcept {
    if (GetArenaNoVirtual() == from.GetArenaNoVirtual()) {
      if (this != &from) InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }
  #endif
  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _internal_metadata_.unknown_fields();
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields();
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const NNHAStatusHeartbeatProto& default_instance();

  static void InitAsDefaultInstance();  // FOR INTERNAL USE ONLY
  static inline const NNHAStatusHeartbeatProto* internal_default_instance() {
    return reinterpret_cast<const NNHAStatusHeartbeatProto*>(
               &_NNHAStatusHeartbeatProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    15;

  void Swap(NNHAStatusHeartbeatProto* other);
  friend void swap(NNHAStatusHeartbeatProto& a, NNHAStatusHeartbeatProto& b) {
    a.Swap(&b);
  }

  // implements Message ----------------------------------------------

  inline NNHAStatusHeartbeatProto* New() const final {
    return CreateMaybeMessage<NNHAStatusHeartbeatProto>(NULL);
  }

  NNHAStatusHeartbeatProto* New(::google::protobuf::Arena* arena) const final {
    return CreateMaybeMessage<NNHAStatusHeartbeatProto>(arena);
  }
  void CopyFrom(const ::google::protobuf::Message& from) final;
  void MergeFrom(const ::google::protobuf::Message& from) final;
  void CopyFrom(const NNHAStatusHeartbeatProto& from);
  void MergeFrom(const NNHAStatusHeartbeatProto& from);
  void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input) final;
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const final;
  ::google::protobuf::uint8* InternalSerializeWithCachedSizesToArray(
      bool deterministic, ::google::protobuf::uint8* target) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const final;
  void InternalSwap(NNHAStatusHeartbeatProto* other);
  private:
  inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
    return NULL;
  }
  inline void* MaybeArenaPtr() const {
    return NULL;
  }
  public:

  ::google::protobuf::Metadata GetMetadata() const final;

  // nested types ----------------------------------------------------

  typedef NNHAStatusHeartbeatProto_State State;
  static const State ACTIVE =
    NNHAStatusHeartbeatProto_State_ACTIVE;
  static const State STANDBY =
    NNHAStatusHeartbeatProto_State_STANDBY;
  static const State OBSERVER =
    NNHAStatusHeartbeatProto_State_OBSERVER;
  static inline bool State_IsValid(int value) {
    return NNHAStatusHeartbeatProto_State_IsValid(value);
  }
  static const State State_MIN =
    NNHAStatusHeartbeatProto_State_State_MIN;
  static const State State_MAX =
    NNHAStatusHeartbeatProto_State_State_MAX;
  static const int State_ARRAYSIZE =
    NNHAStatusHeartbeatProto_State_State_ARRAYSIZE;
  static inline const ::google::protobuf::EnumDescriptor*
  State_descriptor() {
    return NNHAStatusHeartbeatProto_State_descriptor();
  }
  static inline const ::std::string& State_Name(State value) {
    return NNHAStatusHeartbeatProto_State_Name(value);
  }
  static inline bool State_Parse(const ::std::string& name,
      State* value) {
    return NNHAStatusHeartbeatProto_State_Parse(name, value);
  }

  // accessors -------------------------------------------------------

  // required uint64 txid = 2;
  bool has_txid() const;
  void clear_txid();
  static const int kTxidFieldNumber = 2;
  ::google::protobuf::uint64 txid() const;
  void set_txid(::google::protobuf::uint64 value);

  // required .hadoop.hdfs.NNHAStatusHeartbeatProto.State state = 1;
  bool has_state() const;
  void clear_state();
  static const int kStateFieldNumber = 1;
  ::hadoop::hdfs::NNHAStatusHeartbeatProto_State state() const;
  void set_state(::hadoop::hdfs::NNHAStatusHeartbeatProto_State value);

  // @@protoc_insertion_point(class_scope:hadoop.hdfs.NNHAStatusHeartbeatProto)
 private:
  void set_has_state();
  void clear_has_state();
  void set_has_txid();
  void clear_has_txid();

  // helper for ByteSizeLong()
  size_t RequiredFieldsByteSizeFallback() const;

  ::google::protobuf::internal::InternalMetadataWithArena _internal_metadata_;
  ::google::protobuf::internal::HasBits<1> _has_bits_;
  mutable ::google::protobuf::internal::CachedSize _cached_size_;
  ::google::protobuf::uint64 txid_;
  int state_;
  friend struct ::protobuf_HdfsServer_2eproto::TableStruct;
};
// ===================================================================


// ===================================================================

#ifdef __GNUC__
  #pragma GCC diagnostic push
  #pragma GCC diagnostic ignored "-Wstrict-aliasing"
#endif  // __GNUC__
// BlockKeyProto

// required uint32 keyId = 1;
inline bool BlockKeyProto::has_keyid() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void BlockKeyProto::set_has_keyid() {
  _has_bits_[0] |= 0x00000004u;
}
inline void BlockKeyProto::clear_has_keyid() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void BlockKeyProto::clear_keyid() {
  keyid_ = 0u;
  clear_has_keyid();
}
inline ::google::protobuf::uint32 BlockKeyProto::keyid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockKeyProto.keyId)
  return keyid_;
}
inline void BlockKeyProto::set_keyid(::google::protobuf::uint32 value) {
  set_has_keyid();
  keyid_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockKeyProto.keyId)
}

// required uint64 expiryDate = 2;
inline bool BlockKeyProto::has_expirydate() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void BlockKeyProto::set_has_expirydate() {
  _has_bits_[0] |= 0x00000002u;
}
inline void BlockKeyProto::clear_has_expirydate() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void BlockKeyProto::clear_expirydate() {
  expirydate_ = GOOGLE_ULONGLONG(0);
  clear_has_expirydate();
}
inline ::google::protobuf::uint64 BlockKeyProto::expirydate() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockKeyProto.expiryDate)
  return expirydate_;
}
inline void BlockKeyProto::set_expirydate(::google::protobuf::uint64 value) {
  set_has_expirydate();
  expirydate_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockKeyProto.expiryDate)
}

// optional bytes keyBytes = 3;
inline bool BlockKeyProto::has_keybytes() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void BlockKeyProto::set_has_keybytes() {
  _has_bits_[0] |= 0x00000001u;
}
inline void BlockKeyProto::clear_has_keybytes() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void BlockKeyProto::clear_keybytes() {
  keybytes_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_keybytes();
}
inline const ::std::string& BlockKeyProto::keybytes() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockKeyProto.keyBytes)
  return keybytes_.GetNoArena();
}
inline void BlockKeyProto::set_keybytes(const ::std::string& value) {
  set_has_keybytes();
  keybytes_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockKeyProto.keyBytes)
}
#if LANG_CXX11
inline void BlockKeyProto::set_keybytes(::std::string&& value) {
  set_has_keybytes();
  keybytes_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.BlockKeyProto.keyBytes)
}
#endif
inline void BlockKeyProto::set_keybytes(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_keybytes();
  keybytes_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.BlockKeyProto.keyBytes)
}
inline void BlockKeyProto::set_keybytes(const void* value, size_t size) {
  set_has_keybytes();
  keybytes_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.BlockKeyProto.keyBytes)
}
inline ::std::string* BlockKeyProto::mutable_keybytes() {
  set_has_keybytes();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.BlockKeyProto.keyBytes)
  return keybytes_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* BlockKeyProto::release_keybytes() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.BlockKeyProto.keyBytes)
  if (!has_keybytes()) {
    return NULL;
  }
  clear_has_keybytes();
  return keybytes_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void BlockKeyProto::set_allocated_keybytes(::std::string* keybytes) {
  if (keybytes != NULL) {
    set_has_keybytes();
  } else {
    clear_has_keybytes();
  }
  keybytes_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), keybytes);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.BlockKeyProto.keyBytes)
}

// -------------------------------------------------------------------

// ExportedBlockKeysProto

// required bool isBlockTokenEnabled = 1;
inline bool ExportedBlockKeysProto::has_isblocktokenenabled() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void ExportedBlockKeysProto::set_has_isblocktokenenabled() {
  _has_bits_[0] |= 0x00000008u;
}
inline void ExportedBlockKeysProto::clear_has_isblocktokenenabled() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void ExportedBlockKeysProto::clear_isblocktokenenabled() {
  isblocktokenenabled_ = false;
  clear_has_isblocktokenenabled();
}
inline bool ExportedBlockKeysProto::isblocktokenenabled() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ExportedBlockKeysProto.isBlockTokenEnabled)
  return isblocktokenenabled_;
}
inline void ExportedBlockKeysProto::set_isblocktokenenabled(bool value) {
  set_has_isblocktokenenabled();
  isblocktokenenabled_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ExportedBlockKeysProto.isBlockTokenEnabled)
}

// required uint64 keyUpdateInterval = 2;
inline bool ExportedBlockKeysProto::has_keyupdateinterval() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void ExportedBlockKeysProto::set_has_keyupdateinterval() {
  _has_bits_[0] |= 0x00000002u;
}
inline void ExportedBlockKeysProto::clear_has_keyupdateinterval() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void ExportedBlockKeysProto::clear_keyupdateinterval() {
  keyupdateinterval_ = GOOGLE_ULONGLONG(0);
  clear_has_keyupdateinterval();
}
inline ::google::protobuf::uint64 ExportedBlockKeysProto::keyupdateinterval() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ExportedBlockKeysProto.keyUpdateInterval)
  return keyupdateinterval_;
}
inline void ExportedBlockKeysProto::set_keyupdateinterval(::google::protobuf::uint64 value) {
  set_has_keyupdateinterval();
  keyupdateinterval_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ExportedBlockKeysProto.keyUpdateInterval)
}

// required uint64 tokenLifeTime = 3;
inline bool ExportedBlockKeysProto::has_tokenlifetime() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void ExportedBlockKeysProto::set_has_tokenlifetime() {
  _has_bits_[0] |= 0x00000004u;
}
inline void ExportedBlockKeysProto::clear_has_tokenlifetime() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void ExportedBlockKeysProto::clear_tokenlifetime() {
  tokenlifetime_ = GOOGLE_ULONGLONG(0);
  clear_has_tokenlifetime();
}
inline ::google::protobuf::uint64 ExportedBlockKeysProto::tokenlifetime() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ExportedBlockKeysProto.tokenLifeTime)
  return tokenlifetime_;
}
inline void ExportedBlockKeysProto::set_tokenlifetime(::google::protobuf::uint64 value) {
  set_has_tokenlifetime();
  tokenlifetime_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.ExportedBlockKeysProto.tokenLifeTime)
}

// required .hadoop.hdfs.BlockKeyProto currentKey = 4;
inline bool ExportedBlockKeysProto::has_currentkey() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void ExportedBlockKeysProto::set_has_currentkey() {
  _has_bits_[0] |= 0x00000001u;
}
inline void ExportedBlockKeysProto::clear_has_currentkey() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void ExportedBlockKeysProto::clear_currentkey() {
  if (currentkey_ != NULL) currentkey_->Clear();
  clear_has_currentkey();
}
inline const ::hadoop::hdfs::BlockKeyProto& ExportedBlockKeysProto::_internal_currentkey() const {
  return *currentkey_;
}
inline const ::hadoop::hdfs::BlockKeyProto& ExportedBlockKeysProto::currentkey() const {
  const ::hadoop::hdfs::BlockKeyProto* p = currentkey_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ExportedBlockKeysProto.currentKey)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::BlockKeyProto*>(
      &::hadoop::hdfs::_BlockKeyProto_default_instance_);
}
inline ::hadoop::hdfs::BlockKeyProto* ExportedBlockKeysProto::release_currentkey() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.ExportedBlockKeysProto.currentKey)
  clear_has_currentkey();
  ::hadoop::hdfs::BlockKeyProto* temp = currentkey_;
  currentkey_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::BlockKeyProto* ExportedBlockKeysProto::mutable_currentkey() {
  set_has_currentkey();
  if (currentkey_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::BlockKeyProto>(GetArenaNoVirtual());
    currentkey_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.ExportedBlockKeysProto.currentKey)
  return currentkey_;
}
inline void ExportedBlockKeysProto::set_allocated_currentkey(::hadoop::hdfs::BlockKeyProto* currentkey) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete currentkey_;
  }
  if (currentkey) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      currentkey = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, currentkey, submessage_arena);
    }
    set_has_currentkey();
  } else {
    clear_has_currentkey();
  }
  currentkey_ = currentkey;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.ExportedBlockKeysProto.currentKey)
}

// repeated .hadoop.hdfs.BlockKeyProto allKeys = 5;
inline int ExportedBlockKeysProto::allkeys_size() const {
  return allkeys_.size();
}
inline void ExportedBlockKeysProto::clear_allkeys() {
  allkeys_.Clear();
}
inline ::hadoop::hdfs::BlockKeyProto* ExportedBlockKeysProto::mutable_allkeys(int index) {
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.ExportedBlockKeysProto.allKeys)
  return allkeys_.Mutable(index);
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::BlockKeyProto >*
ExportedBlockKeysProto::mutable_allkeys() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.ExportedBlockKeysProto.allKeys)
  return &allkeys_;
}
inline const ::hadoop::hdfs::BlockKeyProto& ExportedBlockKeysProto::allkeys(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.ExportedBlockKeysProto.allKeys)
  return allkeys_.Get(index);
}
inline ::hadoop::hdfs::BlockKeyProto* ExportedBlockKeysProto::add_allkeys() {
  // @@protoc_insertion_point(field_add:hadoop.hdfs.ExportedBlockKeysProto.allKeys)
  return allkeys_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::BlockKeyProto >&
ExportedBlockKeysProto::allkeys() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.ExportedBlockKeysProto.allKeys)
  return allkeys_;
}

// -------------------------------------------------------------------

// BlockWithLocationsProto

// required .hadoop.hdfs.BlockProto block = 1;
inline bool BlockWithLocationsProto::has_block() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void BlockWithLocationsProto::set_has_block() {
  _has_bits_[0] |= 0x00000002u;
}
inline void BlockWithLocationsProto::clear_has_block() {
  _has_bits_[0] &= ~0x00000002u;
}
inline const ::hadoop::hdfs::BlockProto& BlockWithLocationsProto::_internal_block() const {
  return *block_;
}
inline const ::hadoop::hdfs::BlockProto& BlockWithLocationsProto::block() const {
  const ::hadoop::hdfs::BlockProto* p = block_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockWithLocationsProto.block)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::BlockProto*>(
      &::hadoop::hdfs::_BlockProto_default_instance_);
}
inline ::hadoop::hdfs::BlockProto* BlockWithLocationsProto::release_block() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.BlockWithLocationsProto.block)
  clear_has_block();
  ::hadoop::hdfs::BlockProto* temp = block_;
  block_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::BlockProto* BlockWithLocationsProto::mutable_block() {
  set_has_block();
  if (block_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::BlockProto>(GetArenaNoVirtual());
    block_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.BlockWithLocationsProto.block)
  return block_;
}
inline void BlockWithLocationsProto::set_allocated_block(::hadoop::hdfs::BlockProto* block) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete reinterpret_cast< ::google::protobuf::MessageLite*>(block_);
  }
  if (block) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      block = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, block, submessage_arena);
    }
    set_has_block();
  } else {
    clear_has_block();
  }
  block_ = block;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.BlockWithLocationsProto.block)
}

// repeated string datanodeUuids = 2;
inline int BlockWithLocationsProto::datanodeuuids_size() const {
  return datanodeuuids_.size();
}
inline void BlockWithLocationsProto::clear_datanodeuuids() {
  datanodeuuids_.Clear();
}
inline const ::std::string& BlockWithLocationsProto::datanodeuuids(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockWithLocationsProto.datanodeUuids)
  return datanodeuuids_.Get(index);
}
inline ::std::string* BlockWithLocationsProto::mutable_datanodeuuids(int index) {
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.BlockWithLocationsProto.datanodeUuids)
  return datanodeuuids_.Mutable(index);
}
inline void BlockWithLocationsProto::set_datanodeuuids(int index, const ::std::string& value) {
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockWithLocationsProto.datanodeUuids)
  datanodeuuids_.Mutable(index)->assign(value);
}
#if LANG_CXX11
inline void BlockWithLocationsProto::set_datanodeuuids(int index, ::std::string&& value) {
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockWithLocationsProto.datanodeUuids)
  datanodeuuids_.Mutable(index)->assign(std::move(value));
}
#endif
inline void BlockWithLocationsProto::set_datanodeuuids(int index, const char* value) {
  GOOGLE_DCHECK(value != NULL);
  datanodeuuids_.Mutable(index)->assign(value);
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.BlockWithLocationsProto.datanodeUuids)
}
inline void BlockWithLocationsProto::set_datanodeuuids(int index, const char* value, size_t size) {
  datanodeuuids_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.BlockWithLocationsProto.datanodeUuids)
}
inline ::std::string* BlockWithLocationsProto::add_datanodeuuids() {
  // @@protoc_insertion_point(field_add_mutable:hadoop.hdfs.BlockWithLocationsProto.datanodeUuids)
  return datanodeuuids_.Add();
}
inline void BlockWithLocationsProto::add_datanodeuuids(const ::std::string& value) {
  datanodeuuids_.Add()->assign(value);
  // @@protoc_insertion_point(field_add:hadoop.hdfs.BlockWithLocationsProto.datanodeUuids)
}
#if LANG_CXX11
inline void BlockWithLocationsProto::add_datanodeuuids(::std::string&& value) {
  datanodeuuids_.Add(std::move(value));
  // @@protoc_insertion_point(field_add:hadoop.hdfs.BlockWithLocationsProto.datanodeUuids)
}
#endif
inline void BlockWithLocationsProto::add_datanodeuuids(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  datanodeuuids_.Add()->assign(value);
  // @@protoc_insertion_point(field_add_char:hadoop.hdfs.BlockWithLocationsProto.datanodeUuids)
}
inline void BlockWithLocationsProto::add_datanodeuuids(const char* value, size_t size) {
  datanodeuuids_.Add()->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_add_pointer:hadoop.hdfs.BlockWithLocationsProto.datanodeUuids)
}
inline const ::google::protobuf::RepeatedPtrField< ::std::string>&
BlockWithLocationsProto::datanodeuuids() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.BlockWithLocationsProto.datanodeUuids)
  return datanodeuuids_;
}
inline ::google::protobuf::RepeatedPtrField< ::std::string>*
BlockWithLocationsProto::mutable_datanodeuuids() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.BlockWithLocationsProto.datanodeUuids)
  return &datanodeuuids_;
}

// repeated string storageUuids = 3;
inline int BlockWithLocationsProto::storageuuids_size() const {
  return storageuuids_.size();
}
inline void BlockWithLocationsProto::clear_storageuuids() {
  storageuuids_.Clear();
}
inline const ::std::string& BlockWithLocationsProto::storageuuids(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockWithLocationsProto.storageUuids)
  return storageuuids_.Get(index);
}
inline ::std::string* BlockWithLocationsProto::mutable_storageuuids(int index) {
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.BlockWithLocationsProto.storageUuids)
  return storageuuids_.Mutable(index);
}
inline void BlockWithLocationsProto::set_storageuuids(int index, const ::std::string& value) {
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockWithLocationsProto.storageUuids)
  storageuuids_.Mutable(index)->assign(value);
}
#if LANG_CXX11
inline void BlockWithLocationsProto::set_storageuuids(int index, ::std::string&& value) {
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockWithLocationsProto.storageUuids)
  storageuuids_.Mutable(index)->assign(std::move(value));
}
#endif
inline void BlockWithLocationsProto::set_storageuuids(int index, const char* value) {
  GOOGLE_DCHECK(value != NULL);
  storageuuids_.Mutable(index)->assign(value);
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.BlockWithLocationsProto.storageUuids)
}
inline void BlockWithLocationsProto::set_storageuuids(int index, const char* value, size_t size) {
  storageuuids_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.BlockWithLocationsProto.storageUuids)
}
inline ::std::string* BlockWithLocationsProto::add_storageuuids() {
  // @@protoc_insertion_point(field_add_mutable:hadoop.hdfs.BlockWithLocationsProto.storageUuids)
  return storageuuids_.Add();
}
inline void BlockWithLocationsProto::add_storageuuids(const ::std::string& value) {
  storageuuids_.Add()->assign(value);
  // @@protoc_insertion_point(field_add:hadoop.hdfs.BlockWithLocationsProto.storageUuids)
}
#if LANG_CXX11
inline void BlockWithLocationsProto::add_storageuuids(::std::string&& value) {
  storageuuids_.Add(std::move(value));
  // @@protoc_insertion_point(field_add:hadoop.hdfs.BlockWithLocationsProto.storageUuids)
}
#endif
inline void BlockWithLocationsProto::add_storageuuids(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  storageuuids_.Add()->assign(value);
  // @@protoc_insertion_point(field_add_char:hadoop.hdfs.BlockWithLocationsProto.storageUuids)
}
inline void BlockWithLocationsProto::add_storageuuids(const char* value, size_t size) {
  storageuuids_.Add()->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_add_pointer:hadoop.hdfs.BlockWithLocationsProto.storageUuids)
}
inline const ::google::protobuf::RepeatedPtrField< ::std::string>&
BlockWithLocationsProto::storageuuids() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.BlockWithLocationsProto.storageUuids)
  return storageuuids_;
}
inline ::google::protobuf::RepeatedPtrField< ::std::string>*
BlockWithLocationsProto::mutable_storageuuids() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.BlockWithLocationsProto.storageUuids)
  return &storageuuids_;
}

// repeated .hadoop.hdfs.StorageTypeProto storageTypes = 4;
inline int BlockWithLocationsProto::storagetypes_size() const {
  return storagetypes_.size();
}
inline void BlockWithLocationsProto::clear_storagetypes() {
  storagetypes_.Clear();
}
inline ::hadoop::hdfs::StorageTypeProto BlockWithLocationsProto::storagetypes(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockWithLocationsProto.storageTypes)
  return static_cast< ::hadoop::hdfs::StorageTypeProto >(storagetypes_.Get(index));
}
inline void BlockWithLocationsProto::set_storagetypes(int index, ::hadoop::hdfs::StorageTypeProto value) {
  assert(::hadoop::hdfs::StorageTypeProto_IsValid(value));
  storagetypes_.Set(index, value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockWithLocationsProto.storageTypes)
}
inline void BlockWithLocationsProto::add_storagetypes(::hadoop::hdfs::StorageTypeProto value) {
  assert(::hadoop::hdfs::StorageTypeProto_IsValid(value));
  storagetypes_.Add(value);
  // @@protoc_insertion_point(field_add:hadoop.hdfs.BlockWithLocationsProto.storageTypes)
}
inline const ::google::protobuf::RepeatedField<int>&
BlockWithLocationsProto::storagetypes() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.BlockWithLocationsProto.storageTypes)
  return storagetypes_;
}
inline ::google::protobuf::RepeatedField<int>*
BlockWithLocationsProto::mutable_storagetypes() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.BlockWithLocationsProto.storageTypes)
  return &storagetypes_;
}

// optional bytes indices = 5;
inline bool BlockWithLocationsProto::has_indices() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void BlockWithLocationsProto::set_has_indices() {
  _has_bits_[0] |= 0x00000001u;
}
inline void BlockWithLocationsProto::clear_has_indices() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void BlockWithLocationsProto::clear_indices() {
  indices_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_indices();
}
inline const ::std::string& BlockWithLocationsProto::indices() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockWithLocationsProto.indices)
  return indices_.GetNoArena();
}
inline void BlockWithLocationsProto::set_indices(const ::std::string& value) {
  set_has_indices();
  indices_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockWithLocationsProto.indices)
}
#if LANG_CXX11
inline void BlockWithLocationsProto::set_indices(::std::string&& value) {
  set_has_indices();
  indices_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.BlockWithLocationsProto.indices)
}
#endif
inline void BlockWithLocationsProto::set_indices(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_indices();
  indices_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.BlockWithLocationsProto.indices)
}
inline void BlockWithLocationsProto::set_indices(const void* value, size_t size) {
  set_has_indices();
  indices_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.BlockWithLocationsProto.indices)
}
inline ::std::string* BlockWithLocationsProto::mutable_indices() {
  set_has_indices();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.BlockWithLocationsProto.indices)
  return indices_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* BlockWithLocationsProto::release_indices() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.BlockWithLocationsProto.indices)
  if (!has_indices()) {
    return NULL;
  }
  clear_has_indices();
  return indices_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void BlockWithLocationsProto::set_allocated_indices(::std::string* indices) {
  if (indices != NULL) {
    set_has_indices();
  } else {
    clear_has_indices();
  }
  indices_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), indices);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.BlockWithLocationsProto.indices)
}

// optional uint32 dataBlockNum = 6;
inline bool BlockWithLocationsProto::has_datablocknum() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void BlockWithLocationsProto::set_has_datablocknum() {
  _has_bits_[0] |= 0x00000004u;
}
inline void BlockWithLocationsProto::clear_has_datablocknum() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void BlockWithLocationsProto::clear_datablocknum() {
  datablocknum_ = 0u;
  clear_has_datablocknum();
}
inline ::google::protobuf::uint32 BlockWithLocationsProto::datablocknum() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockWithLocationsProto.dataBlockNum)
  return datablocknum_;
}
inline void BlockWithLocationsProto::set_datablocknum(::google::protobuf::uint32 value) {
  set_has_datablocknum();
  datablocknum_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockWithLocationsProto.dataBlockNum)
}

// optional uint32 cellSize = 7;
inline bool BlockWithLocationsProto::has_cellsize() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void BlockWithLocationsProto::set_has_cellsize() {
  _has_bits_[0] |= 0x00000008u;
}
inline void BlockWithLocationsProto::clear_has_cellsize() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void BlockWithLocationsProto::clear_cellsize() {
  cellsize_ = 0u;
  clear_has_cellsize();
}
inline ::google::protobuf::uint32 BlockWithLocationsProto::cellsize() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlockWithLocationsProto.cellSize)
  return cellsize_;
}
inline void BlockWithLocationsProto::set_cellsize(::google::protobuf::uint32 value) {
  set_has_cellsize();
  cellsize_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.BlockWithLocationsProto.cellSize)
}

// -------------------------------------------------------------------

// BlocksWithLocationsProto

// repeated .hadoop.hdfs.BlockWithLocationsProto blocks = 1;
inline int BlocksWithLocationsProto::blocks_size() const {
  return blocks_.size();
}
inline void BlocksWithLocationsProto::clear_blocks() {
  blocks_.Clear();
}
inline ::hadoop::hdfs::BlockWithLocationsProto* BlocksWithLocationsProto::mutable_blocks(int index) {
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.BlocksWithLocationsProto.blocks)
  return blocks_.Mutable(index);
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::BlockWithLocationsProto >*
BlocksWithLocationsProto::mutable_blocks() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.BlocksWithLocationsProto.blocks)
  return &blocks_;
}
inline const ::hadoop::hdfs::BlockWithLocationsProto& BlocksWithLocationsProto::blocks(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.BlocksWithLocationsProto.blocks)
  return blocks_.Get(index);
}
inline ::hadoop::hdfs::BlockWithLocationsProto* BlocksWithLocationsProto::add_blocks() {
  // @@protoc_insertion_point(field_add:hadoop.hdfs.BlocksWithLocationsProto.blocks)
  return blocks_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::BlockWithLocationsProto >&
BlocksWithLocationsProto::blocks() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.BlocksWithLocationsProto.blocks)
  return blocks_;
}

// -------------------------------------------------------------------

// RemoteEditLogProto

// required uint64 startTxId = 1;
inline bool RemoteEditLogProto::has_starttxid() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void RemoteEditLogProto::set_has_starttxid() {
  _has_bits_[0] |= 0x00000001u;
}
inline void RemoteEditLogProto::clear_has_starttxid() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void RemoteEditLogProto::clear_starttxid() {
  starttxid_ = GOOGLE_ULONGLONG(0);
  clear_has_starttxid();
}
inline ::google::protobuf::uint64 RemoteEditLogProto::starttxid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.RemoteEditLogProto.startTxId)
  return starttxid_;
}
inline void RemoteEditLogProto::set_starttxid(::google::protobuf::uint64 value) {
  set_has_starttxid();
  starttxid_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.RemoteEditLogProto.startTxId)
}

// required uint64 endTxId = 2;
inline bool RemoteEditLogProto::has_endtxid() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void RemoteEditLogProto::set_has_endtxid() {
  _has_bits_[0] |= 0x00000002u;
}
inline void RemoteEditLogProto::clear_has_endtxid() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void RemoteEditLogProto::clear_endtxid() {
  endtxid_ = GOOGLE_ULONGLONG(0);
  clear_has_endtxid();
}
inline ::google::protobuf::uint64 RemoteEditLogProto::endtxid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.RemoteEditLogProto.endTxId)
  return endtxid_;
}
inline void RemoteEditLogProto::set_endtxid(::google::protobuf::uint64 value) {
  set_has_endtxid();
  endtxid_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.RemoteEditLogProto.endTxId)
}

// optional bool isInProgress = 3 [default = false];
inline bool RemoteEditLogProto::has_isinprogress() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void RemoteEditLogProto::set_has_isinprogress() {
  _has_bits_[0] |= 0x00000004u;
}
inline void RemoteEditLogProto::clear_has_isinprogress() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void RemoteEditLogProto::clear_isinprogress() {
  isinprogress_ = false;
  clear_has_isinprogress();
}
inline bool RemoteEditLogProto::isinprogress() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.RemoteEditLogProto.isInProgress)
  return isinprogress_;
}
inline void RemoteEditLogProto::set_isinprogress(bool value) {
  set_has_isinprogress();
  isinprogress_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.RemoteEditLogProto.isInProgress)
}

// -------------------------------------------------------------------

// RemoteEditLogManifestProto

// repeated .hadoop.hdfs.RemoteEditLogProto logs = 1;
inline int RemoteEditLogManifestProto::logs_size() const {
  return logs_.size();
}
inline void RemoteEditLogManifestProto::clear_logs() {
  logs_.Clear();
}
inline ::hadoop::hdfs::RemoteEditLogProto* RemoteEditLogManifestProto::mutable_logs(int index) {
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.RemoteEditLogManifestProto.logs)
  return logs_.Mutable(index);
}
inline ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::RemoteEditLogProto >*
RemoteEditLogManifestProto::mutable_logs() {
  // @@protoc_insertion_point(field_mutable_list:hadoop.hdfs.RemoteEditLogManifestProto.logs)
  return &logs_;
}
inline const ::hadoop::hdfs::RemoteEditLogProto& RemoteEditLogManifestProto::logs(int index) const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.RemoteEditLogManifestProto.logs)
  return logs_.Get(index);
}
inline ::hadoop::hdfs::RemoteEditLogProto* RemoteEditLogManifestProto::add_logs() {
  // @@protoc_insertion_point(field_add:hadoop.hdfs.RemoteEditLogManifestProto.logs)
  return logs_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::hadoop::hdfs::RemoteEditLogProto >&
RemoteEditLogManifestProto::logs() const {
  // @@protoc_insertion_point(field_list:hadoop.hdfs.RemoteEditLogManifestProto.logs)
  return logs_;
}

// optional uint64 committedTxnId = 2;
inline bool RemoteEditLogManifestProto::has_committedtxnid() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void RemoteEditLogManifestProto::set_has_committedtxnid() {
  _has_bits_[0] |= 0x00000001u;
}
inline void RemoteEditLogManifestProto::clear_has_committedtxnid() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void RemoteEditLogManifestProto::clear_committedtxnid() {
  committedtxnid_ = GOOGLE_ULONGLONG(0);
  clear_has_committedtxnid();
}
inline ::google::protobuf::uint64 RemoteEditLogManifestProto::committedtxnid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.RemoteEditLogManifestProto.committedTxnId)
  return committedtxnid_;
}
inline void RemoteEditLogManifestProto::set_committedtxnid(::google::protobuf::uint64 value) {
  set_has_committedtxnid();
  committedtxnid_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.RemoteEditLogManifestProto.committedTxnId)
}

// -------------------------------------------------------------------

// NamespaceInfoProto

// required string buildVersion = 1;
inline bool NamespaceInfoProto::has_buildversion() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void NamespaceInfoProto::set_has_buildversion() {
  _has_bits_[0] |= 0x00000001u;
}
inline void NamespaceInfoProto::clear_has_buildversion() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void NamespaceInfoProto::clear_buildversion() {
  buildversion_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_buildversion();
}
inline const ::std::string& NamespaceInfoProto::buildversion() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.NamespaceInfoProto.buildVersion)
  return buildversion_.GetNoArena();
}
inline void NamespaceInfoProto::set_buildversion(const ::std::string& value) {
  set_has_buildversion();
  buildversion_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.NamespaceInfoProto.buildVersion)
}
#if LANG_CXX11
inline void NamespaceInfoProto::set_buildversion(::std::string&& value) {
  set_has_buildversion();
  buildversion_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.NamespaceInfoProto.buildVersion)
}
#endif
inline void NamespaceInfoProto::set_buildversion(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_buildversion();
  buildversion_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.NamespaceInfoProto.buildVersion)
}
inline void NamespaceInfoProto::set_buildversion(const char* value, size_t size) {
  set_has_buildversion();
  buildversion_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.NamespaceInfoProto.buildVersion)
}
inline ::std::string* NamespaceInfoProto::mutable_buildversion() {
  set_has_buildversion();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.NamespaceInfoProto.buildVersion)
  return buildversion_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* NamespaceInfoProto::release_buildversion() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.NamespaceInfoProto.buildVersion)
  if (!has_buildversion()) {
    return NULL;
  }
  clear_has_buildversion();
  return buildversion_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void NamespaceInfoProto::set_allocated_buildversion(::std::string* buildversion) {
  if (buildversion != NULL) {
    set_has_buildversion();
  } else {
    clear_has_buildversion();
  }
  buildversion_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), buildversion);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.NamespaceInfoProto.buildVersion)
}

// required uint32 unused = 2;
inline bool NamespaceInfoProto::has_unused() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void NamespaceInfoProto::set_has_unused() {
  _has_bits_[0] |= 0x00000010u;
}
inline void NamespaceInfoProto::clear_has_unused() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void NamespaceInfoProto::clear_unused() {
  unused_ = 0u;
  clear_has_unused();
}
inline ::google::protobuf::uint32 NamespaceInfoProto::unused() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.NamespaceInfoProto.unused)
  return unused_;
}
inline void NamespaceInfoProto::set_unused(::google::protobuf::uint32 value) {
  set_has_unused();
  unused_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.NamespaceInfoProto.unused)
}

// required string blockPoolID = 3;
inline bool NamespaceInfoProto::has_blockpoolid() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void NamespaceInfoProto::set_has_blockpoolid() {
  _has_bits_[0] |= 0x00000002u;
}
inline void NamespaceInfoProto::clear_has_blockpoolid() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void NamespaceInfoProto::clear_blockpoolid() {
  blockpoolid_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_blockpoolid();
}
inline const ::std::string& NamespaceInfoProto::blockpoolid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.NamespaceInfoProto.blockPoolID)
  return blockpoolid_.GetNoArena();
}
inline void NamespaceInfoProto::set_blockpoolid(const ::std::string& value) {
  set_has_blockpoolid();
  blockpoolid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.NamespaceInfoProto.blockPoolID)
}
#if LANG_CXX11
inline void NamespaceInfoProto::set_blockpoolid(::std::string&& value) {
  set_has_blockpoolid();
  blockpoolid_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.NamespaceInfoProto.blockPoolID)
}
#endif
inline void NamespaceInfoProto::set_blockpoolid(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_blockpoolid();
  blockpoolid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.NamespaceInfoProto.blockPoolID)
}
inline void NamespaceInfoProto::set_blockpoolid(const char* value, size_t size) {
  set_has_blockpoolid();
  blockpoolid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.NamespaceInfoProto.blockPoolID)
}
inline ::std::string* NamespaceInfoProto::mutable_blockpoolid() {
  set_has_blockpoolid();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.NamespaceInfoProto.blockPoolID)
  return blockpoolid_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* NamespaceInfoProto::release_blockpoolid() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.NamespaceInfoProto.blockPoolID)
  if (!has_blockpoolid()) {
    return NULL;
  }
  clear_has_blockpoolid();
  return blockpoolid_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void NamespaceInfoProto::set_allocated_blockpoolid(::std::string* blockpoolid) {
  if (blockpoolid != NULL) {
    set_has_blockpoolid();
  } else {
    clear_has_blockpoolid();
  }
  blockpoolid_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), blockpoolid);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.NamespaceInfoProto.blockPoolID)
}

// required .hadoop.hdfs.StorageInfoProto storageInfo = 4;
inline bool NamespaceInfoProto::has_storageinfo() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void NamespaceInfoProto::set_has_storageinfo() {
  _has_bits_[0] |= 0x00000008u;
}
inline void NamespaceInfoProto::clear_has_storageinfo() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void NamespaceInfoProto::clear_storageinfo() {
  if (storageinfo_ != NULL) storageinfo_->Clear();
  clear_has_storageinfo();
}
inline const ::hadoop::hdfs::StorageInfoProto& NamespaceInfoProto::_internal_storageinfo() const {
  return *storageinfo_;
}
inline const ::hadoop::hdfs::StorageInfoProto& NamespaceInfoProto::storageinfo() const {
  const ::hadoop::hdfs::StorageInfoProto* p = storageinfo_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.NamespaceInfoProto.storageInfo)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::StorageInfoProto*>(
      &::hadoop::hdfs::_StorageInfoProto_default_instance_);
}
inline ::hadoop::hdfs::StorageInfoProto* NamespaceInfoProto::release_storageinfo() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.NamespaceInfoProto.storageInfo)
  clear_has_storageinfo();
  ::hadoop::hdfs::StorageInfoProto* temp = storageinfo_;
  storageinfo_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::StorageInfoProto* NamespaceInfoProto::mutable_storageinfo() {
  set_has_storageinfo();
  if (storageinfo_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::StorageInfoProto>(GetArenaNoVirtual());
    storageinfo_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.NamespaceInfoProto.storageInfo)
  return storageinfo_;
}
inline void NamespaceInfoProto::set_allocated_storageinfo(::hadoop::hdfs::StorageInfoProto* storageinfo) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete storageinfo_;
  }
  if (storageinfo) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      storageinfo = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, storageinfo, submessage_arena);
    }
    set_has_storageinfo();
  } else {
    clear_has_storageinfo();
  }
  storageinfo_ = storageinfo;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.NamespaceInfoProto.storageInfo)
}

// required string softwareVersion = 5;
inline bool NamespaceInfoProto::has_softwareversion() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void NamespaceInfoProto::set_has_softwareversion() {
  _has_bits_[0] |= 0x00000004u;
}
inline void NamespaceInfoProto::clear_has_softwareversion() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void NamespaceInfoProto::clear_softwareversion() {
  softwareversion_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_softwareversion();
}
inline const ::std::string& NamespaceInfoProto::softwareversion() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.NamespaceInfoProto.softwareVersion)
  return softwareversion_.GetNoArena();
}
inline void NamespaceInfoProto::set_softwareversion(const ::std::string& value) {
  set_has_softwareversion();
  softwareversion_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.NamespaceInfoProto.softwareVersion)
}
#if LANG_CXX11
inline void NamespaceInfoProto::set_softwareversion(::std::string&& value) {
  set_has_softwareversion();
  softwareversion_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.NamespaceInfoProto.softwareVersion)
}
#endif
inline void NamespaceInfoProto::set_softwareversion(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_softwareversion();
  softwareversion_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.NamespaceInfoProto.softwareVersion)
}
inline void NamespaceInfoProto::set_softwareversion(const char* value, size_t size) {
  set_has_softwareversion();
  softwareversion_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.NamespaceInfoProto.softwareVersion)
}
inline ::std::string* NamespaceInfoProto::mutable_softwareversion() {
  set_has_softwareversion();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.NamespaceInfoProto.softwareVersion)
  return softwareversion_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* NamespaceInfoProto::release_softwareversion() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.NamespaceInfoProto.softwareVersion)
  if (!has_softwareversion()) {
    return NULL;
  }
  clear_has_softwareversion();
  return softwareversion_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void NamespaceInfoProto::set_allocated_softwareversion(::std::string* softwareversion) {
  if (softwareversion != NULL) {
    set_has_softwareversion();
  } else {
    clear_has_softwareversion();
  }
  softwareversion_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), softwareversion);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.NamespaceInfoProto.softwareVersion)
}

// optional uint64 capabilities = 6 [default = 0];
inline bool NamespaceInfoProto::has_capabilities() const {
  return (_has_bits_[0] & 0x00000040u) != 0;
}
inline void NamespaceInfoProto::set_has_capabilities() {
  _has_bits_[0] |= 0x00000040u;
}
inline void NamespaceInfoProto::clear_has_capabilities() {
  _has_bits_[0] &= ~0x00000040u;
}
inline void NamespaceInfoProto::clear_capabilities() {
  capabilities_ = GOOGLE_ULONGLONG(0);
  clear_has_capabilities();
}
inline ::google::protobuf::uint64 NamespaceInfoProto::capabilities() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.NamespaceInfoProto.capabilities)
  return capabilities_;
}
inline void NamespaceInfoProto::set_capabilities(::google::protobuf::uint64 value) {
  set_has_capabilities();
  capabilities_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.NamespaceInfoProto.capabilities)
}

// optional .hadoop.hdfs.NNHAStatusHeartbeatProto.State state = 7;
inline bool NamespaceInfoProto::has_state() const {
  return (_has_bits_[0] & 0x00000020u) != 0;
}
inline void NamespaceInfoProto::set_has_state() {
  _has_bits_[0] |= 0x00000020u;
}
inline void NamespaceInfoProto::clear_has_state() {
  _has_bits_[0] &= ~0x00000020u;
}
inline void NamespaceInfoProto::clear_state() {
  state_ = 0;
  clear_has_state();
}
inline ::hadoop::hdfs::NNHAStatusHeartbeatProto_State NamespaceInfoProto::state() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.NamespaceInfoProto.state)
  return static_cast< ::hadoop::hdfs::NNHAStatusHeartbeatProto_State >(state_);
}
inline void NamespaceInfoProto::set_state(::hadoop::hdfs::NNHAStatusHeartbeatProto_State value) {
  assert(::hadoop::hdfs::NNHAStatusHeartbeatProto_State_IsValid(value));
  set_has_state();
  state_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.NamespaceInfoProto.state)
}

// -------------------------------------------------------------------

// RecoveringBlockProto

// required uint64 newGenStamp = 1;
inline bool RecoveringBlockProto::has_newgenstamp() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void RecoveringBlockProto::set_has_newgenstamp() {
  _has_bits_[0] |= 0x00000010u;
}
inline void RecoveringBlockProto::clear_has_newgenstamp() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void RecoveringBlockProto::clear_newgenstamp() {
  newgenstamp_ = GOOGLE_ULONGLONG(0);
  clear_has_newgenstamp();
}
inline ::google::protobuf::uint64 RecoveringBlockProto::newgenstamp() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.RecoveringBlockProto.newGenStamp)
  return newgenstamp_;
}
inline void RecoveringBlockProto::set_newgenstamp(::google::protobuf::uint64 value) {
  set_has_newgenstamp();
  newgenstamp_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.RecoveringBlockProto.newGenStamp)
}

// required .hadoop.hdfs.LocatedBlockProto block = 2;
inline bool RecoveringBlockProto::has_block() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void RecoveringBlockProto::set_has_block() {
  _has_bits_[0] |= 0x00000002u;
}
inline void RecoveringBlockProto::clear_has_block() {
  _has_bits_[0] &= ~0x00000002u;
}
inline const ::hadoop::hdfs::LocatedBlockProto& RecoveringBlockProto::_internal_block() const {
  return *block_;
}
inline const ::hadoop::hdfs::LocatedBlockProto& RecoveringBlockProto::block() const {
  const ::hadoop::hdfs::LocatedBlockProto* p = block_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.RecoveringBlockProto.block)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::LocatedBlockProto*>(
      &::hadoop::hdfs::_LocatedBlockProto_default_instance_);
}
inline ::hadoop::hdfs::LocatedBlockProto* RecoveringBlockProto::release_block() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.RecoveringBlockProto.block)
  clear_has_block();
  ::hadoop::hdfs::LocatedBlockProto* temp = block_;
  block_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::LocatedBlockProto* RecoveringBlockProto::mutable_block() {
  set_has_block();
  if (block_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::LocatedBlockProto>(GetArenaNoVirtual());
    block_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.RecoveringBlockProto.block)
  return block_;
}
inline void RecoveringBlockProto::set_allocated_block(::hadoop::hdfs::LocatedBlockProto* block) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete reinterpret_cast< ::google::protobuf::MessageLite*>(block_);
  }
  if (block) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      block = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, block, submessage_arena);
    }
    set_has_block();
  } else {
    clear_has_block();
  }
  block_ = block;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.RecoveringBlockProto.block)
}

// optional .hadoop.hdfs.BlockProto truncateBlock = 3;
inline bool RecoveringBlockProto::has_truncateblock() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void RecoveringBlockProto::set_has_truncateblock() {
  _has_bits_[0] |= 0x00000004u;
}
inline void RecoveringBlockProto::clear_has_truncateblock() {
  _has_bits_[0] &= ~0x00000004u;
}
inline const ::hadoop::hdfs::BlockProto& RecoveringBlockProto::_internal_truncateblock() const {
  return *truncateblock_;
}
inline const ::hadoop::hdfs::BlockProto& RecoveringBlockProto::truncateblock() const {
  const ::hadoop::hdfs::BlockProto* p = truncateblock_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.RecoveringBlockProto.truncateBlock)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::BlockProto*>(
      &::hadoop::hdfs::_BlockProto_default_instance_);
}
inline ::hadoop::hdfs::BlockProto* RecoveringBlockProto::release_truncateblock() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.RecoveringBlockProto.truncateBlock)
  clear_has_truncateblock();
  ::hadoop::hdfs::BlockProto* temp = truncateblock_;
  truncateblock_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::BlockProto* RecoveringBlockProto::mutable_truncateblock() {
  set_has_truncateblock();
  if (truncateblock_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::BlockProto>(GetArenaNoVirtual());
    truncateblock_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.RecoveringBlockProto.truncateBlock)
  return truncateblock_;
}
inline void RecoveringBlockProto::set_allocated_truncateblock(::hadoop::hdfs::BlockProto* truncateblock) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete reinterpret_cast< ::google::protobuf::MessageLite*>(truncateblock_);
  }
  if (truncateblock) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      truncateblock = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, truncateblock, submessage_arena);
    }
    set_has_truncateblock();
  } else {
    clear_has_truncateblock();
  }
  truncateblock_ = truncateblock;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.RecoveringBlockProto.truncateBlock)
}

// optional .hadoop.hdfs.ErasureCodingPolicyProto ecPolicy = 4;
inline bool RecoveringBlockProto::has_ecpolicy() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void RecoveringBlockProto::set_has_ecpolicy() {
  _has_bits_[0] |= 0x00000008u;
}
inline void RecoveringBlockProto::clear_has_ecpolicy() {
  _has_bits_[0] &= ~0x00000008u;
}
inline const ::hadoop::hdfs::ErasureCodingPolicyProto& RecoveringBlockProto::_internal_ecpolicy() const {
  return *ecpolicy_;
}
inline const ::hadoop::hdfs::ErasureCodingPolicyProto& RecoveringBlockProto::ecpolicy() const {
  const ::hadoop::hdfs::ErasureCodingPolicyProto* p = ecpolicy_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.RecoveringBlockProto.ecPolicy)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::ErasureCodingPolicyProto*>(
      &::hadoop::hdfs::_ErasureCodingPolicyProto_default_instance_);
}
inline ::hadoop::hdfs::ErasureCodingPolicyProto* RecoveringBlockProto::release_ecpolicy() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.RecoveringBlockProto.ecPolicy)
  clear_has_ecpolicy();
  ::hadoop::hdfs::ErasureCodingPolicyProto* temp = ecpolicy_;
  ecpolicy_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::ErasureCodingPolicyProto* RecoveringBlockProto::mutable_ecpolicy() {
  set_has_ecpolicy();
  if (ecpolicy_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::ErasureCodingPolicyProto>(GetArenaNoVirtual());
    ecpolicy_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.RecoveringBlockProto.ecPolicy)
  return ecpolicy_;
}
inline void RecoveringBlockProto::set_allocated_ecpolicy(::hadoop::hdfs::ErasureCodingPolicyProto* ecpolicy) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete reinterpret_cast< ::google::protobuf::MessageLite*>(ecpolicy_);
  }
  if (ecpolicy) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      ecpolicy = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, ecpolicy, submessage_arena);
    }
    set_has_ecpolicy();
  } else {
    clear_has_ecpolicy();
  }
  ecpolicy_ = ecpolicy;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.RecoveringBlockProto.ecPolicy)
}

// optional bytes blockIndices = 5;
inline bool RecoveringBlockProto::has_blockindices() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void RecoveringBlockProto::set_has_blockindices() {
  _has_bits_[0] |= 0x00000001u;
}
inline void RecoveringBlockProto::clear_has_blockindices() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void RecoveringBlockProto::clear_blockindices() {
  blockindices_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_blockindices();
}
inline const ::std::string& RecoveringBlockProto::blockindices() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.RecoveringBlockProto.blockIndices)
  return blockindices_.GetNoArena();
}
inline void RecoveringBlockProto::set_blockindices(const ::std::string& value) {
  set_has_blockindices();
  blockindices_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.RecoveringBlockProto.blockIndices)
}
#if LANG_CXX11
inline void RecoveringBlockProto::set_blockindices(::std::string&& value) {
  set_has_blockindices();
  blockindices_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.RecoveringBlockProto.blockIndices)
}
#endif
inline void RecoveringBlockProto::set_blockindices(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_blockindices();
  blockindices_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.RecoveringBlockProto.blockIndices)
}
inline void RecoveringBlockProto::set_blockindices(const void* value, size_t size) {
  set_has_blockindices();
  blockindices_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.RecoveringBlockProto.blockIndices)
}
inline ::std::string* RecoveringBlockProto::mutable_blockindices() {
  set_has_blockindices();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.RecoveringBlockProto.blockIndices)
  return blockindices_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* RecoveringBlockProto::release_blockindices() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.RecoveringBlockProto.blockIndices)
  if (!has_blockindices()) {
    return NULL;
  }
  clear_has_blockindices();
  return blockindices_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void RecoveringBlockProto::set_allocated_blockindices(::std::string* blockindices) {
  if (blockindices != NULL) {
    set_has_blockindices();
  } else {
    clear_has_blockindices();
  }
  blockindices_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), blockindices);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.RecoveringBlockProto.blockIndices)
}

// -------------------------------------------------------------------

// CheckpointSignatureProto

// required string blockPoolId = 1;
inline bool CheckpointSignatureProto::has_blockpoolid() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void CheckpointSignatureProto::set_has_blockpoolid() {
  _has_bits_[0] |= 0x00000001u;
}
inline void CheckpointSignatureProto::clear_has_blockpoolid() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void CheckpointSignatureProto::clear_blockpoolid() {
  blockpoolid_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_blockpoolid();
}
inline const ::std::string& CheckpointSignatureProto::blockpoolid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.CheckpointSignatureProto.blockPoolId)
  return blockpoolid_.GetNoArena();
}
inline void CheckpointSignatureProto::set_blockpoolid(const ::std::string& value) {
  set_has_blockpoolid();
  blockpoolid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.CheckpointSignatureProto.blockPoolId)
}
#if LANG_CXX11
inline void CheckpointSignatureProto::set_blockpoolid(::std::string&& value) {
  set_has_blockpoolid();
  blockpoolid_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.CheckpointSignatureProto.blockPoolId)
}
#endif
inline void CheckpointSignatureProto::set_blockpoolid(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_blockpoolid();
  blockpoolid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.CheckpointSignatureProto.blockPoolId)
}
inline void CheckpointSignatureProto::set_blockpoolid(const char* value, size_t size) {
  set_has_blockpoolid();
  blockpoolid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.CheckpointSignatureProto.blockPoolId)
}
inline ::std::string* CheckpointSignatureProto::mutable_blockpoolid() {
  set_has_blockpoolid();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.CheckpointSignatureProto.blockPoolId)
  return blockpoolid_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* CheckpointSignatureProto::release_blockpoolid() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.CheckpointSignatureProto.blockPoolId)
  if (!has_blockpoolid()) {
    return NULL;
  }
  clear_has_blockpoolid();
  return blockpoolid_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void CheckpointSignatureProto::set_allocated_blockpoolid(::std::string* blockpoolid) {
  if (blockpoolid != NULL) {
    set_has_blockpoolid();
  } else {
    clear_has_blockpoolid();
  }
  blockpoolid_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), blockpoolid);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.CheckpointSignatureProto.blockPoolId)
}

// required uint64 mostRecentCheckpointTxId = 2;
inline bool CheckpointSignatureProto::has_mostrecentcheckpointtxid() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void CheckpointSignatureProto::set_has_mostrecentcheckpointtxid() {
  _has_bits_[0] |= 0x00000004u;
}
inline void CheckpointSignatureProto::clear_has_mostrecentcheckpointtxid() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void CheckpointSignatureProto::clear_mostrecentcheckpointtxid() {
  mostrecentcheckpointtxid_ = GOOGLE_ULONGLONG(0);
  clear_has_mostrecentcheckpointtxid();
}
inline ::google::protobuf::uint64 CheckpointSignatureProto::mostrecentcheckpointtxid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.CheckpointSignatureProto.mostRecentCheckpointTxId)
  return mostrecentcheckpointtxid_;
}
inline void CheckpointSignatureProto::set_mostrecentcheckpointtxid(::google::protobuf::uint64 value) {
  set_has_mostrecentcheckpointtxid();
  mostrecentcheckpointtxid_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.CheckpointSignatureProto.mostRecentCheckpointTxId)
}

// required uint64 curSegmentTxId = 3;
inline bool CheckpointSignatureProto::has_cursegmenttxid() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void CheckpointSignatureProto::set_has_cursegmenttxid() {
  _has_bits_[0] |= 0x00000008u;
}
inline void CheckpointSignatureProto::clear_has_cursegmenttxid() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void CheckpointSignatureProto::clear_cursegmenttxid() {
  cursegmenttxid_ = GOOGLE_ULONGLONG(0);
  clear_has_cursegmenttxid();
}
inline ::google::protobuf::uint64 CheckpointSignatureProto::cursegmenttxid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.CheckpointSignatureProto.curSegmentTxId)
  return cursegmenttxid_;
}
inline void CheckpointSignatureProto::set_cursegmenttxid(::google::protobuf::uint64 value) {
  set_has_cursegmenttxid();
  cursegmenttxid_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.CheckpointSignatureProto.curSegmentTxId)
}

// required .hadoop.hdfs.StorageInfoProto storageInfo = 4;
inline bool CheckpointSignatureProto::has_storageinfo() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void CheckpointSignatureProto::set_has_storageinfo() {
  _has_bits_[0] |= 0x00000002u;
}
inline void CheckpointSignatureProto::clear_has_storageinfo() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void CheckpointSignatureProto::clear_storageinfo() {
  if (storageinfo_ != NULL) storageinfo_->Clear();
  clear_has_storageinfo();
}
inline const ::hadoop::hdfs::StorageInfoProto& CheckpointSignatureProto::_internal_storageinfo() const {
  return *storageinfo_;
}
inline const ::hadoop::hdfs::StorageInfoProto& CheckpointSignatureProto::storageinfo() const {
  const ::hadoop::hdfs::StorageInfoProto* p = storageinfo_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.CheckpointSignatureProto.storageInfo)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::StorageInfoProto*>(
      &::hadoop::hdfs::_StorageInfoProto_default_instance_);
}
inline ::hadoop::hdfs::StorageInfoProto* CheckpointSignatureProto::release_storageinfo() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.CheckpointSignatureProto.storageInfo)
  clear_has_storageinfo();
  ::hadoop::hdfs::StorageInfoProto* temp = storageinfo_;
  storageinfo_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::StorageInfoProto* CheckpointSignatureProto::mutable_storageinfo() {
  set_has_storageinfo();
  if (storageinfo_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::StorageInfoProto>(GetArenaNoVirtual());
    storageinfo_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.CheckpointSignatureProto.storageInfo)
  return storageinfo_;
}
inline void CheckpointSignatureProto::set_allocated_storageinfo(::hadoop::hdfs::StorageInfoProto* storageinfo) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete storageinfo_;
  }
  if (storageinfo) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      storageinfo = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, storageinfo, submessage_arena);
    }
    set_has_storageinfo();
  } else {
    clear_has_storageinfo();
  }
  storageinfo_ = storageinfo;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.CheckpointSignatureProto.storageInfo)
}

// -------------------------------------------------------------------

// CheckpointCommandProto

// required .hadoop.hdfs.CheckpointSignatureProto signature = 1;
inline bool CheckpointCommandProto::has_signature() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void CheckpointCommandProto::set_has_signature() {
  _has_bits_[0] |= 0x00000001u;
}
inline void CheckpointCommandProto::clear_has_signature() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void CheckpointCommandProto::clear_signature() {
  if (signature_ != NULL) signature_->Clear();
  clear_has_signature();
}
inline const ::hadoop::hdfs::CheckpointSignatureProto& CheckpointCommandProto::_internal_signature() const {
  return *signature_;
}
inline const ::hadoop::hdfs::CheckpointSignatureProto& CheckpointCommandProto::signature() const {
  const ::hadoop::hdfs::CheckpointSignatureProto* p = signature_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.CheckpointCommandProto.signature)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::CheckpointSignatureProto*>(
      &::hadoop::hdfs::_CheckpointSignatureProto_default_instance_);
}
inline ::hadoop::hdfs::CheckpointSignatureProto* CheckpointCommandProto::release_signature() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.CheckpointCommandProto.signature)
  clear_has_signature();
  ::hadoop::hdfs::CheckpointSignatureProto* temp = signature_;
  signature_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::CheckpointSignatureProto* CheckpointCommandProto::mutable_signature() {
  set_has_signature();
  if (signature_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::CheckpointSignatureProto>(GetArenaNoVirtual());
    signature_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.CheckpointCommandProto.signature)
  return signature_;
}
inline void CheckpointCommandProto::set_allocated_signature(::hadoop::hdfs::CheckpointSignatureProto* signature) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete signature_;
  }
  if (signature) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      signature = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, signature, submessage_arena);
    }
    set_has_signature();
  } else {
    clear_has_signature();
  }
  signature_ = signature;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.CheckpointCommandProto.signature)
}

// required bool needToReturnImage = 2;
inline bool CheckpointCommandProto::has_needtoreturnimage() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void CheckpointCommandProto::set_has_needtoreturnimage() {
  _has_bits_[0] |= 0x00000002u;
}
inline void CheckpointCommandProto::clear_has_needtoreturnimage() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void CheckpointCommandProto::clear_needtoreturnimage() {
  needtoreturnimage_ = false;
  clear_has_needtoreturnimage();
}
inline bool CheckpointCommandProto::needtoreturnimage() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.CheckpointCommandProto.needToReturnImage)
  return needtoreturnimage_;
}
inline void CheckpointCommandProto::set_needtoreturnimage(bool value) {
  set_has_needtoreturnimage();
  needtoreturnimage_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.CheckpointCommandProto.needToReturnImage)
}

// -------------------------------------------------------------------

// NamenodeCommandProto

// required uint32 action = 1;
inline bool NamenodeCommandProto::has_action() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void NamenodeCommandProto::set_has_action() {
  _has_bits_[0] |= 0x00000002u;
}
inline void NamenodeCommandProto::clear_has_action() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void NamenodeCommandProto::clear_action() {
  action_ = 0u;
  clear_has_action();
}
inline ::google::protobuf::uint32 NamenodeCommandProto::action() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.NamenodeCommandProto.action)
  return action_;
}
inline void NamenodeCommandProto::set_action(::google::protobuf::uint32 value) {
  set_has_action();
  action_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.NamenodeCommandProto.action)
}

// required .hadoop.hdfs.NamenodeCommandProto.Type type = 2;
inline bool NamenodeCommandProto::has_type() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void NamenodeCommandProto::set_has_type() {
  _has_bits_[0] |= 0x00000004u;
}
inline void NamenodeCommandProto::clear_has_type() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void NamenodeCommandProto::clear_type() {
  type_ = 0;
  clear_has_type();
}
inline ::hadoop::hdfs::NamenodeCommandProto_Type NamenodeCommandProto::type() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.NamenodeCommandProto.type)
  return static_cast< ::hadoop::hdfs::NamenodeCommandProto_Type >(type_);
}
inline void NamenodeCommandProto::set_type(::hadoop::hdfs::NamenodeCommandProto_Type value) {
  assert(::hadoop::hdfs::NamenodeCommandProto_Type_IsValid(value));
  set_has_type();
  type_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.NamenodeCommandProto.type)
}

// optional .hadoop.hdfs.CheckpointCommandProto checkpointCmd = 3;
inline bool NamenodeCommandProto::has_checkpointcmd() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void NamenodeCommandProto::set_has_checkpointcmd() {
  _has_bits_[0] |= 0x00000001u;
}
inline void NamenodeCommandProto::clear_has_checkpointcmd() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void NamenodeCommandProto::clear_checkpointcmd() {
  if (checkpointcmd_ != NULL) checkpointcmd_->Clear();
  clear_has_checkpointcmd();
}
inline const ::hadoop::hdfs::CheckpointCommandProto& NamenodeCommandProto::_internal_checkpointcmd() const {
  return *checkpointcmd_;
}
inline const ::hadoop::hdfs::CheckpointCommandProto& NamenodeCommandProto::checkpointcmd() const {
  const ::hadoop::hdfs::CheckpointCommandProto* p = checkpointcmd_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.NamenodeCommandProto.checkpointCmd)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::CheckpointCommandProto*>(
      &::hadoop::hdfs::_CheckpointCommandProto_default_instance_);
}
inline ::hadoop::hdfs::CheckpointCommandProto* NamenodeCommandProto::release_checkpointcmd() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.NamenodeCommandProto.checkpointCmd)
  clear_has_checkpointcmd();
  ::hadoop::hdfs::CheckpointCommandProto* temp = checkpointcmd_;
  checkpointcmd_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::CheckpointCommandProto* NamenodeCommandProto::mutable_checkpointcmd() {
  set_has_checkpointcmd();
  if (checkpointcmd_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::CheckpointCommandProto>(GetArenaNoVirtual());
    checkpointcmd_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.NamenodeCommandProto.checkpointCmd)
  return checkpointcmd_;
}
inline void NamenodeCommandProto::set_allocated_checkpointcmd(::hadoop::hdfs::CheckpointCommandProto* checkpointcmd) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete checkpointcmd_;
  }
  if (checkpointcmd) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      checkpointcmd = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, checkpointcmd, submessage_arena);
    }
    set_has_checkpointcmd();
  } else {
    clear_has_checkpointcmd();
  }
  checkpointcmd_ = checkpointcmd;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.NamenodeCommandProto.checkpointCmd)
}

// -------------------------------------------------------------------

// VersionRequestProto

// -------------------------------------------------------------------

// VersionResponseProto

// required .hadoop.hdfs.NamespaceInfoProto info = 1;
inline bool VersionResponseProto::has_info() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void VersionResponseProto::set_has_info() {
  _has_bits_[0] |= 0x00000001u;
}
inline void VersionResponseProto::clear_has_info() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void VersionResponseProto::clear_info() {
  if (info_ != NULL) info_->Clear();
  clear_has_info();
}
inline const ::hadoop::hdfs::NamespaceInfoProto& VersionResponseProto::_internal_info() const {
  return *info_;
}
inline const ::hadoop::hdfs::NamespaceInfoProto& VersionResponseProto::info() const {
  const ::hadoop::hdfs::NamespaceInfoProto* p = info_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.VersionResponseProto.info)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::NamespaceInfoProto*>(
      &::hadoop::hdfs::_NamespaceInfoProto_default_instance_);
}
inline ::hadoop::hdfs::NamespaceInfoProto* VersionResponseProto::release_info() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.VersionResponseProto.info)
  clear_has_info();
  ::hadoop::hdfs::NamespaceInfoProto* temp = info_;
  info_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::NamespaceInfoProto* VersionResponseProto::mutable_info() {
  set_has_info();
  if (info_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::NamespaceInfoProto>(GetArenaNoVirtual());
    info_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.VersionResponseProto.info)
  return info_;
}
inline void VersionResponseProto::set_allocated_info(::hadoop::hdfs::NamespaceInfoProto* info) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete info_;
  }
  if (info) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      info = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, info, submessage_arena);
    }
    set_has_info();
  } else {
    clear_has_info();
  }
  info_ = info;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.VersionResponseProto.info)
}

// -------------------------------------------------------------------

// StorageInfoProto

// required uint32 layoutVersion = 1;
inline bool StorageInfoProto::has_layoutversion() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void StorageInfoProto::set_has_layoutversion() {
  _has_bits_[0] |= 0x00000002u;
}
inline void StorageInfoProto::clear_has_layoutversion() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void StorageInfoProto::clear_layoutversion() {
  layoutversion_ = 0u;
  clear_has_layoutversion();
}
inline ::google::protobuf::uint32 StorageInfoProto::layoutversion() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.StorageInfoProto.layoutVersion)
  return layoutversion_;
}
inline void StorageInfoProto::set_layoutversion(::google::protobuf::uint32 value) {
  set_has_layoutversion();
  layoutversion_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.StorageInfoProto.layoutVersion)
}

// required uint32 namespceID = 2;
inline bool StorageInfoProto::has_namespceid() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void StorageInfoProto::set_has_namespceid() {
  _has_bits_[0] |= 0x00000004u;
}
inline void StorageInfoProto::clear_has_namespceid() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void StorageInfoProto::clear_namespceid() {
  namespceid_ = 0u;
  clear_has_namespceid();
}
inline ::google::protobuf::uint32 StorageInfoProto::namespceid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.StorageInfoProto.namespceID)
  return namespceid_;
}
inline void StorageInfoProto::set_namespceid(::google::protobuf::uint32 value) {
  set_has_namespceid();
  namespceid_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.StorageInfoProto.namespceID)
}

// required string clusterID = 3;
inline bool StorageInfoProto::has_clusterid() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void StorageInfoProto::set_has_clusterid() {
  _has_bits_[0] |= 0x00000001u;
}
inline void StorageInfoProto::clear_has_clusterid() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void StorageInfoProto::clear_clusterid() {
  clusterid_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_clusterid();
}
inline const ::std::string& StorageInfoProto::clusterid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.StorageInfoProto.clusterID)
  return clusterid_.GetNoArena();
}
inline void StorageInfoProto::set_clusterid(const ::std::string& value) {
  set_has_clusterid();
  clusterid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.StorageInfoProto.clusterID)
}
#if LANG_CXX11
inline void StorageInfoProto::set_clusterid(::std::string&& value) {
  set_has_clusterid();
  clusterid_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.StorageInfoProto.clusterID)
}
#endif
inline void StorageInfoProto::set_clusterid(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_clusterid();
  clusterid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.StorageInfoProto.clusterID)
}
inline void StorageInfoProto::set_clusterid(const char* value, size_t size) {
  set_has_clusterid();
  clusterid_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.StorageInfoProto.clusterID)
}
inline ::std::string* StorageInfoProto::mutable_clusterid() {
  set_has_clusterid();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.StorageInfoProto.clusterID)
  return clusterid_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* StorageInfoProto::release_clusterid() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.StorageInfoProto.clusterID)
  if (!has_clusterid()) {
    return NULL;
  }
  clear_has_clusterid();
  return clusterid_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void StorageInfoProto::set_allocated_clusterid(::std::string* clusterid) {
  if (clusterid != NULL) {
    set_has_clusterid();
  } else {
    clear_has_clusterid();
  }
  clusterid_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), clusterid);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.StorageInfoProto.clusterID)
}

// required uint64 cTime = 4;
inline bool StorageInfoProto::has_ctime() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void StorageInfoProto::set_has_ctime() {
  _has_bits_[0] |= 0x00000008u;
}
inline void StorageInfoProto::clear_has_ctime() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void StorageInfoProto::clear_ctime() {
  ctime_ = GOOGLE_ULONGLONG(0);
  clear_has_ctime();
}
inline ::google::protobuf::uint64 StorageInfoProto::ctime() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.StorageInfoProto.cTime)
  return ctime_;
}
inline void StorageInfoProto::set_ctime(::google::protobuf::uint64 value) {
  set_has_ctime();
  ctime_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.StorageInfoProto.cTime)
}

// -------------------------------------------------------------------

// NamenodeRegistrationProto

// required string rpcAddress = 1;
inline bool NamenodeRegistrationProto::has_rpcaddress() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void NamenodeRegistrationProto::set_has_rpcaddress() {
  _has_bits_[0] |= 0x00000001u;
}
inline void NamenodeRegistrationProto::clear_has_rpcaddress() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void NamenodeRegistrationProto::clear_rpcaddress() {
  rpcaddress_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_rpcaddress();
}
inline const ::std::string& NamenodeRegistrationProto::rpcaddress() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.NamenodeRegistrationProto.rpcAddress)
  return rpcaddress_.GetNoArena();
}
inline void NamenodeRegistrationProto::set_rpcaddress(const ::std::string& value) {
  set_has_rpcaddress();
  rpcaddress_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.NamenodeRegistrationProto.rpcAddress)
}
#if LANG_CXX11
inline void NamenodeRegistrationProto::set_rpcaddress(::std::string&& value) {
  set_has_rpcaddress();
  rpcaddress_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.NamenodeRegistrationProto.rpcAddress)
}
#endif
inline void NamenodeRegistrationProto::set_rpcaddress(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_rpcaddress();
  rpcaddress_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.NamenodeRegistrationProto.rpcAddress)
}
inline void NamenodeRegistrationProto::set_rpcaddress(const char* value, size_t size) {
  set_has_rpcaddress();
  rpcaddress_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.NamenodeRegistrationProto.rpcAddress)
}
inline ::std::string* NamenodeRegistrationProto::mutable_rpcaddress() {
  set_has_rpcaddress();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.NamenodeRegistrationProto.rpcAddress)
  return rpcaddress_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* NamenodeRegistrationProto::release_rpcaddress() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.NamenodeRegistrationProto.rpcAddress)
  if (!has_rpcaddress()) {
    return NULL;
  }
  clear_has_rpcaddress();
  return rpcaddress_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void NamenodeRegistrationProto::set_allocated_rpcaddress(::std::string* rpcaddress) {
  if (rpcaddress != NULL) {
    set_has_rpcaddress();
  } else {
    clear_has_rpcaddress();
  }
  rpcaddress_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), rpcaddress);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.NamenodeRegistrationProto.rpcAddress)
}

// required string httpAddress = 2;
inline bool NamenodeRegistrationProto::has_httpaddress() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void NamenodeRegistrationProto::set_has_httpaddress() {
  _has_bits_[0] |= 0x00000002u;
}
inline void NamenodeRegistrationProto::clear_has_httpaddress() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void NamenodeRegistrationProto::clear_httpaddress() {
  httpaddress_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_httpaddress();
}
inline const ::std::string& NamenodeRegistrationProto::httpaddress() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.NamenodeRegistrationProto.httpAddress)
  return httpaddress_.GetNoArena();
}
inline void NamenodeRegistrationProto::set_httpaddress(const ::std::string& value) {
  set_has_httpaddress();
  httpaddress_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:hadoop.hdfs.NamenodeRegistrationProto.httpAddress)
}
#if LANG_CXX11
inline void NamenodeRegistrationProto::set_httpaddress(::std::string&& value) {
  set_has_httpaddress();
  httpaddress_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:hadoop.hdfs.NamenodeRegistrationProto.httpAddress)
}
#endif
inline void NamenodeRegistrationProto::set_httpaddress(const char* value) {
  GOOGLE_DCHECK(value != NULL);
  set_has_httpaddress();
  httpaddress_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:hadoop.hdfs.NamenodeRegistrationProto.httpAddress)
}
inline void NamenodeRegistrationProto::set_httpaddress(const char* value, size_t size) {
  set_has_httpaddress();
  httpaddress_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:hadoop.hdfs.NamenodeRegistrationProto.httpAddress)
}
inline ::std::string* NamenodeRegistrationProto::mutable_httpaddress() {
  set_has_httpaddress();
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.NamenodeRegistrationProto.httpAddress)
  return httpaddress_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline ::std::string* NamenodeRegistrationProto::release_httpaddress() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.NamenodeRegistrationProto.httpAddress)
  if (!has_httpaddress()) {
    return NULL;
  }
  clear_has_httpaddress();
  return httpaddress_.ReleaseNonDefaultNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
inline void NamenodeRegistrationProto::set_allocated_httpaddress(::std::string* httpaddress) {
  if (httpaddress != NULL) {
    set_has_httpaddress();
  } else {
    clear_has_httpaddress();
  }
  httpaddress_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), httpaddress);
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.NamenodeRegistrationProto.httpAddress)
}

// required .hadoop.hdfs.StorageInfoProto storageInfo = 3;
inline bool NamenodeRegistrationProto::has_storageinfo() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void NamenodeRegistrationProto::set_has_storageinfo() {
  _has_bits_[0] |= 0x00000004u;
}
inline void NamenodeRegistrationProto::clear_has_storageinfo() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void NamenodeRegistrationProto::clear_storageinfo() {
  if (storageinfo_ != NULL) storageinfo_->Clear();
  clear_has_storageinfo();
}
inline const ::hadoop::hdfs::StorageInfoProto& NamenodeRegistrationProto::_internal_storageinfo() const {
  return *storageinfo_;
}
inline const ::hadoop::hdfs::StorageInfoProto& NamenodeRegistrationProto::storageinfo() const {
  const ::hadoop::hdfs::StorageInfoProto* p = storageinfo_;
  // @@protoc_insertion_point(field_get:hadoop.hdfs.NamenodeRegistrationProto.storageInfo)
  return p != NULL ? *p : *reinterpret_cast<const ::hadoop::hdfs::StorageInfoProto*>(
      &::hadoop::hdfs::_StorageInfoProto_default_instance_);
}
inline ::hadoop::hdfs::StorageInfoProto* NamenodeRegistrationProto::release_storageinfo() {
  // @@protoc_insertion_point(field_release:hadoop.hdfs.NamenodeRegistrationProto.storageInfo)
  clear_has_storageinfo();
  ::hadoop::hdfs::StorageInfoProto* temp = storageinfo_;
  storageinfo_ = NULL;
  return temp;
}
inline ::hadoop::hdfs::StorageInfoProto* NamenodeRegistrationProto::mutable_storageinfo() {
  set_has_storageinfo();
  if (storageinfo_ == NULL) {
    auto* p = CreateMaybeMessage<::hadoop::hdfs::StorageInfoProto>(GetArenaNoVirtual());
    storageinfo_ = p;
  }
  // @@protoc_insertion_point(field_mutable:hadoop.hdfs.NamenodeRegistrationProto.storageInfo)
  return storageinfo_;
}
inline void NamenodeRegistrationProto::set_allocated_storageinfo(::hadoop::hdfs::StorageInfoProto* storageinfo) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete storageinfo_;
  }
  if (storageinfo) {
    ::google::protobuf::Arena* submessage_arena = NULL;
    if (message_arena != submessage_arena) {
      storageinfo = ::google::protobuf::internal::GetOwnedMessage(
          message_arena, storageinfo, submessage_arena);
    }
    set_has_storageinfo();
  } else {
    clear_has_storageinfo();
  }
  storageinfo_ = storageinfo;
  // @@protoc_insertion_point(field_set_allocated:hadoop.hdfs.NamenodeRegistrationProto.storageInfo)
}

// optional .hadoop.hdfs.NamenodeRegistrationProto.NamenodeRoleProto role = 4 [default = NAMENODE];
inline bool NamenodeRegistrationProto::has_role() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void NamenodeRegistrationProto::set_has_role() {
  _has_bits_[0] |= 0x00000008u;
}
inline void NamenodeRegistrationProto::clear_has_role() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void NamenodeRegistrationProto::clear_role() {
  role_ = 1;
  clear_has_role();
}
inline ::hadoop::hdfs::NamenodeRegistrationProto_NamenodeRoleProto NamenodeRegistrationProto::role() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.NamenodeRegistrationProto.role)
  return static_cast< ::hadoop::hdfs::NamenodeRegistrationProto_NamenodeRoleProto >(role_);
}
inline void NamenodeRegistrationProto::set_role(::hadoop::hdfs::NamenodeRegistrationProto_NamenodeRoleProto value) {
  assert(::hadoop::hdfs::NamenodeRegistrationProto_NamenodeRoleProto_IsValid(value));
  set_has_role();
  role_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.NamenodeRegistrationProto.role)
}

// -------------------------------------------------------------------

// NNHAStatusHeartbeatProto

// required .hadoop.hdfs.NNHAStatusHeartbeatProto.State state = 1;
inline bool NNHAStatusHeartbeatProto::has_state() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void NNHAStatusHeartbeatProto::set_has_state() {
  _has_bits_[0] |= 0x00000002u;
}
inline void NNHAStatusHeartbeatProto::clear_has_state() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void NNHAStatusHeartbeatProto::clear_state() {
  state_ = 0;
  clear_has_state();
}
inline ::hadoop::hdfs::NNHAStatusHeartbeatProto_State NNHAStatusHeartbeatProto::state() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.NNHAStatusHeartbeatProto.state)
  return static_cast< ::hadoop::hdfs::NNHAStatusHeartbeatProto_State >(state_);
}
inline void NNHAStatusHeartbeatProto::set_state(::hadoop::hdfs::NNHAStatusHeartbeatProto_State value) {
  assert(::hadoop::hdfs::NNHAStatusHeartbeatProto_State_IsValid(value));
  set_has_state();
  state_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.NNHAStatusHeartbeatProto.state)
}

// required uint64 txid = 2;
inline bool NNHAStatusHeartbeatProto::has_txid() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void NNHAStatusHeartbeatProto::set_has_txid() {
  _has_bits_[0] |= 0x00000001u;
}
inline void NNHAStatusHeartbeatProto::clear_has_txid() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void NNHAStatusHeartbeatProto::clear_txid() {
  txid_ = GOOGLE_ULONGLONG(0);
  clear_has_txid();
}
inline ::google::protobuf::uint64 NNHAStatusHeartbeatProto::txid() const {
  // @@protoc_insertion_point(field_get:hadoop.hdfs.NNHAStatusHeartbeatProto.txid)
  return txid_;
}
inline void NNHAStatusHeartbeatProto::set_txid(::google::protobuf::uint64 value) {
  set_has_txid();
  txid_ = value;
  // @@protoc_insertion_point(field_set:hadoop.hdfs.NNHAStatusHeartbeatProto.txid)
}

#ifdef __GNUC__
  #pragma GCC diagnostic pop
#endif  // __GNUC__
// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------

// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

}  // namespace hdfs
}  // namespace hadoop

namespace google {
namespace protobuf {

template <> struct is_proto_enum< ::hadoop::hdfs::NamenodeCommandProto_Type> : ::std::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::hdfs::NamenodeCommandProto_Type>() {
  return ::hadoop::hdfs::NamenodeCommandProto_Type_descriptor();
}
template <> struct is_proto_enum< ::hadoop::hdfs::NamenodeRegistrationProto_NamenodeRoleProto> : ::std::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::hdfs::NamenodeRegistrationProto_NamenodeRoleProto>() {
  return ::hadoop::hdfs::NamenodeRegistrationProto_NamenodeRoleProto_descriptor();
}
template <> struct is_proto_enum< ::hadoop::hdfs::NNHAStatusHeartbeatProto_State> : ::std::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::hdfs::NNHAStatusHeartbeatProto_State>() {
  return ::hadoop::hdfs::NNHAStatusHeartbeatProto_State_descriptor();
}
template <> struct is_proto_enum< ::hadoop::hdfs::ReplicaStateProto> : ::std::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::hadoop::hdfs::ReplicaStateProto>() {
  return ::hadoop::hdfs::ReplicaStateProto_descriptor();
}

}  // namespace protobuf
}  // namespace google

// @@protoc_insertion_point(global_scope)

#endif  // PROTOBUF_INCLUDED_HdfsServer_2eproto
